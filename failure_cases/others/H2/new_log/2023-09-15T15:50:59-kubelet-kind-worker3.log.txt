Sep 15 20:47:44 kind-worker3 kubelet[589656]: I0915 20:47:44.524514  589656 reflector.go:219] Starting reflector *v1.ConfigMap (0s) from object-"default"/"kube-root-ca.crt"
Sep 15 20:47:44 kind-worker3 kubelet[589656]: I0915 20:47:44.524565  589656 reflector.go:255] Listing and watching *v1.ConfigMap from object-"default"/"kube-root-ca.crt"
Sep 15 20:47:44 kind-worker3 kubelet[589656]: I0915 20:47:44.542533  589656 qos_container_manager_linux.go:379] "Updated QoS cgroup configuration"
Sep 15 20:47:44 kind-worker3 kubelet[589656]: I0915 20:47:44.554291  589656 factory.go:262] Factory "containerd" was unable to handle container "/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-pod9950f637_3ce8_428f_a136_02b68a154d8f.slice"
Sep 15 20:47:44 kind-worker3 kubelet[589656]: I0915 20:47:44.554337  589656 factory.go:262] Factory "systemd" was unable to handle container "/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-pod9950f637_3ce8_428f_a136_02b68a154d8f.slice"
Sep 15 20:47:44 kind-worker3 kubelet[589656]: I0915 20:47:44.554362  589656 factory.go:258] Using factory "raw" for container "/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-pod9950f637_3ce8_428f_a136_02b68a154d8f.slice"
Sep 15 20:47:44 kind-worker3 kubelet[589656]: I0915 20:47:44.555140  589656 manager.go:988] Added container: "/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-pod9950f637_3ce8_428f_a136_02b68a154d8f.slice" (aliases: [], namespace: "")
Sep 15 20:47:44 kind-worker3 kubelet[589656]: I0915 20:47:44.555676  589656 handler.go:325] Added event &{/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-pod9950f637_3ce8_428f_a136_02b68a154d8f.slice 2023-09-15 20:47:44.547183673 +0000 UTC containerCreation {<nil>}}
Sep 15 20:47:44 kind-worker3 kubelet[589656]: I0915 20:47:44.555767  589656 container.go:530] Start housekeeping for container "/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-pod9950f637_3ce8_428f_a136_02b68a154d8f.slice"
Sep 15 20:47:44 kind-worker3 kubelet[589656]: I0915 20:47:44.562345  589656 volume_manager.go:404] "Waiting for volumes to attach and mount for pod" pod="default/nginx-deployment-66f58bff7c-n8ncw"
Sep 15 20:47:44 kind-worker3 kubelet[589656]: I0915 20:47:44.585670  589656 desired_state_of_world_populator.go:309] "Added volume to desired state" pod="default/nginx-deployment-66f58bff7c-n8ncw" volumeName="kube-api-access-5c8xs" volumeSpecName="kube-api-access-5c8xs"
Sep 15 20:47:44 kind-worker3 kubelet[589656]: I0915 20:47:44.602761  589656 reconciler.go:342] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-5c8xs\" (UniqueName: \"kubernetes.io/projected/9950f637-3ce8-428f-a136-02b68a154d8f-kube-api-access-5c8xs\") pod \"nginx-deployment-66f58bff7c-n8ncw\" (UID: \"9950f637-3ce8-428f-a136-02b68a154d8f\") " pod="default/nginx-deployment-66f58bff7c-n8ncw"
Sep 15 20:47:44 kind-worker3 kubelet[589656]: I0915 20:47:44.692604  589656 status_manager.go:685] "Patch status for pod" pod="default/nginx-deployment-66f58bff7c-n8ncw" patch="{\"metadata\":{\"uid\":\"9950f637-3ce8-428f-a136-02b68a154d8f\"},\"status\":{\"$setElementOrder/conditions\":[{\"type\":\"Initialized\"},{\"type\":\"Ready\"},{\"type\":\"ContainersReady\"},{\"type\":\"PodScheduled\"}],\"conditions\":[{\"lastProbeTime\":null,\"lastTransitionTime\":\"2023-09-15T20:47:44Z\",\"status\":\"True\",\"type\":\"Initialized\"},{\"lastProbeTime\":null,\"lastTransitionTime\":\"2023-09-15T20:47:44Z\",\"message\":\"containers with unready status: [nginx]\",\"reason\":\"ContainersNotReady\",\"status\":\"False\",\"type\":\"Ready\"},{\"lastProbeTime\":null,\"lastTransitionTime\":\"2023-09-15T20:47:44Z\",\"message\":\"containers with unready status: [nginx]\",\"reason\":\"ContainersNotReady\",\"status\":\"False\",\"type\":\"ContainersReady\"}],\"containerStatuses\":[{\"image\":\"nginx:1.14.2\",\"imageID\":\"\",\"lastState\":{},\"name\":\"nginx\",\"ready\":false,\"restartCount\":0,\"started\":false,\"state\":{\"waiting\":{\"reason\":\"ContainerCreating\"}}}],\"hostIP\":\"172.18.0.4\",\"startTime\":\"2023-09-15T20:47:44Z\"}}"
Sep 15 20:47:44 kind-worker3 kubelet[589656]: I0915 20:47:44.692636  589656 config.go:279] "Setting pods for source" source="api"
Sep 15 20:47:44 kind-worker3 kubelet[589656]: I0915 20:47:44.692841  589656 status_manager.go:694] "Status for pod updated successfully" pod="default/nginx-deployment-66f58bff7c-n8ncw" statusVersion=1 status={Phase:Pending Conditions:[{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-09-15 20:47:44 +0000 UTC Reason: Message:} {Type:Ready Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-09-15 20:47:44 +0000 UTC Reason:ContainersNotReady Message:containers with unready status: [nginx]} {Type:ContainersReady Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-09-15 20:47:44 +0000 UTC Reason:ContainersNotReady Message:containers with unready status: [nginx]} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-09-15 20:47:44 +0000 UTC Reason: Message:}] Message: Reason: NominatedNodeName: HostIP:172.18.0.4 PodIP: PodIPs:[] StartTime:2023-09-15 20:47:44 +0000 UTC InitContainerStatuses:[] ContainerStatuses:[{Name:nginx State:{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,} Running:nil Terminated:nil} LastTerminationState:{Waiting:nil Running:nil Terminated:nil} Ready:false RestartCount:0 Image:nginx:1.14.2 ImageID: ContainerID: Started:0xc0010c63b9}] QOSClass:Burstable EphemeralContainerStatuses:[]}
Sep 15 20:47:44 kind-worker3 kubelet[589656]: I0915 20:47:44.693014  589656 kubelet.go:2085] "SyncLoop RECONCILE" source="api" pods=[default/nginx-deployment-66f58bff7c-n8ncw]
Sep 15 20:47:44 kind-worker3 kubelet[589656]: I0915 20:47:44.703697  589656 reconciler.go:243] "Starting operationExecutor.MountVolume for volume \"kube-api-access-5c8xs\" (UniqueName: \"kubernetes.io/projected/9950f637-3ce8-428f-a136-02b68a154d8f-kube-api-access-5c8xs\") pod \"nginx-deployment-66f58bff7c-n8ncw\" (UID: \"9950f637-3ce8-428f-a136-02b68a154d8f\") " pod="default/nginx-deployment-66f58bff7c-n8ncw"
Sep 15 20:47:44 kind-worker3 kubelet[589656]: I0915 20:47:44.703833  589656 reconciler.go:254] "operationExecutor.MountVolume started for volume \"kube-api-access-5c8xs\" (UniqueName: \"kubernetes.io/projected/9950f637-3ce8-428f-a136-02b68a154d8f-kube-api-access-5c8xs\") pod \"nginx-deployment-66f58bff7c-n8ncw\" (UID: \"9950f637-3ce8-428f-a136-02b68a154d8f\") " pod="default/nginx-deployment-66f58bff7c-n8ncw"
Sep 15 20:47:44 kind-worker3 kubelet[589656]: I0915 20:47:44.703935  589656 projected.go:183] Setting up volume kube-api-access-5c8xs for pod 9950f637-3ce8-428f-a136-02b68a154d8f at /var/lib/kubelet/pods/9950f637-3ce8-428f-a136-02b68a154d8f/volumes/kubernetes.io~projected/kube-api-access-5c8xs
Sep 15 20:47:44 kind-worker3 kubelet[589656]: I0915 20:47:44.739177  589656 empty_dir_linux.go:99] Statfs_t of /var/lib/kubelet/pods/9950f637-3ce8-428f-a136-02b68a154d8f/volumes/kubernetes.io~projected/kube-api-access-5c8xs: {Type:61267 Bsize:4096 Blocks:12835448 Bfree:2603905 Bavail:1944475 Files:3276800 Ffree:2345779 Fsid:{Val:[-2136087178 982747248]} Namelen:255 Frsize:4096 Flags:4128 Spare:[0 0 0 0]}
Sep 15 20:47:44 kind-worker3 kubelet[589656]: I0915 20:47:44.739263  589656 empty_dir.go:334] pod 9950f637-3ce8-428f-a136-02b68a154d8f: mounting tmpfs for volume wrapped_kube-api-access-5c8xs
Sep 15 20:47:44 kind-worker3 kubelet[589656]: I0915 20:47:44.739327  589656 mount_linux.go:183] Mounting cmd (mount) with arguments (-t tmpfs -o size=8362762240 tmpfs /var/lib/kubelet/pods/9950f637-3ce8-428f-a136-02b68a154d8f/volumes/kubernetes.io~projected/kube-api-access-5c8xs)
Sep 15 20:47:44 kind-worker3 kubelet[589656]: I0915 20:47:44.755792  589656 atomic_writer.go:181] pod default/nginx-deployment-66f58bff7c-n8ncw volume kube-api-access-5c8xs: performed write of new data to ts data directory: /var/lib/kubelet/pods/9950f637-3ce8-428f-a136-02b68a154d8f/volumes/kubernetes.io~projected/kube-api-access-5c8xs/..2023_09_15_20_47_44.1428062196
Sep 15 20:47:44 kind-worker3 kubelet[589656]: I0915 20:47:44.756428  589656 operation_generator.go:703] "MountVolume.SetUp succeeded for volume \"kube-api-access-5c8xs\" (UniqueName: \"kubernetes.io/projected/9950f637-3ce8-428f-a136-02b68a154d8f-kube-api-access-5c8xs\") pod \"nginx-deployment-66f58bff7c-n8ncw\" (UID: \"9950f637-3ce8-428f-a136-02b68a154d8f\") " pod="default/nginx-deployment-66f58bff7c-n8ncw"
Sep 15 20:47:44 kind-worker3 kubelet[589656]: I0915 20:47:44.863572  589656 volume_manager.go:435] "All volumes are attached and mounted for pod" pod="default/nginx-deployment-66f58bff7c-n8ncw"
Sep 15 20:47:44 kind-worker3 kubelet[589656]: I0915 20:47:44.863660  589656 kuberuntime_manager.go:469] "No sandbox for pod can be found. Need to start a new one" pod="default/nginx-deployment-66f58bff7c-n8ncw"
Sep 15 20:47:44 kind-worker3 kubelet[589656]: I0915 20:47:44.863747  589656 kuberuntime_manager.go:714] "computePodActions got for pod" podActions={KillPod:true CreateSandbox:true SandboxID: Attempt:0 NextInitContainerToStart:nil ContainersToStart:[0] ContainersToKill:map[] EphemeralContainersToStart:[]} pod="default/nginx-deployment-66f58bff7c-n8ncw"
Sep 15 20:47:44 kind-worker3 kubelet[589656]: I0915 20:47:44.863790  589656 kuberuntime_manager.go:723] "SyncPod received new pod, will create a sandbox for it" pod="default/nginx-deployment-66f58bff7c-n8ncw"
Sep 15 20:47:44 kind-worker3 kubelet[589656]: I0915 20:47:44.863842  589656 kuberuntime_manager.go:730] "Stopping PodSandbox for pod, will start new one" pod="default/nginx-deployment-66f58bff7c-n8ncw"
Sep 15 20:47:44 kind-worker3 kubelet[589656]: I0915 20:47:44.863883  589656 kuberuntime_manager.go:785] "Creating PodSandbox for pod" pod="default/nginx-deployment-66f58bff7c-n8ncw"
Sep 15 20:47:44 kind-worker3 kubelet[589656]: I0915 20:47:44.924829  589656 kubelet.go:2346] "Container runtime status" status="Runtime Conditions: RuntimeReady=true reason: message:, NetworkReady=true reason: message:"
Sep 15 20:47:46 kind-worker3 kubelet[589656]: I0915 20:47:46.499838  589656 kubelet.go:2160] "SyncLoop (housekeeping)"
Sep 15 20:47:46 kind-worker3 kubelet[589656]: I0915 20:47:46.513956  589656 kubelet_pods.go:1079] "Clean up pod workers for terminated pods"
Sep 15 20:47:46 kind-worker3 kubelet[589656]: I0915 20:47:46.514051  589656 kubelet_pods.go:1108] "Clean up probes for terminated pods"
Sep 15 20:47:46 kind-worker3 kubelet[589656]: I0915 20:47:46.531661  589656 kubelet_pods.go:1145] "Clean up orphaned pod statuses"
Sep 15 20:47:46 kind-worker3 kubelet[589656]: I0915 20:47:46.534233  589656 kubelet_pods.go:1164] "Clean up orphaned pod directories"
Sep 15 20:47:46 kind-worker3 kubelet[589656]: I0915 20:47:46.534404  589656 kubelet_pods.go:1175] "Clean up orphaned mirror pods"
Sep 15 20:47:46 kind-worker3 kubelet[589656]: I0915 20:47:46.534434  589656 kubelet_pods.go:1182] "Clean up orphaned pod cgroups"
Sep 15 20:47:46 kind-worker3 kubelet[589656]: I0915 20:47:46.534465  589656 kubelet.go:2168] "SyncLoop (housekeeping) end"
Sep 15 20:47:46 kind-worker3 kubelet[589656]: I0915 20:47:46.639160  589656 factory.go:258] Using factory "containerd" for container "/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-pod9950f637_3ce8_428f_a136_02b68a154d8f.slice/cri-containerd-989c71a5f0b9e1fed741630292d401140445bec2e7fca6fb21d31525fc37072a.scope"
Sep 15 20:47:46 kind-worker3 kubelet[589656]: I0915 20:47:46.880610  589656 manager.go:988] Added container: "/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-pod9950f637_3ce8_428f_a136_02b68a154d8f.slice/cri-containerd-989c71a5f0b9e1fed741630292d401140445bec2e7fca6fb21d31525fc37072a.scope" (aliases: [989c71a5f0b9e1fed741630292d401140445bec2e7fca6fb21d31525fc37072a /kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-pod9950f637_3ce8_428f_a136_02b68a154d8f.slice/cri-containerd-989c71a5f0b9e1fed741630292d401140445bec2e7fca6fb21d31525fc37072a.scope], namespace: "containerd")
Sep 15 20:47:46 kind-worker3 kubelet[589656]: I0915 20:47:46.881205  589656 handler.go:325] Added event &{/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-pod9950f637_3ce8_428f_a136_02b68a154d8f.slice/cri-containerd-989c71a5f0b9e1fed741630292d401140445bec2e7fca6fb21d31525fc37072a.scope 2023-09-15 20:47:46.631170871 +0000 UTC containerCreation {<nil>}}
Sep 15 20:47:46 kind-worker3 kubelet[589656]: I0915 20:47:46.881301  589656 container.go:530] Start housekeeping for container "/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-pod9950f637_3ce8_428f_a136_02b68a154d8f.slice/cri-containerd-989c71a5f0b9e1fed741630292d401140445bec2e7fca6fb21d31525fc37072a.scope"
Sep 15 20:47:46 kind-worker3 kubelet[589656]: I0915 20:47:46.919014  589656 kuberuntime_manager.go:823] "Created PodSandbox for pod" podSandboxID="989c71a5f0b9e1fed741630292d401140445bec2e7fca6fb21d31525fc37072a" pod="default/nginx-deployment-66f58bff7c-n8ncw"
Sep 15 20:47:46 kind-worker3 kubelet[589656]: I0915 20:47:46.920003  589656 kuberuntime_manager.go:846] "Determined the ip for pod after sandbox changed" IPs=[10.244.3.69] pod="default/nginx-deployment-66f58bff7c-n8ncw"
Sep 15 20:47:46 kind-worker3 kubelet[589656]: I0915 20:47:46.920306  589656 kuberuntime_manager.go:889] "Creating container in pod" containerType="container" container="&Container{Name:nginx,Image:nginx:1.14.2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{ContainerPort{Name:,HostPort:0,ContainerPort:80,Protocol:TCP,HostIP:,},},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{cpu: {{500 -3} {<nil>} 500m DecimalSI},},Requests:ResourceList{cpu: {{200 -3} {<nil>} 200m DecimalSI},},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-5c8xs,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,}" pod="default/nginx-deployment-66f58bff7c-n8ncw"
Sep 15 20:47:46 kind-worker3 kubelet[589656]: I0915 20:47:46.922139  589656 kubelet_pods.go:161] "Creating hosts mount for container" pod="default/nginx-deployment-66f58bff7c-n8ncw" containerName="nginx" podIPs=[10.244.3.69] path=true
Sep 15 20:47:46 kind-worker3 kubelet[589656]: I0915 20:47:46.922921  589656 event.go:294] "Event occurred" object="default/nginx-deployment-66f58bff7c-n8ncw" fieldPath="spec.containers{nginx}" kind="Pod" apiVersion="v1" type="Normal" reason="Pulled" message="Container image \"nginx:1.14.2\" already present on machine"
Sep 15 20:47:47 kind-worker3 kubelet[589656]: I0915 20:47:47.490577  589656 event.go:294] "Event occurred" object="default/nginx-deployment-66f58bff7c-n8ncw" fieldPath="spec.containers{nginx}" kind="Pod" apiVersion="v1" type="Normal" reason="Created" message="Created container nginx"
Sep 15 20:47:47 kind-worker3 kubelet[589656]: I0915 20:47:47.548555  589656 factory.go:258] Using factory "containerd" for container "/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-pod9950f637_3ce8_428f_a136_02b68a154d8f.slice/cri-containerd-d7b7bcc17d59e448b6bf1dc609a1d24b871452bc3bacf9a4b4cdda794dbd4d89.scope"
Sep 15 20:47:47 kind-worker3 kubelet[589656]: I0915 20:47:47.764182  589656 generic.go:155] "GenericPLEG" podUID=9950f637-3ce8-428f-a136-02b68a154d8f containerID="d7b7bcc17d59e448b6bf1dc609a1d24b871452bc3bacf9a4b4cdda794dbd4d89" oldState=non-existent newState=unknown
Sep 15 20:47:47 kind-worker3 kubelet[589656]: I0915 20:47:47.764423  589656 generic.go:155] "GenericPLEG" podUID=9950f637-3ce8-428f-a136-02b68a154d8f containerID="989c71a5f0b9e1fed741630292d401140445bec2e7fca6fb21d31525fc37072a" oldState=non-existent newState=running
Sep 15 20:47:47 kind-worker3 kubelet[589656]: I0915 20:47:47.765234  589656 kuberuntime_manager.go:1037] "getSandboxIDByPodUID got sandbox IDs for pod" podSandboxID=[989c71a5f0b9e1fed741630292d401140445bec2e7fca6fb21d31525fc37072a] pod="default/nginx-deployment-66f58bff7c-n8ncw"
Sep 15 20:47:47 kind-worker3 kubelet[589656]: I0915 20:47:47.767955  589656 generic.go:421] "PLEG: Write status" pod="default/nginx-deployment-66f58bff7c-n8ncw"
Sep 15 20:47:47 kind-worker3 kubelet[589656]: I0915 20:47:47.768146  589656 kubelet.go:2110] "SyncLoop (PLEG): event for pod" pod="default/nginx-deployment-66f58bff7c-n8ncw" event=&{ID:9950f637-3ce8-428f-a136-02b68a154d8f Type:ContainerStarted Data:989c71a5f0b9e1fed741630292d401140445bec2e7fca6fb21d31525fc37072a}
Sep 15 20:47:47 kind-worker3 kubelet[589656]: I0915 20:47:47.852281  589656 manager.go:988] Added container: "/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-pod9950f637_3ce8_428f_a136_02b68a154d8f.slice/cri-containerd-d7b7bcc17d59e448b6bf1dc609a1d24b871452bc3bacf9a4b4cdda794dbd4d89.scope" (aliases: [d7b7bcc17d59e448b6bf1dc609a1d24b871452bc3bacf9a4b4cdda794dbd4d89 /kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-pod9950f637_3ce8_428f_a136_02b68a154d8f.slice/cri-containerd-d7b7bcc17d59e448b6bf1dc609a1d24b871452bc3bacf9a4b4cdda794dbd4d89.scope], namespace: "containerd")
Sep 15 20:47:47 kind-worker3 kubelet[589656]: I0915 20:47:47.852990  589656 handler.go:325] Added event &{/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-pod9950f637_3ce8_428f_a136_02b68a154d8f.slice/cri-containerd-d7b7bcc17d59e448b6bf1dc609a1d24b871452bc3bacf9a4b4cdda794dbd4d89.scope 2023-09-15 20:47:47.543165268 +0000 UTC containerCreation {<nil>}}
Sep 15 20:47:47 kind-worker3 kubelet[589656]: I0915 20:47:47.853162  589656 container.go:530] Start housekeeping for container "/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-pod9950f637_3ce8_428f_a136_02b68a154d8f.slice/cri-containerd-d7b7bcc17d59e448b6bf1dc609a1d24b871452bc3bacf9a4b4cdda794dbd4d89.scope"
Sep 15 20:47:47 kind-worker3 kubelet[589656]: I0915 20:47:47.954347  589656 kubelet.go:1503] "syncPod exit" pod="default/nginx-deployment-66f58bff7c-n8ncw" podUID=9950f637-3ce8-428f-a136-02b68a154d8f isTerminal=false
Sep 15 20:47:47 kind-worker3 kubelet[589656]: I0915 20:47:47.954511  589656 pod_workers.go:988] "Processing pod event done" pod="default/nginx-deployment-66f58bff7c-n8ncw" podUID=9950f637-3ce8-428f-a136-02b68a154d8f updateType=0
Sep 15 20:47:47 kind-worker3 kubelet[589656]: I0915 20:47:47.954556  589656 pod_workers.go:888] "Processing pod event" pod="default/nginx-deployment-66f58bff7c-n8ncw" podUID=9950f637-3ce8-428f-a136-02b68a154d8f updateType=0
Sep 15 20:47:47 kind-worker3 kubelet[589656]: I0915 20:47:47.955066  589656 event.go:294] "Event occurred" object="default/nginx-deployment-66f58bff7c-n8ncw" fieldPath="spec.containers{nginx}" kind="Pod" apiVersion="v1" type="Normal" reason="Started" message="Started container nginx"
Sep 15 20:47:48 kind-worker3 kubelet[589656]: I0915 20:47:48.497850  589656 kubelet.go:2160] "SyncLoop (housekeeping)"
Sep 15 20:47:48 kind-worker3 kubelet[589656]: I0915 20:47:48.505409  589656 kubelet_pods.go:1079] "Clean up pod workers for terminated pods"
Sep 15 20:47:48 kind-worker3 kubelet[589656]: I0915 20:47:48.505481  589656 kubelet_pods.go:1108] "Clean up probes for terminated pods"
Sep 15 20:47:48 kind-worker3 kubelet[589656]: I0915 20:47:48.505525  589656 kubelet_pods.go:1145] "Clean up orphaned pod statuses"
Sep 15 20:47:48 kind-worker3 kubelet[589656]: I0915 20:47:48.507996  589656 kubelet_pods.go:1164] "Clean up orphaned pod directories"
Sep 15 20:47:48 kind-worker3 kubelet[589656]: I0915 20:47:48.508169  589656 kubelet_pods.go:1175] "Clean up orphaned mirror pods"
Sep 15 20:47:48 kind-worker3 kubelet[589656]: I0915 20:47:48.508197  589656 kubelet_pods.go:1182] "Clean up orphaned pod cgroups"
Sep 15 20:47:48 kind-worker3 kubelet[589656]: I0915 20:47:48.508225  589656 kubelet.go:2168] "SyncLoop (housekeeping) end"
Sep 15 20:47:48 kind-worker3 kubelet[589656]: I0915 20:47:48.770892  589656 generic.go:155] "GenericPLEG" podUID=9950f637-3ce8-428f-a136-02b68a154d8f containerID="d7b7bcc17d59e448b6bf1dc609a1d24b871452bc3bacf9a4b4cdda794dbd4d89" oldState=unknown newState=running
Sep 15 20:47:48 kind-worker3 kubelet[589656]: I0915 20:47:48.772102  589656 kuberuntime_manager.go:1037] "getSandboxIDByPodUID got sandbox IDs for pod" podSandboxID=[989c71a5f0b9e1fed741630292d401140445bec2e7fca6fb21d31525fc37072a] pod="default/nginx-deployment-66f58bff7c-n8ncw"
Sep 15 20:47:48 kind-worker3 kubelet[589656]: I0915 20:47:48.774108  589656 generic.go:421] "PLEG: Write status" pod="default/nginx-deployment-66f58bff7c-n8ncw"
Sep 15 20:47:48 kind-worker3 kubelet[589656]: I0915 20:47:48.774205  589656 kubelet.go:2110] "SyncLoop (PLEG): event for pod" pod="default/nginx-deployment-66f58bff7c-n8ncw" event=&{ID:9950f637-3ce8-428f-a136-02b68a154d8f Type:ContainerStarted Data:d7b7bcc17d59e448b6bf1dc609a1d24b871452bc3bacf9a4b4cdda794dbd4d89}
Sep 15 20:47:48 kind-worker3 kubelet[589656]: I0915 20:47:48.774225  589656 kubelet.go:1501] "syncPod enter" pod="default/nginx-deployment-66f58bff7c-n8ncw" podUID=9950f637-3ce8-428f-a136-02b68a154d8f
Sep 15 20:47:48 kind-worker3 kubelet[589656]: I0915 20:47:48.774290  589656 kubelet_pods.go:1432] "Generating pod status" pod="default/nginx-deployment-66f58bff7c-n8ncw"
Sep 15 20:47:48 kind-worker3 kubelet[589656]: I0915 20:47:48.774359  589656 kubelet_pods.go:1444] "Got phase for pod" pod="default/nginx-deployment-66f58bff7c-n8ncw" oldPhase=Pending phase=Running
Sep 15 20:47:48 kind-worker3 kubelet[589656]: I0915 20:47:48.775046  589656 volume_manager.go:404] "Waiting for volumes to attach and mount for pod" pod="default/nginx-deployment-66f58bff7c-n8ncw"
Sep 15 20:47:48 kind-worker3 kubelet[589656]: I0915 20:47:48.775103  589656 volume_manager.go:435] "All volumes are attached and mounted for pod" pod="default/nginx-deployment-66f58bff7c-n8ncw"
Sep 15 20:47:48 kind-worker3 kubelet[589656]: I0915 20:47:48.775348  589656 kuberuntime_manager.go:714] "computePodActions got for pod" podActions={KillPod:false CreateSandbox:false SandboxID:989c71a5f0b9e1fed741630292d401140445bec2e7fca6fb21d31525fc37072a Attempt:0 NextInitContainerToStart:nil ContainersToStart:[] ContainersToKill:map[] EphemeralContainersToStart:[]} pod="default/nginx-deployment-66f58bff7c-n8ncw"
Sep 15 20:47:48 kind-worker3 kubelet[589656]: I0915 20:47:48.775525  589656 kubelet.go:1503] "syncPod exit" pod="default/nginx-deployment-66f58bff7c-n8ncw" podUID=9950f637-3ce8-428f-a136-02b68a154d8f isTerminal=false
Sep 15 20:47:48 kind-worker3 kubelet[589656]: I0915 20:47:48.775584  589656 pod_workers.go:988] "Processing pod event done" pod="default/nginx-deployment-66f58bff7c-n8ncw" podUID=9950f637-3ce8-428f-a136-02b68a154d8f updateType=0
Sep 15 20:47:48 kind-worker3 kubelet[589656]: I0915 20:47:48.775634  589656 pod_workers.go:888] "Processing pod event" pod="default/nginx-deployment-66f58bff7c-n8ncw" podUID=9950f637-3ce8-428f-a136-02b68a154d8f updateType=0
Sep 15 20:47:48 kind-worker3 kubelet[589656]: I0915 20:47:48.790242  589656 config.go:279] "Setting pods for source" source="api"
Sep 15 20:47:48 kind-worker3 kubelet[589656]: I0915 20:47:48.790443  589656 status_manager.go:685] "Patch status for pod" pod="default/nginx-deployment-66f58bff7c-n8ncw" patch="{\"metadata\":{\"uid\":\"9950f637-3ce8-428f-a136-02b68a154d8f\"},\"status\":{\"$setElementOrder/conditions\":[{\"type\":\"Initialized\"},{\"type\":\"Ready\"},{\"type\":\"ContainersReady\"},{\"type\":\"PodScheduled\"}],\"conditions\":[{\"lastTransitionTime\":\"2023-09-15T20:47:48Z\",\"message\":null,\"reason\":null,\"status\":\"True\",\"type\":\"Ready\"},{\"lastTransitionTime\":\"2023-09-15T20:47:48Z\",\"message\":null,\"reason\":null,\"status\":\"True\",\"type\":\"ContainersReady\"}],\"containerStatuses\":[{\"containerID\":\"containerd://d7b7bcc17d59e448b6bf1dc609a1d24b871452bc3bacf9a4b4cdda794dbd4d89\",\"image\":\"docker.io/library/nginx:1.14.2\",\"imageID\":\"docker.io/library/nginx@sha256:f7988fb6c02e0ce69257d9bd9cf37ae20a60f1df7563c3a2a6abe24160306b8d\",\"lastState\":{},\"name\":\"nginx\",\"ready\":true,\"restartCount\":0,\"started\":true,\"state\":{\"running\":{\"startedAt\":\"2023-09-15T20:47:47Z\"}}}],\"phase\":\"Running\",\"podIP\":\"10.244.3.69\",\"podIPs\":[{\"ip\":\"10.244.3.69\"}]}}"
Sep 15 20:47:48 kind-worker3 kubelet[589656]: I0915 20:47:48.790505  589656 kubelet.go:2085] "SyncLoop RECONCILE" source="api" pods=[default/nginx-deployment-66f58bff7c-n8ncw]
Sep 15 20:47:48 kind-worker3 kubelet[589656]: I0915 20:47:48.790708  589656 status_manager.go:694] "Status for pod updated successfully" pod="default/nginx-deployment-66f58bff7c-n8ncw" statusVersion=2 status={Phase:Running Conditions:[{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-09-15 20:47:44 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-09-15 20:47:48 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-09-15 20:47:48 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-09-15 20:47:44 +0000 UTC Reason: Message:}] Message: Reason: NominatedNodeName: HostIP:172.18.0.4 PodIP:10.244.3.69 PodIPs:[{IP:10.244.3.69}] StartTime:2023-09-15 20:47:44 +0000 UTC InitContainerStatuses:[] ContainerStatuses:[{Name:nginx State:{Waiting:nil Running:&ContainerStateRunning{StartedAt:2023-09-15 20:47:47 +0000 UTC,} Terminated:nil} LastTerminationState:{Waiting:nil Running:nil Terminated:nil} Ready:true RestartCount:0 Image:docker.io/library/nginx:1.14.2 ImageID:docker.io/library/nginx@sha256:f7988fb6c02e0ce69257d9bd9cf37ae20a60f1df7563c3a2a6abe24160306b8d ContainerID:containerd://d7b7bcc17d59e448b6bf1dc609a1d24b871452bc3bacf9a4b4cdda794dbd4d89 Started:0xc00168c7cc}] QOSClass:Burstable EphemeralContainerStatuses:[]}
Sep 15 20:47:48 kind-worker3 kubelet[589656]: I0915 20:47:48.824460  589656 desired_state_of_world_populator.go:309] "Added volume to desired state" pod="default/nginx-deployment-66f58bff7c-n8ncw" volumeName="kube-api-access-5c8xs" volumeSpecName="kube-api-access-5c8xs"
Sep 15 20:47:48 kind-worker3 kubelet[589656]: I0915 20:47:48.849569  589656 reconciler.go:243] "Starting operationExecutor.MountVolume for volume \"kube-api-access-5c8xs\" (UniqueName: \"kubernetes.io/projected/9950f637-3ce8-428f-a136-02b68a154d8f-kube-api-access-5c8xs\") pod \"nginx-deployment-66f58bff7c-n8ncw\" (UID: \"9950f637-3ce8-428f-a136-02b68a154d8f\") Volume is already mounted to pod, but remount was requested." pod="default/nginx-deployment-66f58bff7c-n8ncw"
Sep 15 20:47:48 kind-worker3 kubelet[589656]: I0915 20:47:48.849906  589656 projected.go:183] Setting up volume kube-api-access-5c8xs for pod 9950f637-3ce8-428f-a136-02b68a154d8f at /var/lib/kubelet/pods/9950f637-3ce8-428f-a136-02b68a154d8f/volumes/kubernetes.io~projected/kube-api-access-5c8xs
Sep 15 20:47:48 kind-worker3 kubelet[589656]: I0915 20:47:48.850720  589656 atomic_writer.go:161] pod default/nginx-deployment-66f58bff7c-n8ncw volume kube-api-access-5c8xs: no update required for target directory /var/lib/kubelet/pods/9950f637-3ce8-428f-a136-02b68a154d8f/volumes/kubernetes.io~projected/kube-api-access-5c8xs
Sep 15 20:47:48 kind-worker3 kubelet[589656]: I0915 20:47:48.850811  589656 operation_generator.go:703] "MountVolume.SetUp succeeded for volume \"kube-api-access-5c8xs\" (UniqueName: \"kubernetes.io/projected/9950f637-3ce8-428f-a136-02b68a154d8f-kube-api-access-5c8xs\") pod \"nginx-deployment-66f58bff7c-n8ncw\" (UID: \"9950f637-3ce8-428f-a136-02b68a154d8f\") " pod="default/nginx-deployment-66f58bff7c-n8ncw"
Sep 15 20:47:49 kind-worker3 kubelet[589656]: I0915 20:47:49.399393  589656 httplog.go:131] "HTTP" verb="GET" URI="/metrics/resource" latency="30.817985ms" userAgent="metrics-server/v0.6.3 (linux/amd64) kubernetes/a938798" audit-ID="" srcIP="172.18.0.3:35538" resp=200
Sep 15 20:47:49 kind-worker3 kubelet[589656]: I0915 20:47:49.778043  589656 kubelet.go:1501] "syncPod enter" pod="default/nginx-deployment-66f58bff7c-n8ncw" podUID=9950f637-3ce8-428f-a136-02b68a154d8f
Sep 15 20:47:49 kind-worker3 kubelet[589656]: I0915 20:47:49.778131  589656 kubelet_pods.go:1432] "Generating pod status" pod="default/nginx-deployment-66f58bff7c-n8ncw"
Sep 15 20:47:49 kind-worker3 kubelet[589656]: I0915 20:47:49.778229  589656 kubelet_pods.go:1444] "Got phase for pod" pod="default/nginx-deployment-66f58bff7c-n8ncw" oldPhase=Running phase=Running
Sep 15 20:47:49 kind-worker3 kubelet[589656]: I0915 20:47:49.778737  589656 status_manager.go:535] "Ignoring same status for pod" pod="default/nginx-deployment-66f58bff7c-n8ncw" status={Phase:Running Conditions:[{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-09-15 20:47:44 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-09-15 20:47:48 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-09-15 20:47:48 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-09-15 20:47:44 +0000 UTC Reason: Message:}] Message: Reason: NominatedNodeName: HostIP:172.18.0.4 PodIP:10.244.3.69 PodIPs:[{IP:10.244.3.69}] StartTime:2023-09-15 20:47:44 +0000 UTC InitContainerStatuses:[] ContainerStatuses:[{Name:nginx State:{Waiting:nil Running:&ContainerStateRunning{StartedAt:2023-09-15 20:47:47 +0000 UTC,} Terminated:nil} LastTerminationState:{Waiting:nil Running:nil Terminated:nil} Ready:true RestartCount:0 Image:docker.io/library/nginx:1.14.2 ImageID:docker.io/library/nginx@sha256:f7988fb6c02e0ce69257d9bd9cf37ae20a60f1df7563c3a2a6abe24160306b8d ContainerID:containerd://d7b7bcc17d59e448b6bf1dc609a1d24b871452bc3bacf9a4b4cdda794dbd4d89 Started:0xc0013b3e0c}] QOSClass:Burstable EphemeralContainerStatuses:[]}
Sep 15 20:47:49 kind-worker3 kubelet[589656]: I0915 20:47:49.779224  589656 volume_manager.go:404] "Waiting for volumes to attach and mount for pod" pod="default/nginx-deployment-66f58bff7c-n8ncw"
Sep 15 20:47:49 kind-worker3 kubelet[589656]: I0915 20:47:49.779271  589656 volume_manager.go:435] "All volumes are attached and mounted for pod" pod="default/nginx-deployment-66f58bff7c-n8ncw"
Sep 15 20:47:49 kind-worker3 kubelet[589656]: I0915 20:47:49.779481  589656 kuberuntime_manager.go:714] "computePodActions got for pod" podActions={KillPod:false CreateSandbox:false SandboxID:989c71a5f0b9e1fed741630292d401140445bec2e7fca6fb21d31525fc37072a Attempt:0 NextInitContainerToStart:nil ContainersToStart:[] ContainersToKill:map[] EphemeralContainersToStart:[]} pod="default/nginx-deployment-66f58bff7c-n8ncw"
Sep 15 20:47:49 kind-worker3 kubelet[589656]: I0915 20:47:49.779668  589656 kubelet.go:1503] "syncPod exit" pod="default/nginx-deployment-66f58bff7c-n8ncw" podUID=9950f637-3ce8-428f-a136-02b68a154d8f isTerminal=false
Sep 15 20:47:49 kind-worker3 kubelet[589656]: I0915 20:47:49.779766  589656 pod_workers.go:988] "Processing pod event done" pod="default/nginx-deployment-66f58bff7c-n8ncw" podUID=9950f637-3ce8-428f-a136-02b68a154d8f updateType=0
Sep 15 20:47:49 kind-worker3 kubelet[589656]: I0915 20:47:49.832046  589656 desired_state_of_world_populator.go:309] "Added volume to desired state" pod="default/nginx-deployment-66f58bff7c-n8ncw" volumeName="kube-api-access-5c8xs" volumeSpecName="kube-api-access-5c8xs"
Sep 15 20:47:49 kind-worker3 kubelet[589656]: I0915 20:47:49.855123  589656 reconciler.go:243] "Starting operationExecutor.MountVolume for volume \"kube-api-access-5c8xs\" (UniqueName: \"kubernetes.io/projected/9950f637-3ce8-428f-a136-02b68a154d8f-kube-api-access-5c8xs\") pod \"nginx-deployment-66f58bff7c-n8ncw\" (UID: \"9950f637-3ce8-428f-a136-02b68a154d8f\") Volume is already mounted to pod, but remount was requested." pod="default/nginx-deployment-66f58bff7c-n8ncw"
Sep 15 20:47:49 kind-worker3 kubelet[589656]: I0915 20:47:49.855359  589656 projected.go:183] Setting up volume kube-api-access-5c8xs for pod 9950f637-3ce8-428f-a136-02b68a154d8f at /var/lib/kubelet/pods/9950f637-3ce8-428f-a136-02b68a154d8f/volumes/kubernetes.io~projected/kube-api-access-5c8xs
Sep 15 20:47:49 kind-worker3 kubelet[589656]: I0915 20:47:49.855826  589656 atomic_writer.go:161] pod default/nginx-deployment-66f58bff7c-n8ncw volume kube-api-access-5c8xs: no update required for target directory /var/lib/kubelet/pods/9950f637-3ce8-428f-a136-02b68a154d8f/volumes/kubernetes.io~projected/kube-api-access-5c8xs
Sep 15 20:47:49 kind-worker3 kubelet[589656]: I0915 20:47:49.855880  589656 operation_generator.go:703] "MountVolume.SetUp succeeded for volume \"kube-api-access-5c8xs\" (UniqueName: \"kubernetes.io/projected/9950f637-3ce8-428f-a136-02b68a154d8f-kube-api-access-5c8xs\") pod \"nginx-deployment-66f58bff7c-n8ncw\" (UID: \"9950f637-3ce8-428f-a136-02b68a154d8f\") " pod="default/nginx-deployment-66f58bff7c-n8ncw"
Sep 15 20:47:49 kind-worker3 kubelet[589656]: I0915 20:47:49.927740  589656 kubelet.go:2346] "Container runtime status" status="Runtime Conditions: RuntimeReady=true reason: message:, NetworkReady=true reason: message:"
Sep 15 20:47:50 kind-worker3 kubelet[589656]: I0915 20:47:50.497904  589656 kubelet.go:2160] "SyncLoop (housekeeping)"
Sep 15 20:47:50 kind-worker3 kubelet[589656]: I0915 20:47:50.506096  589656 kubelet_pods.go:1079] "Clean up pod workers for terminated pods"
Sep 15 20:47:50 kind-worker3 kubelet[589656]: I0915 20:47:50.506160  589656 kubelet_pods.go:1108] "Clean up probes for terminated pods"
Sep 15 20:47:50 kind-worker3 kubelet[589656]: I0915 20:47:50.508658  589656 kubelet_pods.go:1145] "Clean up orphaned pod statuses"
Sep 15 20:47:50 kind-worker3 kubelet[589656]: I0915 20:47:50.509921  589656 kubelet_pods.go:1164] "Clean up orphaned pod directories"
Sep 15 20:47:50 kind-worker3 kubelet[589656]: I0915 20:47:50.510088  589656 kubelet_pods.go:1175] "Clean up orphaned mirror pods"
Sep 15 20:47:50 kind-worker3 kubelet[589656]: I0915 20:47:50.510115  589656 kubelet_pods.go:1182] "Clean up orphaned pod cgroups"
Sep 15 20:47:50 kind-worker3 kubelet[589656]: I0915 20:47:50.510143  589656 kubelet.go:2168] "SyncLoop (housekeeping) end"
Sep 15 20:47:50 kind-worker3 kubelet[589656]: I0915 20:47:50.644927  589656 setters.go:88] "Using node IP" IP="172.18.0.4"
Sep 15 20:47:51 kind-worker3 kubelet[589656]: I0915 20:47:51.498540  589656 kubelet.go:2129] "SyncLoop (SYNC) pods" total=1 pods=[kube-system/kube-proxy-zvz6f]
Sep 15 20:47:51 kind-worker3 kubelet[589656]: I0915 20:47:51.498712  589656 pod_workers.go:888] "Processing pod event" pod="kube-system/kube-proxy-zvz6f" podUID=6b53eb8b-e28c-454a-92e9-b342af428fa5 updateType=0
Sep 15 20:47:51 kind-worker3 kubelet[589656]: I0915 20:47:51.498785  589656 kubelet.go:1501] "syncPod enter" pod="kube-system/kube-proxy-zvz6f" podUID=6b53eb8b-e28c-454a-92e9-b342af428fa5
Sep 15 20:47:51 kind-worker3 kubelet[589656]: I0915 20:47:51.498833  589656 kubelet_pods.go:1432] "Generating pod status" pod="kube-system/kube-proxy-zvz6f"
Sep 15 20:47:51 kind-worker3 kubelet[589656]: I0915 20:47:51.498943  589656 kubelet_pods.go:1444] "Got phase for pod" pod="kube-system/kube-proxy-zvz6f" oldPhase=Running phase=Running
Sep 15 20:47:51 kind-worker3 kubelet[589656]: I0915 20:47:51.499271  589656 status_manager.go:535] "Ignoring same status for pod" pod="kube-system/kube-proxy-zvz6f" status={Phase:Running Conditions:[{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-14 00:07:50 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-07-15 14:56:49 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-07-15 14:56:49 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-14 00:07:47 +0000 UTC Reason: Message:}] Message: Reason: NominatedNodeName: HostIP:172.18.0.4 PodIP:172.18.0.4 PodIPs:[{IP:172.18.0.4}] StartTime:2023-04-14 00:07:50 +0000 UTC InitContainerStatuses:[] ContainerStatuses:[{Name:kube-proxy State:{Waiting:nil Running:&ContainerStateRunning{StartedAt:2023-07-15 14:56:47 +0000 UTC,} Terminated:nil} LastTerminationState:{Waiting:nil Running:nil Terminated:&ContainerStateTerminated{ExitCode:255,Signal:0,Reason:Unknown,Message:,StartedAt:2023-05-13 23:24:22 +0000 UTC,FinishedAt:2023-07-15 14:56:13 +0000 UTC,ContainerID:containerd://1a7bfc39de99704091c5fdcafe31a31e1284778b198adb62ae3b794474907627,}} Ready:true RestartCount:2 Image:k8s.gcr.io/kube-proxy:v1.24.7 ImageID:docker.io/library/import-2022-10-26@sha256:82fa4ddf64d5be44671118fb9b86c454a222ff7ea6e48863ed7e5daeeca3ea42 ContainerID:containerd://041c9bf8c11670337ae7ecef4cae6277cbe6623488dc925c5412e6b4a494b7f0 Started:0xc00199043c}] QOSClass:BestEffort EphemeralContainerStatuses:[]}
Sep 15 20:47:51 kind-worker3 kubelet[589656]: I0915 20:47:51.499743  589656 volume_manager.go:404] "Waiting for volumes to attach and mount for pod" pod="kube-system/kube-proxy-zvz6f"
Sep 15 20:47:51 kind-worker3 kubelet[589656]: I0915 20:47:51.499802  589656 volume_manager.go:435] "All volumes are attached and mounted for pod" pod="kube-system/kube-proxy-zvz6f"
Sep 15 20:47:51 kind-worker3 kubelet[589656]: I0915 20:47:51.500075  589656 kuberuntime_manager.go:714] "computePodActions got for pod" podActions={KillPod:false CreateSandbox:false SandboxID:d0f4d02598fe0e9a32081b1554ae85df2b4224eb9a378fdcf99aa7c0035d33dc Attempt:2 NextInitContainerToStart:nil ContainersToStart:[] ContainersToKill:map[] EphemeralContainersToStart:[]} pod="kube-system/kube-proxy-zvz6f"
Sep 15 20:47:51 kind-worker3 kubelet[589656]: I0915 20:47:51.500256  589656 kubelet.go:1503] "syncPod exit" pod="kube-system/kube-proxy-zvz6f" podUID=6b53eb8b-e28c-454a-92e9-b342af428fa5 isTerminal=false
Sep 15 20:47:51 kind-worker3 kubelet[589656]: I0915 20:47:51.500313  589656 pod_workers.go:988] "Processing pod event done" pod="kube-system/kube-proxy-zvz6f" podUID=6b53eb8b-e28c-454a-92e9-b342af428fa5 updateType=0
Sep 15 20:47:51 kind-worker3 kubelet[589656]: I0915 20:47:51.543837  589656 desired_state_of_world_populator.go:309] "Added volume to desired state" pod="kube-system/kube-proxy-zvz6f" volumeName="kube-proxy" volumeSpecName="kube-proxy"
Sep 15 20:47:51 kind-worker3 kubelet[589656]: I0915 20:47:51.543964  589656 desired_state_of_world_populator.go:309] "Added volume to desired state" pod="kube-system/kube-proxy-zvz6f" volumeName="xtables-lock" volumeSpecName="xtables-lock"
Sep 15 20:47:51 kind-worker3 kubelet[589656]: I0915 20:47:51.544027  589656 desired_state_of_world_populator.go:309] "Added volume to desired state" pod="kube-system/kube-proxy-zvz6f" volumeName="lib-modules" volumeSpecName="lib-modules"
Sep 15 20:47:51 kind-worker3 kubelet[589656]: I0915 20:47:51.544126  589656 desired_state_of_world_populator.go:309] "Added volume to desired state" pod="kube-system/kube-proxy-zvz6f" volumeName="kube-api-access-psmb2" volumeSpecName="kube-api-access-psmb2"
Sep 15 20:47:51 kind-worker3 kubelet[589656]: I0915 20:47:51.566057  589656 reconciler.go:243] "Starting operationExecutor.MountVolume for volume \"kube-api-access-psmb2\" (UniqueName: \"kubernetes.io/projected/6b53eb8b-e28c-454a-92e9-b342af428fa5-kube-api-access-psmb2\") pod \"kube-proxy-zvz6f\" (UID: \"6b53eb8b-e28c-454a-92e9-b342af428fa5\") Volume is already mounted to pod, but remount was requested." pod="kube-system/kube-proxy-zvz6f"
Sep 15 20:47:51 kind-worker3 kubelet[589656]: I0915 20:47:51.566240  589656 reconciler.go:243] "Starting operationExecutor.MountVolume for volume \"kube-proxy\" (UniqueName: \"kubernetes.io/configmap/6b53eb8b-e28c-454a-92e9-b342af428fa5-kube-proxy\") pod \"kube-proxy-zvz6f\" (UID: \"6b53eb8b-e28c-454a-92e9-b342af428fa5\") Volume is already mounted to pod, but remount was requested." pod="kube-system/kube-proxy-zvz6f"
Sep 15 20:47:51 kind-worker3 kubelet[589656]: I0915 20:47:51.566411  589656 configmap.go:181] Setting up volume kube-proxy for pod 6b53eb8b-e28c-454a-92e9-b342af428fa5 at /var/lib/kubelet/pods/6b53eb8b-e28c-454a-92e9-b342af428fa5/volumes/kubernetes.io~configmap/kube-proxy
Sep 15 20:47:51 kind-worker3 kubelet[589656]: I0915 20:47:51.566425  589656 projected.go:183] Setting up volume kube-api-access-psmb2 for pod 6b53eb8b-e28c-454a-92e9-b342af428fa5 at /var/lib/kubelet/pods/6b53eb8b-e28c-454a-92e9-b342af428fa5/volumes/kubernetes.io~projected/kube-api-access-psmb2
Sep 15 20:47:51 kind-worker3 kubelet[589656]: I0915 20:47:51.566477  589656 configmap.go:205] Received configMap kube-system/kube-proxy containing (2) pieces of data, 1466 total bytes
Sep 15 20:47:51 kind-worker3 kubelet[589656]: I0915 20:47:51.566579  589656 quota_linux.go:271] SupportsQuotas called, but quotas disabled
Sep 15 20:47:51 kind-worker3 kubelet[589656]: I0915 20:47:51.566915  589656 atomic_writer.go:161] pod kube-system/kube-proxy-zvz6f volume kube-proxy: no update required for target directory /var/lib/kubelet/pods/6b53eb8b-e28c-454a-92e9-b342af428fa5/volumes/kubernetes.io~configmap/kube-proxy
Sep 15 20:47:51 kind-worker3 kubelet[589656]: I0915 20:47:51.566963  589656 operation_generator.go:703] "MountVolume.SetUp succeeded for volume \"kube-proxy\" (UniqueName: \"kubernetes.io/configmap/6b53eb8b-e28c-454a-92e9-b342af428fa5-kube-proxy\") pod \"kube-proxy-zvz6f\" (UID: \"6b53eb8b-e28c-454a-92e9-b342af428fa5\") " pod="kube-system/kube-proxy-zvz6f"
Sep 15 20:47:51 kind-worker3 kubelet[589656]: I0915 20:47:51.601675  589656 atomic_writer.go:164] pod kube-system/kube-proxy-zvz6f volume kube-api-access-psmb2: write required for target directory /var/lib/kubelet/pods/6b53eb8b-e28c-454a-92e9-b342af428fa5/volumes/kubernetes.io~projected/kube-api-access-psmb2
Sep 15 20:47:51 kind-worker3 kubelet[589656]: I0915 20:47:51.602001  589656 atomic_writer.go:181] pod kube-system/kube-proxy-zvz6f volume kube-api-access-psmb2: performed write of new data to ts data directory: /var/lib/kubelet/pods/6b53eb8b-e28c-454a-92e9-b342af428fa5/volumes/kubernetes.io~projected/kube-api-access-psmb2/..2023_09_15_20_47_51.2629985024
Sep 15 20:47:51 kind-worker3 kubelet[589656]: I0915 20:47:51.602313  589656 operation_generator.go:703] "MountVolume.SetUp succeeded for volume \"kube-api-access-psmb2\" (UniqueName: \"kubernetes.io/projected/6b53eb8b-e28c-454a-92e9-b342af428fa5-kube-api-access-psmb2\") pod \"kube-proxy-zvz6f\" (UID: \"6b53eb8b-e28c-454a-92e9-b342af428fa5\") " pod="kube-system/kube-proxy-zvz6f"
Sep 15 20:47:52 kind-worker3 kubelet[589656]: I0915 20:47:52.497684  589656 kubelet.go:2160] "SyncLoop (housekeeping)"
Sep 15 20:47:52 kind-worker3 kubelet[589656]: I0915 20:47:52.506995  589656 kubelet_pods.go:1079] "Clean up pod workers for terminated pods"
Sep 15 20:47:52 kind-worker3 kubelet[589656]: I0915 20:47:52.507074  589656 kubelet_pods.go:1108] "Clean up probes for terminated pods"
Sep 15 20:47:52 kind-worker3 kubelet[589656]: I0915 20:47:52.509871  589656 kubelet_pods.go:1145] "Clean up orphaned pod statuses"
Sep 15 20:47:52 kind-worker3 kubelet[589656]: I0915 20:47:52.511842  589656 kubelet_pods.go:1164] "Clean up orphaned pod directories"
Sep 15 20:47:52 kind-worker3 kubelet[589656]: I0915 20:47:52.512022  589656 kubelet_pods.go:1175] "Clean up orphaned mirror pods"
Sep 15 20:47:52 kind-worker3 kubelet[589656]: I0915 20:47:52.512063  589656 kubelet_pods.go:1182] "Clean up orphaned pod cgroups"
Sep 15 20:47:52 kind-worker3 kubelet[589656]: I0915 20:47:52.512099  589656 kubelet.go:2168] "SyncLoop (housekeeping) end"
Sep 15 20:47:52 kind-worker3 kubelet[589656]: I0915 20:47:52.614925  589656 handler.go:293] error while reading "/proc/589656/fd/38" link: readlink /proc/589656/fd/38: no such file or directory
Sep 15 20:47:54 kind-worker3 kubelet[589656]: I0915 20:47:54.069215  589656 eviction_manager.go:237] "Eviction manager: synchronize housekeeping"
Sep 15 20:47:54 kind-worker3 kubelet[589656]: I0915 20:47:54.088060  589656 cri_stats_provider.go:525] "Unable to find network stats for sandbox" sandboxID="d0f4d02598fe0e9a32081b1554ae85df2b4224eb9a378fdcf99aa7c0035d33dc"
Sep 15 20:47:54 kind-worker3 kubelet[589656]: I0915 20:47:54.088508  589656 cri_stats_provider.go:525] "Unable to find network stats for sandbox" sandboxID="b477a0e3bdd1b445ce34dc6f173590a56dbfec252950ee838d5af2a2515a773b"
Sep 15 20:47:54 kind-worker3 kubelet[589656]: I0915 20:47:54.091124  589656 helpers.go:775] "Eviction manager:" log="observations" signal=nodefs.available resourceName="7782160Ki" capacity="51341792Ki" time="2023-09-15 20:47:54.071620628 +0000 UTC m=+2146337.994445807"
Sep 15 20:47:54 kind-worker3 kubelet[589656]: I0915 20:47:54.091174  589656 helpers.go:775] "Eviction manager:" log="observations" signal=nodefs.inodesFree resourceName="2345622" capacity="3276800" time="2023-09-15 20:47:54.071620628 +0000 UTC m=+2146337.994445807"
Sep 15 20:47:54 kind-worker3 kubelet[589656]: I0915 20:47:54.091204  589656 helpers.go:775] "Eviction manager:" log="observations" signal=imagefs.available resourceName="7782160Ki" capacity="51341792Ki" time="2023-09-15 20:47:48.904529925 +0000 UTC"
Sep 15 20:47:54 kind-worker3 kubelet[589656]: I0915 20:47:54.091230  589656 helpers.go:775] "Eviction manager:" log="observations" signal=imagefs.inodesFree resourceName="2345622" capacity="3276800" time="2023-09-15 20:47:48.904529925 +0000 UTC"
Sep 15 20:47:54 kind-worker3 kubelet[589656]: I0915 20:47:54.091255  589656 helpers.go:775] "Eviction manager:" log="observations" signal=pid.available resourceName="62176" capacity="63272" time="2023-09-15 20:47:54.089001944 +0000 UTC m=+2146338.011827080"
Sep 15 20:47:54 kind-worker3 kubelet[589656]: I0915 20:47:54.091280  589656 helpers.go:775] "Eviction manager:" log="observations" signal=memory.available resourceName="7832292Ki" capacity="8166760Ki" time="2023-09-15 20:47:54.071620628 +0000 UTC m=+2146337.994445807"
Sep 15 20:47:54 kind-worker3 kubelet[589656]: I0915 20:47:54.091306  589656 helpers.go:775] "Eviction manager:" log="observations" signal=allocatableMemory.available resourceName="8092276Ki" capacity="8166760Ki" time="2023-09-15 20:47:54.090908042 +0000 UTC m=+2146338.013733203"
Sep 15 20:47:54 kind-worker3 kubelet[589656]: I0915 20:47:54.091353  589656 eviction_manager.go:328] "Eviction manager: no resources are starved"
Sep 15 20:47:54 kind-worker3 kubelet[589656]: I0915 20:47:54.497901  589656 kubelet.go:2160] "SyncLoop (housekeeping)"
Sep 15 20:47:54 kind-worker3 kubelet[589656]: I0915 20:47:54.505349  589656 kubelet_pods.go:1079] "Clean up pod workers for terminated pods"
Sep 15 20:47:54 kind-worker3 kubelet[589656]: I0915 20:47:54.505400  589656 kubelet_pods.go:1108] "Clean up probes for terminated pods"
Sep 15 20:47:54 kind-worker3 kubelet[589656]: I0915 20:47:54.505427  589656 kubelet_pods.go:1145] "Clean up orphaned pod statuses"
Sep 15 20:47:54 kind-worker3 kubelet[589656]: I0915 20:47:54.507475  589656 kubelet_pods.go:1164] "Clean up orphaned pod directories"
Sep 15 20:47:54 kind-worker3 kubelet[589656]: I0915 20:47:54.507616  589656 kubelet_pods.go:1175] "Clean up orphaned mirror pods"
Sep 15 20:47:54 kind-worker3 kubelet[589656]: I0915 20:47:54.507644  589656 kubelet_pods.go:1182] "Clean up orphaned pod cgroups"
Sep 15 20:47:54 kind-worker3 kubelet[589656]: I0915 20:47:54.507674  589656 kubelet.go:2168] "SyncLoop (housekeeping) end"
Sep 15 20:47:54 kind-worker3 kubelet[589656]: I0915 20:47:54.929215  589656 kubelet.go:2346] "Container runtime status" status="Runtime Conditions: RuntimeReady=true reason: message:, NetworkReady=true reason: message:"
Sep 15 20:47:55 kind-worker3 kubelet[589656]: I0915 20:47:55.128245  589656 config.go:279] "Setting pods for source" source="api"
Sep 15 20:47:55 kind-worker3 kubelet[589656]: I0915 20:47:55.128803  589656 kubelet.go:2088] "SyncLoop DELETE" source="api" pods=[default/nginx-deployment-66f58bff7c-n8ncw]
Sep 15 20:47:55 kind-worker3 kubelet[589656]: I0915 20:47:55.128910  589656 pod_workers.go:625] "Pod is marked for graceful deletion, begin teardown" pod="default/nginx-deployment-66f58bff7c-n8ncw" podUID=9950f637-3ce8-428f-a136-02b68a154d8f
Sep 15 20:47:55 kind-worker3 kubelet[589656]: I0915 20:47:55.129004  589656 pod_workers.go:888] "Processing pod event" pod="default/nginx-deployment-66f58bff7c-n8ncw" podUID=9950f637-3ce8-428f-a136-02b68a154d8f updateType=1
Sep 15 20:47:55 kind-worker3 kubelet[589656]: I0915 20:47:55.129094  589656 pod_workers.go:1005] "Pod worker has observed request to terminate" pod="default/nginx-deployment-66f58bff7c-n8ncw" podUID=9950f637-3ce8-428f-a136-02b68a154d8f
Sep 15 20:47:55 kind-worker3 kubelet[589656]: I0915 20:47:55.129153  589656 kubelet.go:1743] "syncTerminatingPod enter" pod="default/nginx-deployment-66f58bff7c-n8ncw" podUID=9950f637-3ce8-428f-a136-02b68a154d8f
Sep 15 20:47:55 kind-worker3 kubelet[589656]: I0915 20:47:55.129179  589656 kubelet_pods.go:1432] "Generating pod status" pod="default/nginx-deployment-66f58bff7c-n8ncw"
Sep 15 20:47:55 kind-worker3 kubelet[589656]: I0915 20:47:55.129348  589656 kubelet_pods.go:1444] "Got phase for pod" pod="default/nginx-deployment-66f58bff7c-n8ncw" oldPhase=Running phase=Running
Sep 15 20:47:55 kind-worker3 kubelet[589656]: I0915 20:47:55.129605  589656 kubelet.go:1773] "Pod terminating with grace period" pod="default/nginx-deployment-66f58bff7c-n8ncw" podUID=9950f637-3ce8-428f-a136-02b68a154d8f gracePeriod=30
Sep 15 20:47:55 kind-worker3 kubelet[589656]: I0915 20:47:55.129862  589656 kuberuntime_container.go:718] "Killing container with a grace period override" pod="default/nginx-deployment-66f58bff7c-n8ncw" podUID=9950f637-3ce8-428f-a136-02b68a154d8f containerName="nginx" containerID="containerd://d7b7bcc17d59e448b6bf1dc609a1d24b871452bc3bacf9a4b4cdda794dbd4d89" gracePeriod=30
Sep 15 20:47:55 kind-worker3 kubelet[589656]: I0915 20:47:55.129950  589656 kuberuntime_container.go:722] "Killing container with a grace period" pod="default/nginx-deployment-66f58bff7c-n8ncw" podUID=9950f637-3ce8-428f-a136-02b68a154d8f containerName="nginx" containerID="containerd://d7b7bcc17d59e448b6bf1dc609a1d24b871452bc3bacf9a4b4cdda794dbd4d89" gracePeriod=30
Sep 15 20:47:55 kind-worker3 kubelet[589656]: I0915 20:47:55.129976  589656 event.go:294] "Event occurred" object="default/nginx-deployment-66f58bff7c-n8ncw" fieldPath="spec.containers{nginx}" kind="Pod" apiVersion="v1" type="Normal" reason="Killing" message="Stopping container nginx"
Sep 15 20:47:55 kind-worker3 kubelet[589656]: I0915 20:47:55.282912  589656 manager.go:1044] Destroyed container: "/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-pod9950f637_3ce8_428f_a136_02b68a154d8f.slice/cri-containerd-d7b7bcc17d59e448b6bf1dc609a1d24b871452bc3bacf9a4b4cdda794dbd4d89.scope" (aliases: [d7b7bcc17d59e448b6bf1dc609a1d24b871452bc3bacf9a4b4cdda794dbd4d89 /kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-pod9950f637_3ce8_428f_a136_02b68a154d8f.slice/cri-containerd-d7b7bcc17d59e448b6bf1dc609a1d24b871452bc3bacf9a4b4cdda794dbd4d89.scope], namespace: "containerd")
Sep 15 20:47:55 kind-worker3 kubelet[589656]: I0915 20:47:55.283033  589656 handler.go:325] Added event &{/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-pod9950f637_3ce8_428f_a136_02b68a154d8f.slice/cri-containerd-d7b7bcc17d59e448b6bf1dc609a1d24b871452bc3bacf9a4b4cdda794dbd4d89.scope 2023-09-15 20:47:55.283018965 +0000 UTC m=+2146339.205844103 containerDeletion {<nil>}}
Sep 15 20:47:55 kind-worker3 kubelet[589656]: I0915 20:47:55.291955  589656 status_manager.go:685] "Patch status for pod" pod="default/nginx-deployment-66f58bff7c-n8ncw" patch="{\"metadata\":{\"uid\":\"9950f637-3ce8-428f-a136-02b68a154d8f\"}}"
Sep 15 20:47:55 kind-worker3 kubelet[589656]: I0915 20:47:55.292011  589656 status_manager.go:692] "Status for pod is up-to-date" pod="default/nginx-deployment-66f58bff7c-n8ncw" statusVersion=3
Sep 15 20:47:55 kind-worker3 kubelet[589656]: I0915 20:47:55.292039  589656 kubelet_pods.go:929] "Pod is terminated, but some containers are still running" pod="default/nginx-deployment-66f58bff7c-n8ncw"
Sep 15 20:47:56 kind-worker3 kubelet[589656]: I0915 20:47:56.256413  589656 config.go:279] "Setting pods for source" source="file"
Sep 15 20:47:56 kind-worker3 kubelet[589656]: I0915 20:47:56.498485  589656 kubelet.go:2160] "SyncLoop (housekeeping)"
Sep 15 20:47:56 kind-worker3 kubelet[589656]: I0915 20:47:56.498825  589656 kubelet_pods.go:929] "Pod is terminated, but some containers are still running" pod="default/nginx-deployment-66f58bff7c-n8ncw"
Sep 15 20:47:56 kind-worker3 kubelet[589656]: I0915 20:47:56.512662  589656 kubelet_pods.go:1079] "Clean up pod workers for terminated pods"
Sep 15 20:47:56 kind-worker3 kubelet[589656]: I0915 20:47:56.512788  589656 kubelet_pods.go:1108] "Clean up probes for terminated pods"
Sep 15 20:47:56 kind-worker3 kubelet[589656]: I0915 20:47:56.562496  589656 kuberuntime_container.go:731] "Container exited normally" pod="default/nginx-deployment-66f58bff7c-n8ncw" podUID=9950f637-3ce8-428f-a136-02b68a154d8f containerName="nginx" containerID="containerd://d7b7bcc17d59e448b6bf1dc609a1d24b871452bc3bacf9a4b4cdda794dbd4d89"
Sep 15 20:47:56 kind-worker3 kubelet[589656]: I0915 20:47:56.562871  589656 kubelet_pods.go:1145] "Clean up orphaned pod statuses"
Sep 15 20:47:56 kind-worker3 kubelet[589656]: I0915 20:47:56.573966  589656 kubelet_pods.go:1164] "Clean up orphaned pod directories"
Sep 15 20:47:56 kind-worker3 kubelet[589656]: I0915 20:47:56.574116  589656 kubelet_pods.go:1175] "Clean up orphaned mirror pods"
Sep 15 20:47:56 kind-worker3 kubelet[589656]: I0915 20:47:56.574158  589656 kubelet_pods.go:1182] "Clean up orphaned pod cgroups"
Sep 15 20:47:56 kind-worker3 kubelet[589656]: I0915 20:47:56.574192  589656 kubelet.go:2168] "SyncLoop (housekeeping) end"
Sep 15 20:47:56 kind-worker3 kubelet[589656]: I0915 20:47:56.746917  589656 manager.go:1044] Destroyed container: "/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-pod9950f637_3ce8_428f_a136_02b68a154d8f.slice/cri-containerd-989c71a5f0b9e1fed741630292d401140445bec2e7fca6fb21d31525fc37072a.scope" (aliases: [989c71a5f0b9e1fed741630292d401140445bec2e7fca6fb21d31525fc37072a /kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-pod9950f637_3ce8_428f_a136_02b68a154d8f.slice/cri-containerd-989c71a5f0b9e1fed741630292d401140445bec2e7fca6fb21d31525fc37072a.scope], namespace: "containerd")
Sep 15 20:47:56 kind-worker3 kubelet[589656]: I0915 20:47:56.747009  589656 handler.go:325] Added event &{/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-pod9950f637_3ce8_428f_a136_02b68a154d8f.slice/cri-containerd-989c71a5f0b9e1fed741630292d401140445bec2e7fca6fb21d31525fc37072a.scope 2023-09-15 20:47:56.74699638 +0000 UTC m=+2146340.669821512 containerDeletion {<nil>}}
Sep 15 20:47:56 kind-worker3 kubelet[589656]: I0915 20:47:56.800432  589656 generic.go:155] "GenericPLEG" podUID=9950f637-3ce8-428f-a136-02b68a154d8f containerID="d7b7bcc17d59e448b6bf1dc609a1d24b871452bc3bacf9a4b4cdda794dbd4d89" oldState=running newState=exited
Sep 15 20:47:56 kind-worker3 kubelet[589656]: I0915 20:47:56.801119  589656 kuberuntime_manager.go:1037] "getSandboxIDByPodUID got sandbox IDs for pod" podSandboxID=[989c71a5f0b9e1fed741630292d401140445bec2e7fca6fb21d31525fc37072a] pod="default/nginx-deployment-66f58bff7c-n8ncw"
Sep 15 20:47:56 kind-worker3 kubelet[589656]: I0915 20:47:56.805957  589656 generic.go:421] "PLEG: Write status" pod="default/nginx-deployment-66f58bff7c-n8ncw"
Sep 15 20:47:56 kind-worker3 kubelet[589656]: I0915 20:47:56.806018  589656 generic.go:296] "Generic (PLEG): container finished" podID=9950f637-3ce8-428f-a136-02b68a154d8f containerID="d7b7bcc17d59e448b6bf1dc609a1d24b871452bc3bacf9a4b4cdda794dbd4d89" exitCode=0
Sep 15 20:47:56 kind-worker3 kubelet[589656]: I0915 20:47:56.806070  589656 kubelet.go:2110] "SyncLoop (PLEG): event for pod" pod="default/nginx-deployment-66f58bff7c-n8ncw" event=&{ID:9950f637-3ce8-428f-a136-02b68a154d8f Type:ContainerDied Data:d7b7bcc17d59e448b6bf1dc609a1d24b871452bc3bacf9a4b4cdda794dbd4d89}
Sep 15 20:47:57 kind-worker3 kubelet[589656]: I0915 20:47:57.194821  589656 qos_container_manager_linux.go:379] "Updated QoS cgroup configuration"
Sep 15 20:47:57 kind-worker3 kubelet[589656]: I0915 20:47:57.195674  589656 kuberuntime_manager.go:1037] "getSandboxIDByPodUID got sandbox IDs for pod" podSandboxID=[989c71a5f0b9e1fed741630292d401140445bec2e7fca6fb21d31525fc37072a] pod="default/nginx-deployment-66f58bff7c-n8ncw"
Sep 15 20:47:57 kind-worker3 kubelet[589656]: I0915 20:47:57.197844  589656 kubelet.go:1824] "Post-termination container state" pod="default/nginx-deployment-66f58bff7c-n8ncw" podUID=9950f637-3ce8-428f-a136-02b68a154d8f containers=[{Name:nginx State:exited ExitCode:0 FinishedAt:2023-09-15T20:47:55.22120103Z}]
Sep 15 20:47:57 kind-worker3 kubelet[589656]: I0915 20:47:57.197892  589656 kubelet.go:1831] "Pod termination stopped all running containers" pod="default/nginx-deployment-66f58bff7c-n8ncw" podUID=9950f637-3ce8-428f-a136-02b68a154d8f
Sep 15 20:47:57 kind-worker3 kubelet[589656]: I0915 20:47:57.197926  589656 kubelet.go:1833] "syncTerminatingPod exit" pod="default/nginx-deployment-66f58bff7c-n8ncw" podUID=9950f637-3ce8-428f-a136-02b68a154d8f
Sep 15 20:47:57 kind-worker3 kubelet[589656]: I0915 20:47:57.197951  589656 pod_workers.go:1050] "Pod terminated all containers successfully" pod="default/nginx-deployment-66f58bff7c-n8ncw" podUID=9950f637-3ce8-428f-a136-02b68a154d8f
Sep 15 20:47:57 kind-worker3 kubelet[589656]: I0915 20:47:57.198008  589656 pod_workers.go:988] "Processing pod event done" pod="default/nginx-deployment-66f58bff7c-n8ncw" podUID=9950f637-3ce8-428f-a136-02b68a154d8f updateType=1
Sep 15 20:47:57 kind-worker3 kubelet[589656]: I0915 20:47:57.198036  589656 pod_workers.go:888] "Processing pod event" pod="default/nginx-deployment-66f58bff7c-n8ncw" podUID=9950f637-3ce8-428f-a136-02b68a154d8f updateType=2
Sep 15 20:47:57 kind-worker3 kubelet[589656]: I0915 20:47:57.282967  589656 desired_state_of_world_populator.go:253] "Removing volume from desired state" pod="default/nginx-deployment-66f58bff7c-n8ncw" podUID=9950f637-3ce8-428f-a136-02b68a154d8f volumeName="kube-api-access-5c8xs"
Sep 15 20:47:57 kind-worker3 kubelet[589656]: I0915 20:47:57.323206  589656 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"kube-api-access-5c8xs\" (UniqueName: \"kubernetes.io/projected/9950f637-3ce8-428f-a136-02b68a154d8f-kube-api-access-5c8xs\") pod \"9950f637-3ce8-428f-a136-02b68a154d8f\" (UID: \"9950f637-3ce8-428f-a136-02b68a154d8f\") "
Sep 15 20:47:57 kind-worker3 kubelet[589656]: I0915 20:47:57.323301  589656 subpath_linux.go:244] Cleaning up subpath mounts for /var/lib/kubelet/pods/9950f637-3ce8-428f-a136-02b68a154d8f/volume-subpaths/kube-api-access-5c8xs
Sep 15 20:47:57 kind-worker3 kubelet[589656]: I0915 20:47:57.323371  589656 projected.go:366] Tearing down volume kube-api-access-5c8xs for pod 9950f637-3ce8-428f-a136-02b68a154d8f at /var/lib/kubelet/pods/9950f637-3ce8-428f-a136-02b68a154d8f/volumes/kubernetes.io~projected/kube-api-access-5c8xs
Sep 15 20:47:57 kind-worker3 kubelet[589656]: I0915 20:47:57.323693  589656 empty_dir_linux.go:99] Statfs_t of /var/lib/kubelet/pods/9950f637-3ce8-428f-a136-02b68a154d8f/volumes/kubernetes.io~projected/kube-api-access-5c8xs: {Type:16914836 Bsize:4096 Blocks:2041690 Bfree:2041687 Bavail:2041687 Files:1020845 Ffree:1020836 Fsid:{Val:[0 0]} Namelen:255 Frsize:4096 Flags:4128 Spare:[0 0 0 0]}
Sep 15 20:47:57 kind-worker3 kubelet[589656]: I0915 20:47:57.323752  589656 mount_linux.go:294] Unmounting /var/lib/kubelet/pods/9950f637-3ce8-428f-a136-02b68a154d8f/volumes/kubernetes.io~projected/kube-api-access-5c8xs
Sep 15 20:47:57 kind-worker3 kubelet[589656]: I0915 20:47:57.346013  589656 operation_generator.go:863] UnmountVolume.TearDown succeeded for volume "kubernetes.io/projected/9950f637-3ce8-428f-a136-02b68a154d8f-kube-api-access-5c8xs" (OuterVolumeSpecName: "kube-api-access-5c8xs") pod "9950f637-3ce8-428f-a136-02b68a154d8f" (UID: "9950f637-3ce8-428f-a136-02b68a154d8f"). InnerVolumeSpecName "kube-api-access-5c8xs". PluginName "kubernetes.io/projected", VolumeGidValue ""
Sep 15 20:47:57 kind-worker3 kubelet[589656]: I0915 20:47:57.424390  589656 reconciler.go:384] "Volume detached for volume \"kube-api-access-5c8xs\" (UniqueName: \"kubernetes.io/projected/9950f637-3ce8-428f-a136-02b68a154d8f-kube-api-access-5c8xs\") on node \"kind-worker3\" DevicePath \"\""
Sep 15 20:47:57 kind-worker3 kubelet[589656]: I0915 20:47:57.497966  589656 kubelet.go:2129] "SyncLoop (SYNC) pods" total=1 pods=[default/nginx-deployment-66f58bff7c-n8ncw]
Sep 15 20:47:57 kind-worker3 kubelet[589656]: I0915 20:47:57.809420  589656 generic.go:155] "GenericPLEG" podUID=9950f637-3ce8-428f-a136-02b68a154d8f containerID="989c71a5f0b9e1fed741630292d401140445bec2e7fca6fb21d31525fc37072a" oldState=running newState=exited
Sep 15 20:47:57 kind-worker3 kubelet[589656]: I0915 20:47:57.810316  589656 kuberuntime_manager.go:1037] "getSandboxIDByPodUID got sandbox IDs for pod" podSandboxID=[989c71a5f0b9e1fed741630292d401140445bec2e7fca6fb21d31525fc37072a] pod="default/nginx-deployment-66f58bff7c-n8ncw"
Sep 15 20:47:57 kind-worker3 kubelet[589656]: I0915 20:47:57.812485  589656 generic.go:421] "PLEG: Write status" pod="default/nginx-deployment-66f58bff7c-n8ncw"
Sep 15 20:47:57 kind-worker3 kubelet[589656]: I0915 20:47:57.812604  589656 kubelet.go:2110] "SyncLoop (PLEG): event for pod" pod="default/nginx-deployment-66f58bff7c-n8ncw" event=&{ID:9950f637-3ce8-428f-a136-02b68a154d8f Type:ContainerDied Data:989c71a5f0b9e1fed741630292d401140445bec2e7fca6fb21d31525fc37072a}
Sep 15 20:47:57 kind-worker3 kubelet[589656]: I0915 20:47:57.812697  589656 kuberuntime_container.go:950] "Removing container" containerID="d7b7bcc17d59e448b6bf1dc609a1d24b871452bc3bacf9a4b4cdda794dbd4d89"
Sep 15 20:47:57 kind-worker3 kubelet[589656]: I0915 20:47:57.812608  589656 kubelet.go:1841] "syncTerminatedPod enter" pod="default/nginx-deployment-66f58bff7c-n8ncw" podUID=9950f637-3ce8-428f-a136-02b68a154d8f
Sep 15 20:47:57 kind-worker3 kubelet[589656]: I0915 20:47:57.812758  589656 scope.go:110] "RemoveContainer" containerID="d7b7bcc17d59e448b6bf1dc609a1d24b871452bc3bacf9a4b4cdda794dbd4d89"
Sep 15 20:47:57 kind-worker3 kubelet[589656]: I0915 20:47:57.812793  589656 kubelet_pods.go:1432] "Generating pod status" pod="default/nginx-deployment-66f58bff7c-n8ncw"
Sep 15 20:47:57 kind-worker3 kubelet[589656]: I0915 20:47:57.812907  589656 kubelet_pods.go:1444] "Got phase for pod" pod="default/nginx-deployment-66f58bff7c-n8ncw" oldPhase=Running phase=Running
Sep 15 20:47:57 kind-worker3 kubelet[589656]: I0915 20:47:57.813110  589656 volume_manager.go:444] "Waiting for volumes to unmount for pod" pod="default/nginx-deployment-66f58bff7c-n8ncw"
Sep 15 20:47:57 kind-worker3 kubelet[589656]: I0915 20:47:57.813236  589656 volume_manager.go:471] "All volumes are unmounted for pod" pod="default/nginx-deployment-66f58bff7c-n8ncw"
Sep 15 20:47:57 kind-worker3 kubelet[589656]: I0915 20:47:57.813274  589656 kubelet.go:1854] "Pod termination unmounted volumes" pod="default/nginx-deployment-66f58bff7c-n8ncw" podUID=9950f637-3ce8-428f-a136-02b68a154d8f
Sep 15 20:47:57 kind-worker3 kubelet[589656]: I0915 20:47:57.813570  589656 reflector.go:225] Stopping reflector *v1.ConfigMap (0s) from object-"default"/"kube-root-ca.crt"
Sep 15 20:47:57 kind-worker3 kubelet[589656]: I0915 20:47:57.827971  589656 kubelet.go:1875] "Pod termination removed cgroups" pod="default/nginx-deployment-66f58bff7c-n8ncw" podUID=9950f637-3ce8-428f-a136-02b68a154d8f
Sep 15 20:47:57 kind-worker3 kubelet[589656]: I0915 20:47:57.828174  589656 kubelet.go:1880] "Pod is terminated and will need no more status updates" pod="default/nginx-deployment-66f58bff7c-n8ncw" podUID=9950f637-3ce8-428f-a136-02b68a154d8f
Sep 15 20:47:57 kind-worker3 kubelet[589656]: I0915 20:47:57.828244  589656 kubelet.go:1882] "syncTerminatedPod exit" pod="default/nginx-deployment-66f58bff7c-n8ncw" podUID=9950f637-3ce8-428f-a136-02b68a154d8f
Sep 15 20:47:57 kind-worker3 kubelet[589656]: I0915 20:47:57.828271  589656 pod_workers.go:1105] "Pod is complete and the worker can now stop" pod="default/nginx-deployment-66f58bff7c-n8ncw" podUID=9950f637-3ce8-428f-a136-02b68a154d8f
Sep 15 20:47:57 kind-worker3 kubelet[589656]: I0915 20:47:57.828338  589656 pod_workers.go:959] "Processing pod event done" pod="default/nginx-deployment-66f58bff7c-n8ncw" podUID=9950f637-3ce8-428f-a136-02b68a154d8f updateType=2
Sep 15 20:47:57 kind-worker3 kubelet[589656]: I0915 20:47:57.828693  589656 manager.go:1044] Destroyed container: "/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-pod9950f637_3ce8_428f_a136_02b68a154d8f.slice" (aliases: [], namespace: "")
Sep 15 20:47:57 kind-worker3 kubelet[589656]: I0915 20:47:57.828777  589656 handler.go:325] Added event &{/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-pod9950f637_3ce8_428f_a136_02b68a154d8f.slice 2023-09-15 20:47:57.828723372 +0000 UTC m=+2146341.751548485 containerDeletion {<nil>}}
Sep 15 20:47:57 kind-worker3 kubelet[589656]: I0915 20:47:57.846257  589656 config.go:279] "Setting pods for source" source="api"
Sep 15 20:47:57 kind-worker3 kubelet[589656]: I0915 20:47:57.846657  589656 kubelet.go:2085] "SyncLoop RECONCILE" source="api" pods=[default/nginx-deployment-66f58bff7c-n8ncw]
Sep 15 20:47:57 kind-worker3 kubelet[589656]: I0915 20:47:57.847322  589656 status_manager.go:685] "Patch status for pod" pod="default/nginx-deployment-66f58bff7c-n8ncw" patch="{\"metadata\":{\"uid\":\"9950f637-3ce8-428f-a136-02b68a154d8f\"},\"status\":{\"$setElementOrder/conditions\":[{\"type\":\"Initialized\"},{\"type\":\"Ready\"},{\"type\":\"ContainersReady\"},{\"type\":\"PodScheduled\"}],\"conditions\":[{\"lastTransitionTime\":\"2023-09-15T20:47:57Z\",\"message\":\"containers with unready status: [nginx]\",\"reason\":\"ContainersNotReady\",\"status\":\"False\",\"type\":\"Ready\"},{\"lastTransitionTime\":\"2023-09-15T20:47:57Z\",\"message\":\"containers with unready status: [nginx]\",\"reason\":\"ContainersNotReady\",\"status\":\"False\",\"type\":\"ContainersReady\"}],\"containerStatuses\":[{\"containerID\":\"containerd://d7b7bcc17d59e448b6bf1dc609a1d24b871452bc3bacf9a4b4cdda794dbd4d89\",\"image\":\"docker.io/library/nginx:1.14.2\",\"imageID\":\"docker.io/library/nginx@sha256:f7988fb6c02e0ce69257d9bd9cf37ae20a60f1df7563c3a2a6abe24160306b8d\",\"lastState\":{},\"name\":\"nginx\",\"ready\":false,\"restartCount\":0,\"started\":false,\"state\":{\"terminated\":{\"containerID\":\"containerd://d7b7bcc17d59e448b6bf1dc609a1d24b871452bc3bacf9a4b4cdda794dbd4d89\",\"exitCode\":0,\"finishedAt\":\"2023-09-15T20:47:55Z\",\"reason\":\"Completed\",\"startedAt\":\"2023-09-15T20:47:47Z\"}}}]}}"
Sep 15 20:47:57 kind-worker3 kubelet[589656]: I0915 20:47:57.847504  589656 status_manager.go:694] "Status for pod updated successfully" pod="default/nginx-deployment-66f58bff7c-n8ncw" statusVersion=4 status={Phase:Running Conditions:[{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-09-15 20:47:44 +0000 UTC Reason: Message:} {Type:Ready Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-09-15 20:47:57 +0000 UTC Reason:ContainersNotReady Message:containers with unready status: [nginx]} {Type:ContainersReady Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-09-15 20:47:57 +0000 UTC Reason:ContainersNotReady Message:containers with unready status: [nginx]} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-09-15 20:47:44 +0000 UTC Reason: Message:}] Message: Reason: NominatedNodeName: HostIP:172.18.0.4 PodIP:10.244.3.69 PodIPs:[{IP:10.244.3.69}] StartTime:2023-09-15 20:47:44 +0000 UTC InitContainerStatuses:[] ContainerStatuses:[{Name:nginx State:{Waiting:nil Running:nil Terminated:&ContainerStateTerminated{ExitCode:0,Signal:0,Reason:Completed,Message:,StartedAt:2023-09-15 20:47:47 +0000 UTC,FinishedAt:2023-09-15 20:47:55 +0000 UTC,ContainerID:containerd://d7b7bcc17d59e448b6bf1dc609a1d24b871452bc3bacf9a4b4cdda794dbd4d89,}} LastTerminationState:{Waiting:nil Running:nil Terminated:nil} Ready:false RestartCount:0 Image:docker.io/library/nginx:1.14.2 ImageID:docker.io/library/nginx@sha256:f7988fb6c02e0ce69257d9bd9cf37ae20a60f1df7563c3a2a6abe24160306b8d ContainerID:containerd://d7b7bcc17d59e448b6bf1dc609a1d24b871452bc3bacf9a4b4cdda794dbd4d89 Started:0xc00154cc89}] QOSClass:Burstable EphemeralContainerStatuses:[]}
Sep 15 20:47:57 kind-worker3 kubelet[589656]: I0915 20:47:57.848003  589656 kubelet_pods.go:955] "Pod is terminated and all resources are reclaimed" pod="default/nginx-deployment-66f58bff7c-n8ncw"
Sep 15 20:47:58 kind-worker3 kubelet[589656]: I0915 20:47:58.274074  589656 config.go:279] "Setting pods for source" source="api"
Sep 15 20:47:58 kind-worker3 kubelet[589656]: I0915 20:47:58.274329  589656 kubelet.go:2088] "SyncLoop DELETE" source="api" pods=[default/nginx-deployment-66f58bff7c-n8ncw]
Sep 15 20:47:58 kind-worker3 kubelet[589656]: I0915 20:47:58.274413  589656 pod_workers.go:611] "Pod is finished processing, no further updates" pod="default/nginx-deployment-66f58bff7c-n8ncw" podUID=9950f637-3ce8-428f-a136-02b68a154d8f
Sep 15 20:47:58 kind-worker3 kubelet[589656]: I0915 20:47:58.308852  589656 config.go:279] "Setting pods for source" source="api"
Sep 15 20:47:58 kind-worker3 kubelet[589656]: I0915 20:47:58.309049  589656 kubelet.go:2082] "SyncLoop REMOVE" source="api" pods=[default/nginx-deployment-66f58bff7c-n8ncw]
Sep 15 20:47:58 kind-worker3 kubelet[589656]: I0915 20:47:58.309126  589656 kubelet.go:1927] "Pod has been deleted and must be killed" pod="default/nginx-deployment-66f58bff7c-n8ncw" podUID=9950f637-3ce8-428f-a136-02b68a154d8f
Sep 15 20:47:58 kind-worker3 kubelet[589656]: I0915 20:47:58.309170  589656 pod_workers.go:611] "Pod is finished processing, no further updates" pod="default/nginx-deployment-66f58bff7c-n8ncw" podUID=9950f637-3ce8-428f-a136-02b68a154d8f
Sep 15 20:47:58 kind-worker3 kubelet[589656]: I0915 20:47:58.311982  589656 status_manager.go:713] "Pod fully terminated and removed from etcd" pod="default/nginx-deployment-66f58bff7c-n8ncw"
Sep 15 20:47:58 kind-worker3 kubelet[589656]: I0915 20:47:58.359144  589656 status_manager.go:656] "Pod does not exist on the server" podUID=9950f637-3ce8-428f-a136-02b68a154d8f pod="default/nginx-deployment-66f58bff7c-n8ncw"
Sep 15 20:47:58 kind-worker3 kubelet[589656]: I0915 20:47:58.498952  589656 kubelet.go:2160] "SyncLoop (housekeeping)"
Sep 15 20:47:58 kind-worker3 kubelet[589656]: I0915 20:47:58.511174  589656 kubelet_pods.go:1079] "Clean up pod workers for terminated pods"
Sep 15 20:47:58 kind-worker3 kubelet[589656]: I0915 20:47:58.511260  589656 pod_workers.go:1258] "Pod has been terminated and is no longer known to the kubelet, remove all history" podUID=9950f637-3ce8-428f-a136-02b68a154d8f
Sep 15 20:47:58 kind-worker3 kubelet[589656]: I0915 20:47:58.511288  589656 kubelet_pods.go:1108] "Clean up probes for terminated pods"
Sep 15 20:47:58 kind-worker3 kubelet[589656]: I0915 20:47:58.511314  589656 kubelet_pods.go:1131] "Clean up orphaned pod containers" podUID=9950f637-3ce8-428f-a136-02b68a154d8f
Sep 15 20:47:58 kind-worker3 kubelet[589656]: I0915 20:47:58.511344  589656 pod_workers.go:571] "Pod is being synced for the first time" pod="default/nginx-deployment-66f58bff7c-n8ncw" podUID=9950f637-3ce8-428f-a136-02b68a154d8f
Sep 15 20:47:58 kind-worker3 kubelet[589656]: I0915 20:47:58.511373  589656 pod_workers.go:620] "Pod is orphaned and must be torn down" pod="default/nginx-deployment-66f58bff7c-n8ncw" podUID=9950f637-3ce8-428f-a136-02b68a154d8f
Sep 15 20:47:58 kind-worker3 kubelet[589656]: I0915 20:47:58.511419  589656 kubelet_pods.go:1145] "Clean up orphaned pod statuses"
Sep 15 20:47:58 kind-worker3 kubelet[589656]: I0915 20:47:58.511648  589656 pod_workers.go:888] "Processing pod event" pod="default/nginx-deployment-66f58bff7c-n8ncw" podUID=9950f637-3ce8-428f-a136-02b68a154d8f updateType=1
Sep 15 20:47:58 kind-worker3 kubelet[589656]: I0915 20:47:58.511721  589656 pod_workers.go:1005] "Pod worker has observed request to terminate" pod="default/nginx-deployment-66f58bff7c-n8ncw" podUID=9950f637-3ce8-428f-a136-02b68a154d8f
Sep 15 20:47:58 kind-worker3 kubelet[589656]: I0915 20:47:58.511785  589656 kubelet.go:1743] "syncTerminatingPod enter" pod="default/nginx-deployment-66f58bff7c-n8ncw" podUID=9950f637-3ce8-428f-a136-02b68a154d8f
Sep 15 20:47:58 kind-worker3 kubelet[589656]: I0915 20:47:58.511814  589656 kubelet.go:1752] "Pod terminating with grace period" pod="default/nginx-deployment-66f58bff7c-n8ncw" podUID=9950f637-3ce8-428f-a136-02b68a154d8f gracePeriod=1
Sep 15 20:47:58 kind-worker3 kubelet[589656]: I0915 20:47:58.513419  589656 kubelet_pods.go:1164] "Clean up orphaned pod directories"
Sep 15 20:47:58 kind-worker3 kubelet[589656]: I0915 20:47:58.514364  589656 kubelet_volumes.go:160] "Cleaned up orphaned pod volumes dir" podUID=9950f637-3ce8-428f-a136-02b68a154d8f path="/var/lib/kubelet/pods/9950f637-3ce8-428f-a136-02b68a154d8f/volumes"
Sep 15 20:47:58 kind-worker3 kubelet[589656]: I0915 20:47:58.515608  589656 kubelet_volumes.go:236] "Orphaned pod found, removing" podUID=9950f637-3ce8-428f-a136-02b68a154d8f
Sep 15 20:47:58 kind-worker3 kubelet[589656]: I0915 20:47:58.515698  589656 kubelet_pods.go:1175] "Clean up orphaned mirror pods"
Sep 15 20:47:58 kind-worker3 kubelet[589656]: I0915 20:47:58.515731  589656 kubelet_pods.go:1182] "Clean up orphaned pod cgroups"
Sep 15 20:47:58 kind-worker3 kubelet[589656]: I0915 20:47:58.515767  589656 kubelet.go:2168] "SyncLoop (housekeeping) end"
Sep 15 20:47:58 kind-worker3 kubelet[589656]: I0915 20:47:58.549739  589656 qos_container_manager_linux.go:379] "Updated QoS cgroup configuration"
Sep 15 20:47:58 kind-worker3 kubelet[589656]: I0915 20:47:58.549799  589656 kubelet.go:1762] "Pod termination stopped all running orphan containers" pod="default/nginx-deployment-66f58bff7c-n8ncw" podUID=9950f637-3ce8-428f-a136-02b68a154d8f
Sep 15 20:47:58 kind-worker3 kubelet[589656]: I0915 20:47:58.549826  589656 kubelet.go:1763] "syncTerminatingPod exit" pod="default/nginx-deployment-66f58bff7c-n8ncw" podUID=9950f637-3ce8-428f-a136-02b68a154d8f
Sep 15 20:47:58 kind-worker3 kubelet[589656]: I0915 20:47:58.549870  589656 pod_workers.go:1081] "Pod terminated all orphaned containers successfully and worker can now stop" pod="default/nginx-deployment-66f58bff7c-n8ncw" podUID=9950f637-3ce8-428f-a136-02b68a154d8f
Sep 15 20:47:58 kind-worker3 kubelet[589656]: I0915 20:47:58.549909  589656 pod_workers.go:969] "Processing pod event done" pod="default/nginx-deployment-66f58bff7c-n8ncw" podUID=9950f637-3ce8-428f-a136-02b68a154d8f updateType=1
Sep 15 20:47:58 kind-worker3 kubelet[589656]: I0915 20:47:58.814705  589656 generic.go:155] "GenericPLEG" podUID=9950f637-3ce8-428f-a136-02b68a154d8f containerID="d7b7bcc17d59e448b6bf1dc609a1d24b871452bc3bacf9a4b4cdda794dbd4d89" oldState=exited newState=non-existent
Sep 15 20:47:58 kind-worker3 kubelet[589656]: I0915 20:47:58.815222  589656 kuberuntime_manager.go:1037] "getSandboxIDByPodUID got sandbox IDs for pod" podSandboxID=[989c71a5f0b9e1fed741630292d401140445bec2e7fca6fb21d31525fc37072a] pod="default/nginx-deployment-66f58bff7c-n8ncw"
Sep 15 20:47:58 kind-worker3 kubelet[589656]: I0915 20:47:58.816431  589656 generic.go:421] "PLEG: Write status" pod="default/nginx-deployment-66f58bff7c-n8ncw"
Sep 15 20:47:59 kind-worker3 kubelet[589656]: I0915 20:47:59.405448  589656 httplog.go:131] "HTTP" verb="GET" URI="/metrics/resource" latency="34.220878ms" userAgent="metrics-server/v0.6.3 (linux/amd64) kubernetes/a938798" audit-ID="" srcIP="172.18.0.3:35538" resp=200
Sep 15 20:47:59 kind-worker3 kubelet[589656]: I0915 20:47:59.930459  589656 kubelet.go:2346] "Container runtime status" status="Runtime Conditions: RuntimeReady=true reason: message:, NetworkReady=true reason: message:"
Sep 15 20:48:00 kind-worker3 kubelet[589656]: I0915 20:48:00.498417  589656 kubelet.go:2160] "SyncLoop (housekeeping)"
Sep 15 20:48:00 kind-worker3 kubelet[589656]: I0915 20:48:00.507569  589656 kubelet_pods.go:1079] "Clean up pod workers for terminated pods"
Sep 15 20:48:00 kind-worker3 kubelet[589656]: I0915 20:48:00.507660  589656 pod_workers.go:1258] "Pod has been terminated and is no longer known to the kubelet, remove all history" podUID=9950f637-3ce8-428f-a136-02b68a154d8f
Sep 15 20:48:00 kind-worker3 kubelet[589656]: I0915 20:48:00.507719  589656 kubelet_pods.go:1108] "Clean up probes for terminated pods"
Sep 15 20:48:00 kind-worker3 kubelet[589656]: I0915 20:48:00.512230  589656 kubelet_pods.go:1145] "Clean up orphaned pod statuses"
Sep 15 20:48:00 kind-worker3 kubelet[589656]: I0915 20:48:00.515759  589656 kubelet_pods.go:1164] "Clean up orphaned pod directories"
Sep 15 20:48:00 kind-worker3 kubelet[589656]: I0915 20:48:00.515931  589656 kubelet_pods.go:1175] "Clean up orphaned mirror pods"
Sep 15 20:48:00 kind-worker3 kubelet[589656]: I0915 20:48:00.515961  589656 kubelet_pods.go:1182] "Clean up orphaned pod cgroups"
Sep 15 20:48:00 kind-worker3 kubelet[589656]: I0915 20:48:00.515990  589656 kubelet.go:2168] "SyncLoop (housekeeping) end"
Sep 15 20:48:00 kind-worker3 kubelet[589656]: I0915 20:48:00.912266  589656 setters.go:88] "Using node IP" IP="172.18.0.4"
Sep 15 20:48:02 kind-worker3 kubelet[589656]: I0915 20:48:02.498167  589656 kubelet.go:2160] "SyncLoop (housekeeping)"
Sep 15 20:48:02 kind-worker3 kubelet[589656]: I0915 20:48:02.511854  589656 kubelet_pods.go:1079] "Clean up pod workers for terminated pods"
Sep 15 20:48:02 kind-worker3 kubelet[589656]: I0915 20:48:02.511888  589656 kubelet_pods.go:1108] "Clean up probes for terminated pods"
Sep 15 20:48:02 kind-worker3 kubelet[589656]: I0915 20:48:02.515106  589656 kubelet_pods.go:1145] "Clean up orphaned pod statuses"
Sep 15 20:48:02 kind-worker3 kubelet[589656]: I0915 20:48:02.516465  589656 kubelet_pods.go:1164] "Clean up orphaned pod directories"
Sep 15 20:48:02 kind-worker3 kubelet[589656]: I0915 20:48:02.516609  589656 kubelet_pods.go:1175] "Clean up orphaned mirror pods"
Sep 15 20:48:02 kind-worker3 kubelet[589656]: I0915 20:48:02.516649  589656 kubelet_pods.go:1182] "Clean up orphaned pod cgroups"
Sep 15 20:48:02 kind-worker3 kubelet[589656]: I0915 20:48:02.516680  589656 kubelet.go:2168] "SyncLoop (housekeeping) end"
Sep 15 20:48:03 kind-worker3 kubelet[589656]: I0915 20:48:03.202802  589656 handler.go:293] error while reading "/proc/589656/fd/38" link: readlink /proc/589656/fd/38: no such file or directory
Sep 15 20:48:04 kind-worker3 kubelet[589656]: I0915 20:48:04.092377  589656 eviction_manager.go:237] "Eviction manager: synchronize housekeeping"
Sep 15 20:48:04 kind-worker3 kubelet[589656]: I0915 20:48:04.110755  589656 cri_stats_provider.go:525] "Unable to find network stats for sandbox" sandboxID="b477a0e3bdd1b445ce34dc6f173590a56dbfec252950ee838d5af2a2515a773b"
Sep 15 20:48:04 kind-worker3 kubelet[589656]: I0915 20:48:04.111081  589656 cri_stats_provider.go:525] "Unable to find network stats for sandbox" sandboxID="d0f4d02598fe0e9a32081b1554ae85df2b4224eb9a378fdcf99aa7c0035d33dc"
Sep 15 20:48:04 kind-worker3 kubelet[589656]: I0915 20:48:04.115507  589656 helpers.go:775] "Eviction manager:" log="observations" signal=pid.available resourceName="62285" capacity="63272" time="2023-09-15 20:48:04.111802322 +0000 UTC m=+2146348.034627494"
Sep 15 20:48:04 kind-worker3 kubelet[589656]: I0915 20:48:04.115626  589656 helpers.go:775] "Eviction manager:" log="observations" signal=memory.available resourceName="7839348Ki" capacity="8166760Ki" time="2023-09-15 20:48:04.095894403 +0000 UTC m=+2146348.018719639"
Sep 15 20:48:04 kind-worker3 kubelet[589656]: I0915 20:48:04.115696  589656 helpers.go:775] "Eviction manager:" log="observations" signal=allocatableMemory.available resourceName="8096648Ki" capacity="8166760Ki" time="2023-09-15 20:48:04.115167982 +0000 UTC m=+2146348.037993173"
Sep 15 20:48:04 kind-worker3 kubelet[589656]: I0915 20:48:04.115757  589656 helpers.go:775] "Eviction manager:" log="observations" signal=nodefs.available resourceName="7779292Ki" capacity="51341792Ki" time="2023-09-15 20:48:04.095894403 +0000 UTC m=+2146348.018719639"
Sep 15 20:48:04 kind-worker3 kubelet[589656]: I0915 20:48:04.115817  589656 helpers.go:775] "Eviction manager:" log="observations" signal=nodefs.inodesFree resourceName="2345704" capacity="3276800" time="2023-09-15 20:48:04.095894403 +0000 UTC m=+2146348.018719639"
Sep 15 20:48:04 kind-worker3 kubelet[589656]: I0915 20:48:04.115892  589656 helpers.go:775] "Eviction manager:" log="observations" signal=imagefs.available resourceName="7779292Ki" capacity="51341792Ki" time="2023-09-15 20:47:58.913382277 +0000 UTC"
Sep 15 20:48:04 kind-worker3 kubelet[589656]: I0915 20:48:04.115953  589656 helpers.go:775] "Eviction manager:" log="observations" signal=imagefs.inodesFree resourceName="2345704" capacity="3276800" time="2023-09-15 20:47:58.913382277 +0000 UTC"
Sep 15 20:48:04 kind-worker3 kubelet[589656]: I0915 20:48:04.116029  589656 eviction_manager.go:328] "Eviction manager: no resources are starved"
Sep 15 20:48:04 kind-worker3 kubelet[589656]: I0915 20:48:04.498122  589656 kubelet.go:2160] "SyncLoop (housekeeping)"
Sep 15 20:48:04 kind-worker3 kubelet[589656]: I0915 20:48:04.509212  589656 kubelet_pods.go:1079] "Clean up pod workers for terminated pods"
Sep 15 20:48:04 kind-worker3 kubelet[589656]: I0915 20:48:04.509276  589656 kubelet_pods.go:1108] "Clean up probes for terminated pods"
Sep 15 20:48:04 kind-worker3 kubelet[589656]: I0915 20:48:04.509302  589656 kubelet_pods.go:1145] "Clean up orphaned pod statuses"
Sep 15 20:48:04 kind-worker3 kubelet[589656]: I0915 20:48:04.517797  589656 kubelet_pods.go:1164] "Clean up orphaned pod directories"
Sep 15 20:48:04 kind-worker3 kubelet[589656]: I0915 20:48:04.518036  589656 kubelet_pods.go:1175] "Clean up orphaned mirror pods"
Sep 15 20:48:04 kind-worker3 kubelet[589656]: I0915 20:48:04.518082  589656 kubelet_pods.go:1182] "Clean up orphaned pod cgroups"
Sep 15 20:48:04 kind-worker3 kubelet[589656]: I0915 20:48:04.518133  589656 kubelet.go:2168] "SyncLoop (housekeeping) end"
Sep 15 20:48:04 kind-worker3 kubelet[589656]: I0915 20:48:04.863774  589656 config.go:279] "Setting pods for source" source="api"
Sep 15 20:48:04 kind-worker3 kubelet[589656]: I0915 20:48:04.863975  589656 config.go:384] "Receiving a new pod" pod="default/nginx-deployment-66f58bff7c-lhxbk"
Sep 15 20:48:04 kind-worker3 kubelet[589656]: I0915 20:48:04.864173  589656 kubelet.go:2072] "SyncLoop ADD" source="api" pods=[default/nginx-deployment-66f58bff7c-lhxbk]
Sep 15 20:48:04 kind-worker3 kubelet[589656]: I0915 20:48:04.864293  589656 topology_manager.go:200] "Topology Admit Handler"
Sep 15 20:48:04 kind-worker3 kubelet[589656]: I0915 20:48:04.864375  589656 manager.go:914] "Looking for needed resources" needed=1 resourceName="cpu"
Sep 15 20:48:04 kind-worker3 kubelet[589656]: E0915 20:48:04.864490  589656 cpu_manager.go:394] "RemoveStaleState: removing container" podUID="9950f637-3ce8-428f-a136-02b68a154d8f" containerName="nginx"
Sep 15 20:48:04 kind-worker3 kubelet[589656]: I0915 20:48:04.864556  589656 state_mem.go:107] "Deleted CPUSet assignment" podUID="9950f637-3ce8-428f-a136-02b68a154d8f" containerName="nginx"
Sep 15 20:48:04 kind-worker3 kubelet[589656]: I0915 20:48:04.864696  589656 memory_manager.go:345] "RemoveStaleState removing state" podUID="9950f637-3ce8-428f-a136-02b68a154d8f" containerName="nginx"
Sep 15 20:48:04 kind-worker3 kubelet[589656]: I0915 20:48:04.864945  589656 pod_workers.go:571] "Pod is being synced for the first time" pod="default/nginx-deployment-66f58bff7c-lhxbk" podUID=f73dab4a-7b50-4d78-87ff-9600f1129748
Sep 15 20:48:04 kind-worker3 kubelet[589656]: I0915 20:48:04.865169  589656 pod_workers.go:888] "Processing pod event" pod="default/nginx-deployment-66f58bff7c-lhxbk" podUID=f73dab4a-7b50-4d78-87ff-9600f1129748 updateType=0
Sep 15 20:48:04 kind-worker3 kubelet[589656]: I0915 20:48:04.865328  589656 kubelet.go:1501] "syncPod enter" pod="default/nginx-deployment-66f58bff7c-lhxbk" podUID=f73dab4a-7b50-4d78-87ff-9600f1129748
Sep 15 20:48:04 kind-worker3 kubelet[589656]: I0915 20:48:04.865415  589656 kubelet_pods.go:1432] "Generating pod status" pod="default/nginx-deployment-66f58bff7c-lhxbk"
Sep 15 20:48:04 kind-worker3 kubelet[589656]: I0915 20:48:04.865597  589656 kubelet_pods.go:1444] "Got phase for pod" pod="default/nginx-deployment-66f58bff7c-lhxbk" oldPhase=Pending phase=Pending
Sep 15 20:48:04 kind-worker3 kubelet[589656]: I0915 20:48:04.866212  589656 reflector.go:219] Starting reflector *v1.ConfigMap (0s) from object-"default"/"kube-root-ca.crt"
Sep 15 20:48:04 kind-worker3 kubelet[589656]: I0915 20:48:04.866274  589656 reflector.go:255] Listing and watching *v1.ConfigMap from object-"default"/"kube-root-ca.crt"
Sep 15 20:48:04 kind-worker3 kubelet[589656]: I0915 20:48:04.887898  589656 qos_container_manager_linux.go:379] "Updated QoS cgroup configuration"
Sep 15 20:48:04 kind-worker3 kubelet[589656]: I0915 20:48:04.890902  589656 config.go:279] "Setting pods for source" source="api"
Sep 15 20:48:04 kind-worker3 kubelet[589656]: I0915 20:48:04.891109  589656 kubelet.go:2085] "SyncLoop RECONCILE" source="api" pods=[default/nginx-deployment-66f58bff7c-lhxbk]
Sep 15 20:48:04 kind-worker3 kubelet[589656]: I0915 20:48:04.891438  589656 status_manager.go:685] "Patch status for pod" pod="default/nginx-deployment-66f58bff7c-lhxbk" patch="{\"metadata\":{\"uid\":\"f73dab4a-7b50-4d78-87ff-9600f1129748\"},\"status\":{\"$setElementOrder/conditions\":[{\"type\":\"Initialized\"},{\"type\":\"Ready\"},{\"type\":\"ContainersReady\"},{\"type\":\"PodScheduled\"}],\"conditions\":[{\"lastProbeTime\":null,\"lastTransitionTime\":\"2023-09-15T20:48:04Z\",\"status\":\"True\",\"type\":\"Initialized\"},{\"lastProbeTime\":null,\"lastTransitionTime\":\"2023-09-15T20:48:04Z\",\"message\":\"containers with unready status: [nginx]\",\"reason\":\"ContainersNotReady\",\"status\":\"False\",\"type\":\"Ready\"},{\"lastProbeTime\":null,\"lastTransitionTime\":\"2023-09-15T20:48:04Z\",\"message\":\"containers with unready status: [nginx]\",\"reason\":\"ContainersNotReady\",\"status\":\"False\",\"type\":\"ContainersReady\"}],\"containerStatuses\":[{\"image\":\"nginx:1.14.2\",\"imageID\":\"\",\"lastState\":{},\"name\":\"nginx\",\"ready\":false,\"restartCount\":0,\"started\":false,\"state\":{\"waiting\":{\"reason\":\"ContainerCreating\"}}}],\"hostIP\":\"172.18.0.4\",\"startTime\":\"2023-09-15T20:48:04Z\"}}"
Sep 15 20:48:04 kind-worker3 kubelet[589656]: I0915 20:48:04.891554  589656 status_manager.go:694] "Status for pod updated successfully" pod="default/nginx-deployment-66f58bff7c-lhxbk" statusVersion=1 status={Phase:Pending Conditions:[{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-09-15 20:48:04 +0000 UTC Reason: Message:} {Type:Ready Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-09-15 20:48:04 +0000 UTC Reason:ContainersNotReady Message:containers with unready status: [nginx]} {Type:ContainersReady Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-09-15 20:48:04 +0000 UTC Reason:ContainersNotReady Message:containers with unready status: [nginx]} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-09-15 20:48:04 +0000 UTC Reason: Message:}] Message: Reason: NominatedNodeName: HostIP:172.18.0.4 PodIP: PodIPs:[] StartTime:2023-09-15 20:48:04 +0000 UTC InitContainerStatuses:[] ContainerStatuses:[{Name:nginx State:{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,} Running:nil Terminated:nil} LastTerminationState:{Waiting:nil Running:nil Terminated:nil} Ready:false RestartCount:0 Image:nginx:1.14.2 ImageID: ContainerID: Started:0xc001b17d4c}] QOSClass:Burstable EphemeralContainerStatuses:[]}
Sep 15 20:48:04 kind-worker3 kubelet[589656]: I0915 20:48:04.897630  589656 factory.go:262] Factory "containerd" was unable to handle container "/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-podf73dab4a_7b50_4d78_87ff_9600f1129748.slice"
Sep 15 20:48:04 kind-worker3 kubelet[589656]: I0915 20:48:04.897707  589656 factory.go:262] Factory "systemd" was unable to handle container "/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-podf73dab4a_7b50_4d78_87ff_9600f1129748.slice"
Sep 15 20:48:04 kind-worker3 kubelet[589656]: I0915 20:48:04.897767  589656 factory.go:258] Using factory "raw" for container "/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-podf73dab4a_7b50_4d78_87ff_9600f1129748.slice"
Sep 15 20:48:04 kind-worker3 kubelet[589656]: I0915 20:48:04.898934  589656 manager.go:988] Added container: "/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-podf73dab4a_7b50_4d78_87ff_9600f1129748.slice" (aliases: [], namespace: "")
Sep 15 20:48:04 kind-worker3 kubelet[589656]: I0915 20:48:04.899471  589656 handler.go:325] Added event &{/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-podf73dab4a_7b50_4d78_87ff_9600f1129748.slice 2023-09-15 20:48:04.891058779 +0000 UTC containerCreation {<nil>}}
Sep 15 20:48:04 kind-worker3 kubelet[589656]: I0915 20:48:04.899543  589656 container.go:530] Start housekeeping for container "/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-podf73dab4a_7b50_4d78_87ff_9600f1129748.slice"
Sep 15 20:48:04 kind-worker3 kubelet[589656]: I0915 20:48:04.903870  589656 volume_manager.go:404] "Waiting for volumes to attach and mount for pod" pod="default/nginx-deployment-66f58bff7c-lhxbk"
Sep 15 20:48:04 kind-worker3 kubelet[589656]: I0915 20:48:04.932272  589656 kubelet.go:2346] "Container runtime status" status="Runtime Conditions: RuntimeReady=true reason: message:, NetworkReady=true reason: message:"
Sep 15 20:48:04 kind-worker3 kubelet[589656]: I0915 20:48:04.938904  589656 desired_state_of_world_populator.go:309] "Added volume to desired state" pod="default/nginx-deployment-66f58bff7c-lhxbk" volumeName="kube-api-access-95chw" volumeSpecName="kube-api-access-95chw"
Sep 15 20:48:04 kind-worker3 kubelet[589656]: I0915 20:48:04.978131  589656 reconciler.go:342] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-95chw\" (UniqueName: \"kubernetes.io/projected/f73dab4a-7b50-4d78-87ff-9600f1129748-kube-api-access-95chw\") pod \"nginx-deployment-66f58bff7c-lhxbk\" (UID: \"f73dab4a-7b50-4d78-87ff-9600f1129748\") " pod="default/nginx-deployment-66f58bff7c-lhxbk"
Sep 15 20:48:05 kind-worker3 kubelet[589656]: I0915 20:48:05.079492  589656 reconciler.go:243] "Starting operationExecutor.MountVolume for volume \"kube-api-access-95chw\" (UniqueName: \"kubernetes.io/projected/f73dab4a-7b50-4d78-87ff-9600f1129748-kube-api-access-95chw\") pod \"nginx-deployment-66f58bff7c-lhxbk\" (UID: \"f73dab4a-7b50-4d78-87ff-9600f1129748\") " pod="default/nginx-deployment-66f58bff7c-lhxbk"
Sep 15 20:48:05 kind-worker3 kubelet[589656]: I0915 20:48:05.079652  589656 reconciler.go:254] "operationExecutor.MountVolume started for volume \"kube-api-access-95chw\" (UniqueName: \"kubernetes.io/projected/f73dab4a-7b50-4d78-87ff-9600f1129748-kube-api-access-95chw\") pod \"nginx-deployment-66f58bff7c-lhxbk\" (UID: \"f73dab4a-7b50-4d78-87ff-9600f1129748\") " pod="default/nginx-deployment-66f58bff7c-lhxbk"
Sep 15 20:48:05 kind-worker3 kubelet[589656]: I0915 20:48:05.079788  589656 projected.go:183] Setting up volume kube-api-access-95chw for pod f73dab4a-7b50-4d78-87ff-9600f1129748 at /var/lib/kubelet/pods/f73dab4a-7b50-4d78-87ff-9600f1129748/volumes/kubernetes.io~projected/kube-api-access-95chw
Sep 15 20:48:05 kind-worker3 kubelet[589656]: I0915 20:48:05.100710  589656 empty_dir_linux.go:99] Statfs_t of /var/lib/kubelet/pods/f73dab4a-7b50-4d78-87ff-9600f1129748/volumes/kubernetes.io~projected/kube-api-access-95chw: {Type:61267 Bsize:4096 Blocks:12835448 Bfree:2604223 Bavail:1944793 Files:3276800 Ffree:2345690 Fsid:{Val:[-2136087178 982747248]} Namelen:255 Frsize:4096 Flags:4128 Spare:[0 0 0 0]}
Sep 15 20:48:05 kind-worker3 kubelet[589656]: I0915 20:48:05.100780  589656 empty_dir.go:334] pod f73dab4a-7b50-4d78-87ff-9600f1129748: mounting tmpfs for volume wrapped_kube-api-access-95chw
Sep 15 20:48:05 kind-worker3 kubelet[589656]: I0915 20:48:05.100821  589656 mount_linux.go:183] Mounting cmd (mount) with arguments (-t tmpfs -o size=8362762240 tmpfs /var/lib/kubelet/pods/f73dab4a-7b50-4d78-87ff-9600f1129748/volumes/kubernetes.io~projected/kube-api-access-95chw)
Sep 15 20:48:05 kind-worker3 kubelet[589656]: I0915 20:48:05.105535  589656 atomic_writer.go:181] pod default/nginx-deployment-66f58bff7c-lhxbk volume kube-api-access-95chw: performed write of new data to ts data directory: /var/lib/kubelet/pods/f73dab4a-7b50-4d78-87ff-9600f1129748/volumes/kubernetes.io~projected/kube-api-access-95chw/..2023_09_15_20_48_05.857171902
Sep 15 20:48:05 kind-worker3 kubelet[589656]: I0915 20:48:05.105773  589656 operation_generator.go:703] "MountVolume.SetUp succeeded for volume \"kube-api-access-95chw\" (UniqueName: \"kubernetes.io/projected/f73dab4a-7b50-4d78-87ff-9600f1129748-kube-api-access-95chw\") pod \"nginx-deployment-66f58bff7c-lhxbk\" (UID: \"f73dab4a-7b50-4d78-87ff-9600f1129748\") " pod="default/nginx-deployment-66f58bff7c-lhxbk"
Sep 15 20:48:05 kind-worker3 kubelet[589656]: I0915 20:48:05.205120  589656 volume_manager.go:435] "All volumes are attached and mounted for pod" pod="default/nginx-deployment-66f58bff7c-lhxbk"
Sep 15 20:48:05 kind-worker3 kubelet[589656]: I0915 20:48:05.205197  589656 kuberuntime_manager.go:469] "No sandbox for pod can be found. Need to start a new one" pod="default/nginx-deployment-66f58bff7c-lhxbk"
Sep 15 20:48:05 kind-worker3 kubelet[589656]: I0915 20:48:05.205247  589656 kuberuntime_manager.go:714] "computePodActions got for pod" podActions={KillPod:true CreateSandbox:true SandboxID: Attempt:0 NextInitContainerToStart:nil ContainersToStart:[0] ContainersToKill:map[] EphemeralContainersToStart:[]} pod="default/nginx-deployment-66f58bff7c-lhxbk"
Sep 15 20:48:05 kind-worker3 kubelet[589656]: I0915 20:48:05.205282  589656 kuberuntime_manager.go:723] "SyncPod received new pod, will create a sandbox for it" pod="default/nginx-deployment-66f58bff7c-lhxbk"
Sep 15 20:48:05 kind-worker3 kubelet[589656]: I0915 20:48:05.205303  589656 kuberuntime_manager.go:730] "Stopping PodSandbox for pod, will start new one" pod="default/nginx-deployment-66f58bff7c-lhxbk"
Sep 15 20:48:05 kind-worker3 kubelet[589656]: I0915 20:48:05.205334  589656 kuberuntime_manager.go:785] "Creating PodSandbox for pod" pod="default/nginx-deployment-66f58bff7c-lhxbk"
Sep 15 20:48:06 kind-worker3 kubelet[589656]: I0915 20:48:06.078441  589656 factory.go:258] Using factory "containerd" for container "/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-podf73dab4a_7b50_4d78_87ff_9600f1129748.slice/cri-containerd-fc30c1f4e2ab17c030bbc0f9228e59d7c7a6d2b9b4070a68335ad8d174320a99.scope"
Sep 15 20:48:06 kind-worker3 kubelet[589656]: I0915 20:48:06.261778  589656 manager.go:988] Added container: "/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-podf73dab4a_7b50_4d78_87ff_9600f1129748.slice/cri-containerd-fc30c1f4e2ab17c030bbc0f9228e59d7c7a6d2b9b4070a68335ad8d174320a99.scope" (aliases: [fc30c1f4e2ab17c030bbc0f9228e59d7c7a6d2b9b4070a68335ad8d174320a99 /kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-podf73dab4a_7b50_4d78_87ff_9600f1129748.slice/cri-containerd-fc30c1f4e2ab17c030bbc0f9228e59d7c7a6d2b9b4070a68335ad8d174320a99.scope], namespace: "containerd")
Sep 15 20:48:06 kind-worker3 kubelet[589656]: I0915 20:48:06.262609  589656 handler.go:325] Added event &{/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-podf73dab4a_7b50_4d78_87ff_9600f1129748.slice/cri-containerd-fc30c1f4e2ab17c030bbc0f9228e59d7c7a6d2b9b4070a68335ad8d174320a99.scope 2023-09-15 20:48:06.071051541 +0000 UTC containerCreation {<nil>}}
Sep 15 20:48:06 kind-worker3 kubelet[589656]: I0915 20:48:06.262789  589656 container.go:530] Start housekeeping for container "/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-podf73dab4a_7b50_4d78_87ff_9600f1129748.slice/cri-containerd-fc30c1f4e2ab17c030bbc0f9228e59d7c7a6d2b9b4070a68335ad8d174320a99.scope"
Sep 15 20:48:06 kind-worker3 kubelet[589656]: I0915 20:48:06.283930  589656 kuberuntime_manager.go:823] "Created PodSandbox for pod" podSandboxID="fc30c1f4e2ab17c030bbc0f9228e59d7c7a6d2b9b4070a68335ad8d174320a99" pod="default/nginx-deployment-66f58bff7c-lhxbk"
Sep 15 20:48:06 kind-worker3 kubelet[589656]: I0915 20:48:06.284821  589656 kuberuntime_manager.go:846] "Determined the ip for pod after sandbox changed" IPs=[10.244.3.70] pod="default/nginx-deployment-66f58bff7c-lhxbk"
Sep 15 20:48:06 kind-worker3 kubelet[589656]: I0915 20:48:06.285238  589656 kuberuntime_manager.go:889] "Creating container in pod" containerType="container" container="&Container{Name:nginx,Image:nginx:1.14.2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{ContainerPort{Name:,HostPort:0,ContainerPort:80,Protocol:TCP,HostIP:,},},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{cpu: {{500 -3} {<nil>} 500m DecimalSI},},Requests:ResourceList{cpu: {{200 -3} {<nil>} 200m DecimalSI},},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-95chw,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,}" pod="default/nginx-deployment-66f58bff7c-lhxbk"
Sep 15 20:48:06 kind-worker3 kubelet[589656]: I0915 20:48:06.286568  589656 kubelet_pods.go:161] "Creating hosts mount for container" pod="default/nginx-deployment-66f58bff7c-lhxbk" containerName="nginx" podIPs=[10.244.3.70] path=true
Sep 15 20:48:06 kind-worker3 kubelet[589656]: I0915 20:48:06.286712  589656 event.go:294] "Event occurred" object="default/nginx-deployment-66f58bff7c-lhxbk" fieldPath="spec.containers{nginx}" kind="Pod" apiVersion="v1" type="Normal" reason="Pulled" message="Container image \"nginx:1.14.2\" already present on machine"
Sep 15 20:48:06 kind-worker3 kubelet[589656]: I0915 20:48:06.498156  589656 kubelet.go:2160] "SyncLoop (housekeeping)"
Sep 15 20:48:06 kind-worker3 kubelet[589656]: I0915 20:48:06.512080  589656 kubelet_pods.go:1079] "Clean up pod workers for terminated pods"
Sep 15 20:48:06 kind-worker3 kubelet[589656]: I0915 20:48:06.512145  589656 kubelet_pods.go:1108] "Clean up probes for terminated pods"
Sep 15 20:48:06 kind-worker3 kubelet[589656]: I0915 20:48:06.514605  589656 kubelet_pods.go:1145] "Clean up orphaned pod statuses"
Sep 15 20:48:06 kind-worker3 kubelet[589656]: I0915 20:48:06.515968  589656 kubelet_pods.go:1164] "Clean up orphaned pod directories"
Sep 15 20:48:06 kind-worker3 kubelet[589656]: I0915 20:48:06.516222  589656 kubelet_pods.go:1175] "Clean up orphaned mirror pods"
Sep 15 20:48:06 kind-worker3 kubelet[589656]: I0915 20:48:06.516267  589656 kubelet_pods.go:1182] "Clean up orphaned pod cgroups"
Sep 15 20:48:06 kind-worker3 kubelet[589656]: I0915 20:48:06.516318  589656 kubelet.go:2168] "SyncLoop (housekeeping) end"
Sep 15 20:48:06 kind-worker3 kubelet[589656]: I0915 20:48:06.837168  589656 event.go:294] "Event occurred" object="default/nginx-deployment-66f58bff7c-lhxbk" fieldPath="spec.containers{nginx}" kind="Pod" apiVersion="v1" type="Normal" reason="Created" message="Created container nginx"
Sep 15 20:48:06 kind-worker3 kubelet[589656]: I0915 20:48:06.842835  589656 generic.go:155] "GenericPLEG" podUID=f73dab4a-7b50-4d78-87ff-9600f1129748 containerID="04371653069bfc4e7adfe1202329b3f4c4d28768f5943be47084472fb3068e57" oldState=non-existent newState=unknown
Sep 15 20:48:06 kind-worker3 kubelet[589656]: I0915 20:48:06.842892  589656 generic.go:155] "GenericPLEG" podUID=f73dab4a-7b50-4d78-87ff-9600f1129748 containerID="fc30c1f4e2ab17c030bbc0f9228e59d7c7a6d2b9b4070a68335ad8d174320a99" oldState=non-existent newState=running
Sep 15 20:48:06 kind-worker3 kubelet[589656]: I0915 20:48:06.844011  589656 kuberuntime_manager.go:1037] "getSandboxIDByPodUID got sandbox IDs for pod" podSandboxID=[fc30c1f4e2ab17c030bbc0f9228e59d7c7a6d2b9b4070a68335ad8d174320a99] pod="default/nginx-deployment-66f58bff7c-lhxbk"
Sep 15 20:48:06 kind-worker3 kubelet[589656]: I0915 20:48:06.847062  589656 generic.go:421] "PLEG: Write status" pod="default/nginx-deployment-66f58bff7c-lhxbk"
Sep 15 20:48:06 kind-worker3 kubelet[589656]: I0915 20:48:06.847156  589656 kubelet.go:2110] "SyncLoop (PLEG): event for pod" pod="default/nginx-deployment-66f58bff7c-lhxbk" event=&{ID:f73dab4a-7b50-4d78-87ff-9600f1129748 Type:ContainerStarted Data:fc30c1f4e2ab17c030bbc0f9228e59d7c7a6d2b9b4070a68335ad8d174320a99}
Sep 15 20:48:06 kind-worker3 kubelet[589656]: I0915 20:48:06.892377  589656 factory.go:258] Using factory "containerd" for container "/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-podf73dab4a_7b50_4d78_87ff_9600f1129748.slice/cri-containerd-04371653069bfc4e7adfe1202329b3f4c4d28768f5943be47084472fb3068e57.scope"
Sep 15 20:48:07 kind-worker3 kubelet[589656]: I0915 20:48:07.232727  589656 manager.go:988] Added container: "/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-podf73dab4a_7b50_4d78_87ff_9600f1129748.slice/cri-containerd-04371653069bfc4e7adfe1202329b3f4c4d28768f5943be47084472fb3068e57.scope" (aliases: [04371653069bfc4e7adfe1202329b3f4c4d28768f5943be47084472fb3068e57 /kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-podf73dab4a_7b50_4d78_87ff_9600f1129748.slice/cri-containerd-04371653069bfc4e7adfe1202329b3f4c4d28768f5943be47084472fb3068e57.scope], namespace: "containerd")
Sep 15 20:48:07 kind-worker3 kubelet[589656]: I0915 20:48:07.233401  589656 handler.go:325] Added event &{/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-podf73dab4a_7b50_4d78_87ff_9600f1129748.slice/cri-containerd-04371653069bfc4e7adfe1202329b3f4c4d28768f5943be47084472fb3068e57.scope 2023-09-15 20:48:06.88304656 +0000 UTC containerCreation {<nil>}}
Sep 15 20:48:07 kind-worker3 kubelet[589656]: I0915 20:48:07.233500  589656 container.go:530] Start housekeeping for container "/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-podf73dab4a_7b50_4d78_87ff_9600f1129748.slice/cri-containerd-04371653069bfc4e7adfe1202329b3f4c4d28768f5943be47084472fb3068e57.scope"
Sep 15 20:48:07 kind-worker3 kubelet[589656]: I0915 20:48:07.315321  589656 event.go:294] "Event occurred" object="default/nginx-deployment-66f58bff7c-lhxbk" fieldPath="spec.containers{nginx}" kind="Pod" apiVersion="v1" type="Normal" reason="Started" message="Started container nginx"
Sep 15 20:48:07 kind-worker3 kubelet[589656]: I0915 20:48:07.315397  589656 kubelet.go:1503] "syncPod exit" pod="default/nginx-deployment-66f58bff7c-lhxbk" podUID=f73dab4a-7b50-4d78-87ff-9600f1129748 isTerminal=false
Sep 15 20:48:07 kind-worker3 kubelet[589656]: I0915 20:48:07.315534  589656 pod_workers.go:988] "Processing pod event done" pod="default/nginx-deployment-66f58bff7c-lhxbk" podUID=f73dab4a-7b50-4d78-87ff-9600f1129748 updateType=0
Sep 15 20:48:07 kind-worker3 kubelet[589656]: I0915 20:48:07.315584  589656 pod_workers.go:888] "Processing pod event" pod="default/nginx-deployment-66f58bff7c-lhxbk" podUID=f73dab4a-7b50-4d78-87ff-9600f1129748 updateType=0
Sep 15 20:48:07 kind-worker3 kubelet[589656]: I0915 20:48:07.851542  589656 generic.go:155] "GenericPLEG" podUID=f73dab4a-7b50-4d78-87ff-9600f1129748 containerID="04371653069bfc4e7adfe1202329b3f4c4d28768f5943be47084472fb3068e57" oldState=unknown newState=running
Sep 15 20:48:07 kind-worker3 kubelet[589656]: I0915 20:48:07.852649  589656 kuberuntime_manager.go:1037] "getSandboxIDByPodUID got sandbox IDs for pod" podSandboxID=[fc30c1f4e2ab17c030bbc0f9228e59d7c7a6d2b9b4070a68335ad8d174320a99] pod="default/nginx-deployment-66f58bff7c-lhxbk"
Sep 15 20:48:07 kind-worker3 kubelet[589656]: I0915 20:48:07.855998  589656 generic.go:421] "PLEG: Write status" pod="default/nginx-deployment-66f58bff7c-lhxbk"
Sep 15 20:48:07 kind-worker3 kubelet[589656]: I0915 20:48:07.856112  589656 kubelet.go:1501] "syncPod enter" pod="default/nginx-deployment-66f58bff7c-lhxbk" podUID=f73dab4a-7b50-4d78-87ff-9600f1129748
Sep 15 20:48:07 kind-worker3 kubelet[589656]: I0915 20:48:07.856178  589656 kubelet_pods.go:1432] "Generating pod status" pod="default/nginx-deployment-66f58bff7c-lhxbk"
Sep 15 20:48:07 kind-worker3 kubelet[589656]: I0915 20:48:07.856116  589656 kubelet.go:2110] "SyncLoop (PLEG): event for pod" pod="default/nginx-deployment-66f58bff7c-lhxbk" event=&{ID:f73dab4a-7b50-4d78-87ff-9600f1129748 Type:ContainerStarted Data:04371653069bfc4e7adfe1202329b3f4c4d28768f5943be47084472fb3068e57}
Sep 15 20:48:07 kind-worker3 kubelet[589656]: I0915 20:48:07.856281  589656 kubelet_pods.go:1444] "Got phase for pod" pod="default/nginx-deployment-66f58bff7c-lhxbk" oldPhase=Pending phase=Running
Sep 15 20:48:07 kind-worker3 kubelet[589656]: I0915 20:48:07.856910  589656 volume_manager.go:404] "Waiting for volumes to attach and mount for pod" pod="default/nginx-deployment-66f58bff7c-lhxbk"
Sep 15 20:48:07 kind-worker3 kubelet[589656]: I0915 20:48:07.857022  589656 volume_manager.go:435] "All volumes are attached and mounted for pod" pod="default/nginx-deployment-66f58bff7c-lhxbk"
Sep 15 20:48:07 kind-worker3 kubelet[589656]: I0915 20:48:07.857321  589656 kuberuntime_manager.go:714] "computePodActions got for pod" podActions={KillPod:false CreateSandbox:false SandboxID:fc30c1f4e2ab17c030bbc0f9228e59d7c7a6d2b9b4070a68335ad8d174320a99 Attempt:0 NextInitContainerToStart:nil ContainersToStart:[] ContainersToKill:map[] EphemeralContainersToStart:[]} pod="default/nginx-deployment-66f58bff7c-lhxbk"
Sep 15 20:48:07 kind-worker3 kubelet[589656]: I0915 20:48:07.857561  589656 kubelet.go:1503] "syncPod exit" pod="default/nginx-deployment-66f58bff7c-lhxbk" podUID=f73dab4a-7b50-4d78-87ff-9600f1129748 isTerminal=false
Sep 15 20:48:07 kind-worker3 kubelet[589656]: I0915 20:48:07.857653  589656 pod_workers.go:988] "Processing pod event done" pod="default/nginx-deployment-66f58bff7c-lhxbk" podUID=f73dab4a-7b50-4d78-87ff-9600f1129748 updateType=0
Sep 15 20:48:07 kind-worker3 kubelet[589656]: I0915 20:48:07.857699  589656 pod_workers.go:888] "Processing pod event" pod="default/nginx-deployment-66f58bff7c-lhxbk" podUID=f73dab4a-7b50-4d78-87ff-9600f1129748 updateType=0
Sep 15 20:48:07 kind-worker3 kubelet[589656]: I0915 20:48:07.859514  589656 desired_state_of_world_populator.go:309] "Added volume to desired state" pod="default/nginx-deployment-66f58bff7c-lhxbk" volumeName="kube-api-access-95chw" volumeSpecName="kube-api-access-95chw"
Sep 15 20:48:07 kind-worker3 kubelet[589656]: I0915 20:48:07.897696  589656 reconciler.go:243] "Starting operationExecutor.MountVolume for volume \"kube-api-access-95chw\" (UniqueName: \"kubernetes.io/projected/f73dab4a-7b50-4d78-87ff-9600f1129748-kube-api-access-95chw\") pod \"nginx-deployment-66f58bff7c-lhxbk\" (UID: \"f73dab4a-7b50-4d78-87ff-9600f1129748\") Volume is already mounted to pod, but remount was requested." pod="default/nginx-deployment-66f58bff7c-lhxbk"
Sep 15 20:48:07 kind-worker3 kubelet[589656]: I0915 20:48:07.897961  589656 projected.go:183] Setting up volume kube-api-access-95chw for pod f73dab4a-7b50-4d78-87ff-9600f1129748 at /var/lib/kubelet/pods/f73dab4a-7b50-4d78-87ff-9600f1129748/volumes/kubernetes.io~projected/kube-api-access-95chw
Sep 15 20:48:07 kind-worker3 kubelet[589656]: I0915 20:48:07.898758  589656 atomic_writer.go:161] pod default/nginx-deployment-66f58bff7c-lhxbk volume kube-api-access-95chw: no update required for target directory /var/lib/kubelet/pods/f73dab4a-7b50-4d78-87ff-9600f1129748/volumes/kubernetes.io~projected/kube-api-access-95chw
Sep 15 20:48:07 kind-worker3 kubelet[589656]: I0915 20:48:07.898851  589656 operation_generator.go:703] "MountVolume.SetUp succeeded for volume \"kube-api-access-95chw\" (UniqueName: \"kubernetes.io/projected/f73dab4a-7b50-4d78-87ff-9600f1129748-kube-api-access-95chw\") pod \"nginx-deployment-66f58bff7c-lhxbk\" (UID: \"f73dab4a-7b50-4d78-87ff-9600f1129748\") " pod="default/nginx-deployment-66f58bff7c-lhxbk"
Sep 15 20:48:07 kind-worker3 kubelet[589656]: I0915 20:48:07.914380  589656 config.go:279] "Setting pods for source" source="api"
Sep 15 20:48:07 kind-worker3 kubelet[589656]: I0915 20:48:07.914389  589656 status_manager.go:685] "Patch status for pod" pod="default/nginx-deployment-66f58bff7c-lhxbk" patch="{\"metadata\":{\"uid\":\"f73dab4a-7b50-4d78-87ff-9600f1129748\"},\"status\":{\"$setElementOrder/conditions\":[{\"type\":\"Initialized\"},{\"type\":\"Ready\"},{\"type\":\"ContainersReady\"},{\"type\":\"PodScheduled\"}],\"conditions\":[{\"lastTransitionTime\":\"2023-09-15T20:48:07Z\",\"message\":null,\"reason\":null,\"status\":\"True\",\"type\":\"Ready\"},{\"lastTransitionTime\":\"2023-09-15T20:48:07Z\",\"message\":null,\"reason\":null,\"status\":\"True\",\"type\":\"ContainersReady\"}],\"containerStatuses\":[{\"containerID\":\"containerd://04371653069bfc4e7adfe1202329b3f4c4d28768f5943be47084472fb3068e57\",\"image\":\"docker.io/library/nginx:1.14.2\",\"imageID\":\"docker.io/library/nginx@sha256:f7988fb6c02e0ce69257d9bd9cf37ae20a60f1df7563c3a2a6abe24160306b8d\",\"lastState\":{},\"name\":\"nginx\",\"ready\":true,\"restartCount\":0,\"started\":true,\"state\":{\"running\":{\"startedAt\":\"2023-09-15T20:48:07Z\"}}}],\"phase\":\"Running\",\"podIP\":\"10.244.3.70\",\"podIPs\":[{\"ip\":\"10.244.3.70\"}]}}"
Sep 15 20:48:07 kind-worker3 kubelet[589656]: I0915 20:48:07.914771  589656 kubelet.go:2085] "SyncLoop RECONCILE" source="api" pods=[default/nginx-deployment-66f58bff7c-lhxbk]
Sep 15 20:48:07 kind-worker3 kubelet[589656]: I0915 20:48:07.914832  589656 status_manager.go:694] "Status for pod updated successfully" pod="default/nginx-deployment-66f58bff7c-lhxbk" statusVersion=2 status={Phase:Running Conditions:[{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-09-15 20:48:04 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-09-15 20:48:07 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-09-15 20:48:07 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-09-15 20:48:04 +0000 UTC Reason: Message:}] Message: Reason: NominatedNodeName: HostIP:172.18.0.4 PodIP:10.244.3.70 PodIPs:[{IP:10.244.3.70}] StartTime:2023-09-15 20:48:04 +0000 UTC InitContainerStatuses:[] ContainerStatuses:[{Name:nginx State:{Waiting:nil Running:&ContainerStateRunning{StartedAt:2023-09-15 20:48:07 +0000 UTC,} Terminated:nil} LastTerminationState:{Waiting:nil Running:nil Terminated:nil} Ready:true RestartCount:0 Image:docker.io/library/nginx:1.14.2 ImageID:docker.io/library/nginx@sha256:f7988fb6c02e0ce69257d9bd9cf37ae20a60f1df7563c3a2a6abe24160306b8d ContainerID:containerd://04371653069bfc4e7adfe1202329b3f4c4d28768f5943be47084472fb3068e57 Started:0xc00176328c}] QOSClass:Burstable EphemeralContainerStatuses:[]}
Sep 15 20:48:08 kind-worker3 kubelet[589656]: I0915 20:48:08.497759  589656 kubelet.go:2160] "SyncLoop (housekeeping)"
Sep 15 20:48:08 kind-worker3 kubelet[589656]: I0915 20:48:08.511544  589656 kubelet_pods.go:1079] "Clean up pod workers for terminated pods"
Sep 15 20:48:08 kind-worker3 kubelet[589656]: I0915 20:48:08.511588  589656 kubelet_pods.go:1108] "Clean up probes for terminated pods"
Sep 15 20:48:08 kind-worker3 kubelet[589656]: I0915 20:48:08.511613  589656 kubelet_pods.go:1145] "Clean up orphaned pod statuses"
Sep 15 20:48:08 kind-worker3 kubelet[589656]: I0915 20:48:08.513299  589656 kubelet_pods.go:1164] "Clean up orphaned pod directories"
Sep 15 20:48:08 kind-worker3 kubelet[589656]: I0915 20:48:08.513445  589656 kubelet_pods.go:1175] "Clean up orphaned mirror pods"
Sep 15 20:48:08 kind-worker3 kubelet[589656]: I0915 20:48:08.513472  589656 kubelet_pods.go:1182] "Clean up orphaned pod cgroups"
Sep 15 20:48:08 kind-worker3 kubelet[589656]: I0915 20:48:08.513530  589656 kubelet.go:2168] "SyncLoop (housekeeping) end"
Sep 15 20:48:08 kind-worker3 kubelet[589656]: I0915 20:48:08.859654  589656 kubelet.go:1501] "syncPod enter" pod="default/nginx-deployment-66f58bff7c-lhxbk" podUID=f73dab4a-7b50-4d78-87ff-9600f1129748
Sep 15 20:48:08 kind-worker3 kubelet[589656]: I0915 20:48:08.859797  589656 kubelet_pods.go:1432] "Generating pod status" pod="default/nginx-deployment-66f58bff7c-lhxbk"
Sep 15 20:48:08 kind-worker3 kubelet[589656]: I0915 20:48:08.859974  589656 kubelet_pods.go:1444] "Got phase for pod" pod="default/nginx-deployment-66f58bff7c-lhxbk" oldPhase=Running phase=Running
Sep 15 20:48:08 kind-worker3 kubelet[589656]: I0915 20:48:08.860416  589656 status_manager.go:535] "Ignoring same status for pod" pod="default/nginx-deployment-66f58bff7c-lhxbk" status={Phase:Running Conditions:[{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-09-15 20:48:04 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-09-15 20:48:07 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-09-15 20:48:07 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-09-15 20:48:04 +0000 UTC Reason: Message:}] Message: Reason: NominatedNodeName: HostIP:172.18.0.4 PodIP:10.244.3.70 PodIPs:[{IP:10.244.3.70}] StartTime:2023-09-15 20:48:04 +0000 UTC InitContainerStatuses:[] ContainerStatuses:[{Name:nginx State:{Waiting:nil Running:&ContainerStateRunning{StartedAt:2023-09-15 20:48:07 +0000 UTC,} Terminated:nil} LastTerminationState:{Waiting:nil Running:nil Terminated:nil} Ready:true RestartCount:0 Image:docker.io/library/nginx:1.14.2 ImageID:docker.io/library/nginx@sha256:f7988fb6c02e0ce69257d9bd9cf37ae20a60f1df7563c3a2a6abe24160306b8d ContainerID:containerd://04371653069bfc4e7adfe1202329b3f4c4d28768f5943be47084472fb3068e57 Started:0xc001391a9c}] QOSClass:Burstable EphemeralContainerStatuses:[]}
Sep 15 20:48:08 kind-worker3 kubelet[589656]: I0915 20:48:08.861406  589656 volume_manager.go:404] "Waiting for volumes to attach and mount for pod" pod="default/nginx-deployment-66f58bff7c-lhxbk"
Sep 15 20:48:08 kind-worker3 kubelet[589656]: I0915 20:48:08.861515  589656 volume_manager.go:435] "All volumes are attached and mounted for pod" pod="default/nginx-deployment-66f58bff7c-lhxbk"
Sep 15 20:48:08 kind-worker3 kubelet[589656]: I0915 20:48:08.861845  589656 kuberuntime_manager.go:714] "computePodActions got for pod" podActions={KillPod:false CreateSandbox:false SandboxID:fc30c1f4e2ab17c030bbc0f9228e59d7c7a6d2b9b4070a68335ad8d174320a99 Attempt:0 NextInitContainerToStart:nil ContainersToStart:[] ContainersToKill:map[] EphemeralContainersToStart:[]} pod="default/nginx-deployment-66f58bff7c-lhxbk"
Sep 15 20:48:08 kind-worker3 kubelet[589656]: I0915 20:48:08.862087  589656 kubelet.go:1503] "syncPod exit" pod="default/nginx-deployment-66f58bff7c-lhxbk" podUID=f73dab4a-7b50-4d78-87ff-9600f1129748 isTerminal=false
Sep 15 20:48:08 kind-worker3 kubelet[589656]: I0915 20:48:08.862197  589656 pod_workers.go:988] "Processing pod event done" pod="default/nginx-deployment-66f58bff7c-lhxbk" podUID=f73dab4a-7b50-4d78-87ff-9600f1129748 updateType=0
Sep 15 20:48:08 kind-worker3 kubelet[589656]: I0915 20:48:08.867737  589656 desired_state_of_world_populator.go:309] "Added volume to desired state" pod="default/nginx-deployment-66f58bff7c-lhxbk" volumeName="kube-api-access-95chw" volumeSpecName="kube-api-access-95chw"
Sep 15 20:48:08 kind-worker3 kubelet[589656]: I0915 20:48:08.905496  589656 reconciler.go:243] "Starting operationExecutor.MountVolume for volume \"kube-api-access-95chw\" (UniqueName: \"kubernetes.io/projected/f73dab4a-7b50-4d78-87ff-9600f1129748-kube-api-access-95chw\") pod \"nginx-deployment-66f58bff7c-lhxbk\" (UID: \"f73dab4a-7b50-4d78-87ff-9600f1129748\") Volume is already mounted to pod, but remount was requested." pod="default/nginx-deployment-66f58bff7c-lhxbk"
Sep 15 20:48:08 kind-worker3 kubelet[589656]: I0915 20:48:08.905788  589656 projected.go:183] Setting up volume kube-api-access-95chw for pod f73dab4a-7b50-4d78-87ff-9600f1129748 at /var/lib/kubelet/pods/f73dab4a-7b50-4d78-87ff-9600f1129748/volumes/kubernetes.io~projected/kube-api-access-95chw
Sep 15 20:48:08 kind-worker3 kubelet[589656]: I0915 20:48:08.906532  589656 atomic_writer.go:161] pod default/nginx-deployment-66f58bff7c-lhxbk volume kube-api-access-95chw: no update required for target directory /var/lib/kubelet/pods/f73dab4a-7b50-4d78-87ff-9600f1129748/volumes/kubernetes.io~projected/kube-api-access-95chw
Sep 15 20:48:08 kind-worker3 kubelet[589656]: I0915 20:48:08.906678  589656 operation_generator.go:703] "MountVolume.SetUp succeeded for volume \"kube-api-access-95chw\" (UniqueName: \"kubernetes.io/projected/f73dab4a-7b50-4d78-87ff-9600f1129748-kube-api-access-95chw\") pod \"nginx-deployment-66f58bff7c-lhxbk\" (UID: \"f73dab4a-7b50-4d78-87ff-9600f1129748\") " pod="default/nginx-deployment-66f58bff7c-lhxbk"
Sep 15 20:48:09 kind-worker3 kubelet[589656]: I0915 20:48:09.403569  589656 httplog.go:131] "HTTP" verb="GET" URI="/metrics/resource" latency="32.718626ms" userAgent="metrics-server/v0.6.3 (linux/amd64) kubernetes/a938798" audit-ID="" srcIP="172.18.0.3:35538" resp=200
Sep 15 20:48:09 kind-worker3 kubelet[589656]: I0915 20:48:09.934869  589656 kubelet.go:2346] "Container runtime status" status="Runtime Conditions: RuntimeReady=true reason: message:, NetworkReady=true reason: message:"
Sep 15 20:48:10 kind-worker3 kubelet[589656]: I0915 20:48:10.035621  589656 reflector.go:536] vendor/k8s.io/client-go/informers/factory.go:134: Watch close - *v1.Service total 2 items received
Sep 15 20:48:10 kind-worker3 kubelet[589656]: I0915 20:48:10.498154  589656 kubelet.go:2129] "SyncLoop (SYNC) pods" total=1 pods=[kube-system/kindnet-mxmhl]
Sep 15 20:48:10 kind-worker3 kubelet[589656]: I0915 20:48:10.498338  589656 kubelet.go:2160] "SyncLoop (housekeeping)"
Sep 15 20:48:10 kind-worker3 kubelet[589656]: I0915 20:48:10.498425  589656 pod_workers.go:888] "Processing pod event" pod="kube-system/kindnet-mxmhl" podUID=d2a8b1e2-f8ec-4685-881d-a4d1c26134c2 updateType=0
Sep 15 20:48:10 kind-worker3 kubelet[589656]: I0915 20:48:10.498530  589656 kubelet.go:1501] "syncPod enter" pod="kube-system/kindnet-mxmhl" podUID=d2a8b1e2-f8ec-4685-881d-a4d1c26134c2
Sep 15 20:48:10 kind-worker3 kubelet[589656]: I0915 20:48:10.498613  589656 kubelet_pods.go:1432] "Generating pod status" pod="kube-system/kindnet-mxmhl"
Sep 15 20:48:10 kind-worker3 kubelet[589656]: I0915 20:48:10.498789  589656 kubelet_pods.go:1444] "Got phase for pod" pod="kube-system/kindnet-mxmhl" oldPhase=Running phase=Running
Sep 15 20:48:10 kind-worker3 kubelet[589656]: I0915 20:48:10.499154  589656 status_manager.go:535] "Ignoring same status for pod" pod="kube-system/kindnet-mxmhl" status={Phase:Running Conditions:[{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-14 00:07:50 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-07-15 14:56:50 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-07-15 14:56:50 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-14 00:07:47 +0000 UTC Reason: Message:}] Message: Reason: NominatedNodeName: HostIP:172.18.0.4 PodIP:172.18.0.4 PodIPs:[{IP:172.18.0.4}] StartTime:2023-04-14 00:07:50 +0000 UTC InitContainerStatuses:[] ContainerStatuses:[{Name:kindnet-cni State:{Waiting:nil Running:&ContainerStateRunning{StartedAt:2023-07-15 14:56:49 +0000 UTC,} Terminated:nil} LastTerminationState:{Waiting:nil Running:nil Terminated:&ContainerStateTerminated{ExitCode:255,Signal:0,Reason:Unknown,Message:,StartedAt:2023-05-13 23:24:24 +0000 UTC,FinishedAt:2023-07-15 14:56:13 +0000 UTC,ContainerID:containerd://f98e00c8217d4308a58d79ba51534150a7f921ba9587fc5badea4fb5300ee3b7,}} Ready:true RestartCount:2 Image:docker.io/kindest/kindnetd:v20221004-44d545d1 ImageID:sha256:d6e3e26021b60c625f0ef5b2dd3f9e22d2d398e05bccc4fdd7d59fbbb6a04d3f ContainerID:containerd://ec9b47aba6f0d651c6da6e8282ad0e4f699e83e716938f3c1f3f34bb4edc2aa2 Started:0xc00148dd59}] QOSClass:Guaranteed EphemeralContainerStatuses:[]}
Sep 15 20:48:10 kind-worker3 kubelet[589656]: I0915 20:48:10.499640  589656 volume_manager.go:404] "Waiting for volumes to attach and mount for pod" pod="kube-system/kindnet-mxmhl"
Sep 15 20:48:10 kind-worker3 kubelet[589656]: I0915 20:48:10.499704  589656 volume_manager.go:435] "All volumes are attached and mounted for pod" pod="kube-system/kindnet-mxmhl"
Sep 15 20:48:10 kind-worker3 kubelet[589656]: I0915 20:48:10.500133  589656 kuberuntime_manager.go:714] "computePodActions got for pod" podActions={KillPod:false CreateSandbox:false SandboxID:b477a0e3bdd1b445ce34dc6f173590a56dbfec252950ee838d5af2a2515a773b Attempt:2 NextInitContainerToStart:nil ContainersToStart:[] ContainersToKill:map[] EphemeralContainersToStart:[]} pod="kube-system/kindnet-mxmhl"
Sep 15 20:48:10 kind-worker3 kubelet[589656]: I0915 20:48:10.500371  589656 kubelet.go:1503] "syncPod exit" pod="kube-system/kindnet-mxmhl" podUID=d2a8b1e2-f8ec-4685-881d-a4d1c26134c2 isTerminal=false
Sep 15 20:48:10 kind-worker3 kubelet[589656]: I0915 20:48:10.500451  589656 pod_workers.go:988] "Processing pod event done" pod="kube-system/kindnet-mxmhl" podUID=d2a8b1e2-f8ec-4685-881d-a4d1c26134c2 updateType=0
Sep 15 20:48:10 kind-worker3 kubelet[589656]: I0915 20:48:10.511038  589656 kubelet_pods.go:1079] "Clean up pod workers for terminated pods"
Sep 15 20:48:10 kind-worker3 kubelet[589656]: I0915 20:48:10.511125  589656 kubelet_pods.go:1108] "Clean up probes for terminated pods"
Sep 15 20:48:10 kind-worker3 kubelet[589656]: I0915 20:48:10.513493  589656 kubelet_pods.go:1145] "Clean up orphaned pod statuses"
Sep 15 20:48:10 kind-worker3 kubelet[589656]: I0915 20:48:10.515049  589656 kubelet_pods.go:1164] "Clean up orphaned pod directories"
Sep 15 20:48:10 kind-worker3 kubelet[589656]: I0915 20:48:10.515219  589656 kubelet_pods.go:1175] "Clean up orphaned mirror pods"
Sep 15 20:48:10 kind-worker3 kubelet[589656]: I0915 20:48:10.515247  589656 kubelet_pods.go:1182] "Clean up orphaned pod cgroups"
Sep 15 20:48:10 kind-worker3 kubelet[589656]: I0915 20:48:10.515278  589656 kubelet.go:2168] "SyncLoop (housekeeping) end"
Sep 15 20:48:10 kind-worker3 kubelet[589656]: I0915 20:48:10.579846  589656 desired_state_of_world_populator.go:309] "Added volume to desired state" pod="kube-system/kindnet-mxmhl" volumeName="cni-cfg" volumeSpecName="cni-cfg"
Sep 15 20:48:10 kind-worker3 kubelet[589656]: I0915 20:48:10.579988  589656 desired_state_of_world_populator.go:309] "Added volume to desired state" pod="kube-system/kindnet-mxmhl" volumeName="xtables-lock" volumeSpecName="xtables-lock"
Sep 15 20:48:10 kind-worker3 kubelet[589656]: I0915 20:48:10.580057  589656 desired_state_of_world_populator.go:309] "Added volume to desired state" pod="kube-system/kindnet-mxmhl" volumeName="lib-modules" volumeSpecName="lib-modules"
Sep 15 20:48:10 kind-worker3 kubelet[589656]: I0915 20:48:10.580256  589656 desired_state_of_world_populator.go:309] "Added volume to desired state" pod="kube-system/kindnet-mxmhl" volumeName="kube-api-access-2d7bz" volumeSpecName="kube-api-access-2d7bz"
Sep 15 20:48:10 kind-worker3 kubelet[589656]: I0915 20:48:10.618952  589656 reconciler.go:243] "Starting operationExecutor.MountVolume for volume \"kube-api-access-2d7bz\" (UniqueName: \"kubernetes.io/projected/d2a8b1e2-f8ec-4685-881d-a4d1c26134c2-kube-api-access-2d7bz\") pod \"kindnet-mxmhl\" (UID: \"d2a8b1e2-f8ec-4685-881d-a4d1c26134c2\") Volume is already mounted to pod, but remount was requested." pod="kube-system/kindnet-mxmhl"
Sep 15 20:48:10 kind-worker3 kubelet[589656]: I0915 20:48:10.619482  589656 projected.go:183] Setting up volume kube-api-access-2d7bz for pod d2a8b1e2-f8ec-4685-881d-a4d1c26134c2 at /var/lib/kubelet/pods/d2a8b1e2-f8ec-4685-881d-a4d1c26134c2/volumes/kubernetes.io~projected/kube-api-access-2d7bz
Sep 15 20:48:10 kind-worker3 kubelet[589656]: I0915 20:48:10.620516  589656 atomic_writer.go:161] pod kube-system/kindnet-mxmhl volume kube-api-access-2d7bz: no update required for target directory /var/lib/kubelet/pods/d2a8b1e2-f8ec-4685-881d-a4d1c26134c2/volumes/kubernetes.io~projected/kube-api-access-2d7bz
Sep 15 20:48:10 kind-worker3 kubelet[589656]: I0915 20:48:10.620654  589656 operation_generator.go:703] "MountVolume.SetUp succeeded for volume \"kube-api-access-2d7bz\" (UniqueName: \"kubernetes.io/projected/d2a8b1e2-f8ec-4685-881d-a4d1c26134c2-kube-api-access-2d7bz\") pod \"kindnet-mxmhl\" (UID: \"d2a8b1e2-f8ec-4685-881d-a4d1c26134c2\") " pod="kube-system/kindnet-mxmhl"
Sep 15 20:48:11 kind-worker3 kubelet[589656]: I0915 20:48:11.091699  589656 setters.go:88] "Using node IP" IP="172.18.0.4"
Sep 15 20:48:12 kind-worker3 kubelet[589656]: I0915 20:48:12.498227  589656 kubelet.go:2160] "SyncLoop (housekeeping)"
Sep 15 20:48:12 kind-worker3 kubelet[589656]: I0915 20:48:12.508953  589656 kubelet_pods.go:1079] "Clean up pod workers for terminated pods"
Sep 15 20:48:12 kind-worker3 kubelet[589656]: I0915 20:48:12.509010  589656 kubelet_pods.go:1108] "Clean up probes for terminated pods"
Sep 15 20:48:12 kind-worker3 kubelet[589656]: I0915 20:48:12.509041  589656 kubelet_pods.go:1145] "Clean up orphaned pod statuses"
Sep 15 20:48:12 kind-worker3 kubelet[589656]: I0915 20:48:12.511419  589656 kubelet_pods.go:1164] "Clean up orphaned pod directories"
Sep 15 20:48:12 kind-worker3 kubelet[589656]: I0915 20:48:12.511578  589656 kubelet_pods.go:1175] "Clean up orphaned mirror pods"
Sep 15 20:48:12 kind-worker3 kubelet[589656]: I0915 20:48:12.511606  589656 kubelet_pods.go:1182] "Clean up orphaned pod cgroups"
Sep 15 20:48:12 kind-worker3 kubelet[589656]: I0915 20:48:12.511635  589656 kubelet.go:2168] "SyncLoop (housekeeping) end"
Sep 15 20:48:14 kind-worker3 kubelet[589656]: I0915 20:48:14.116217  589656 eviction_manager.go:237] "Eviction manager: synchronize housekeeping"
Sep 15 20:48:14 kind-worker3 kubelet[589656]: I0915 20:48:14.136880  589656 cri_stats_provider.go:525] "Unable to find network stats for sandbox" sandboxID="d0f4d02598fe0e9a32081b1554ae85df2b4224eb9a378fdcf99aa7c0035d33dc"
Sep 15 20:48:14 kind-worker3 kubelet[589656]: I0915 20:48:14.138141  589656 cri_stats_provider.go:525] "Unable to find network stats for sandbox" sandboxID="b477a0e3bdd1b445ce34dc6f173590a56dbfec252950ee838d5af2a2515a773b"
Sep 15 20:48:14 kind-worker3 kubelet[589656]: I0915 20:48:14.142889  589656 helpers.go:775] "Eviction manager:" log="observations" signal=memory.available resourceName="7829220Ki" capacity="8166760Ki" time="2023-09-15 20:48:14.119669804 +0000 UTC m=+2146358.042495085"
Sep 15 20:48:14 kind-worker3 kubelet[589656]: I0915 20:48:14.142948  589656 helpers.go:775] "Eviction manager:" log="observations" signal=allocatableMemory.available resourceName="8092416Ki" capacity="8166760Ki" time="2023-09-15 20:48:14.142610623 +0000 UTC m=+2146358.065435767"
Sep 15 20:48:14 kind-worker3 kubelet[589656]: I0915 20:48:14.142984  589656 helpers.go:775] "Eviction manager:" log="observations" signal=nodefs.available resourceName="7770792Ki" capacity="51341792Ki" time="2023-09-15 20:48:14.119669804 +0000 UTC m=+2146358.042495085"
Sep 15 20:48:14 kind-worker3 kubelet[589656]: I0915 20:48:14.143016  589656 helpers.go:775] "Eviction manager:" log="observations" signal=nodefs.inodesFree resourceName="2345587" capacity="3276800" time="2023-09-15 20:48:14.119669804 +0000 UTC m=+2146358.042495085"
Sep 15 20:48:14 kind-worker3 kubelet[589656]: I0915 20:48:14.143052  589656 helpers.go:775] "Eviction manager:" log="observations" signal=imagefs.available resourceName="7770792Ki" capacity="51341792Ki" time="2023-09-15 20:48:08.906563315 +0000 UTC"
Sep 15 20:48:14 kind-worker3 kubelet[589656]: I0915 20:48:14.143079  589656 helpers.go:775] "Eviction manager:" log="observations" signal=imagefs.inodesFree resourceName="2345587" capacity="3276800" time="2023-09-15 20:48:08.906563315 +0000 UTC"
Sep 15 20:48:14 kind-worker3 kubelet[589656]: I0915 20:48:14.143177  589656 helpers.go:775] "Eviction manager:" log="observations" signal=pid.available resourceName="62252" capacity="63272" time="2023-09-15 20:48:14.139042277 +0000 UTC m=+2146358.061867388"
Sep 15 20:48:14 kind-worker3 kubelet[589656]: I0915 20:48:14.143254  589656 eviction_manager.go:328] "Eviction manager: no resources are starved"
Sep 15 20:48:14 kind-worker3 kubelet[589656]: I0915 20:48:14.498118  589656 kubelet.go:2160] "SyncLoop (housekeeping)"
Sep 15 20:48:14 kind-worker3 kubelet[589656]: I0915 20:48:14.515044  589656 kubelet_pods.go:1079] "Clean up pod workers for terminated pods"
Sep 15 20:48:14 kind-worker3 kubelet[589656]: I0915 20:48:14.515111  589656 kubelet_pods.go:1108] "Clean up probes for terminated pods"
Sep 15 20:48:14 kind-worker3 kubelet[589656]: I0915 20:48:14.517000  589656 kubelet_pods.go:1145] "Clean up orphaned pod statuses"
Sep 15 20:48:14 kind-worker3 kubelet[589656]: I0915 20:48:14.518719  589656 kubelet_pods.go:1164] "Clean up orphaned pod directories"
Sep 15 20:48:14 kind-worker3 kubelet[589656]: I0915 20:48:14.518891  589656 kubelet_pods.go:1175] "Clean up orphaned mirror pods"
Sep 15 20:48:14 kind-worker3 kubelet[589656]: I0915 20:48:14.518928  589656 kubelet_pods.go:1182] "Clean up orphaned pod cgroups"
Sep 15 20:48:14 kind-worker3 kubelet[589656]: I0915 20:48:14.518968  589656 kubelet.go:2168] "SyncLoop (housekeeping) end"
Sep 15 20:48:14 kind-worker3 kubelet[589656]: I0915 20:48:14.936660  589656 kubelet.go:2346] "Container runtime status" status="Runtime Conditions: RuntimeReady=true reason: message:, NetworkReady=true reason: message:"
Sep 15 20:48:16 kind-worker3 kubelet[589656]: I0915 20:48:16.256892  589656 config.go:279] "Setting pods for source" source="file"
Sep 15 20:48:16 kind-worker3 kubelet[589656]: I0915 20:48:16.497676  589656 kubelet.go:2160] "SyncLoop (housekeeping)"
Sep 15 20:48:16 kind-worker3 kubelet[589656]: I0915 20:48:16.509465  589656 kubelet_pods.go:1079] "Clean up pod workers for terminated pods"
Sep 15 20:48:16 kind-worker3 kubelet[589656]: I0915 20:48:16.509542  589656 kubelet_pods.go:1108] "Clean up probes for terminated pods"
Sep 15 20:48:16 kind-worker3 kubelet[589656]: I0915 20:48:16.509579  589656 kubelet_pods.go:1145] "Clean up orphaned pod statuses"
Sep 15 20:48:16 kind-worker3 kubelet[589656]: I0915 20:48:16.512591  589656 kubelet_pods.go:1164] "Clean up orphaned pod directories"
Sep 15 20:48:16 kind-worker3 kubelet[589656]: I0915 20:48:16.512829  589656 kubelet_pods.go:1175] "Clean up orphaned mirror pods"
Sep 15 20:48:16 kind-worker3 kubelet[589656]: I0915 20:48:16.513049  589656 kubelet_pods.go:1182] "Clean up orphaned pod cgroups"
Sep 15 20:48:16 kind-worker3 kubelet[589656]: I0915 20:48:16.513202  589656 kubelet.go:2168] "SyncLoop (housekeeping) end"
Sep 15 20:48:18 kind-worker3 kubelet[589656]: I0915 20:48:18.498143  589656 kubelet.go:2160] "SyncLoop (housekeeping)"
Sep 15 20:48:18 kind-worker3 kubelet[589656]: I0915 20:48:18.509378  589656 kubelet_pods.go:1079] "Clean up pod workers for terminated pods"
Sep 15 20:48:18 kind-worker3 kubelet[589656]: I0915 20:48:18.509430  589656 kubelet_pods.go:1108] "Clean up probes for terminated pods"
Sep 15 20:48:18 kind-worker3 kubelet[589656]: I0915 20:48:18.511931  589656 kubelet_pods.go:1145] "Clean up orphaned pod statuses"
Sep 15 20:48:18 kind-worker3 kubelet[589656]: I0915 20:48:18.514050  589656 kubelet_pods.go:1164] "Clean up orphaned pod directories"
Sep 15 20:48:18 kind-worker3 kubelet[589656]: I0915 20:48:18.514260  589656 kubelet_pods.go:1175] "Clean up orphaned mirror pods"
Sep 15 20:48:18 kind-worker3 kubelet[589656]: I0915 20:48:18.514316  589656 kubelet_pods.go:1182] "Clean up orphaned pod cgroups"
Sep 15 20:48:18 kind-worker3 kubelet[589656]: I0915 20:48:18.514361  589656 kubelet.go:2168] "SyncLoop (housekeeping) end"
Sep 15 20:48:19 kind-worker3 kubelet[589656]: I0915 20:48:19.069699  589656 handler.go:293] error while reading "/proc/589656/fd/38" link: readlink /proc/589656/fd/38: no such file or directory
Sep 15 20:48:19 kind-worker3 kubelet[589656]: I0915 20:48:19.396995  589656 httplog.go:131] "HTTP" verb="GET" URI="/metrics/resource" latency="31.294842ms" userAgent="metrics-server/v0.6.3 (linux/amd64) kubernetes/a938798" audit-ID="" srcIP="172.18.0.3:35538" resp=200
Sep 15 20:48:19 kind-worker3 kubelet[589656]: I0915 20:48:19.938456  589656 kubelet.go:2346] "Container runtime status" status="Runtime Conditions: RuntimeReady=true reason: message:, NetworkReady=true reason: message:"
Sep 15 20:48:20 kind-worker3 kubelet[589656]: I0915 20:48:20.498714  589656 kubelet.go:2160] "SyncLoop (housekeeping)"
Sep 15 20:48:20 kind-worker3 kubelet[589656]: I0915 20:48:20.511702  589656 kubelet_pods.go:1079] "Clean up pod workers for terminated pods"
Sep 15 20:48:20 kind-worker3 kubelet[589656]: I0915 20:48:20.511758  589656 kubelet_pods.go:1108] "Clean up probes for terminated pods"
Sep 15 20:48:20 kind-worker3 kubelet[589656]: I0915 20:48:20.513991  589656 kubelet_pods.go:1145] "Clean up orphaned pod statuses"
Sep 15 20:48:20 kind-worker3 kubelet[589656]: I0915 20:48:20.515226  589656 kubelet_pods.go:1164] "Clean up orphaned pod directories"
Sep 15 20:48:20 kind-worker3 kubelet[589656]: I0915 20:48:20.515355  589656 kubelet_pods.go:1175] "Clean up orphaned mirror pods"
Sep 15 20:48:20 kind-worker3 kubelet[589656]: I0915 20:48:20.515381  589656 kubelet_pods.go:1182] "Clean up orphaned pod cgroups"
Sep 15 20:48:20 kind-worker3 kubelet[589656]: I0915 20:48:20.515409  589656 kubelet.go:2168] "SyncLoop (housekeeping) end"
Sep 15 20:48:20 kind-worker3 kubelet[589656]: I0915 20:48:20.879645  589656 qos_container_manager_linux.go:379] "Updated QoS cgroup configuration"
Sep 15 20:48:21 kind-worker3 kubelet[589656]: I0915 20:48:21.119364  589656 setters.go:88] "Using node IP" IP="172.18.0.4"
Sep 15 20:48:22 kind-worker3 kubelet[589656]: I0915 20:48:22.498037  589656 kubelet.go:2160] "SyncLoop (housekeeping)"
Sep 15 20:48:22 kind-worker3 kubelet[589656]: I0915 20:48:22.505602  589656 kubelet_pods.go:1079] "Clean up pod workers for terminated pods"
Sep 15 20:48:22 kind-worker3 kubelet[589656]: I0915 20:48:22.505664  589656 kubelet_pods.go:1108] "Clean up probes for terminated pods"
Sep 15 20:48:22 kind-worker3 kubelet[589656]: I0915 20:48:22.505691  589656 kubelet_pods.go:1145] "Clean up orphaned pod statuses"
Sep 15 20:48:22 kind-worker3 kubelet[589656]: I0915 20:48:22.507399  589656 kubelet_pods.go:1164] "Clean up orphaned pod directories"
Sep 15 20:48:22 kind-worker3 kubelet[589656]: I0915 20:48:22.507584  589656 kubelet_pods.go:1175] "Clean up orphaned mirror pods"
Sep 15 20:48:22 kind-worker3 kubelet[589656]: I0915 20:48:22.507625  589656 kubelet_pods.go:1182] "Clean up orphaned pod cgroups"
Sep 15 20:48:22 kind-worker3 kubelet[589656]: I0915 20:48:22.507656  589656 kubelet.go:2168] "SyncLoop (housekeeping) end"
Sep 15 20:48:23 kind-worker3 kubelet[589656]: I0915 20:48:23.825322  589656 reflector.go:536] vendor/k8s.io/client-go/informers/factory.go:134: Watch close - *v1.Node total 6 items received
Sep 15 20:48:24 kind-worker3 kubelet[589656]: I0915 20:48:24.143784  589656 eviction_manager.go:237] "Eviction manager: synchronize housekeeping"
Sep 15 20:48:24 kind-worker3 kubelet[589656]: I0915 20:48:24.168153  589656 cri_stats_provider.go:525] "Unable to find network stats for sandbox" sandboxID="b477a0e3bdd1b445ce34dc6f173590a56dbfec252950ee838d5af2a2515a773b"
Sep 15 20:48:24 kind-worker3 kubelet[589656]: I0915 20:48:24.168411  589656 cri_stats_provider.go:525] "Unable to find network stats for sandbox" sandboxID="d0f4d02598fe0e9a32081b1554ae85df2b4224eb9a378fdcf99aa7c0035d33dc"
Sep 15 20:48:24 kind-worker3 kubelet[589656]: I0915 20:48:24.170903  589656 helpers.go:775] "Eviction manager:" log="observations" signal=pid.available resourceName="62258" capacity="63272" time="2023-09-15 20:48:24.168789594 +0000 UTC m=+2146368.091614731"
Sep 15 20:48:24 kind-worker3 kubelet[589656]: I0915 20:48:24.170953  589656 helpers.go:775] "Eviction manager:" log="observations" signal=memory.available resourceName="7829500Ki" capacity="8166760Ki" time="2023-09-15 20:48:24.147618162 +0000 UTC m=+2146368.070443443"
Sep 15 20:48:24 kind-worker3 kubelet[589656]: I0915 20:48:24.170992  589656 helpers.go:775] "Eviction manager:" log="observations" signal=allocatableMemory.available resourceName="8092412Ki" capacity="8166760Ki" time="2023-09-15 20:48:24.170699475 +0000 UTC m=+2146368.093524637"
Sep 15 20:48:24 kind-worker3 kubelet[589656]: I0915 20:48:24.171024  589656 helpers.go:775] "Eviction manager:" log="observations" signal=nodefs.available resourceName="7770736Ki" capacity="51341792Ki" time="2023-09-15 20:48:24.147618162 +0000 UTC m=+2146368.070443443"
Sep 15 20:48:24 kind-worker3 kubelet[589656]: I0915 20:48:24.171050  589656 helpers.go:775] "Eviction manager:" log="observations" signal=nodefs.inodesFree resourceName="2345592" capacity="3276800" time="2023-09-15 20:48:24.147618162 +0000 UTC m=+2146368.070443443"
Sep 15 20:48:24 kind-worker3 kubelet[589656]: I0915 20:48:24.171075  589656 helpers.go:775] "Eviction manager:" log="observations" signal=imagefs.available resourceName="7770736Ki" capacity="51341792Ki" time="2023-09-15 20:48:18.908661415 +0000 UTC"
Sep 15 20:48:24 kind-worker3 kubelet[589656]: I0915 20:48:24.171100  589656 helpers.go:775] "Eviction manager:" log="observations" signal=imagefs.inodesFree resourceName="2345592" capacity="3276800" time="2023-09-15 20:48:18.908661415 +0000 UTC"
Sep 15 20:48:24 kind-worker3 kubelet[589656]: I0915 20:48:24.171163  589656 eviction_manager.go:328] "Eviction manager: no resources are starved"
Sep 15 20:48:24 kind-worker3 kubelet[589656]: I0915 20:48:24.497935  589656 kubelet.go:2160] "SyncLoop (housekeeping)"
Sep 15 20:48:24 kind-worker3 kubelet[589656]: I0915 20:48:24.508791  589656 kubelet_pods.go:1079] "Clean up pod workers for terminated pods"
Sep 15 20:48:24 kind-worker3 kubelet[589656]: I0915 20:48:24.508842  589656 kubelet_pods.go:1108] "Clean up probes for terminated pods"
Sep 15 20:48:24 kind-worker3 kubelet[589656]: I0915 20:48:24.513142  589656 kubelet_pods.go:1145] "Clean up orphaned pod statuses"
Sep 15 20:48:24 kind-worker3 kubelet[589656]: I0915 20:48:24.515089  589656 kubelet_pods.go:1164] "Clean up orphaned pod directories"
Sep 15 20:48:24 kind-worker3 kubelet[589656]: I0915 20:48:24.515251  589656 kubelet_pods.go:1175] "Clean up orphaned mirror pods"
Sep 15 20:48:24 kind-worker3 kubelet[589656]: I0915 20:48:24.515287  589656 kubelet_pods.go:1182] "Clean up orphaned pod cgroups"
Sep 15 20:48:24 kind-worker3 kubelet[589656]: I0915 20:48:24.515317  589656 kubelet.go:2168] "SyncLoop (housekeeping) end"
Sep 15 20:48:24 kind-worker3 kubelet[589656]: I0915 20:48:24.940475  589656 kubelet.go:2346] "Container runtime status" status="Runtime Conditions: RuntimeReady=true reason: message:, NetworkReady=true reason: message:"
Sep 15 20:48:25 kind-worker3 kubelet[589656]: I0915 20:48:25.688548  589656 config.go:279] "Setting pods for source" source="api"
Sep 15 20:48:25 kind-worker3 kubelet[589656]: I0915 20:48:25.689373  589656 kubelet.go:2088] "SyncLoop DELETE" source="api" pods=[default/nginx-deployment-66f58bff7c-lhxbk]
Sep 15 20:48:25 kind-worker3 kubelet[589656]: I0915 20:48:25.689557  589656 pod_workers.go:625] "Pod is marked for graceful deletion, begin teardown" pod="default/nginx-deployment-66f58bff7c-lhxbk" podUID=f73dab4a-7b50-4d78-87ff-9600f1129748
Sep 15 20:48:25 kind-worker3 kubelet[589656]: I0915 20:48:25.689705  589656 pod_workers.go:888] "Processing pod event" pod="default/nginx-deployment-66f58bff7c-lhxbk" podUID=f73dab4a-7b50-4d78-87ff-9600f1129748 updateType=1
Sep 15 20:48:25 kind-worker3 kubelet[589656]: I0915 20:48:25.689795  589656 pod_workers.go:1005] "Pod worker has observed request to terminate" pod="default/nginx-deployment-66f58bff7c-lhxbk" podUID=f73dab4a-7b50-4d78-87ff-9600f1129748
Sep 15 20:48:25 kind-worker3 kubelet[589656]: I0915 20:48:25.689879  589656 kubelet.go:1743] "syncTerminatingPod enter" pod="default/nginx-deployment-66f58bff7c-lhxbk" podUID=f73dab4a-7b50-4d78-87ff-9600f1129748
Sep 15 20:48:25 kind-worker3 kubelet[589656]: I0915 20:48:25.689944  589656 kubelet_pods.go:1432] "Generating pod status" pod="default/nginx-deployment-66f58bff7c-lhxbk"
Sep 15 20:48:25 kind-worker3 kubelet[589656]: I0915 20:48:25.690160  589656 kubelet_pods.go:1444] "Got phase for pod" pod="default/nginx-deployment-66f58bff7c-lhxbk" oldPhase=Running phase=Running
Sep 15 20:48:25 kind-worker3 kubelet[589656]: I0915 20:48:25.690519  589656 kubelet.go:1773] "Pod terminating with grace period" pod="default/nginx-deployment-66f58bff7c-lhxbk" podUID=f73dab4a-7b50-4d78-87ff-9600f1129748 gracePeriod=30
Sep 15 20:48:25 kind-worker3 kubelet[589656]: I0915 20:48:25.690830  589656 kuberuntime_container.go:718] "Killing container with a grace period override" pod="default/nginx-deployment-66f58bff7c-lhxbk" podUID=f73dab4a-7b50-4d78-87ff-9600f1129748 containerName="nginx" containerID="containerd://04371653069bfc4e7adfe1202329b3f4c4d28768f5943be47084472fb3068e57" gracePeriod=30
Sep 15 20:48:25 kind-worker3 kubelet[589656]: I0915 20:48:25.690954  589656 kuberuntime_container.go:722] "Killing container with a grace period" pod="default/nginx-deployment-66f58bff7c-lhxbk" podUID=f73dab4a-7b50-4d78-87ff-9600f1129748 containerName="nginx" containerID="containerd://04371653069bfc4e7adfe1202329b3f4c4d28768f5943be47084472fb3068e57" gracePeriod=30
Sep 15 20:48:25 kind-worker3 kubelet[589656]: I0915 20:48:25.691073  589656 event.go:294] "Event occurred" object="default/nginx-deployment-66f58bff7c-lhxbk" fieldPath="spec.containers{nginx}" kind="Pod" apiVersion="v1" type="Normal" reason="Killing" message="Stopping container nginx"
Sep 15 20:48:25 kind-worker3 kubelet[589656]: I0915 20:48:25.779471  589656 status_manager.go:685] "Patch status for pod" pod="default/nginx-deployment-66f58bff7c-lhxbk" patch="{\"metadata\":{\"uid\":\"f73dab4a-7b50-4d78-87ff-9600f1129748\"}}"
Sep 15 20:48:25 kind-worker3 kubelet[589656]: I0915 20:48:25.779540  589656 status_manager.go:692] "Status for pod is up-to-date" pod="default/nginx-deployment-66f58bff7c-lhxbk" statusVersion=3
Sep 15 20:48:25 kind-worker3 kubelet[589656]: I0915 20:48:25.779587  589656 kubelet_pods.go:929] "Pod is terminated, but some containers are still running" pod="default/nginx-deployment-66f58bff7c-lhxbk"
Sep 15 20:48:25 kind-worker3 kubelet[589656]: I0915 20:48:25.833997  589656 manager.go:1044] Destroyed container: "/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-podf73dab4a_7b50_4d78_87ff_9600f1129748.slice/cri-containerd-04371653069bfc4e7adfe1202329b3f4c4d28768f5943be47084472fb3068e57.scope" (aliases: [04371653069bfc4e7adfe1202329b3f4c4d28768f5943be47084472fb3068e57 /kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-podf73dab4a_7b50_4d78_87ff_9600f1129748.slice/cri-containerd-04371653069bfc4e7adfe1202329b3f4c4d28768f5943be47084472fb3068e57.scope], namespace: "containerd")
Sep 15 20:48:25 kind-worker3 kubelet[589656]: I0915 20:48:25.834192  589656 handler.go:325] Added event &{/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-podf73dab4a_7b50_4d78_87ff_9600f1129748.slice/cri-containerd-04371653069bfc4e7adfe1202329b3f4c4d28768f5943be47084472fb3068e57.scope 2023-09-15 20:48:25.834167467 +0000 UTC m=+2146369.756992688 containerDeletion {<nil>}}
Sep 15 20:48:26 kind-worker3 kubelet[589656]: I0915 20:48:26.121281  589656 kuberuntime_container.go:731] "Container exited normally" pod="default/nginx-deployment-66f58bff7c-lhxbk" podUID=f73dab4a-7b50-4d78-87ff-9600f1129748 containerName="nginx" containerID="containerd://04371653069bfc4e7adfe1202329b3f4c4d28768f5943be47084472fb3068e57"
Sep 15 20:48:26 kind-worker3 kubelet[589656]: I0915 20:48:26.259796  589656 manager.go:1044] Destroyed container: "/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-podf73dab4a_7b50_4d78_87ff_9600f1129748.slice/cri-containerd-fc30c1f4e2ab17c030bbc0f9228e59d7c7a6d2b9b4070a68335ad8d174320a99.scope" (aliases: [fc30c1f4e2ab17c030bbc0f9228e59d7c7a6d2b9b4070a68335ad8d174320a99 /kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-podf73dab4a_7b50_4d78_87ff_9600f1129748.slice/cri-containerd-fc30c1f4e2ab17c030bbc0f9228e59d7c7a6d2b9b4070a68335ad8d174320a99.scope], namespace: "containerd")
Sep 15 20:48:26 kind-worker3 kubelet[589656]: I0915 20:48:26.259900  589656 handler.go:325] Added event &{/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-podf73dab4a_7b50_4d78_87ff_9600f1129748.slice/cri-containerd-fc30c1f4e2ab17c030bbc0f9228e59d7c7a6d2b9b4070a68335ad8d174320a99.scope 2023-09-15 20:48:26.259866703 +0000 UTC m=+2146370.182691836 containerDeletion {<nil>}}
Sep 15 20:48:26 kind-worker3 kubelet[589656]: I0915 20:48:26.498119  589656 kubelet.go:2160] "SyncLoop (housekeeping)"
Sep 15 20:48:26 kind-worker3 kubelet[589656]: I0915 20:48:26.500312  589656 kubelet_pods.go:929] "Pod is terminated, but some containers are still running" pod="default/nginx-deployment-66f58bff7c-lhxbk"
Sep 15 20:48:26 kind-worker3 kubelet[589656]: I0915 20:48:26.504961  589656 qos_container_manager_linux.go:379] "Updated QoS cgroup configuration"
Sep 15 20:48:26 kind-worker3 kubelet[589656]: I0915 20:48:26.506190  589656 kuberuntime_manager.go:1037] "getSandboxIDByPodUID got sandbox IDs for pod" podSandboxID=[fc30c1f4e2ab17c030bbc0f9228e59d7c7a6d2b9b4070a68335ad8d174320a99] pod="default/nginx-deployment-66f58bff7c-lhxbk"
Sep 15 20:48:26 kind-worker3 kubelet[589656]: I0915 20:48:26.507680  589656 kubelet_pods.go:1079] "Clean up pod workers for terminated pods"
Sep 15 20:48:26 kind-worker3 kubelet[589656]: I0915 20:48:26.507726  589656 kubelet_pods.go:1108] "Clean up probes for terminated pods"
Sep 15 20:48:26 kind-worker3 kubelet[589656]: I0915 20:48:26.507751  589656 kubelet_pods.go:1145] "Clean up orphaned pod statuses"
Sep 15 20:48:26 kind-worker3 kubelet[589656]: I0915 20:48:26.509765  589656 kubelet.go:1824] "Post-termination container state" pod="default/nginx-deployment-66f58bff7c-lhxbk" podUID=f73dab4a-7b50-4d78-87ff-9600f1129748 containers=[{Name:nginx State:exited ExitCode:0 FinishedAt:2023-09-15T20:48:25.7698211Z}]
Sep 15 20:48:26 kind-worker3 kubelet[589656]: I0915 20:48:26.509825  589656 kubelet.go:1831] "Pod termination stopped all running containers" pod="default/nginx-deployment-66f58bff7c-lhxbk" podUID=f73dab4a-7b50-4d78-87ff-9600f1129748
Sep 15 20:48:26 kind-worker3 kubelet[589656]: I0915 20:48:26.509861  589656 kubelet.go:1833] "syncTerminatingPod exit" pod="default/nginx-deployment-66f58bff7c-lhxbk" podUID=f73dab4a-7b50-4d78-87ff-9600f1129748
Sep 15 20:48:26 kind-worker3 kubelet[589656]: I0915 20:48:26.509896  589656 pod_workers.go:1050] "Pod terminated all containers successfully" pod="default/nginx-deployment-66f58bff7c-lhxbk" podUID=f73dab4a-7b50-4d78-87ff-9600f1129748
Sep 15 20:48:26 kind-worker3 kubelet[589656]: I0915 20:48:26.509952  589656 pod_workers.go:988] "Processing pod event done" pod="default/nginx-deployment-66f58bff7c-lhxbk" podUID=f73dab4a-7b50-4d78-87ff-9600f1129748 updateType=1
Sep 15 20:48:26 kind-worker3 kubelet[589656]: I0915 20:48:26.509981  589656 pod_workers.go:888] "Processing pod event" pod="default/nginx-deployment-66f58bff7c-lhxbk" podUID=f73dab4a-7b50-4d78-87ff-9600f1129748 updateType=2
Sep 15 20:48:26 kind-worker3 kubelet[589656]: I0915 20:48:26.510920  589656 kubelet_pods.go:1164] "Clean up orphaned pod directories"
Sep 15 20:48:26 kind-worker3 kubelet[589656]: I0915 20:48:26.511050  589656 kubelet_pods.go:1175] "Clean up orphaned mirror pods"
Sep 15 20:48:26 kind-worker3 kubelet[589656]: I0915 20:48:26.511080  589656 kubelet_pods.go:1182] "Clean up orphaned pod cgroups"
Sep 15 20:48:26 kind-worker3 kubelet[589656]: I0915 20:48:26.511108  589656 kubelet.go:2168] "SyncLoop (housekeeping) end"
Sep 15 20:48:26 kind-worker3 kubelet[589656]: I0915 20:48:26.520472  589656 desired_state_of_world_populator.go:253] "Removing volume from desired state" pod="default/nginx-deployment-66f58bff7c-lhxbk" podUID=f73dab4a-7b50-4d78-87ff-9600f1129748 volumeName="kube-api-access-95chw"
Sep 15 20:48:26 kind-worker3 kubelet[589656]: I0915 20:48:26.549837  589656 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"kube-api-access-95chw\" (UniqueName: \"kubernetes.io/projected/f73dab4a-7b50-4d78-87ff-9600f1129748-kube-api-access-95chw\") pod \"f73dab4a-7b50-4d78-87ff-9600f1129748\" (UID: \"f73dab4a-7b50-4d78-87ff-9600f1129748\") "
Sep 15 20:48:26 kind-worker3 kubelet[589656]: I0915 20:48:26.549964  589656 subpath_linux.go:244] Cleaning up subpath mounts for /var/lib/kubelet/pods/f73dab4a-7b50-4d78-87ff-9600f1129748/volume-subpaths/kube-api-access-95chw
Sep 15 20:48:26 kind-worker3 kubelet[589656]: I0915 20:48:26.550050  589656 projected.go:366] Tearing down volume kube-api-access-95chw for pod f73dab4a-7b50-4d78-87ff-9600f1129748 at /var/lib/kubelet/pods/f73dab4a-7b50-4d78-87ff-9600f1129748/volumes/kubernetes.io~projected/kube-api-access-95chw
Sep 15 20:48:26 kind-worker3 kubelet[589656]: I0915 20:48:26.550456  589656 empty_dir_linux.go:99] Statfs_t of /var/lib/kubelet/pods/f73dab4a-7b50-4d78-87ff-9600f1129748/volumes/kubernetes.io~projected/kube-api-access-95chw: {Type:16914836 Bsize:4096 Blocks:2041690 Bfree:2041687 Bavail:2041687 Files:1020845 Ffree:1020836 Fsid:{Val:[0 0]} Namelen:255 Frsize:4096 Flags:4128 Spare:[0 0 0 0]}
Sep 15 20:48:26 kind-worker3 kubelet[589656]: I0915 20:48:26.550550  589656 mount_linux.go:294] Unmounting /var/lib/kubelet/pods/f73dab4a-7b50-4d78-87ff-9600f1129748/volumes/kubernetes.io~projected/kube-api-access-95chw
Sep 15 20:48:26 kind-worker3 kubelet[589656]: I0915 20:48:26.586044  589656 operation_generator.go:863] UnmountVolume.TearDown succeeded for volume "kubernetes.io/projected/f73dab4a-7b50-4d78-87ff-9600f1129748-kube-api-access-95chw" (OuterVolumeSpecName: "kube-api-access-95chw") pod "f73dab4a-7b50-4d78-87ff-9600f1129748" (UID: "f73dab4a-7b50-4d78-87ff-9600f1129748"). InnerVolumeSpecName "kube-api-access-95chw". PluginName "kubernetes.io/projected", VolumeGidValue ""
Sep 15 20:48:26 kind-worker3 kubelet[589656]: I0915 20:48:26.650473  589656 reconciler.go:384] "Volume detached for volume \"kube-api-access-95chw\" (UniqueName: \"kubernetes.io/projected/f73dab4a-7b50-4d78-87ff-9600f1129748-kube-api-access-95chw\") on node \"kind-worker3\" DevicePath \"\""
Sep 15 20:48:26 kind-worker3 kubelet[589656]: I0915 20:48:26.948847  589656 generic.go:155] "GenericPLEG" podUID=f73dab4a-7b50-4d78-87ff-9600f1129748 containerID="04371653069bfc4e7adfe1202329b3f4c4d28768f5943be47084472fb3068e57" oldState=running newState=exited
Sep 15 20:48:26 kind-worker3 kubelet[589656]: I0915 20:48:26.951874  589656 generic.go:155] "GenericPLEG" podUID=f73dab4a-7b50-4d78-87ff-9600f1129748 containerID="fc30c1f4e2ab17c030bbc0f9228e59d7c7a6d2b9b4070a68335ad8d174320a99" oldState=running newState=exited
Sep 15 20:48:26 kind-worker3 kubelet[589656]: I0915 20:48:26.953948  589656 kuberuntime_manager.go:1037] "getSandboxIDByPodUID got sandbox IDs for pod" podSandboxID=[fc30c1f4e2ab17c030bbc0f9228e59d7c7a6d2b9b4070a68335ad8d174320a99] pod="default/nginx-deployment-66f58bff7c-lhxbk"
Sep 15 20:48:26 kind-worker3 kubelet[589656]: I0915 20:48:26.956392  589656 generic.go:421] "PLEG: Write status" pod="default/nginx-deployment-66f58bff7c-lhxbk"
Sep 15 20:48:26 kind-worker3 kubelet[589656]: I0915 20:48:26.956590  589656 generic.go:296] "Generic (PLEG): container finished" podID=f73dab4a-7b50-4d78-87ff-9600f1129748 containerID="04371653069bfc4e7adfe1202329b3f4c4d28768f5943be47084472fb3068e57" exitCode=0
Sep 15 20:48:26 kind-worker3 kubelet[589656]: I0915 20:48:26.956764  589656 kubelet.go:2110] "SyncLoop (PLEG): event for pod" pod="default/nginx-deployment-66f58bff7c-lhxbk" event=&{ID:f73dab4a-7b50-4d78-87ff-9600f1129748 Type:ContainerDied Data:04371653069bfc4e7adfe1202329b3f4c4d28768f5943be47084472fb3068e57}
Sep 15 20:48:26 kind-worker3 kubelet[589656]: I0915 20:48:26.956961  589656 kubelet.go:2110] "SyncLoop (PLEG): event for pod" pod="default/nginx-deployment-66f58bff7c-lhxbk" event=&{ID:f73dab4a-7b50-4d78-87ff-9600f1129748 Type:ContainerDied Data:fc30c1f4e2ab17c030bbc0f9228e59d7c7a6d2b9b4070a68335ad8d174320a99}
Sep 15 20:48:26 kind-worker3 kubelet[589656]: I0915 20:48:26.957218  589656 kuberuntime_container.go:950] "Removing container" containerID="04371653069bfc4e7adfe1202329b3f4c4d28768f5943be47084472fb3068e57"
Sep 15 20:48:26 kind-worker3 kubelet[589656]: I0915 20:48:26.957406  589656 scope.go:110] "RemoveContainer" containerID="04371653069bfc4e7adfe1202329b3f4c4d28768f5943be47084472fb3068e57"
Sep 15 20:48:26 kind-worker3 kubelet[589656]: I0915 20:48:26.957372  589656 kubelet.go:1841] "syncTerminatedPod enter" pod="default/nginx-deployment-66f58bff7c-lhxbk" podUID=f73dab4a-7b50-4d78-87ff-9600f1129748
Sep 15 20:48:26 kind-worker3 kubelet[589656]: I0915 20:48:26.957908  589656 kubelet_pods.go:1432] "Generating pod status" pod="default/nginx-deployment-66f58bff7c-lhxbk"
Sep 15 20:48:26 kind-worker3 kubelet[589656]: I0915 20:48:26.958086  589656 kubelet_pods.go:1444] "Got phase for pod" pod="default/nginx-deployment-66f58bff7c-lhxbk" oldPhase=Running phase=Running
Sep 15 20:48:26 kind-worker3 kubelet[589656]: I0915 20:48:26.958290  589656 volume_manager.go:444] "Waiting for volumes to unmount for pod" pod="default/nginx-deployment-66f58bff7c-lhxbk"
Sep 15 20:48:26 kind-worker3 kubelet[589656]: I0915 20:48:26.958480  589656 volume_manager.go:471] "All volumes are unmounted for pod" pod="default/nginx-deployment-66f58bff7c-lhxbk"
Sep 15 20:48:26 kind-worker3 kubelet[589656]: I0915 20:48:26.958652  589656 kubelet.go:1854] "Pod termination unmounted volumes" pod="default/nginx-deployment-66f58bff7c-lhxbk" podUID=f73dab4a-7b50-4d78-87ff-9600f1129748
Sep 15 20:48:26 kind-worker3 kubelet[589656]: I0915 20:48:26.960937  589656 reflector.go:225] Stopping reflector *v1.ConfigMap (0s) from object-"default"/"kube-root-ca.crt"
Sep 15 20:48:26 kind-worker3 kubelet[589656]: I0915 20:48:26.989611  589656 kubelet.go:1875] "Pod termination removed cgroups" pod="default/nginx-deployment-66f58bff7c-lhxbk" podUID=f73dab4a-7b50-4d78-87ff-9600f1129748
Sep 15 20:48:26 kind-worker3 kubelet[589656]: I0915 20:48:26.989747  589656 kubelet.go:1880] "Pod is terminated and will need no more status updates" pod="default/nginx-deployment-66f58bff7c-lhxbk" podUID=f73dab4a-7b50-4d78-87ff-9600f1129748
Sep 15 20:48:26 kind-worker3 kubelet[589656]: I0915 20:48:26.989781  589656 kubelet.go:1882] "syncTerminatedPod exit" pod="default/nginx-deployment-66f58bff7c-lhxbk" podUID=f73dab4a-7b50-4d78-87ff-9600f1129748
Sep 15 20:48:26 kind-worker3 kubelet[589656]: I0915 20:48:26.989806  589656 pod_workers.go:1105] "Pod is complete and the worker can now stop" pod="default/nginx-deployment-66f58bff7c-lhxbk" podUID=f73dab4a-7b50-4d78-87ff-9600f1129748
Sep 15 20:48:26 kind-worker3 kubelet[589656]: I0915 20:48:26.989844  589656 pod_workers.go:959] "Processing pod event done" pod="default/nginx-deployment-66f58bff7c-lhxbk" podUID=f73dab4a-7b50-4d78-87ff-9600f1129748 updateType=2
Sep 15 20:48:26 kind-worker3 kubelet[589656]: I0915 20:48:26.990036  589656 manager.go:1044] Destroyed container: "/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-podf73dab4a_7b50_4d78_87ff_9600f1129748.slice" (aliases: [], namespace: "")
Sep 15 20:48:26 kind-worker3 kubelet[589656]: I0915 20:48:26.990076  589656 handler.go:325] Added event &{/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-podf73dab4a_7b50_4d78_87ff_9600f1129748.slice 2023-09-15 20:48:26.990065502 +0000 UTC m=+2146370.912890632 containerDeletion {<nil>}}
Sep 15 20:48:27 kind-worker3 kubelet[589656]: I0915 20:48:27.164975  589656 kuberuntime_container.go:950] "Removing container" containerID="04371653069bfc4e7adfe1202329b3f4c4d28768f5943be47084472fb3068e57"
Sep 15 20:48:27 kind-worker3 kubelet[589656]: I0915 20:48:27.165007  589656 config.go:279] "Setting pods for source" source="api"
Sep 15 20:48:27 kind-worker3 kubelet[589656]: I0915 20:48:27.165535  589656 scope.go:110] "RemoveContainer" containerID="04371653069bfc4e7adfe1202329b3f4c4d28768f5943be47084472fb3068e57"
Sep 15 20:48:27 kind-worker3 kubelet[589656]: I0915 20:48:27.166055  589656 kubelet.go:2085] "SyncLoop RECONCILE" source="api" pods=[default/nginx-deployment-66f58bff7c-lhxbk]
Sep 15 20:48:27 kind-worker3 kubelet[589656]: E0915 20:48:27.167376  589656 remote_runtime.go:604] "ContainerStatus from runtime service failed" err="rpc error: code = NotFound desc = an error occurred when try to find container \"04371653069bfc4e7adfe1202329b3f4c4d28768f5943be47084472fb3068e57\": not found" containerID="04371653069bfc4e7adfe1202329b3f4c4d28768f5943be47084472fb3068e57"
Sep 15 20:48:27 kind-worker3 kubelet[589656]: I0915 20:48:27.167452  589656 pod_container_deletor.go:52] "DeleteContainer returned error" containerID={Type:containerd ID:04371653069bfc4e7adfe1202329b3f4c4d28768f5943be47084472fb3068e57} err="failed to get container status \"04371653069bfc4e7adfe1202329b3f4c4d28768f5943be47084472fb3068e57\": rpc error: code = NotFound desc = an error occurred when try to find container \"04371653069bfc4e7adfe1202329b3f4c4d28768f5943be47084472fb3068e57\": not found"
Sep 15 20:48:27 kind-worker3 kubelet[589656]: I0915 20:48:27.168121  589656 status_manager.go:685] "Patch status for pod" pod="default/nginx-deployment-66f58bff7c-lhxbk" patch="{\"metadata\":{\"uid\":\"f73dab4a-7b50-4d78-87ff-9600f1129748\"},\"status\":{\"$setElementOrder/conditions\":[{\"type\":\"Initialized\"},{\"type\":\"Ready\"},{\"type\":\"ContainersReady\"},{\"type\":\"PodScheduled\"}],\"conditions\":[{\"lastTransitionTime\":\"2023-09-15T20:48:26Z\",\"message\":\"containers with unready status: [nginx]\",\"reason\":\"ContainersNotReady\",\"status\":\"False\",\"type\":\"Ready\"},{\"lastTransitionTime\":\"2023-09-15T20:48:26Z\",\"message\":\"containers with unready status: [nginx]\",\"reason\":\"ContainersNotReady\",\"status\":\"False\",\"type\":\"ContainersReady\"}],\"containerStatuses\":[{\"containerID\":\"containerd://04371653069bfc4e7adfe1202329b3f4c4d28768f5943be47084472fb3068e57\",\"image\":\"docker.io/library/nginx:1.14.2\",\"imageID\":\"docker.io/library/nginx@sha256:f7988fb6c02e0ce69257d9bd9cf37ae20a60f1df7563c3a2a6abe24160306b8d\",\"lastState\":{},\"name\":\"nginx\",\"ready\":false,\"restartCount\":0,\"started\":false,\"state\":{\"terminated\":{\"containerID\":\"containerd://04371653069bfc4e7adfe1202329b3f4c4d28768f5943be47084472fb3068e57\",\"exitCode\":0,\"finishedAt\":\"2023-09-15T20:48:25Z\",\"reason\":\"Completed\",\"startedAt\":\"2023-09-15T20:48:07Z\"}}}]}}"
Sep 15 20:48:27 kind-worker3 kubelet[589656]: I0915 20:48:27.168283  589656 status_manager.go:694] "Status for pod updated successfully" pod="default/nginx-deployment-66f58bff7c-lhxbk" statusVersion=4 status={Phase:Running Conditions:[{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-09-15 20:48:04 +0000 UTC Reason: Message:} {Type:Ready Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-09-15 20:48:26 +0000 UTC Reason:ContainersNotReady Message:containers with unready status: [nginx]} {Type:ContainersReady Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-09-15 20:48:26 +0000 UTC Reason:ContainersNotReady Message:containers with unready status: [nginx]} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-09-15 20:48:04 +0000 UTC Reason: Message:}] Message: Reason: NominatedNodeName: HostIP:172.18.0.4 PodIP:10.244.3.70 PodIPs:[{IP:10.244.3.70}] StartTime:2023-09-15 20:48:04 +0000 UTC InitContainerStatuses:[] ContainerStatuses:[{Name:nginx State:{Waiting:nil Running:nil Terminated:&ContainerStateTerminated{ExitCode:0,Signal:0,Reason:Completed,Message:,StartedAt:2023-09-15 20:48:07 +0000 UTC,FinishedAt:2023-09-15 20:48:25 +0000 UTC,ContainerID:containerd://04371653069bfc4e7adfe1202329b3f4c4d28768f5943be47084472fb3068e57,}} LastTerminationState:{Waiting:nil Running:nil Terminated:nil} Ready:false RestartCount:0 Image:docker.io/library/nginx:1.14.2 ImageID:docker.io/library/nginx@sha256:f7988fb6c02e0ce69257d9bd9cf37ae20a60f1df7563c3a2a6abe24160306b8d ContainerID:containerd://04371653069bfc4e7adfe1202329b3f4c4d28768f5943be47084472fb3068e57 Started:0xc00154d2d9}] QOSClass:Burstable EphemeralContainerStatuses:[]}
Sep 15 20:48:27 kind-worker3 kubelet[589656]: I0915 20:48:27.168708  589656 kubelet_pods.go:955] "Pod is terminated and all resources are reclaimed" pod="default/nginx-deployment-66f58bff7c-lhxbk"
Sep 15 20:48:27 kind-worker3 kubelet[589656]: I0915 20:48:27.223985  589656 config.go:279] "Setting pods for source" source="api"
Sep 15 20:48:27 kind-worker3 kubelet[589656]: I0915 20:48:27.224398  589656 kubelet.go:2088] "SyncLoop DELETE" source="api" pods=[default/nginx-deployment-66f58bff7c-lhxbk]
Sep 15 20:48:27 kind-worker3 kubelet[589656]: I0915 20:48:27.224516  589656 pod_workers.go:611] "Pod is finished processing, no further updates" pod="default/nginx-deployment-66f58bff7c-lhxbk" podUID=f73dab4a-7b50-4d78-87ff-9600f1129748
Sep 15 20:48:27 kind-worker3 kubelet[589656]: I0915 20:48:27.352044  589656 status_manager.go:713] "Pod fully terminated and removed from etcd" pod="default/nginx-deployment-66f58bff7c-lhxbk"
Sep 15 20:48:27 kind-worker3 kubelet[589656]: I0915 20:48:27.352160  589656 config.go:279] "Setting pods for source" source="api"
Sep 15 20:48:27 kind-worker3 kubelet[589656]: I0915 20:48:27.352369  589656 kubelet.go:2082] "SyncLoop REMOVE" source="api" pods=[default/nginx-deployment-66f58bff7c-lhxbk]
Sep 15 20:48:27 kind-worker3 kubelet[589656]: I0915 20:48:27.352458  589656 kubelet.go:1927] "Pod has been deleted and must be killed" pod="default/nginx-deployment-66f58bff7c-lhxbk" podUID=f73dab4a-7b50-4d78-87ff-9600f1129748
Sep 15 20:48:27 kind-worker3 kubelet[589656]: I0915 20:48:27.352564  589656 pod_workers.go:611] "Pod is finished processing, no further updates" pod="default/nginx-deployment-66f58bff7c-lhxbk" podUID=f73dab4a-7b50-4d78-87ff-9600f1129748
Sep 15 20:48:27 kind-worker3 kubelet[589656]: I0915 20:48:27.358715  589656 status_manager.go:656] "Pod does not exist on the server" podUID=f73dab4a-7b50-4d78-87ff-9600f1129748 pod="default/nginx-deployment-66f58bff7c-lhxbk"
Sep 15 20:48:27 kind-worker3 kubelet[589656]: I0915 20:48:27.959384  589656 generic.go:155] "GenericPLEG" podUID=f73dab4a-7b50-4d78-87ff-9600f1129748 containerID="04371653069bfc4e7adfe1202329b3f4c4d28768f5943be47084472fb3068e57" oldState=exited newState=non-existent
Sep 15 20:48:27 kind-worker3 kubelet[589656]: I0915 20:48:27.960841  589656 kuberuntime_manager.go:1037] "getSandboxIDByPodUID got sandbox IDs for pod" podSandboxID=[fc30c1f4e2ab17c030bbc0f9228e59d7c7a6d2b9b4070a68335ad8d174320a99] pod="default/nginx-deployment-66f58bff7c-lhxbk"
Sep 15 20:48:27 kind-worker3 kubelet[589656]: I0915 20:48:27.962738  589656 generic.go:421] "PLEG: Write status" pod="default/nginx-deployment-66f58bff7c-lhxbk"
Sep 15 20:48:28 kind-worker3 kubelet[589656]: I0915 20:48:28.498573  589656 kubelet.go:2160] "SyncLoop (housekeeping)"
Sep 15 20:48:28 kind-worker3 kubelet[589656]: I0915 20:48:28.512490  589656 kubelet_pods.go:1079] "Clean up pod workers for terminated pods"
Sep 15 20:48:28 kind-worker3 kubelet[589656]: I0915 20:48:28.512619  589656 pod_workers.go:1258] "Pod has been terminated and is no longer known to the kubelet, remove all history" podUID=f73dab4a-7b50-4d78-87ff-9600f1129748
Sep 15 20:48:28 kind-worker3 kubelet[589656]: I0915 20:48:28.512663  589656 kubelet_pods.go:1108] "Clean up probes for terminated pods"
Sep 15 20:48:28 kind-worker3 kubelet[589656]: I0915 20:48:28.515042  589656 kubelet_pods.go:1145] "Clean up orphaned pod statuses"
Sep 15 20:48:28 kind-worker3 kubelet[589656]: I0915 20:48:28.516162  589656 kubelet_pods.go:1164] "Clean up orphaned pod directories"
Sep 15 20:48:28 kind-worker3 kubelet[589656]: I0915 20:48:28.516731  589656 kubelet_volumes.go:160] "Cleaned up orphaned pod volumes dir" podUID=f73dab4a-7b50-4d78-87ff-9600f1129748 path="/var/lib/kubelet/pods/f73dab4a-7b50-4d78-87ff-9600f1129748/volumes"
Sep 15 20:48:28 kind-worker3 kubelet[589656]: I0915 20:48:28.517577  589656 kubelet_volumes.go:236] "Orphaned pod found, removing" podUID=f73dab4a-7b50-4d78-87ff-9600f1129748
Sep 15 20:48:28 kind-worker3 kubelet[589656]: I0915 20:48:28.517672  589656 kubelet_pods.go:1175] "Clean up orphaned mirror pods"
Sep 15 20:48:28 kind-worker3 kubelet[589656]: I0915 20:48:28.517700  589656 kubelet_pods.go:1182] "Clean up orphaned pod cgroups"
Sep 15 20:48:28 kind-worker3 kubelet[589656]: I0915 20:48:28.517729  589656 kubelet.go:2168] "SyncLoop (housekeeping) end"
Sep 15 20:48:29 kind-worker3 kubelet[589656]: I0915 20:48:29.247137  589656 handler.go:293] error while reading "/proc/589656/fd/38" link: readlink /proc/589656/fd/38: no such file or directory
Sep 15 20:48:29 kind-worker3 kubelet[589656]: I0915 20:48:29.402767  589656 httplog.go:131] "HTTP" verb="GET" URI="/metrics/resource" latency="18.476623ms" userAgent="metrics-server/v0.6.3 (linux/amd64) kubernetes/a938798" audit-ID="" srcIP="172.18.0.3:35538" resp=200
Sep 15 20:48:29 kind-worker3 kubelet[589656]: I0915 20:48:29.942011  589656 kubelet.go:2346] "Container runtime status" status="Runtime Conditions: RuntimeReady=true reason: message:, NetworkReady=true reason: message:"
Sep 15 20:48:30 kind-worker3 kubelet[589656]: I0915 20:48:30.498226  589656 kubelet.go:2160] "SyncLoop (housekeeping)"
Sep 15 20:48:30 kind-worker3 kubelet[589656]: I0915 20:48:30.510882  589656 kubelet_pods.go:1079] "Clean up pod workers for terminated pods"
Sep 15 20:48:30 kind-worker3 kubelet[589656]: I0915 20:48:30.510940  589656 kubelet_pods.go:1108] "Clean up probes for terminated pods"
Sep 15 20:48:30 kind-worker3 kubelet[589656]: I0915 20:48:30.510982  589656 kubelet_pods.go:1145] "Clean up orphaned pod statuses"
Sep 15 20:48:30 kind-worker3 kubelet[589656]: I0915 20:48:30.512770  589656 kubelet_pods.go:1164] "Clean up orphaned pod directories"
Sep 15 20:48:30 kind-worker3 kubelet[589656]: I0915 20:48:30.513002  589656 kubelet_pods.go:1175] "Clean up orphaned mirror pods"
Sep 15 20:48:30 kind-worker3 kubelet[589656]: I0915 20:48:30.513133  589656 kubelet_pods.go:1182] "Clean up orphaned pod cgroups"
Sep 15 20:48:30 kind-worker3 kubelet[589656]: I0915 20:48:30.513185  589656 kubelet.go:2168] "SyncLoop (housekeeping) end"
Sep 15 20:48:31 kind-worker3 kubelet[589656]: I0915 20:48:31.291093  589656 setters.go:88] "Using node IP" IP="172.18.0.4"
Sep 15 20:48:32 kind-worker3 kubelet[589656]: I0915 20:48:32.498209  589656 kubelet.go:2160] "SyncLoop (housekeeping)"
Sep 15 20:48:32 kind-worker3 kubelet[589656]: I0915 20:48:32.506142  589656 kubelet_pods.go:1079] "Clean up pod workers for terminated pods"
Sep 15 20:48:32 kind-worker3 kubelet[589656]: I0915 20:48:32.506198  589656 kubelet_pods.go:1108] "Clean up probes for terminated pods"
Sep 15 20:48:32 kind-worker3 kubelet[589656]: I0915 20:48:32.508056  589656 kubelet_pods.go:1145] "Clean up orphaned pod statuses"
Sep 15 20:48:32 kind-worker3 kubelet[589656]: I0915 20:48:32.509543  589656 kubelet_pods.go:1164] "Clean up orphaned pod directories"
Sep 15 20:48:32 kind-worker3 kubelet[589656]: I0915 20:48:32.509697  589656 kubelet_pods.go:1175] "Clean up orphaned mirror pods"
Sep 15 20:48:32 kind-worker3 kubelet[589656]: I0915 20:48:32.509725  589656 kubelet_pods.go:1182] "Clean up orphaned pod cgroups"
Sep 15 20:48:32 kind-worker3 kubelet[589656]: I0915 20:48:32.509777  589656 kubelet.go:2168] "SyncLoop (housekeeping) end"
Sep 15 20:48:34 kind-worker3 kubelet[589656]: I0915 20:48:34.171890  589656 eviction_manager.go:237] "Eviction manager: synchronize housekeeping"
Sep 15 20:48:34 kind-worker3 kubelet[589656]: I0915 20:48:34.190323  589656 cri_stats_provider.go:525] "Unable to find network stats for sandbox" sandboxID="d0f4d02598fe0e9a32081b1554ae85df2b4224eb9a378fdcf99aa7c0035d33dc"
Sep 15 20:48:34 kind-worker3 kubelet[589656]: I0915 20:48:34.190897  589656 cri_stats_provider.go:525] "Unable to find network stats for sandbox" sandboxID="b477a0e3bdd1b445ce34dc6f173590a56dbfec252950ee838d5af2a2515a773b"
Sep 15 20:48:34 kind-worker3 kubelet[589656]: I0915 20:48:34.193820  589656 helpers.go:775] "Eviction manager:" log="observations" signal=memory.available resourceName="7837308Ki" capacity="8166760Ki" time="2023-09-15 20:48:34.176635081 +0000 UTC m=+2146378.099460309"
Sep 15 20:48:34 kind-worker3 kubelet[589656]: I0915 20:48:34.193898  589656 helpers.go:775] "Eviction manager:" log="observations" signal=allocatableMemory.available resourceName="8096592Ki" capacity="8166760Ki" time="2023-09-15 20:48:34.193615499 +0000 UTC m=+2146378.116440686"
Sep 15 20:48:34 kind-worker3 kubelet[589656]: I0915 20:48:34.193946  589656 helpers.go:775] "Eviction manager:" log="observations" signal=nodefs.available resourceName="7771180Ki" capacity="51341792Ki" time="2023-09-15 20:48:34.176635081 +0000 UTC m=+2146378.099460309"
Sep 15 20:48:34 kind-worker3 kubelet[589656]: I0915 20:48:34.193974  589656 helpers.go:775] "Eviction manager:" log="observations" signal=nodefs.inodesFree resourceName="2345739" capacity="3276800" time="2023-09-15 20:48:34.176635081 +0000 UTC m=+2146378.099460309"
Sep 15 20:48:34 kind-worker3 kubelet[589656]: I0915 20:48:34.193999  589656 helpers.go:775] "Eviction manager:" log="observations" signal=imagefs.available resourceName="7771180Ki" capacity="51341792Ki" time="2023-09-15 20:48:28.906558891 +0000 UTC"
Sep 15 20:48:34 kind-worker3 kubelet[589656]: I0915 20:48:34.194026  589656 helpers.go:775] "Eviction manager:" log="observations" signal=imagefs.inodesFree resourceName="2345739" capacity="3276800" time="2023-09-15 20:48:28.906558891 +0000 UTC"
Sep 15 20:48:34 kind-worker3 kubelet[589656]: I0915 20:48:34.194054  589656 helpers.go:775] "Eviction manager:" log="observations" signal=pid.available resourceName="62301" capacity="63272" time="2023-09-15 20:48:34.191389679 +0000 UTC m=+2146378.114214812"
Sep 15 20:48:34 kind-worker3 kubelet[589656]: I0915 20:48:34.194112  589656 eviction_manager.go:328] "Eviction manager: no resources are starved"
Sep 15 20:48:34 kind-worker3 kubelet[589656]: I0915 20:48:34.498687  589656 kubelet.go:2160] "SyncLoop (housekeeping)"
Sep 15 20:48:34 kind-worker3 kubelet[589656]: I0915 20:48:34.510119  589656 kubelet_pods.go:1079] "Clean up pod workers for terminated pods"
Sep 15 20:48:34 kind-worker3 kubelet[589656]: I0915 20:48:34.510167  589656 kubelet_pods.go:1108] "Clean up probes for terminated pods"
Sep 15 20:48:34 kind-worker3 kubelet[589656]: I0915 20:48:34.511834  589656 kubelet_pods.go:1145] "Clean up orphaned pod statuses"
Sep 15 20:48:34 kind-worker3 kubelet[589656]: I0915 20:48:34.513286  589656 kubelet_pods.go:1164] "Clean up orphaned pod directories"
Sep 15 20:48:34 kind-worker3 kubelet[589656]: I0915 20:48:34.513504  589656 kubelet_pods.go:1175] "Clean up orphaned mirror pods"
Sep 15 20:48:34 kind-worker3 kubelet[589656]: I0915 20:48:34.513531  589656 kubelet_pods.go:1182] "Clean up orphaned pod cgroups"
Sep 15 20:48:34 kind-worker3 kubelet[589656]: I0915 20:48:34.513572  589656 kubelet.go:2168] "SyncLoop (housekeeping) end"
Sep 15 20:48:34 kind-worker3 kubelet[589656]: I0915 20:48:34.943986  589656 kubelet.go:2346] "Container runtime status" status="Runtime Conditions: RuntimeReady=true reason: message:, NetworkReady=true reason: message:"
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.256279  589656 config.go:279] "Setting pods for source" source="file"
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.497881  589656 kubelet.go:2160] "SyncLoop (housekeeping)"
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.509894  589656 kubelet_pods.go:1079] "Clean up pod workers for terminated pods"
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.509938  589656 kubelet_pods.go:1108] "Clean up probes for terminated pods"
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.509961  589656 kubelet_pods.go:1145] "Clean up orphaned pod statuses"
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.511386  589656 kubelet_pods.go:1164] "Clean up orphaned pod directories"
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.511537  589656 kubelet_pods.go:1175] "Clean up orphaned mirror pods"
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.511578  589656 kubelet_pods.go:1182] "Clean up orphaned pod cgroups"
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.511607  589656 kubelet.go:2168] "SyncLoop (housekeeping) end"
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.515227  589656 factory.go:262] Factory "containerd" was unable to handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/sys-kernel-debug.mount"
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.515283  589656 factory.go:255] Factory "systemd" can handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/sys-kernel-debug.mount", but ignoring.
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.515328  589656 manager.go:925] ignoring container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/sys-kernel-debug.mount"
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.515365  589656 factory.go:262] Factory "containerd" was unable to handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/system.slice/systemd-journald.service"
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.515400  589656 factory.go:262] Factory "systemd" was unable to handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/system.slice/systemd-journald.service"
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.515433  589656 factory.go:255] Factory "raw" can handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/system.slice/systemd-journald.service", but ignoring.
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.515469  589656 manager.go:925] ignoring container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/system.slice/systemd-journald.service"
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.515505  589656 factory.go:262] Factory "containerd" was unable to handle container "/system.slice/containerd.service"
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.515535  589656 factory.go:262] Factory "systemd" was unable to handle container "/system.slice/containerd.service"
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.515564  589656 factory.go:255] Factory "raw" can handle container "/system.slice/containerd.service", but ignoring.
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.515595  589656 manager.go:925] ignoring container "/system.slice/containerd.service"
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.515626  589656 factory.go:262] Factory "containerd" was unable to handle container "/sys-fs-fuse-connections.mount"
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.515660  589656 factory.go:255] Factory "systemd" can handle container "/sys-fs-fuse-connections.mount", but ignoring.
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.515695  589656 manager.go:925] ignoring container "/sys-fs-fuse-connections.mount"
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.515722  589656 factory.go:262] Factory "containerd" was unable to handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet.slice"
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.515753  589656 factory.go:262] Factory "systemd" was unable to handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet.slice"
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.515787  589656 factory.go:255] Factory "raw" can handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet.slice", but ignoring.
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.515818  589656 manager.go:925] ignoring container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet.slice"
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.515850  589656 factory.go:262] Factory "containerd" was unable to handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/dev-hugepages.mount"
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.515884  589656 factory.go:255] Factory "systemd" can handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/dev-hugepages.mount", but ignoring.
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.515916  589656 manager.go:925] ignoring container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/dev-hugepages.mount"
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.515948  589656 factory.go:262] Factory "containerd" was unable to handle container "/sys-kernel-tracing.mount"
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.515981  589656 factory.go:255] Factory "systemd" can handle container "/sys-kernel-tracing.mount", but ignoring.
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.516014  589656 manager.go:925] ignoring container "/sys-kernel-tracing.mount"
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.516045  589656 factory.go:262] Factory "containerd" was unable to handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/sys-kernel-tracing.mount"
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.516080  589656 factory.go:255] Factory "systemd" can handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/sys-kernel-tracing.mount", but ignoring.
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.516113  589656 manager.go:925] ignoring container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/sys-kernel-tracing.mount"
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.516145  589656 factory.go:262] Factory "containerd" was unable to handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet"
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.516178  589656 factory.go:262] Factory "systemd" was unable to handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet"
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.516209  589656 factory.go:255] Factory "raw" can handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet", but ignoring.
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.516243  589656 manager.go:925] ignoring container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet"
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.516277  589656 factory.go:262] Factory "containerd" was unable to handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/system.slice/system-modprobe.slice"
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.516325  589656 factory.go:262] Factory "systemd" was unable to handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/system.slice/system-modprobe.slice"
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.516362  589656 factory.go:255] Factory "raw" can handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/system.slice/system-modprobe.slice", but ignoring.
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.516400  589656 manager.go:925] ignoring container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/system.slice/system-modprobe.slice"
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.516432  589656 factory.go:262] Factory "containerd" was unable to handle container "/system.slice/systemd-journald.service"
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.516462  589656 factory.go:262] Factory "systemd" was unable to handle container "/system.slice/systemd-journald.service"
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.516492  589656 factory.go:255] Factory "raw" can handle container "/system.slice/systemd-journald.service", but ignoring.
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.516526  589656 manager.go:925] ignoring container "/system.slice/systemd-journald.service"
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.516555  589656 factory.go:262] Factory "containerd" was unable to handle container "/kubelet.slice/kubelet.service"
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.516582  589656 factory.go:262] Factory "systemd" was unable to handle container "/kubelet.slice/kubelet.service"
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.516611  589656 factory.go:255] Factory "raw" can handle container "/kubelet.slice/kubelet.service", but ignoring.
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.516644  589656 manager.go:925] ignoring container "/kubelet.slice/kubelet.service"
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.516670  589656 factory.go:262] Factory "containerd" was unable to handle container "/sys-kernel-debug.mount"
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.516702  589656 factory.go:255] Factory "systemd" can handle container "/sys-kernel-debug.mount", but ignoring.
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.516736  589656 manager.go:925] ignoring container "/sys-kernel-debug.mount"
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.516762  589656 factory.go:262] Factory "containerd" was unable to handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/system.slice"
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.516796  589656 factory.go:262] Factory "systemd" was unable to handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/system.slice"
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.516832  589656 factory.go:255] Factory "raw" can handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/system.slice", but ignoring.
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.516865  589656 manager.go:925] ignoring container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/system.slice"
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.516897  589656 factory.go:262] Factory "containerd" was unable to handle container "/system.slice/system-modprobe.slice"
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.516928  589656 factory.go:262] Factory "systemd" was unable to handle container "/system.slice/system-modprobe.slice"
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.516959  589656 factory.go:255] Factory "raw" can handle container "/system.slice/system-modprobe.slice", but ignoring.
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.516989  589656 manager.go:925] ignoring container "/system.slice/system-modprobe.slice"
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.517019  589656 factory.go:262] Factory "containerd" was unable to handle container "/kubelet"
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.517049  589656 factory.go:262] Factory "systemd" was unable to handle container "/kubelet"
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.517120  589656 factory.go:255] Factory "raw" can handle container "/kubelet", but ignoring.
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.517168  589656 manager.go:925] ignoring container "/kubelet"
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.517200  589656 factory.go:262] Factory "containerd" was unable to handle container "/dev-hugepages.mount"
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.517228  589656 factory.go:255] Factory "systemd" can handle container "/dev-hugepages.mount", but ignoring.
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.517259  589656 manager.go:925] ignoring container "/dev-hugepages.mount"
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.518350  589656 factory.go:251] Error trying to work out if we can handle /docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267: failed to load container: container "ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267" in namespace "k8s.io": not found
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.518388  589656 factory.go:262] Factory "containerd" was unable to handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267"
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.518416  589656 factory.go:262] Factory "systemd" was unable to handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267"
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.518444  589656 factory.go:255] Factory "raw" can handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267", but ignoring.
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.518473  589656 manager.go:925] ignoring container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267"
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.518501  589656 factory.go:262] Factory "containerd" was unable to handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet.slice/kubelet-kubepods.slice"
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.518523  589656 factory.go:262] Factory "systemd" was unable to handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet.slice/kubelet-kubepods.slice"
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.518547  589656 factory.go:255] Factory "raw" can handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet.slice/kubelet-kubepods.slice", but ignoring.
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.518573  589656 manager.go:925] ignoring container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet.slice/kubelet-kubepods.slice"
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.518596  589656 factory.go:262] Factory "containerd" was unable to handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-podd2a8b1e2_f8ec_4685_881d_a4d1c26134c2.slice"
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.518675  589656 factory.go:262] Factory "systemd" was unable to handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-podd2a8b1e2_f8ec_4685_881d_a4d1c26134c2.slice"
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.518705  589656 factory.go:255] Factory "raw" can handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-podd2a8b1e2_f8ec_4685_881d_a4d1c26134c2.slice", but ignoring.
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.518744  589656 manager.go:925] ignoring container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-podd2a8b1e2_f8ec_4685_881d_a4d1c26134c2.slice"
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.518771  589656 factory.go:262] Factory "containerd" was unable to handle container "/system.slice"
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.518791  589656 factory.go:262] Factory "systemd" was unable to handle container "/system.slice"
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.518812  589656 factory.go:255] Factory "raw" can handle container "/system.slice", but ignoring.
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.518834  589656 manager.go:925] ignoring container "/system.slice"
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.518854  589656 factory.go:262] Factory "containerd" was unable to handle container "/kubelet.slice"
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.518873  589656 factory.go:262] Factory "systemd" was unable to handle container "/kubelet.slice"
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.518894  589656 factory.go:255] Factory "raw" can handle container "/kubelet.slice", but ignoring.
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.518917  589656 manager.go:925] ignoring container "/kubelet.slice"
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.518943  589656 factory.go:262] Factory "containerd" was unable to handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice"
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.518967  589656 factory.go:262] Factory "systemd" was unable to handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice"
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.518992  589656 factory.go:255] Factory "raw" can handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice", but ignoring.
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.519018  589656 manager.go:925] ignoring container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice"
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.519046  589656 factory.go:262] Factory "containerd" was unable to handle container "/docker"
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.519065  589656 factory.go:262] Factory "systemd" was unable to handle container "/docker"
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.519088  589656 factory.go:255] Factory "raw" can handle container "/docker", but ignoring.
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.519112  589656 manager.go:925] ignoring container "/docker"
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.519780  589656 factory.go:251] Error trying to work out if we can handle /docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267: failed to load container: container "ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267" in namespace "k8s.io": not found
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.519816  589656 factory.go:262] Factory "containerd" was unable to handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267"
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.519858  589656 factory.go:262] Factory "systemd" was unable to handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267"
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.519890  589656 factory.go:255] Factory "raw" can handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267", but ignoring.
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.519928  589656 manager.go:925] ignoring container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267"
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.519956  589656 factory.go:262] Factory "containerd" was unable to handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/sys-fs-fuse-connections.mount"
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.519984  589656 factory.go:255] Factory "systemd" can handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/sys-fs-fuse-connections.mount", but ignoring.
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.520014  589656 manager.go:925] ignoring container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/sys-fs-fuse-connections.mount"
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.520040  589656 factory.go:262] Factory "containerd" was unable to handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/docker"
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.520069  589656 factory.go:262] Factory "systemd" was unable to handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/docker"
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.520096  589656 factory.go:255] Factory "raw" can handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/docker", but ignoring.
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.520124  589656 manager.go:925] ignoring container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/docker"
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.520167  589656 factory.go:262] Factory "containerd" was unable to handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-besteffort.slice"
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.520201  589656 factory.go:262] Factory "systemd" was unable to handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-besteffort.slice"
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.520250  589656 factory.go:255] Factory "raw" can handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-besteffort.slice", but ignoring.
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.520282  589656 manager.go:925] ignoring container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-besteffort.slice"
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.520331  589656 factory.go:262] Factory "containerd" was unable to handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-besteffort.slice/kubelet-kubepods-besteffort-pod6b53eb8b_e28c_454a_92e9_b342af428fa5.slice"
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.520366  589656 factory.go:262] Factory "systemd" was unable to handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-besteffort.slice/kubelet-kubepods-besteffort-pod6b53eb8b_e28c_454a_92e9_b342af428fa5.slice"
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.520406  589656 factory.go:255] Factory "raw" can handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-besteffort.slice/kubelet-kubepods-besteffort-pod6b53eb8b_e28c_454a_92e9_b342af428fa5.slice", but ignoring.
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.520443  589656 manager.go:925] ignoring container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-besteffort.slice/kubelet-kubepods-besteffort-pod6b53eb8b_e28c_454a_92e9_b342af428fa5.slice"
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.520476  589656 factory.go:262] Factory "containerd" was unable to handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/system.slice/containerd.service"
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.520503  589656 factory.go:262] Factory "systemd" was unable to handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/system.slice/containerd.service"
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.520530  589656 factory.go:255] Factory "raw" can handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/system.slice/containerd.service", but ignoring.
Sep 15 20:48:36 kind-worker3 kubelet[589656]: I0915 20:48:36.520559  589656 manager.go:925] ignoring container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/system.slice/containerd.service"
Sep 15 20:48:38 kind-worker3 kubelet[589656]: I0915 20:48:38.497776  589656 kubelet.go:2160] "SyncLoop (housekeeping)"
Sep 15 20:48:38 kind-worker3 kubelet[589656]: I0915 20:48:38.513632  589656 kubelet_pods.go:1079] "Clean up pod workers for terminated pods"
Sep 15 20:48:38 kind-worker3 kubelet[589656]: I0915 20:48:38.513754  589656 kubelet_pods.go:1108] "Clean up probes for terminated pods"
Sep 15 20:48:38 kind-worker3 kubelet[589656]: I0915 20:48:38.516232  589656 kubelet_pods.go:1145] "Clean up orphaned pod statuses"
Sep 15 20:48:38 kind-worker3 kubelet[589656]: I0915 20:48:38.518407  589656 kubelet_pods.go:1164] "Clean up orphaned pod directories"
Sep 15 20:48:38 kind-worker3 kubelet[589656]: I0915 20:48:38.518593  589656 kubelet_pods.go:1175] "Clean up orphaned mirror pods"
Sep 15 20:48:38 kind-worker3 kubelet[589656]: I0915 20:48:38.518650  589656 kubelet_pods.go:1182] "Clean up orphaned pod cgroups"
Sep 15 20:48:38 kind-worker3 kubelet[589656]: I0915 20:48:38.518686  589656 kubelet.go:2168] "SyncLoop (housekeeping) end"
Sep 15 20:48:39 kind-worker3 kubelet[589656]: I0915 20:48:39.327091  589656 kuberuntime_gc.go:171] "Removing sandbox" sandboxID="fc30c1f4e2ab17c030bbc0f9228e59d7c7a6d2b9b4070a68335ad8d174320a99"
Sep 15 20:48:39 kind-worker3 kubelet[589656]: I0915 20:48:39.403339  589656 httplog.go:131] "HTTP" verb="GET" URI="/metrics/resource" latency="33.316878ms" userAgent="metrics-server/v0.6.3 (linux/amd64) kubernetes/a938798" audit-ID="" srcIP="172.18.0.3:35538" resp=200
Sep 15 20:48:39 kind-worker3 kubelet[589656]: I0915 20:48:39.449420  589656 kuberuntime_gc.go:171] "Removing sandbox" sandboxID="989c71a5f0b9e1fed741630292d401140445bec2e7fca6fb21d31525fc37072a"
Sep 15 20:48:39 kind-worker3 kubelet[589656]: I0915 20:48:39.566327  589656 kuberuntime_gc.go:343] "Removing pod logs" podUID=f73dab4a-7b50-4d78-87ff-9600f1129748
Sep 15 20:48:39 kind-worker3 kubelet[589656]: I0915 20:48:39.566922  589656 kuberuntime_gc.go:343] "Removing pod logs" podUID=9950f637-3ce8-428f-a136-02b68a154d8f
Sep 15 20:48:39 kind-worker3 kubelet[589656]: I0915 20:48:39.567618  589656 kubelet.go:1280] "Container garbage collection succeeded"
Sep 15 20:48:39 kind-worker3 kubelet[589656]: I0915 20:48:39.945794  589656 kubelet.go:2346] "Container runtime status" status="Runtime Conditions: RuntimeReady=true reason: message:, NetworkReady=true reason: message:"
Sep 15 20:48:40 kind-worker3 kubelet[589656]: I0915 20:48:40.000793  589656 generic.go:155] "GenericPLEG" podUID=9950f637-3ce8-428f-a136-02b68a154d8f containerID="989c71a5f0b9e1fed741630292d401140445bec2e7fca6fb21d31525fc37072a" oldState=exited newState=non-existent
Sep 15 20:48:40 kind-worker3 kubelet[589656]: I0915 20:48:40.000868  589656 generic.go:155] "GenericPLEG" podUID=f73dab4a-7b50-4d78-87ff-9600f1129748 containerID="fc30c1f4e2ab17c030bbc0f9228e59d7c7a6d2b9b4070a68335ad8d174320a99" oldState=exited newState=non-existent
Sep 15 20:48:40 kind-worker3 kubelet[589656]: I0915 20:48:40.000907  589656 generic.go:399] "PLEG: Delete status for pod" podUID="9950f637-3ce8-428f-a136-02b68a154d8f"
Sep 15 20:48:40 kind-worker3 kubelet[589656]: I0915 20:48:40.000944  589656 generic.go:399] "PLEG: Delete status for pod" podUID="f73dab4a-7b50-4d78-87ff-9600f1129748"
Sep 15 20:48:40 kind-worker3 kubelet[589656]: I0915 20:48:40.497627  589656 kubelet.go:2160] "SyncLoop (housekeeping)"
Sep 15 20:48:40 kind-worker3 kubelet[589656]: I0915 20:48:40.511394  589656 kubelet_pods.go:1079] "Clean up pod workers for terminated pods"
Sep 15 20:48:40 kind-worker3 kubelet[589656]: I0915 20:48:40.511452  589656 kubelet_pods.go:1108] "Clean up probes for terminated pods"
Sep 15 20:48:40 kind-worker3 kubelet[589656]: I0915 20:48:40.511477  589656 kubelet_pods.go:1145] "Clean up orphaned pod statuses"
Sep 15 20:48:40 kind-worker3 kubelet[589656]: I0915 20:48:40.513140  589656 kubelet_pods.go:1164] "Clean up orphaned pod directories"
Sep 15 20:48:40 kind-worker3 kubelet[589656]: I0915 20:48:40.513261  589656 kubelet_pods.go:1175] "Clean up orphaned mirror pods"
Sep 15 20:48:40 kind-worker3 kubelet[589656]: I0915 20:48:40.513288  589656 kubelet_pods.go:1182] "Clean up orphaned pod cgroups"
Sep 15 20:48:40 kind-worker3 kubelet[589656]: I0915 20:48:40.513317  589656 kubelet.go:2168] "SyncLoop (housekeeping) end"
Sep 15 20:48:41 kind-worker3 kubelet[589656]: I0915 20:48:41.412005  589656 setters.go:88] "Using node IP" IP="172.18.0.4"
Sep 15 20:48:42 kind-worker3 kubelet[589656]: I0915 20:48:42.498384  589656 kubelet.go:2160] "SyncLoop (housekeeping)"
Sep 15 20:48:42 kind-worker3 kubelet[589656]: I0915 20:48:42.511389  589656 kubelet_pods.go:1079] "Clean up pod workers for terminated pods"
Sep 15 20:48:42 kind-worker3 kubelet[589656]: I0915 20:48:42.511432  589656 kubelet_pods.go:1108] "Clean up probes for terminated pods"
Sep 15 20:48:42 kind-worker3 kubelet[589656]: I0915 20:48:42.513035  589656 kubelet_pods.go:1145] "Clean up orphaned pod statuses"
Sep 15 20:48:42 kind-worker3 kubelet[589656]: I0915 20:48:42.514374  589656 kubelet_pods.go:1164] "Clean up orphaned pod directories"
Sep 15 20:48:42 kind-worker3 kubelet[589656]: I0915 20:48:42.514524  589656 kubelet_pods.go:1175] "Clean up orphaned mirror pods"
Sep 15 20:48:42 kind-worker3 kubelet[589656]: I0915 20:48:42.514552  589656 kubelet_pods.go:1182] "Clean up orphaned pod cgroups"
Sep 15 20:48:42 kind-worker3 kubelet[589656]: I0915 20:48:42.514579  589656 kubelet.go:2168] "SyncLoop (housekeeping) end"
Sep 15 20:48:44 kind-worker3 kubelet[589656]: I0915 20:48:44.194546  589656 eviction_manager.go:237] "Eviction manager: synchronize housekeeping"
Sep 15 20:48:44 kind-worker3 kubelet[589656]: I0915 20:48:44.213640  589656 cri_stats_provider.go:525] "Unable to find network stats for sandbox" sandboxID="d0f4d02598fe0e9a32081b1554ae85df2b4224eb9a378fdcf99aa7c0035d33dc"
Sep 15 20:48:44 kind-worker3 kubelet[589656]: I0915 20:48:44.214494  589656 cri_stats_provider.go:525] "Unable to find network stats for sandbox" sandboxID="b477a0e3bdd1b445ce34dc6f173590a56dbfec252950ee838d5af2a2515a773b"
Sep 15 20:48:44 kind-worker3 kubelet[589656]: I0915 20:48:44.218958  589656 helpers.go:775] "Eviction manager:" log="observations" signal=nodefs.inodesFree resourceName="2345769" capacity="3276800" time="2023-09-15 20:48:44.197781695 +0000 UTC m=+2146388.120606973"
Sep 15 20:48:44 kind-worker3 kubelet[589656]: I0915 20:48:44.219017  589656 helpers.go:775] "Eviction manager:" log="observations" signal=imagefs.available resourceName="7771220Ki" capacity="51341792Ki" time="2023-09-15 20:48:38.905311866 +0000 UTC"
Sep 15 20:48:44 kind-worker3 kubelet[589656]: I0915 20:48:44.219053  589656 helpers.go:775] "Eviction manager:" log="observations" signal=imagefs.inodesFree resourceName="2345769" capacity="3276800" time="2023-09-15 20:48:38.905311866 +0000 UTC"
Sep 15 20:48:44 kind-worker3 kubelet[589656]: I0915 20:48:44.219081  589656 helpers.go:775] "Eviction manager:" log="observations" signal=pid.available resourceName="62299" capacity="63272" time="2023-09-15 20:48:44.215319455 +0000 UTC m=+2146388.138144616"
Sep 15 20:48:44 kind-worker3 kubelet[589656]: I0915 20:48:44.219119  589656 helpers.go:775] "Eviction manager:" log="observations" signal=memory.available resourceName="7836680Ki" capacity="8166760Ki" time="2023-09-15 20:48:44.197781695 +0000 UTC m=+2146388.120606973"
Sep 15 20:48:44 kind-worker3 kubelet[589656]: I0915 20:48:44.219175  589656 helpers.go:775] "Eviction manager:" log="observations" signal=allocatableMemory.available resourceName="8097412Ki" capacity="8166760Ki" time="2023-09-15 20:48:44.218756019 +0000 UTC m=+2146388.141581163"
Sep 15 20:48:44 kind-worker3 kubelet[589656]: I0915 20:48:44.219238  589656 helpers.go:775] "Eviction manager:" log="observations" signal=nodefs.available resourceName="7771220Ki" capacity="51341792Ki" time="2023-09-15 20:48:44.197781695 +0000 UTC m=+2146388.120606973"
Sep 15 20:48:44 kind-worker3 kubelet[589656]: I0915 20:48:44.219295  589656 eviction_manager.go:328] "Eviction manager: no resources are starved"
Sep 15 20:48:44 kind-worker3 kubelet[589656]: I0915 20:48:44.498704  589656 kubelet.go:2160] "SyncLoop (housekeeping)"
Sep 15 20:48:44 kind-worker3 kubelet[589656]: I0915 20:48:44.515368  589656 kubelet_pods.go:1079] "Clean up pod workers for terminated pods"
Sep 15 20:48:44 kind-worker3 kubelet[589656]: I0915 20:48:44.515429  589656 kubelet_pods.go:1108] "Clean up probes for terminated pods"
Sep 15 20:48:44 kind-worker3 kubelet[589656]: I0915 20:48:44.517237  589656 kubelet_pods.go:1145] "Clean up orphaned pod statuses"
Sep 15 20:48:44 kind-worker3 kubelet[589656]: I0915 20:48:44.518703  589656 kubelet_pods.go:1164] "Clean up orphaned pod directories"
Sep 15 20:48:44 kind-worker3 kubelet[589656]: I0915 20:48:44.518893  589656 kubelet_pods.go:1175] "Clean up orphaned mirror pods"
Sep 15 20:48:44 kind-worker3 kubelet[589656]: I0915 20:48:44.518934  589656 kubelet_pods.go:1182] "Clean up orphaned pod cgroups"
Sep 15 20:48:44 kind-worker3 kubelet[589656]: I0915 20:48:44.518981  589656 kubelet.go:2168] "SyncLoop (housekeeping) end"
Sep 15 20:48:44 kind-worker3 kubelet[589656]: I0915 20:48:44.947628  589656 kubelet.go:2346] "Container runtime status" status="Runtime Conditions: RuntimeReady=true reason: message:, NetworkReady=true reason: message:"
Sep 15 20:48:46 kind-worker3 kubelet[589656]: I0915 20:48:46.498373  589656 kubelet.go:2160] "SyncLoop (housekeeping)"
Sep 15 20:48:46 kind-worker3 kubelet[589656]: I0915 20:48:46.510207  589656 kubelet_pods.go:1079] "Clean up pod workers for terminated pods"
Sep 15 20:48:46 kind-worker3 kubelet[589656]: I0915 20:48:46.510281  589656 kubelet_pods.go:1108] "Clean up probes for terminated pods"
Sep 15 20:48:46 kind-worker3 kubelet[589656]: I0915 20:48:46.510321  589656 kubelet_pods.go:1145] "Clean up orphaned pod statuses"
Sep 15 20:48:46 kind-worker3 kubelet[589656]: I0915 20:48:46.513112  589656 kubelet_pods.go:1164] "Clean up orphaned pod directories"
Sep 15 20:48:46 kind-worker3 kubelet[589656]: I0915 20:48:46.513496  589656 kubelet_pods.go:1175] "Clean up orphaned mirror pods"
Sep 15 20:48:46 kind-worker3 kubelet[589656]: I0915 20:48:46.513779  589656 kubelet_pods.go:1182] "Clean up orphaned pod cgroups"
Sep 15 20:48:46 kind-worker3 kubelet[589656]: I0915 20:48:46.514058  589656 kubelet.go:2168] "SyncLoop (housekeeping) end"
Sep 15 20:48:47 kind-worker3 kubelet[589656]: I0915 20:48:47.564549  589656 handler.go:293] error while reading "/proc/589656/fd/38" link: readlink /proc/589656/fd/38: no such file or directory
Sep 15 20:48:48 kind-worker3 kubelet[589656]: I0915 20:48:48.498433  589656 kubelet.go:2160] "SyncLoop (housekeeping)"
Sep 15 20:48:48 kind-worker3 kubelet[589656]: I0915 20:48:48.509561  589656 kubelet_pods.go:1079] "Clean up pod workers for terminated pods"
Sep 15 20:48:48 kind-worker3 kubelet[589656]: I0915 20:48:48.509630  589656 kubelet_pods.go:1108] "Clean up probes for terminated pods"
Sep 15 20:48:48 kind-worker3 kubelet[589656]: I0915 20:48:48.511775  589656 kubelet_pods.go:1145] "Clean up orphaned pod statuses"
Sep 15 20:48:48 kind-worker3 kubelet[589656]: I0915 20:48:48.513840  589656 kubelet_pods.go:1164] "Clean up orphaned pod directories"
Sep 15 20:48:48 kind-worker3 kubelet[589656]: I0915 20:48:48.513991  589656 kubelet_pods.go:1175] "Clean up orphaned mirror pods"
Sep 15 20:48:48 kind-worker3 kubelet[589656]: I0915 20:48:48.514024  589656 kubelet_pods.go:1182] "Clean up orphaned pod cgroups"
Sep 15 20:48:48 kind-worker3 kubelet[589656]: I0915 20:48:48.514059  589656 kubelet.go:2168] "SyncLoop (housekeeping) end"
Sep 15 20:48:49 kind-worker3 kubelet[589656]: I0915 20:48:49.418317  589656 httplog.go:131] "HTTP" verb="GET" URI="/metrics/resource" latency="39.155395ms" userAgent="metrics-server/v0.6.3 (linux/amd64) kubernetes/a938798" audit-ID="" srcIP="172.18.0.3:35538" resp=200
Sep 15 20:48:49 kind-worker3 kubelet[589656]: I0915 20:48:49.949601  589656 kubelet.go:2346] "Container runtime status" status="Runtime Conditions: RuntimeReady=true reason: message:, NetworkReady=true reason: message:"
Sep 15 20:48:50 kind-worker3 kubelet[589656]: I0915 20:48:50.498759  589656 kubelet.go:2160] "SyncLoop (housekeeping)"
Sep 15 20:48:50 kind-worker3 kubelet[589656]: I0915 20:48:50.511472  589656 kubelet_pods.go:1079] "Clean up pod workers for terminated pods"
Sep 15 20:48:50 kind-worker3 kubelet[589656]: I0915 20:48:50.511540  589656 kubelet_pods.go:1108] "Clean up probes for terminated pods"
Sep 15 20:48:50 kind-worker3 kubelet[589656]: I0915 20:48:50.513872  589656 kubelet_pods.go:1145] "Clean up orphaned pod statuses"
Sep 15 20:48:50 kind-worker3 kubelet[589656]: I0915 20:48:50.515693  589656 kubelet_pods.go:1164] "Clean up orphaned pod directories"
Sep 15 20:48:50 kind-worker3 kubelet[589656]: I0915 20:48:50.515844  589656 kubelet_pods.go:1175] "Clean up orphaned mirror pods"
Sep 15 20:48:50 kind-worker3 kubelet[589656]: I0915 20:48:50.515877  589656 kubelet_pods.go:1182] "Clean up orphaned pod cgroups"
Sep 15 20:48:50 kind-worker3 kubelet[589656]: I0915 20:48:50.515913  589656 kubelet.go:2168] "SyncLoop (housekeeping) end"
Sep 15 20:48:51 kind-worker3 kubelet[589656]: I0915 20:48:51.801749  589656 setters.go:88] "Using node IP" IP="172.18.0.4"
Sep 15 20:48:52 kind-worker3 kubelet[589656]: I0915 20:48:52.498202  589656 kubelet.go:2160] "SyncLoop (housekeeping)"
Sep 15 20:48:52 kind-worker3 kubelet[589656]: I0915 20:48:52.506601  589656 kubelet_pods.go:1079] "Clean up pod workers for terminated pods"
Sep 15 20:48:52 kind-worker3 kubelet[589656]: I0915 20:48:52.506674  589656 kubelet_pods.go:1108] "Clean up probes for terminated pods"
Sep 15 20:48:52 kind-worker3 kubelet[589656]: I0915 20:48:52.506703  589656 kubelet_pods.go:1145] "Clean up orphaned pod statuses"
Sep 15 20:48:52 kind-worker3 kubelet[589656]: I0915 20:48:52.508442  589656 kubelet_pods.go:1164] "Clean up orphaned pod directories"
Sep 15 20:48:52 kind-worker3 kubelet[589656]: I0915 20:48:52.508619  589656 kubelet_pods.go:1175] "Clean up orphaned mirror pods"
Sep 15 20:48:52 kind-worker3 kubelet[589656]: I0915 20:48:52.508661  589656 kubelet_pods.go:1182] "Clean up orphaned pod cgroups"
Sep 15 20:48:52 kind-worker3 kubelet[589656]: I0915 20:48:52.508693  589656 kubelet.go:2168] "SyncLoop (housekeeping) end"
Sep 15 20:48:54 kind-worker3 kubelet[589656]: I0915 20:48:54.219406  589656 eviction_manager.go:237] "Eviction manager: synchronize housekeeping"
Sep 15 20:48:54 kind-worker3 kubelet[589656]: I0915 20:48:54.237009  589656 cri_stats_provider.go:525] "Unable to find network stats for sandbox" sandboxID="d0f4d02598fe0e9a32081b1554ae85df2b4224eb9a378fdcf99aa7c0035d33dc"
Sep 15 20:48:54 kind-worker3 kubelet[589656]: I0915 20:48:54.237927  589656 cri_stats_provider.go:525] "Unable to find network stats for sandbox" sandboxID="b477a0e3bdd1b445ce34dc6f173590a56dbfec252950ee838d5af2a2515a773b"
Sep 15 20:48:54 kind-worker3 kubelet[589656]: I0915 20:48:54.244469  589656 helpers.go:775] "Eviction manager:" log="observations" signal=imagefs.inodesFree resourceName="2345769" capacity="3276800" time="2023-09-15 20:48:48.906417973 +0000 UTC"
Sep 15 20:48:54 kind-worker3 kubelet[589656]: I0915 20:48:54.244520  589656 helpers.go:775] "Eviction manager:" log="observations" signal=pid.available resourceName="62299" capacity="63272" time="2023-09-15 20:48:54.238832592 +0000 UTC m=+2146398.161657830"
Sep 15 20:48:54 kind-worker3 kubelet[589656]: I0915 20:48:54.244554  589656 helpers.go:775] "Eviction manager:" log="observations" signal=memory.available resourceName="7837644Ki" capacity="8166760Ki" time="2023-09-15 20:48:54.222850419 +0000 UTC m=+2146398.145675645"
Sep 15 20:48:54 kind-worker3 kubelet[589656]: I0915 20:48:54.244582  589656 helpers.go:775] "Eviction manager:" log="observations" signal=allocatableMemory.available resourceName="8097412Ki" capacity="8166760Ki" time="2023-09-15 20:48:54.244275537 +0000 UTC m=+2146398.167100713"
Sep 15 20:48:54 kind-worker3 kubelet[589656]: I0915 20:48:54.244608  589656 helpers.go:775] "Eviction manager:" log="observations" signal=nodefs.available resourceName="7771140Ki" capacity="51341792Ki" time="2023-09-15 20:48:54.222850419 +0000 UTC m=+2146398.145675645"
Sep 15 20:48:54 kind-worker3 kubelet[589656]: I0915 20:48:54.244634  589656 helpers.go:775] "Eviction manager:" log="observations" signal=nodefs.inodesFree resourceName="2345769" capacity="3276800" time="2023-09-15 20:48:54.222850419 +0000 UTC m=+2146398.145675645"
Sep 15 20:48:54 kind-worker3 kubelet[589656]: I0915 20:48:54.244660  589656 helpers.go:775] "Eviction manager:" log="observations" signal=imagefs.available resourceName="7771140Ki" capacity="51341792Ki" time="2023-09-15 20:48:48.906417973 +0000 UTC"
Sep 15 20:48:54 kind-worker3 kubelet[589656]: I0915 20:48:54.244701  589656 eviction_manager.go:328] "Eviction manager: no resources are starved"
Sep 15 20:48:54 kind-worker3 kubelet[589656]: I0915 20:48:54.498464  589656 kubelet.go:2160] "SyncLoop (housekeeping)"
Sep 15 20:48:54 kind-worker3 kubelet[589656]: I0915 20:48:54.512800  589656 kubelet_pods.go:1079] "Clean up pod workers for terminated pods"
Sep 15 20:48:54 kind-worker3 kubelet[589656]: I0915 20:48:54.512851  589656 kubelet_pods.go:1108] "Clean up probes for terminated pods"
Sep 15 20:48:54 kind-worker3 kubelet[589656]: I0915 20:48:54.514787  589656 kubelet_pods.go:1145] "Clean up orphaned pod statuses"
Sep 15 20:48:54 kind-worker3 kubelet[589656]: I0915 20:48:54.516286  589656 kubelet_pods.go:1164] "Clean up orphaned pod directories"
Sep 15 20:48:54 kind-worker3 kubelet[589656]: I0915 20:48:54.516527  589656 kubelet_pods.go:1175] "Clean up orphaned mirror pods"
Sep 15 20:48:54 kind-worker3 kubelet[589656]: I0915 20:48:54.516652  589656 kubelet_pods.go:1182] "Clean up orphaned pod cgroups"
Sep 15 20:48:54 kind-worker3 kubelet[589656]: I0915 20:48:54.516707  589656 kubelet.go:2168] "SyncLoop (housekeeping) end"
Sep 15 20:48:54 kind-worker3 kubelet[589656]: I0915 20:48:54.951617  589656 kubelet.go:2346] "Container runtime status" status="Runtime Conditions: RuntimeReady=true reason: message:, NetworkReady=true reason: message:"
Sep 15 20:48:56 kind-worker3 kubelet[589656]: I0915 20:48:56.256886  589656 config.go:279] "Setting pods for source" source="file"
Sep 15 20:48:56 kind-worker3 kubelet[589656]: I0915 20:48:56.497788  589656 kubelet.go:2160] "SyncLoop (housekeeping)"
Sep 15 20:48:56 kind-worker3 kubelet[589656]: I0915 20:48:56.511533  589656 kubelet_pods.go:1079] "Clean up pod workers for terminated pods"
Sep 15 20:48:56 kind-worker3 kubelet[589656]: I0915 20:48:56.511803  589656 kubelet_pods.go:1108] "Clean up probes for terminated pods"
Sep 15 20:48:56 kind-worker3 kubelet[589656]: I0915 20:48:56.511996  589656 kubelet_pods.go:1145] "Clean up orphaned pod statuses"
Sep 15 20:48:56 kind-worker3 kubelet[589656]: I0915 20:48:56.513808  589656 kubelet_pods.go:1164] "Clean up orphaned pod directories"
Sep 15 20:48:56 kind-worker3 kubelet[589656]: I0915 20:48:56.513980  589656 kubelet_pods.go:1175] "Clean up orphaned mirror pods"
Sep 15 20:48:56 kind-worker3 kubelet[589656]: I0915 20:48:56.514022  589656 kubelet_pods.go:1182] "Clean up orphaned pod cgroups"
Sep 15 20:48:56 kind-worker3 kubelet[589656]: I0915 20:48:56.514067  589656 kubelet.go:2168] "SyncLoop (housekeeping) end"
Sep 15 20:48:58 kind-worker3 kubelet[589656]: I0915 20:48:58.498220  589656 kubelet.go:2160] "SyncLoop (housekeeping)"
Sep 15 20:48:58 kind-worker3 kubelet[589656]: I0915 20:48:58.509659  589656 kubelet_pods.go:1079] "Clean up pod workers for terminated pods"
Sep 15 20:48:58 kind-worker3 kubelet[589656]: I0915 20:48:58.509733  589656 kubelet_pods.go:1108] "Clean up probes for terminated pods"
Sep 15 20:48:58 kind-worker3 kubelet[589656]: I0915 20:48:58.511989  589656 kubelet_pods.go:1145] "Clean up orphaned pod statuses"
Sep 15 20:48:58 kind-worker3 kubelet[589656]: I0915 20:48:58.513893  589656 kubelet_pods.go:1164] "Clean up orphaned pod directories"
Sep 15 20:48:58 kind-worker3 kubelet[589656]: I0915 20:48:58.514130  589656 kubelet_pods.go:1175] "Clean up orphaned mirror pods"
Sep 15 20:48:58 kind-worker3 kubelet[589656]: I0915 20:48:58.514169  589656 kubelet_pods.go:1182] "Clean up orphaned pod cgroups"
Sep 15 20:48:58 kind-worker3 kubelet[589656]: I0915 20:48:58.514218  589656 kubelet.go:2168] "SyncLoop (housekeeping) end"
Sep 15 20:48:59 kind-worker3 kubelet[589656]: I0915 20:48:59.413778  589656 httplog.go:131] "HTTP" verb="GET" URI="/metrics/resource" latency="43.603088ms" userAgent="metrics-server/v0.6.3 (linux/amd64) kubernetes/a938798" audit-ID="" srcIP="172.18.0.3:35538" resp=200
Sep 15 20:48:59 kind-worker3 kubelet[589656]: I0915 20:48:59.954149  589656 kubelet.go:2346] "Container runtime status" status="Runtime Conditions: RuntimeReady=true reason: message:, NetworkReady=true reason: message:"
Sep 15 20:49:00 kind-worker3 kubelet[589656]: I0915 20:49:00.498271  589656 kubelet.go:2129] "SyncLoop (SYNC) pods" total=1 pods=[kube-system/kube-proxy-zvz6f]
Sep 15 20:49:00 kind-worker3 kubelet[589656]: I0915 20:49:00.498440  589656 kubelet.go:2160] "SyncLoop (housekeeping)"
Sep 15 20:49:00 kind-worker3 kubelet[589656]: I0915 20:49:00.498985  589656 pod_workers.go:888] "Processing pod event" pod="kube-system/kube-proxy-zvz6f" podUID=6b53eb8b-e28c-454a-92e9-b342af428fa5 updateType=0
Sep 15 20:49:00 kind-worker3 kubelet[589656]: I0915 20:49:00.499099  589656 kubelet.go:1501] "syncPod enter" pod="kube-system/kube-proxy-zvz6f" podUID=6b53eb8b-e28c-454a-92e9-b342af428fa5
Sep 15 20:49:00 kind-worker3 kubelet[589656]: I0915 20:49:00.499155  589656 kubelet_pods.go:1432] "Generating pod status" pod="kube-system/kube-proxy-zvz6f"
Sep 15 20:49:00 kind-worker3 kubelet[589656]: I0915 20:49:00.499270  589656 kubelet_pods.go:1444] "Got phase for pod" pod="kube-system/kube-proxy-zvz6f" oldPhase=Running phase=Running
Sep 15 20:49:00 kind-worker3 kubelet[589656]: I0915 20:49:00.499595  589656 status_manager.go:535] "Ignoring same status for pod" pod="kube-system/kube-proxy-zvz6f" status={Phase:Running Conditions:[{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-14 00:07:50 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-07-15 14:56:49 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-07-15 14:56:49 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-14 00:07:47 +0000 UTC Reason: Message:}] Message: Reason: NominatedNodeName: HostIP:172.18.0.4 PodIP:172.18.0.4 PodIPs:[{IP:172.18.0.4}] StartTime:2023-04-14 00:07:50 +0000 UTC InitContainerStatuses:[] ContainerStatuses:[{Name:kube-proxy State:{Waiting:nil Running:&ContainerStateRunning{StartedAt:2023-07-15 14:56:47 +0000 UTC,} Terminated:nil} LastTerminationState:{Waiting:nil Running:nil Terminated:&ContainerStateTerminated{ExitCode:255,Signal:0,Reason:Unknown,Message:,StartedAt:2023-05-13 23:24:22 +0000 UTC,FinishedAt:2023-07-15 14:56:13 +0000 UTC,ContainerID:containerd://1a7bfc39de99704091c5fdcafe31a31e1284778b198adb62ae3b794474907627,}} Ready:true RestartCount:2 Image:k8s.gcr.io/kube-proxy:v1.24.7 ImageID:docker.io/library/import-2022-10-26@sha256:82fa4ddf64d5be44671118fb9b86c454a222ff7ea6e48863ed7e5daeeca3ea42 ContainerID:containerd://041c9bf8c11670337ae7ecef4cae6277cbe6623488dc925c5412e6b4a494b7f0 Started:0xc00121a829}] QOSClass:BestEffort EphemeralContainerStatuses:[]}
Sep 15 20:49:00 kind-worker3 kubelet[589656]: I0915 20:49:00.500231  589656 volume_manager.go:404] "Waiting for volumes to attach and mount for pod" pod="kube-system/kube-proxy-zvz6f"
Sep 15 20:49:00 kind-worker3 kubelet[589656]: I0915 20:49:00.500315  589656 volume_manager.go:435] "All volumes are attached and mounted for pod" pod="kube-system/kube-proxy-zvz6f"
Sep 15 20:49:00 kind-worker3 kubelet[589656]: I0915 20:49:00.500713  589656 kuberuntime_manager.go:714] "computePodActions got for pod" podActions={KillPod:false CreateSandbox:false SandboxID:d0f4d02598fe0e9a32081b1554ae85df2b4224eb9a378fdcf99aa7c0035d33dc Attempt:2 NextInitContainerToStart:nil ContainersToStart:[] ContainersToKill:map[] EphemeralContainersToStart:[]} pod="kube-system/kube-proxy-zvz6f"
Sep 15 20:49:00 kind-worker3 kubelet[589656]: I0915 20:49:00.500949  589656 kubelet.go:1503] "syncPod exit" pod="kube-system/kube-proxy-zvz6f" podUID=6b53eb8b-e28c-454a-92e9-b342af428fa5 isTerminal=false
Sep 15 20:49:00 kind-worker3 kubelet[589656]: I0915 20:49:00.501030  589656 pod_workers.go:988] "Processing pod event done" pod="kube-system/kube-proxy-zvz6f" podUID=6b53eb8b-e28c-454a-92e9-b342af428fa5 updateType=0
Sep 15 20:49:00 kind-worker3 kubelet[589656]: I0915 20:49:00.510785  589656 kubelet_pods.go:1079] "Clean up pod workers for terminated pods"
Sep 15 20:49:00 kind-worker3 kubelet[589656]: I0915 20:49:00.510828  589656 kubelet_pods.go:1108] "Clean up probes for terminated pods"
Sep 15 20:49:00 kind-worker3 kubelet[589656]: I0915 20:49:00.512773  589656 kubelet_pods.go:1145] "Clean up orphaned pod statuses"
Sep 15 20:49:00 kind-worker3 kubelet[589656]: I0915 20:49:00.514154  589656 kubelet_pods.go:1164] "Clean up orphaned pod directories"
Sep 15 20:49:00 kind-worker3 kubelet[589656]: I0915 20:49:00.514333  589656 kubelet_pods.go:1175] "Clean up orphaned mirror pods"
Sep 15 20:49:00 kind-worker3 kubelet[589656]: I0915 20:49:00.514369  589656 kubelet_pods.go:1182] "Clean up orphaned pod cgroups"
Sep 15 20:49:00 kind-worker3 kubelet[589656]: I0915 20:49:00.514409  589656 kubelet.go:2168] "SyncLoop (housekeeping) end"
Sep 15 20:49:00 kind-worker3 kubelet[589656]: I0915 20:49:00.575440  589656 desired_state_of_world_populator.go:309] "Added volume to desired state" pod="kube-system/kube-proxy-zvz6f" volumeName="kube-proxy" volumeSpecName="kube-proxy"
Sep 15 20:49:00 kind-worker3 kubelet[589656]: I0915 20:49:00.575798  589656 desired_state_of_world_populator.go:309] "Added volume to desired state" pod="kube-system/kube-proxy-zvz6f" volumeName="xtables-lock" volumeSpecName="xtables-lock"
Sep 15 20:49:00 kind-worker3 kubelet[589656]: I0915 20:49:00.576079  589656 desired_state_of_world_populator.go:309] "Added volume to desired state" pod="kube-system/kube-proxy-zvz6f" volumeName="lib-modules" volumeSpecName="lib-modules"
Sep 15 20:49:00 kind-worker3 kubelet[589656]: I0915 20:49:00.576579  589656 desired_state_of_world_populator.go:309] "Added volume to desired state" pod="kube-system/kube-proxy-zvz6f" volumeName="kube-api-access-psmb2" volumeSpecName="kube-api-access-psmb2"
Sep 15 20:49:00 kind-worker3 kubelet[589656]: I0915 20:49:00.598007  589656 reconciler.go:243] "Starting operationExecutor.MountVolume for volume \"kube-proxy\" (UniqueName: \"kubernetes.io/configmap/6b53eb8b-e28c-454a-92e9-b342af428fa5-kube-proxy\") pod \"kube-proxy-zvz6f\" (UID: \"6b53eb8b-e28c-454a-92e9-b342af428fa5\") Volume is already mounted to pod, but remount was requested." pod="kube-system/kube-proxy-zvz6f"
Sep 15 20:49:00 kind-worker3 kubelet[589656]: I0915 20:49:00.598436  589656 reconciler.go:243] "Starting operationExecutor.MountVolume for volume \"kube-api-access-psmb2\" (UniqueName: \"kubernetes.io/projected/6b53eb8b-e28c-454a-92e9-b342af428fa5-kube-api-access-psmb2\") pod \"kube-proxy-zvz6f\" (UID: \"6b53eb8b-e28c-454a-92e9-b342af428fa5\") Volume is already mounted to pod, but remount was requested." pod="kube-system/kube-proxy-zvz6f"
Sep 15 20:49:00 kind-worker3 kubelet[589656]: I0915 20:49:00.598711  589656 configmap.go:181] Setting up volume kube-proxy for pod 6b53eb8b-e28c-454a-92e9-b342af428fa5 at /var/lib/kubelet/pods/6b53eb8b-e28c-454a-92e9-b342af428fa5/volumes/kubernetes.io~configmap/kube-proxy
Sep 15 20:49:00 kind-worker3 kubelet[589656]: I0915 20:49:00.598978  589656 configmap.go:205] Received configMap kube-system/kube-proxy containing (2) pieces of data, 1466 total bytes
Sep 15 20:49:00 kind-worker3 kubelet[589656]: I0915 20:49:00.599145  589656 quota_linux.go:271] SupportsQuotas called, but quotas disabled
Sep 15 20:49:00 kind-worker3 kubelet[589656]: I0915 20:49:00.599514  589656 projected.go:183] Setting up volume kube-api-access-psmb2 for pod 6b53eb8b-e28c-454a-92e9-b342af428fa5 at /var/lib/kubelet/pods/6b53eb8b-e28c-454a-92e9-b342af428fa5/volumes/kubernetes.io~projected/kube-api-access-psmb2
Sep 15 20:49:00 kind-worker3 kubelet[589656]: I0915 20:49:00.599637  589656 atomic_writer.go:161] pod kube-system/kube-proxy-zvz6f volume kube-proxy: no update required for target directory /var/lib/kubelet/pods/6b53eb8b-e28c-454a-92e9-b342af428fa5/volumes/kubernetes.io~configmap/kube-proxy
Sep 15 20:49:00 kind-worker3 kubelet[589656]: I0915 20:49:00.599981  589656 operation_generator.go:703] "MountVolume.SetUp succeeded for volume \"kube-proxy\" (UniqueName: \"kubernetes.io/configmap/6b53eb8b-e28c-454a-92e9-b342af428fa5-kube-proxy\") pod \"kube-proxy-zvz6f\" (UID: \"6b53eb8b-e28c-454a-92e9-b342af428fa5\") " pod="kube-system/kube-proxy-zvz6f"
Sep 15 20:49:00 kind-worker3 kubelet[589656]: I0915 20:49:00.600792  589656 atomic_writer.go:161] pod kube-system/kube-proxy-zvz6f volume kube-api-access-psmb2: no update required for target directory /var/lib/kubelet/pods/6b53eb8b-e28c-454a-92e9-b342af428fa5/volumes/kubernetes.io~projected/kube-api-access-psmb2
Sep 15 20:49:00 kind-worker3 kubelet[589656]: I0915 20:49:00.601109  589656 operation_generator.go:703] "MountVolume.SetUp succeeded for volume \"kube-api-access-psmb2\" (UniqueName: \"kubernetes.io/projected/6b53eb8b-e28c-454a-92e9-b342af428fa5-kube-api-access-psmb2\") pod \"kube-proxy-zvz6f\" (UID: \"6b53eb8b-e28c-454a-92e9-b342af428fa5\") " pod="kube-system/kube-proxy-zvz6f"
Sep 15 20:49:00 kind-worker3 kubelet[589656]: I0915 20:49:00.619856  589656 handler.go:293] error while reading "/proc/589656/fd/38" link: readlink /proc/589656/fd/38: no such file or directory
Sep 15 20:49:02 kind-worker3 kubelet[589656]: I0915 20:49:02.201890  589656 setters.go:88] "Using node IP" IP="172.18.0.4"
Sep 15 20:49:02 kind-worker3 kubelet[589656]: I0915 20:49:02.498401  589656 kubelet.go:2160] "SyncLoop (housekeeping)"
Sep 15 20:49:02 kind-worker3 kubelet[589656]: I0915 20:49:02.510448  589656 kubelet_pods.go:1079] "Clean up pod workers for terminated pods"
Sep 15 20:49:02 kind-worker3 kubelet[589656]: I0915 20:49:02.510516  589656 kubelet_pods.go:1108] "Clean up probes for terminated pods"
Sep 15 20:49:02 kind-worker3 kubelet[589656]: I0915 20:49:02.510553  589656 kubelet_pods.go:1145] "Clean up orphaned pod statuses"
Sep 15 20:49:02 kind-worker3 kubelet[589656]: I0915 20:49:02.512747  589656 kubelet_pods.go:1164] "Clean up orphaned pod directories"
Sep 15 20:49:02 kind-worker3 kubelet[589656]: I0915 20:49:02.512959  589656 kubelet_pods.go:1175] "Clean up orphaned mirror pods"
Sep 15 20:49:02 kind-worker3 kubelet[589656]: I0915 20:49:02.513004  589656 kubelet_pods.go:1182] "Clean up orphaned pod cgroups"
Sep 15 20:49:02 kind-worker3 kubelet[589656]: I0915 20:49:02.513124  589656 kubelet.go:2168] "SyncLoop (housekeeping) end"
Sep 15 20:49:04 kind-worker3 kubelet[589656]: I0915 20:49:04.245258  589656 eviction_manager.go:237] "Eviction manager: synchronize housekeeping"
Sep 15 20:49:04 kind-worker3 kubelet[589656]: I0915 20:49:04.264869  589656 cri_stats_provider.go:525] "Unable to find network stats for sandbox" sandboxID="b477a0e3bdd1b445ce34dc6f173590a56dbfec252950ee838d5af2a2515a773b"
Sep 15 20:49:04 kind-worker3 kubelet[589656]: I0915 20:49:04.265236  589656 cri_stats_provider.go:525] "Unable to find network stats for sandbox" sandboxID="d0f4d02598fe0e9a32081b1554ae85df2b4224eb9a378fdcf99aa7c0035d33dc"
Sep 15 20:49:04 kind-worker3 kubelet[589656]: I0915 20:49:04.268079  589656 helpers.go:775] "Eviction manager:" log="observations" signal=imagefs.inodesFree resourceName="2345769" capacity="3276800" time="2023-09-15 20:48:58.904355237 +0000 UTC"
Sep 15 20:49:04 kind-worker3 kubelet[589656]: I0915 20:49:04.268129  589656 helpers.go:775] "Eviction manager:" log="observations" signal=pid.available resourceName="62292" capacity="63272" time="2023-09-15 20:49:04.265648763 +0000 UTC m=+2146408.188473908"
Sep 15 20:49:04 kind-worker3 kubelet[589656]: I0915 20:49:04.268161  589656 helpers.go:775] "Eviction manager:" log="observations" signal=memory.available resourceName="7836636Ki" capacity="8166760Ki" time="2023-09-15 20:49:04.24808526 +0000 UTC m=+2146408.170910487"
Sep 15 20:49:04 kind-worker3 kubelet[589656]: I0915 20:49:04.268187  589656 helpers.go:775] "Eviction manager:" log="observations" signal=allocatableMemory.available resourceName="8097356Ki" capacity="8166760Ki" time="2023-09-15 20:49:04.267831505 +0000 UTC m=+2146408.190656676"
Sep 15 20:49:04 kind-worker3 kubelet[589656]: I0915 20:49:04.268215  589656 helpers.go:775] "Eviction manager:" log="observations" signal=nodefs.available resourceName="7771068Ki" capacity="51341792Ki" time="2023-09-15 20:49:04.24808526 +0000 UTC m=+2146408.170910487"
Sep 15 20:49:04 kind-worker3 kubelet[589656]: I0915 20:49:04.268240  589656 helpers.go:775] "Eviction manager:" log="observations" signal=nodefs.inodesFree resourceName="2345769" capacity="3276800" time="2023-09-15 20:49:04.24808526 +0000 UTC m=+2146408.170910487"
Sep 15 20:49:04 kind-worker3 kubelet[589656]: I0915 20:49:04.268265  589656 helpers.go:775] "Eviction manager:" log="observations" signal=imagefs.available resourceName="7771068Ki" capacity="51341792Ki" time="2023-09-15 20:48:58.904355237 +0000 UTC"
Sep 15 20:49:04 kind-worker3 kubelet[589656]: I0915 20:49:04.268314  589656 eviction_manager.go:328] "Eviction manager: no resources are starved"
Sep 15 20:49:04 kind-worker3 kubelet[589656]: I0915 20:49:04.497815  589656 kubelet.go:2160] "SyncLoop (housekeeping)"
Sep 15 20:49:04 kind-worker3 kubelet[589656]: I0915 20:49:04.511002  589656 kubelet_pods.go:1079] "Clean up pod workers for terminated pods"
Sep 15 20:49:04 kind-worker3 kubelet[589656]: I0915 20:49:04.511214  589656 kubelet_pods.go:1108] "Clean up probes for terminated pods"
Sep 15 20:49:04 kind-worker3 kubelet[589656]: I0915 20:49:04.514666  589656 kubelet_pods.go:1145] "Clean up orphaned pod statuses"
Sep 15 20:49:04 kind-worker3 kubelet[589656]: I0915 20:49:04.515869  589656 kubelet_pods.go:1164] "Clean up orphaned pod directories"
Sep 15 20:49:04 kind-worker3 kubelet[589656]: I0915 20:49:04.516039  589656 kubelet_pods.go:1175] "Clean up orphaned mirror pods"
Sep 15 20:49:04 kind-worker3 kubelet[589656]: I0915 20:49:04.516066  589656 kubelet_pods.go:1182] "Clean up orphaned pod cgroups"
Sep 15 20:49:04 kind-worker3 kubelet[589656]: I0915 20:49:04.516096  589656 kubelet.go:2168] "SyncLoop (housekeeping) end"
Sep 15 20:49:04 kind-worker3 kubelet[589656]: I0915 20:49:04.955913  589656 kubelet.go:2346] "Container runtime status" status="Runtime Conditions: RuntimeReady=true reason: message:, NetworkReady=true reason: message:"
Sep 15 20:49:06 kind-worker3 kubelet[589656]: I0915 20:49:06.497829  589656 kubelet.go:2160] "SyncLoop (housekeeping)"
Sep 15 20:49:06 kind-worker3 kubelet[589656]: I0915 20:49:06.511450  589656 kubelet_pods.go:1079] "Clean up pod workers for terminated pods"
Sep 15 20:49:06 kind-worker3 kubelet[589656]: I0915 20:49:06.511498  589656 kubelet_pods.go:1108] "Clean up probes for terminated pods"
Sep 15 20:49:06 kind-worker3 kubelet[589656]: I0915 20:49:06.513144  589656 kubelet_pods.go:1145] "Clean up orphaned pod statuses"
Sep 15 20:49:06 kind-worker3 kubelet[589656]: I0915 20:49:06.514218  589656 kubelet_pods.go:1164] "Clean up orphaned pod directories"
Sep 15 20:49:06 kind-worker3 kubelet[589656]: I0915 20:49:06.514346  589656 kubelet_pods.go:1175] "Clean up orphaned mirror pods"
Sep 15 20:49:06 kind-worker3 kubelet[589656]: I0915 20:49:06.514372  589656 kubelet_pods.go:1182] "Clean up orphaned pod cgroups"
Sep 15 20:49:06 kind-worker3 kubelet[589656]: I0915 20:49:06.514400  589656 kubelet.go:2168] "SyncLoop (housekeeping) end"
Sep 15 20:49:08 kind-worker3 kubelet[589656]: I0915 20:49:08.497885  589656 kubelet.go:2160] "SyncLoop (housekeeping)"
Sep 15 20:49:08 kind-worker3 kubelet[589656]: I0915 20:49:08.508592  589656 kubelet_pods.go:1079] "Clean up pod workers for terminated pods"
Sep 15 20:49:08 kind-worker3 kubelet[589656]: I0915 20:49:08.508639  589656 kubelet_pods.go:1108] "Clean up probes for terminated pods"
Sep 15 20:49:08 kind-worker3 kubelet[589656]: I0915 20:49:08.508665  589656 kubelet_pods.go:1145] "Clean up orphaned pod statuses"
Sep 15 20:49:08 kind-worker3 kubelet[589656]: I0915 20:49:08.511506  589656 kubelet_pods.go:1164] "Clean up orphaned pod directories"
Sep 15 20:49:08 kind-worker3 kubelet[589656]: I0915 20:49:08.511641  589656 kubelet_pods.go:1175] "Clean up orphaned mirror pods"
Sep 15 20:49:08 kind-worker3 kubelet[589656]: I0915 20:49:08.511709  589656 kubelet_pods.go:1182] "Clean up orphaned pod cgroups"
Sep 15 20:49:08 kind-worker3 kubelet[589656]: I0915 20:49:08.511759  589656 kubelet.go:2168] "SyncLoop (housekeeping) end"
Sep 15 20:49:09 kind-worker3 kubelet[589656]: I0915 20:49:09.409429  589656 httplog.go:131] "HTTP" verb="GET" URI="/metrics/resource" latency="33.668648ms" userAgent="metrics-server/v0.6.3 (linux/amd64) kubernetes/a938798" audit-ID="" srcIP="172.18.0.3:35538" resp=200
Sep 15 20:49:09 kind-worker3 kubelet[589656]: I0915 20:49:09.957459  589656 kubelet.go:2346] "Container runtime status" status="Runtime Conditions: RuntimeReady=true reason: message:, NetworkReady=true reason: message:"
Sep 15 20:49:10 kind-worker3 kubelet[589656]: I0915 20:49:10.497715  589656 kubelet.go:2160] "SyncLoop (housekeeping)"
Sep 15 20:49:10 kind-worker3 kubelet[589656]: I0915 20:49:10.510577  589656 kubelet_pods.go:1079] "Clean up pod workers for terminated pods"
Sep 15 20:49:10 kind-worker3 kubelet[589656]: I0915 20:49:10.510698  589656 kubelet_pods.go:1108] "Clean up probes for terminated pods"
Sep 15 20:49:10 kind-worker3 kubelet[589656]: I0915 20:49:10.513571  589656 kubelet_pods.go:1145] "Clean up orphaned pod statuses"
Sep 15 20:49:10 kind-worker3 kubelet[589656]: I0915 20:49:10.514827  589656 kubelet_pods.go:1164] "Clean up orphaned pod directories"
Sep 15 20:49:10 kind-worker3 kubelet[589656]: I0915 20:49:10.514964  589656 kubelet_pods.go:1175] "Clean up orphaned mirror pods"
Sep 15 20:49:10 kind-worker3 kubelet[589656]: I0915 20:49:10.514993  589656 kubelet_pods.go:1182] "Clean up orphaned pod cgroups"
Sep 15 20:49:10 kind-worker3 kubelet[589656]: I0915 20:49:10.515020  589656 kubelet.go:2168] "SyncLoop (housekeeping) end"
Sep 15 20:49:12 kind-worker3 kubelet[589656]: I0915 20:49:12.475637  589656 setters.go:88] "Using node IP" IP="172.18.0.4"
Sep 15 20:49:12 kind-worker3 kubelet[589656]: I0915 20:49:12.498469  589656 kubelet.go:2160] "SyncLoop (housekeeping)"
Sep 15 20:49:12 kind-worker3 kubelet[589656]: I0915 20:49:12.512187  589656 kubelet_pods.go:1079] "Clean up pod workers for terminated pods"
Sep 15 20:49:12 kind-worker3 kubelet[589656]: I0915 20:49:12.512528  589656 kubelet_pods.go:1108] "Clean up probes for terminated pods"
Sep 15 20:49:12 kind-worker3 kubelet[589656]: I0915 20:49:12.514477  589656 kubelet_pods.go:1145] "Clean up orphaned pod statuses"
Sep 15 20:49:12 kind-worker3 kubelet[589656]: I0915 20:49:12.515549  589656 kubelet_pods.go:1164] "Clean up orphaned pod directories"
Sep 15 20:49:12 kind-worker3 kubelet[589656]: I0915 20:49:12.515707  589656 kubelet_pods.go:1175] "Clean up orphaned mirror pods"
Sep 15 20:49:12 kind-worker3 kubelet[589656]: I0915 20:49:12.515744  589656 kubelet_pods.go:1182] "Clean up orphaned pod cgroups"
Sep 15 20:49:12 kind-worker3 kubelet[589656]: I0915 20:49:12.515786  589656 kubelet.go:2168] "SyncLoop (housekeeping) end"
Sep 15 20:49:14 kind-worker3 kubelet[589656]: I0915 20:49:14.269167  589656 eviction_manager.go:237] "Eviction manager: synchronize housekeeping"
Sep 15 20:49:14 kind-worker3 kubelet[589656]: I0915 20:49:14.281884  589656 cri_stats_provider.go:525] "Unable to find network stats for sandbox" sandboxID="d0f4d02598fe0e9a32081b1554ae85df2b4224eb9a378fdcf99aa7c0035d33dc"
Sep 15 20:49:14 kind-worker3 kubelet[589656]: I0915 20:49:14.282329  589656 cri_stats_provider.go:525] "Unable to find network stats for sandbox" sandboxID="b477a0e3bdd1b445ce34dc6f173590a56dbfec252950ee838d5af2a2515a773b"
Sep 15 20:49:14 kind-worker3 kubelet[589656]: I0915 20:49:14.285352  589656 helpers.go:775] "Eviction manager:" log="observations" signal=memory.available resourceName="7652Mi" capacity="8166760Ki" time="2023-09-15 20:49:14.271688755 +0000 UTC m=+2146418.194513996"
Sep 15 20:49:14 kind-worker3 kubelet[589656]: I0915 20:49:14.285417  589656 helpers.go:775] "Eviction manager:" log="observations" signal=allocatableMemory.available resourceName="8097212Ki" capacity="8166760Ki" time="2023-09-15 20:49:14.285053606 +0000 UTC m=+2146418.207878794"
Sep 15 20:49:14 kind-worker3 kubelet[589656]: I0915 20:49:14.285464  589656 helpers.go:775] "Eviction manager:" log="observations" signal=nodefs.available resourceName="7787040Ki" capacity="51341792Ki" time="2023-09-15 20:49:14.271688755 +0000 UTC m=+2146418.194513996"
Sep 15 20:49:14 kind-worker3 kubelet[589656]: I0915 20:49:14.285496  589656 helpers.go:775] "Eviction manager:" log="observations" signal=nodefs.inodesFree resourceName="2345788" capacity="3276800" time="2023-09-15 20:49:14.271688755 +0000 UTC m=+2146418.194513996"
Sep 15 20:49:14 kind-worker3 kubelet[589656]: I0915 20:49:14.285523  589656 helpers.go:775] "Eviction manager:" log="observations" signal=imagefs.available resourceName="7787040Ki" capacity="51341792Ki" time="2023-09-15 20:49:08.905607366 +0000 UTC"
Sep 15 20:49:14 kind-worker3 kubelet[589656]: I0915 20:49:14.285557  589656 helpers.go:775] "Eviction manager:" log="observations" signal=imagefs.inodesFree resourceName="2345788" capacity="3276800" time="2023-09-15 20:49:08.905607366 +0000 UTC"
Sep 15 20:49:14 kind-worker3 kubelet[589656]: I0915 20:49:14.285619  589656 helpers.go:775] "Eviction manager:" log="observations" signal=pid.available resourceName="62295" capacity="63272" time="2023-09-15 20:49:14.282779099 +0000 UTC m=+2146418.205604240"
Sep 15 20:49:14 kind-worker3 kubelet[589656]: I0915 20:49:14.285688  589656 eviction_manager.go:328] "Eviction manager: no resources are starved"
Sep 15 20:49:14 kind-worker3 kubelet[589656]: I0915 20:49:14.498602  589656 kubelet.go:2160] "SyncLoop (housekeeping)"
Sep 15 20:49:14 kind-worker3 kubelet[589656]: I0915 20:49:14.508499  589656 kubelet_pods.go:1079] "Clean up pod workers for terminated pods"
Sep 15 20:49:14 kind-worker3 kubelet[589656]: I0915 20:49:14.508564  589656 kubelet_pods.go:1108] "Clean up probes for terminated pods"
Sep 15 20:49:14 kind-worker3 kubelet[589656]: I0915 20:49:14.508589  589656 kubelet_pods.go:1145] "Clean up orphaned pod statuses"
Sep 15 20:49:14 kind-worker3 kubelet[589656]: I0915 20:49:14.510799  589656 kubelet_pods.go:1164] "Clean up orphaned pod directories"
Sep 15 20:49:14 kind-worker3 kubelet[589656]: I0915 20:49:14.510988  589656 kubelet_pods.go:1175] "Clean up orphaned mirror pods"
Sep 15 20:49:14 kind-worker3 kubelet[589656]: I0915 20:49:14.511042  589656 kubelet_pods.go:1182] "Clean up orphaned pod cgroups"
Sep 15 20:49:14 kind-worker3 kubelet[589656]: I0915 20:49:14.511103  589656 kubelet.go:2168] "SyncLoop (housekeeping) end"
Sep 15 20:49:14 kind-worker3 kubelet[589656]: I0915 20:49:14.960077  589656 kubelet.go:2346] "Container runtime status" status="Runtime Conditions: RuntimeReady=true reason: message:, NetworkReady=true reason: message:"
Sep 15 20:49:15 kind-worker3 kubelet[589656]: I0915 20:49:15.434959  589656 reflector.go:536] pkg/kubelet/config/apiserver.go:66: Watch close - *v1.Pod total 17 items received
Sep 15 20:49:16 kind-worker3 kubelet[589656]: I0915 20:49:16.256446  589656 config.go:279] "Setting pods for source" source="file"
Sep 15 20:49:16 kind-worker3 kubelet[589656]: I0915 20:49:16.497920  589656 kubelet.go:2160] "SyncLoop (housekeeping)"
Sep 15 20:49:16 kind-worker3 kubelet[589656]: I0915 20:49:16.509373  589656 kubelet_pods.go:1079] "Clean up pod workers for terminated pods"
Sep 15 20:49:16 kind-worker3 kubelet[589656]: I0915 20:49:16.509420  589656 kubelet_pods.go:1108] "Clean up probes for terminated pods"
Sep 15 20:49:16 kind-worker3 kubelet[589656]: I0915 20:49:16.511000  589656 kubelet_pods.go:1145] "Clean up orphaned pod statuses"
Sep 15 20:49:16 kind-worker3 kubelet[589656]: I0915 20:49:16.512183  589656 kubelet_pods.go:1164] "Clean up orphaned pod directories"
Sep 15 20:49:16 kind-worker3 kubelet[589656]: I0915 20:49:16.512308  589656 kubelet_pods.go:1175] "Clean up orphaned mirror pods"
Sep 15 20:49:16 kind-worker3 kubelet[589656]: I0915 20:49:16.512335  589656 kubelet_pods.go:1182] "Clean up orphaned pod cgroups"
Sep 15 20:49:16 kind-worker3 kubelet[589656]: I0915 20:49:16.512362  589656 kubelet.go:2168] "SyncLoop (housekeeping) end"
Sep 15 20:49:18 kind-worker3 kubelet[589656]: I0915 20:49:18.497702  589656 kubelet.go:2160] "SyncLoop (housekeeping)"
Sep 15 20:49:18 kind-worker3 kubelet[589656]: I0915 20:49:18.507829  589656 kubelet_pods.go:1079] "Clean up pod workers for terminated pods"
Sep 15 20:49:18 kind-worker3 kubelet[589656]: I0915 20:49:18.507902  589656 kubelet_pods.go:1108] "Clean up probes for terminated pods"
Sep 15 20:49:18 kind-worker3 kubelet[589656]: I0915 20:49:18.507932  589656 kubelet_pods.go:1145] "Clean up orphaned pod statuses"
Sep 15 20:49:18 kind-worker3 kubelet[589656]: I0915 20:49:18.509880  589656 kubelet_pods.go:1164] "Clean up orphaned pod directories"
Sep 15 20:49:18 kind-worker3 kubelet[589656]: I0915 20:49:18.510037  589656 kubelet_pods.go:1175] "Clean up orphaned mirror pods"
Sep 15 20:49:18 kind-worker3 kubelet[589656]: I0915 20:49:18.510068  589656 kubelet_pods.go:1182] "Clean up orphaned pod cgroups"
Sep 15 20:49:18 kind-worker3 kubelet[589656]: I0915 20:49:18.510109  589656 kubelet.go:2168] "SyncLoop (housekeeping) end"
Sep 15 20:49:19 kind-worker3 kubelet[589656]: I0915 20:49:19.407502  589656 httplog.go:131] "HTTP" verb="GET" URI="/metrics/resource" latency="17.367521ms" userAgent="metrics-server/v0.6.3 (linux/amd64) kubernetes/a938798" audit-ID="" srcIP="172.18.0.3:35538" resp=200
Sep 15 20:49:19 kind-worker3 kubelet[589656]: I0915 20:49:19.962509  589656 kubelet.go:2346] "Container runtime status" status="Runtime Conditions: RuntimeReady=true reason: message:, NetworkReady=true reason: message:"
Sep 15 20:49:19 kind-worker3 kubelet[589656]: I0915 20:49:19.995354  589656 handler.go:293] error while reading "/proc/589656/fd/38" link: readlink /proc/589656/fd/38: no such file or directory
Sep 15 20:49:20 kind-worker3 kubelet[589656]: I0915 20:49:20.497793  589656 kubelet.go:2160] "SyncLoop (housekeeping)"
Sep 15 20:49:20 kind-worker3 kubelet[589656]: I0915 20:49:20.505160  589656 kubelet_pods.go:1079] "Clean up pod workers for terminated pods"
Sep 15 20:49:20 kind-worker3 kubelet[589656]: I0915 20:49:20.505227  589656 kubelet_pods.go:1108] "Clean up probes for terminated pods"
Sep 15 20:49:20 kind-worker3 kubelet[589656]: I0915 20:49:20.506862  589656 kubelet_pods.go:1145] "Clean up orphaned pod statuses"
Sep 15 20:49:20 kind-worker3 kubelet[589656]: I0915 20:49:20.508088  589656 kubelet_pods.go:1164] "Clean up orphaned pod directories"
Sep 15 20:49:20 kind-worker3 kubelet[589656]: I0915 20:49:20.508226  589656 kubelet_pods.go:1175] "Clean up orphaned mirror pods"
Sep 15 20:49:20 kind-worker3 kubelet[589656]: I0915 20:49:20.508254  589656 kubelet_pods.go:1182] "Clean up orphaned pod cgroups"
Sep 15 20:49:20 kind-worker3 kubelet[589656]: I0915 20:49:20.508283  589656 kubelet.go:2168] "SyncLoop (housekeeping) end"
Sep 15 20:49:20 kind-worker3 kubelet[589656]: I0915 20:49:20.893647  589656 qos_container_manager_linux.go:379] "Updated QoS cgroup configuration"
Sep 15 20:49:22 kind-worker3 kubelet[589656]: I0915 20:49:22.497864  589656 kubelet.go:2160] "SyncLoop (housekeeping)"
Sep 15 20:49:22 kind-worker3 kubelet[589656]: I0915 20:49:22.505434  589656 kubelet_pods.go:1079] "Clean up pod workers for terminated pods"
Sep 15 20:49:22 kind-worker3 kubelet[589656]: I0915 20:49:22.505489  589656 kubelet_pods.go:1108] "Clean up probes for terminated pods"
Sep 15 20:49:22 kind-worker3 kubelet[589656]: I0915 20:49:22.507112  589656 kubelet_pods.go:1145] "Clean up orphaned pod statuses"
Sep 15 20:49:22 kind-worker3 kubelet[589656]: I0915 20:49:22.508732  589656 kubelet_pods.go:1164] "Clean up orphaned pod directories"
Sep 15 20:49:22 kind-worker3 kubelet[589656]: I0915 20:49:22.508912  589656 kubelet_pods.go:1175] "Clean up orphaned mirror pods"
Sep 15 20:49:22 kind-worker3 kubelet[589656]: I0915 20:49:22.508943  589656 kubelet_pods.go:1182] "Clean up orphaned pod cgroups"
Sep 15 20:49:22 kind-worker3 kubelet[589656]: I0915 20:49:22.508976  589656 kubelet.go:2168] "SyncLoop (housekeeping) end"
Sep 15 20:49:22 kind-worker3 kubelet[589656]: I0915 20:49:22.603673  589656 setters.go:88] "Using node IP" IP="172.18.0.4"
Sep 15 20:49:23 kind-worker3 kubelet[589656]: I0915 20:49:23.483560  589656 config.go:279] "Setting pods for source" source="api"
Sep 15 20:49:23 kind-worker3 kubelet[589656]: I0915 20:49:23.483671  589656 config.go:384] "Receiving a new pod" pod="default/nginx-deployment-66f58bff7c-7kkk5"
Sep 15 20:49:23 kind-worker3 kubelet[589656]: I0915 20:49:23.483865  589656 kubelet.go:2072] "SyncLoop ADD" source="api" pods=[default/nginx-deployment-66f58bff7c-7kkk5]
Sep 15 20:49:23 kind-worker3 kubelet[589656]: I0915 20:49:23.483942  589656 topology_manager.go:200] "Topology Admit Handler"
Sep 15 20:49:23 kind-worker3 kubelet[589656]: I0915 20:49:23.484047  589656 manager.go:914] "Looking for needed resources" needed=1 resourceName="cpu"
Sep 15 20:49:23 kind-worker3 kubelet[589656]: E0915 20:49:23.484172  589656 cpu_manager.go:394] "RemoveStaleState: removing container" podUID="f73dab4a-7b50-4d78-87ff-9600f1129748" containerName="nginx"
Sep 15 20:49:23 kind-worker3 kubelet[589656]: I0915 20:49:23.484235  589656 state_mem.go:107] "Deleted CPUSet assignment" podUID="f73dab4a-7b50-4d78-87ff-9600f1129748" containerName="nginx"
Sep 15 20:49:23 kind-worker3 kubelet[589656]: I0915 20:49:23.484343  589656 memory_manager.go:345] "RemoveStaleState removing state" podUID="f73dab4a-7b50-4d78-87ff-9600f1129748" containerName="nginx"
Sep 15 20:49:23 kind-worker3 kubelet[589656]: I0915 20:49:23.484565  589656 pod_workers.go:571] "Pod is being synced for the first time" pod="default/nginx-deployment-66f58bff7c-7kkk5" podUID=f602fc75-3d22-475f-8c0a-de933744ab4e
Sep 15 20:49:23 kind-worker3 kubelet[589656]: I0915 20:49:23.484690  589656 pod_workers.go:888] "Processing pod event" pod="default/nginx-deployment-66f58bff7c-7kkk5" podUID=f602fc75-3d22-475f-8c0a-de933744ab4e updateType=0
Sep 15 20:49:23 kind-worker3 kubelet[589656]: I0915 20:49:23.484779  589656 kubelet.go:1501] "syncPod enter" pod="default/nginx-deployment-66f58bff7c-7kkk5" podUID=f602fc75-3d22-475f-8c0a-de933744ab4e
Sep 15 20:49:23 kind-worker3 kubelet[589656]: I0915 20:49:23.484825  589656 kubelet_pods.go:1432] "Generating pod status" pod="default/nginx-deployment-66f58bff7c-7kkk5"
Sep 15 20:49:23 kind-worker3 kubelet[589656]: I0915 20:49:23.484900  589656 kubelet_pods.go:1444] "Got phase for pod" pod="default/nginx-deployment-66f58bff7c-7kkk5" oldPhase=Pending phase=Pending
Sep 15 20:49:23 kind-worker3 kubelet[589656]: I0915 20:49:23.485302  589656 reflector.go:219] Starting reflector *v1.ConfigMap (0s) from object-"default"/"kube-root-ca.crt"
Sep 15 20:49:23 kind-worker3 kubelet[589656]: I0915 20:49:23.485385  589656 reflector.go:255] Listing and watching *v1.ConfigMap from object-"default"/"kube-root-ca.crt"
Sep 15 20:49:23 kind-worker3 kubelet[589656]: I0915 20:49:23.495702  589656 qos_container_manager_linux.go:379] "Updated QoS cgroup configuration"
Sep 15 20:49:23 kind-worker3 kubelet[589656]: I0915 20:49:23.502409  589656 factory.go:262] Factory "containerd" was unable to handle container "/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-podf602fc75_3d22_475f_8c0a_de933744ab4e.slice"
Sep 15 20:49:23 kind-worker3 kubelet[589656]: I0915 20:49:23.502457  589656 factory.go:262] Factory "systemd" was unable to handle container "/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-podf602fc75_3d22_475f_8c0a_de933744ab4e.slice"
Sep 15 20:49:23 kind-worker3 kubelet[589656]: I0915 20:49:23.502481  589656 factory.go:258] Using factory "raw" for container "/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-podf602fc75_3d22_475f_8c0a_de933744ab4e.slice"
Sep 15 20:49:23 kind-worker3 kubelet[589656]: I0915 20:49:23.506313  589656 manager.go:988] Added container: "/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-podf602fc75_3d22_475f_8c0a_de933744ab4e.slice" (aliases: [], namespace: "")
Sep 15 20:49:23 kind-worker3 kubelet[589656]: I0915 20:49:23.508208  589656 handler.go:325] Added event &{/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-podf602fc75_3d22_475f_8c0a_de933744ab4e.slice 2023-09-15 20:49:23.49457792 +0000 UTC containerCreation {<nil>}}
Sep 15 20:49:23 kind-worker3 kubelet[589656]: I0915 20:49:23.508317  589656 container.go:530] Start housekeeping for container "/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-podf602fc75_3d22_475f_8c0a_de933744ab4e.slice"
Sep 15 20:49:23 kind-worker3 kubelet[589656]: I0915 20:49:23.509385  589656 volume_manager.go:404] "Waiting for volumes to attach and mount for pod" pod="default/nginx-deployment-66f58bff7c-7kkk5"
Sep 15 20:49:23 kind-worker3 kubelet[589656]: I0915 20:49:23.549492  589656 desired_state_of_world_populator.go:309] "Added volume to desired state" pod="default/nginx-deployment-66f58bff7c-7kkk5" volumeName="kube-api-access-kgpd5" volumeSpecName="kube-api-access-kgpd5"
Sep 15 20:49:23 kind-worker3 kubelet[589656]: I0915 20:49:23.578239  589656 reconciler.go:342] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-kgpd5\" (UniqueName: \"kubernetes.io/projected/f602fc75-3d22-475f-8c0a-de933744ab4e-kube-api-access-kgpd5\") pod \"nginx-deployment-66f58bff7c-7kkk5\" (UID: \"f602fc75-3d22-475f-8c0a-de933744ab4e\") " pod="default/nginx-deployment-66f58bff7c-7kkk5"
Sep 15 20:49:23 kind-worker3 kubelet[589656]: I0915 20:49:23.662316  589656 config.go:279] "Setting pods for source" source="api"
Sep 15 20:49:23 kind-worker3 kubelet[589656]: I0915 20:49:23.662323  589656 status_manager.go:685] "Patch status for pod" pod="default/nginx-deployment-66f58bff7c-7kkk5" patch="{\"metadata\":{\"uid\":\"f602fc75-3d22-475f-8c0a-de933744ab4e\"},\"status\":{\"$setElementOrder/conditions\":[{\"type\":\"Initialized\"},{\"type\":\"Ready\"},{\"type\":\"ContainersReady\"},{\"type\":\"PodScheduled\"}],\"conditions\":[{\"lastProbeTime\":null,\"lastTransitionTime\":\"2023-09-15T20:49:23Z\",\"status\":\"True\",\"type\":\"Initialized\"},{\"lastProbeTime\":null,\"lastTransitionTime\":\"2023-09-15T20:49:23Z\",\"message\":\"containers with unready status: [nginx]\",\"reason\":\"ContainersNotReady\",\"status\":\"False\",\"type\":\"Ready\"},{\"lastProbeTime\":null,\"lastTransitionTime\":\"2023-09-15T20:49:23Z\",\"message\":\"containers with unready status: [nginx]\",\"reason\":\"ContainersNotReady\",\"status\":\"False\",\"type\":\"ContainersReady\"}],\"containerStatuses\":[{\"image\":\"nginx:1.14.2\",\"imageID\":\"\",\"lastState\":{},\"name\":\"nginx\",\"ready\":false,\"restartCount\":0,\"started\":false,\"state\":{\"waiting\":{\"reason\":\"ContainerCreating\"}}}],\"hostIP\":\"172.18.0.4\",\"startTime\":\"2023-09-15T20:49:23Z\"}}"
Sep 15 20:49:23 kind-worker3 kubelet[589656]: I0915 20:49:23.662860  589656 status_manager.go:694] "Status for pod updated successfully" pod="default/nginx-deployment-66f58bff7c-7kkk5" statusVersion=1 status={Phase:Pending Conditions:[{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-09-15 20:49:23 +0000 UTC Reason: Message:} {Type:Ready Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-09-15 20:49:23 +0000 UTC Reason:ContainersNotReady Message:containers with unready status: [nginx]} {Type:ContainersReady Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-09-15 20:49:23 +0000 UTC Reason:ContainersNotReady Message:containers with unready status: [nginx]} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-09-15 20:49:23 +0000 UTC Reason: Message:}] Message: Reason: NominatedNodeName: HostIP:172.18.0.4 PodIP: PodIPs:[] StartTime:2023-09-15 20:49:23 +0000 UTC InitContainerStatuses:[] ContainerStatuses:[{Name:nginx State:{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,} Running:nil Terminated:nil} LastTerminationState:{Waiting:nil Running:nil Terminated:nil} Ready:false RestartCount:0 Image:nginx:1.14.2 ImageID: ContainerID: Started:0xc0014a1429}] QOSClass:Burstable EphemeralContainerStatuses:[]}
Sep 15 20:49:23 kind-worker3 kubelet[589656]: I0915 20:49:23.663187  589656 kubelet.go:2085] "SyncLoop RECONCILE" source="api" pods=[default/nginx-deployment-66f58bff7c-7kkk5]
Sep 15 20:49:23 kind-worker3 kubelet[589656]: I0915 20:49:23.679440  589656 reconciler.go:243] "Starting operationExecutor.MountVolume for volume \"kube-api-access-kgpd5\" (UniqueName: \"kubernetes.io/projected/f602fc75-3d22-475f-8c0a-de933744ab4e-kube-api-access-kgpd5\") pod \"nginx-deployment-66f58bff7c-7kkk5\" (UID: \"f602fc75-3d22-475f-8c0a-de933744ab4e\") " pod="default/nginx-deployment-66f58bff7c-7kkk5"
Sep 15 20:49:23 kind-worker3 kubelet[589656]: I0915 20:49:23.679558  589656 reconciler.go:254] "operationExecutor.MountVolume started for volume \"kube-api-access-kgpd5\" (UniqueName: \"kubernetes.io/projected/f602fc75-3d22-475f-8c0a-de933744ab4e-kube-api-access-kgpd5\") pod \"nginx-deployment-66f58bff7c-7kkk5\" (UID: \"f602fc75-3d22-475f-8c0a-de933744ab4e\") " pod="default/nginx-deployment-66f58bff7c-7kkk5"
Sep 15 20:49:23 kind-worker3 kubelet[589656]: I0915 20:49:23.679651  589656 projected.go:183] Setting up volume kube-api-access-kgpd5 for pod f602fc75-3d22-475f-8c0a-de933744ab4e at /var/lib/kubelet/pods/f602fc75-3d22-475f-8c0a-de933744ab4e/volumes/kubernetes.io~projected/kube-api-access-kgpd5
Sep 15 20:49:23 kind-worker3 kubelet[589656]: I0915 20:49:23.780435  589656 reconciler.go:243] "Starting operationExecutor.MountVolume for volume \"kube-api-access-kgpd5\" (UniqueName: \"kubernetes.io/projected/f602fc75-3d22-475f-8c0a-de933744ab4e-kube-api-access-kgpd5\") pod \"nginx-deployment-66f58bff7c-7kkk5\" (UID: \"f602fc75-3d22-475f-8c0a-de933744ab4e\") " pod="default/nginx-deployment-66f58bff7c-7kkk5"
Sep 15 20:49:23 kind-worker3 kubelet[589656]: I0915 20:49:23.803621  589656 empty_dir_linux.go:99] Statfs_t of /var/lib/kubelet/pods/f602fc75-3d22-475f-8c0a-de933744ab4e/volumes/kubernetes.io~projected/kube-api-access-kgpd5: {Type:61267 Bsize:4096 Blocks:12835448 Bfree:2606108 Bavail:1946678 Files:3276800 Ffree:2345768 Fsid:{Val:[-2136087178 982747248]} Namelen:255 Frsize:4096 Flags:4128 Spare:[0 0 0 0]}
Sep 15 20:49:23 kind-worker3 kubelet[589656]: I0915 20:49:23.803780  589656 empty_dir.go:334] pod f602fc75-3d22-475f-8c0a-de933744ab4e: mounting tmpfs for volume wrapped_kube-api-access-kgpd5
Sep 15 20:49:23 kind-worker3 kubelet[589656]: I0915 20:49:23.803870  589656 mount_linux.go:183] Mounting cmd (mount) with arguments (-t tmpfs -o size=8362762240 tmpfs /var/lib/kubelet/pods/f602fc75-3d22-475f-8c0a-de933744ab4e/volumes/kubernetes.io~projected/kube-api-access-kgpd5)
Sep 15 20:49:23 kind-worker3 kubelet[589656]: I0915 20:49:23.809429  589656 atomic_writer.go:181] pod default/nginx-deployment-66f58bff7c-7kkk5 volume kube-api-access-kgpd5: performed write of new data to ts data directory: /var/lib/kubelet/pods/f602fc75-3d22-475f-8c0a-de933744ab4e/volumes/kubernetes.io~projected/kube-api-access-kgpd5/..2023_09_15_20_49_23.1507061852
Sep 15 20:49:23 kind-worker3 kubelet[589656]: I0915 20:49:23.809660  589656 operation_generator.go:703] "MountVolume.SetUp succeeded for volume \"kube-api-access-kgpd5\" (UniqueName: \"kubernetes.io/projected/f602fc75-3d22-475f-8c0a-de933744ab4e-kube-api-access-kgpd5\") pod \"nginx-deployment-66f58bff7c-7kkk5\" (UID: \"f602fc75-3d22-475f-8c0a-de933744ab4e\") " pod="default/nginx-deployment-66f58bff7c-7kkk5"
Sep 15 20:49:23 kind-worker3 kubelet[589656]: I0915 20:49:23.813152  589656 volume_manager.go:435] "All volumes are attached and mounted for pod" pod="default/nginx-deployment-66f58bff7c-7kkk5"
Sep 15 20:49:23 kind-worker3 kubelet[589656]: I0915 20:49:23.813200  589656 kuberuntime_manager.go:469] "No sandbox for pod can be found. Need to start a new one" pod="default/nginx-deployment-66f58bff7c-7kkk5"
Sep 15 20:49:23 kind-worker3 kubelet[589656]: I0915 20:49:23.813244  589656 kuberuntime_manager.go:714] "computePodActions got for pod" podActions={KillPod:true CreateSandbox:true SandboxID: Attempt:0 NextInitContainerToStart:nil ContainersToStart:[0] ContainersToKill:map[] EphemeralContainersToStart:[]} pod="default/nginx-deployment-66f58bff7c-7kkk5"
Sep 15 20:49:23 kind-worker3 kubelet[589656]: I0915 20:49:23.813277  589656 kuberuntime_manager.go:723] "SyncPod received new pod, will create a sandbox for it" pod="default/nginx-deployment-66f58bff7c-7kkk5"
Sep 15 20:49:23 kind-worker3 kubelet[589656]: I0915 20:49:23.813316  589656 kuberuntime_manager.go:730] "Stopping PodSandbox for pod, will start new one" pod="default/nginx-deployment-66f58bff7c-7kkk5"
Sep 15 20:49:23 kind-worker3 kubelet[589656]: I0915 20:49:23.813351  589656 kuberuntime_manager.go:785] "Creating PodSandbox for pod" pod="default/nginx-deployment-66f58bff7c-7kkk5"
Sep 15 20:49:24 kind-worker3 kubelet[589656]: I0915 20:49:24.286353  589656 eviction_manager.go:237] "Eviction manager: synchronize housekeeping"
Sep 15 20:49:24 kind-worker3 kubelet[589656]: I0915 20:49:24.305490  589656 cri_stats_provider.go:525] "Unable to find network stats for sandbox" sandboxID="b477a0e3bdd1b445ce34dc6f173590a56dbfec252950ee838d5af2a2515a773b"
Sep 15 20:49:24 kind-worker3 kubelet[589656]: I0915 20:49:24.305858  589656 cri_stats_provider.go:525] "Unable to find network stats for sandbox" sandboxID="d0f4d02598fe0e9a32081b1554ae85df2b4224eb9a378fdcf99aa7c0035d33dc"
Sep 15 20:49:24 kind-worker3 kubelet[589656]: I0915 20:49:24.310795  589656 helpers.go:775] "Eviction manager:" log="observations" signal=memory.available resourceName="7887440Ki" capacity="8166760Ki" time="2023-09-15 20:49:24.28975304 +0000 UTC m=+2146428.212578224"
Sep 15 20:49:24 kind-worker3 kubelet[589656]: I0915 20:49:24.310836  589656 helpers.go:775] "Eviction manager:" log="observations" signal=allocatableMemory.available resourceName="8097184Ki" capacity="8166760Ki" time="2023-09-15 20:49:24.310454933 +0000 UTC m=+2146428.233280189"
Sep 15 20:49:24 kind-worker3 kubelet[589656]: I0915 20:49:24.310865  589656 helpers.go:775] "Eviction manager:" log="observations" signal=nodefs.available resourceName="7786248Ki" capacity="51341792Ki" time="2023-09-15 20:49:24.28975304 +0000 UTC m=+2146428.212578224"
Sep 15 20:49:24 kind-worker3 kubelet[589656]: I0915 20:49:24.310893  589656 helpers.go:775] "Eviction manager:" log="observations" signal=nodefs.inodesFree resourceName="2345745" capacity="3276800" time="2023-09-15 20:49:24.28975304 +0000 UTC m=+2146428.212578224"
Sep 15 20:49:24 kind-worker3 kubelet[589656]: I0915 20:49:24.310918  589656 helpers.go:775] "Eviction manager:" log="observations" signal=imagefs.available resourceName="7786248Ki" capacity="51341792Ki" time="2023-09-15 20:49:18.904960779 +0000 UTC"
Sep 15 20:49:24 kind-worker3 kubelet[589656]: I0915 20:49:24.310944  589656 helpers.go:775] "Eviction manager:" log="observations" signal=imagefs.inodesFree resourceName="2345745" capacity="3276800" time="2023-09-15 20:49:18.904960779 +0000 UTC"
Sep 15 20:49:24 kind-worker3 kubelet[589656]: I0915 20:49:24.310971  589656 helpers.go:775] "Eviction manager:" log="observations" signal=pid.available resourceName="62232" capacity="63272" time="2023-09-15 20:49:24.306936597 +0000 UTC m=+2146428.229761816"
Sep 15 20:49:24 kind-worker3 kubelet[589656]: I0915 20:49:24.311015  589656 eviction_manager.go:328] "Eviction manager: no resources are starved"
Sep 15 20:49:24 kind-worker3 kubelet[589656]: I0915 20:49:24.498533  589656 kubelet.go:2160] "SyncLoop (housekeeping)"
Sep 15 20:49:24 kind-worker3 kubelet[589656]: I0915 20:49:24.510890  589656 kubelet_pods.go:1079] "Clean up pod workers for terminated pods"
Sep 15 20:49:24 kind-worker3 kubelet[589656]: I0915 20:49:24.510952  589656 kubelet_pods.go:1108] "Clean up probes for terminated pods"
Sep 15 20:49:24 kind-worker3 kubelet[589656]: I0915 20:49:24.513365  589656 kubelet_pods.go:1145] "Clean up orphaned pod statuses"
Sep 15 20:49:24 kind-worker3 kubelet[589656]: I0915 20:49:24.515263  589656 kubelet_pods.go:1164] "Clean up orphaned pod directories"
Sep 15 20:49:24 kind-worker3 kubelet[589656]: I0915 20:49:24.515552  589656 kubelet_pods.go:1175] "Clean up orphaned mirror pods"
Sep 15 20:49:24 kind-worker3 kubelet[589656]: I0915 20:49:24.515622  589656 kubelet_pods.go:1182] "Clean up orphaned pod cgroups"
Sep 15 20:49:24 kind-worker3 kubelet[589656]: I0915 20:49:24.515669  589656 kubelet.go:2168] "SyncLoop (housekeeping) end"
Sep 15 20:49:24 kind-worker3 kubelet[589656]: I0915 20:49:24.918308  589656 factory.go:258] Using factory "containerd" for container "/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-podf602fc75_3d22_475f_8c0a_de933744ab4e.slice/cri-containerd-b553881ecd35bacb71b6c14fb9ca775d38c625d547bf3c076902f1ed25c4d0c1.scope"
Sep 15 20:49:24 kind-worker3 kubelet[589656]: I0915 20:49:24.965966  589656 kubelet.go:2346] "Container runtime status" status="Runtime Conditions: RuntimeReady=true reason: message:, NetworkReady=true reason: message:"
Sep 15 20:49:25 kind-worker3 kubelet[589656]: I0915 20:49:25.144610  589656 manager.go:988] Added container: "/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-podf602fc75_3d22_475f_8c0a_de933744ab4e.slice/cri-containerd-b553881ecd35bacb71b6c14fb9ca775d38c625d547bf3c076902f1ed25c4d0c1.scope" (aliases: [b553881ecd35bacb71b6c14fb9ca775d38c625d547bf3c076902f1ed25c4d0c1 /kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-podf602fc75_3d22_475f_8c0a_de933744ab4e.slice/cri-containerd-b553881ecd35bacb71b6c14fb9ca775d38c625d547bf3c076902f1ed25c4d0c1.scope], namespace: "containerd")
Sep 15 20:49:25 kind-worker3 kubelet[589656]: I0915 20:49:25.145934  589656 handler.go:325] Added event &{/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-podf602fc75_3d22_475f_8c0a_de933744ab4e.slice/cri-containerd-b553881ecd35bacb71b6c14fb9ca775d38c625d547bf3c076902f1ed25c4d0c1.scope 2023-09-15 20:49:24.906569306 +0000 UTC containerCreation {<nil>}}
Sep 15 20:49:25 kind-worker3 kubelet[589656]: I0915 20:49:25.146047  589656 container.go:530] Start housekeeping for container "/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-podf602fc75_3d22_475f_8c0a_de933744ab4e.slice/cri-containerd-b553881ecd35bacb71b6c14fb9ca775d38c625d547bf3c076902f1ed25c4d0c1.scope"
Sep 15 20:49:25 kind-worker3 kubelet[589656]: I0915 20:49:25.200579  589656 kuberuntime_manager.go:823] "Created PodSandbox for pod" podSandboxID="b553881ecd35bacb71b6c14fb9ca775d38c625d547bf3c076902f1ed25c4d0c1" pod="default/nginx-deployment-66f58bff7c-7kkk5"
Sep 15 20:49:25 kind-worker3 kubelet[589656]: I0915 20:49:25.202250  589656 kuberuntime_manager.go:846] "Determined the ip for pod after sandbox changed" IPs=[10.244.3.71] pod="default/nginx-deployment-66f58bff7c-7kkk5"
Sep 15 20:49:25 kind-worker3 kubelet[589656]: I0915 20:49:25.202518  589656 kuberuntime_manager.go:889] "Creating container in pod" containerType="container" container="&Container{Name:nginx,Image:nginx:1.14.2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{ContainerPort{Name:,HostPort:0,ContainerPort:80,Protocol:TCP,HostIP:,},},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{cpu: {{500 -3} {<nil>} 500m DecimalSI},},Requests:ResourceList{cpu: {{200 -3} {<nil>} 200m DecimalSI},},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-kgpd5,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,}" pod="default/nginx-deployment-66f58bff7c-7kkk5"
Sep 15 20:49:25 kind-worker3 kubelet[589656]: I0915 20:49:25.205255  589656 kubelet_pods.go:161] "Creating hosts mount for container" pod="default/nginx-deployment-66f58bff7c-7kkk5" containerName="nginx" podIPs=[10.244.3.71] path=true
Sep 15 20:49:25 kind-worker3 kubelet[589656]: I0915 20:49:25.206068  589656 event.go:294] "Event occurred" object="default/nginx-deployment-66f58bff7c-7kkk5" fieldPath="spec.containers{nginx}" kind="Pod" apiVersion="v1" type="Normal" reason="Pulled" message="Container image \"nginx:1.14.2\" already present on machine"
Sep 15 20:49:25 kind-worker3 kubelet[589656]: I0915 20:49:25.737952  589656 event.go:294] "Event occurred" object="default/nginx-deployment-66f58bff7c-7kkk5" fieldPath="spec.containers{nginx}" kind="Pod" apiVersion="v1" type="Normal" reason="Created" message="Created container nginx"
Sep 15 20:49:25 kind-worker3 kubelet[589656]: I0915 20:49:25.784298  589656 factory.go:258] Using factory "containerd" for container "/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-podf602fc75_3d22_475f_8c0a_de933744ab4e.slice/cri-containerd-5432e78771d09f84901cf4700d2078034e73119a187802ac085fa1e2e4829a62.scope"
Sep 15 20:49:26 kind-worker3 kubelet[589656]: I0915 20:49:26.154758  589656 generic.go:155] "GenericPLEG" podUID=f602fc75-3d22-475f-8c0a-de933744ab4e containerID="5432e78771d09f84901cf4700d2078034e73119a187802ac085fa1e2e4829a62" oldState=non-existent newState=unknown
Sep 15 20:49:26 kind-worker3 kubelet[589656]: I0915 20:49:26.154817  589656 generic.go:155] "GenericPLEG" podUID=f602fc75-3d22-475f-8c0a-de933744ab4e containerID="b553881ecd35bacb71b6c14fb9ca775d38c625d547bf3c076902f1ed25c4d0c1" oldState=non-existent newState=running
Sep 15 20:49:26 kind-worker3 kubelet[589656]: I0915 20:49:26.157778  589656 kuberuntime_manager.go:1037] "getSandboxIDByPodUID got sandbox IDs for pod" podSandboxID=[b553881ecd35bacb71b6c14fb9ca775d38c625d547bf3c076902f1ed25c4d0c1] pod="default/nginx-deployment-66f58bff7c-7kkk5"
Sep 15 20:49:26 kind-worker3 kubelet[589656]: I0915 20:49:26.176269  589656 generic.go:421] "PLEG: Write status" pod="default/nginx-deployment-66f58bff7c-7kkk5"
Sep 15 20:49:26 kind-worker3 kubelet[589656]: I0915 20:49:26.176350  589656 kubelet.go:2110] "SyncLoop (PLEG): event for pod" pod="default/nginx-deployment-66f58bff7c-7kkk5" event=&{ID:f602fc75-3d22-475f-8c0a-de933744ab4e Type:ContainerStarted Data:b553881ecd35bacb71b6c14fb9ca775d38c625d547bf3c076902f1ed25c4d0c1}
Sep 15 20:49:26 kind-worker3 kubelet[589656]: I0915 20:49:26.186881  589656 manager.go:988] Added container: "/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-podf602fc75_3d22_475f_8c0a_de933744ab4e.slice/cri-containerd-5432e78771d09f84901cf4700d2078034e73119a187802ac085fa1e2e4829a62.scope" (aliases: [5432e78771d09f84901cf4700d2078034e73119a187802ac085fa1e2e4829a62 /kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-podf602fc75_3d22_475f_8c0a_de933744ab4e.slice/cri-containerd-5432e78771d09f84901cf4700d2078034e73119a187802ac085fa1e2e4829a62.scope], namespace: "containerd")
Sep 15 20:49:26 kind-worker3 kubelet[589656]: I0915 20:49:26.187792  589656 handler.go:325] Added event &{/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-podf602fc75_3d22_475f_8c0a_de933744ab4e.slice/cri-containerd-5432e78771d09f84901cf4700d2078034e73119a187802ac085fa1e2e4829a62.scope 2023-09-15 20:49:25.778563985 +0000 UTC containerCreation {<nil>}}
Sep 15 20:49:26 kind-worker3 kubelet[589656]: I0915 20:49:26.187886  589656 container.go:530] Start housekeeping for container "/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-podf602fc75_3d22_475f_8c0a_de933744ab4e.slice/cri-containerd-5432e78771d09f84901cf4700d2078034e73119a187802ac085fa1e2e4829a62.scope"
Sep 15 20:49:26 kind-worker3 kubelet[589656]: I0915 20:49:26.286896  589656 kubelet.go:1503] "syncPod exit" pod="default/nginx-deployment-66f58bff7c-7kkk5" podUID=f602fc75-3d22-475f-8c0a-de933744ab4e isTerminal=false
Sep 15 20:49:26 kind-worker3 kubelet[589656]: I0915 20:49:26.286966  589656 event.go:294] "Event occurred" object="default/nginx-deployment-66f58bff7c-7kkk5" fieldPath="spec.containers{nginx}" kind="Pod" apiVersion="v1" type="Normal" reason="Started" message="Started container nginx"
Sep 15 20:49:26 kind-worker3 kubelet[589656]: I0915 20:49:26.286973  589656 pod_workers.go:988] "Processing pod event done" pod="default/nginx-deployment-66f58bff7c-7kkk5" podUID=f602fc75-3d22-475f-8c0a-de933744ab4e updateType=0
Sep 15 20:49:26 kind-worker3 kubelet[589656]: I0915 20:49:26.287062  589656 pod_workers.go:888] "Processing pod event" pod="default/nginx-deployment-66f58bff7c-7kkk5" podUID=f602fc75-3d22-475f-8c0a-de933744ab4e updateType=0
Sep 15 20:49:26 kind-worker3 kubelet[589656]: I0915 20:49:26.498324  589656 kubelet.go:2160] "SyncLoop (housekeeping)"
Sep 15 20:49:26 kind-worker3 kubelet[589656]: I0915 20:49:26.507106  589656 kubelet_pods.go:1079] "Clean up pod workers for terminated pods"
Sep 15 20:49:26 kind-worker3 kubelet[589656]: I0915 20:49:26.507154  589656 kubelet_pods.go:1108] "Clean up probes for terminated pods"
Sep 15 20:49:26 kind-worker3 kubelet[589656]: I0915 20:49:26.507179  589656 kubelet_pods.go:1145] "Clean up orphaned pod statuses"
Sep 15 20:49:26 kind-worker3 kubelet[589656]: I0915 20:49:26.508678  589656 kubelet_pods.go:1164] "Clean up orphaned pod directories"
Sep 15 20:49:26 kind-worker3 kubelet[589656]: I0915 20:49:26.509163  589656 kubelet_pods.go:1175] "Clean up orphaned mirror pods"
Sep 15 20:49:26 kind-worker3 kubelet[589656]: I0915 20:49:26.509472  589656 kubelet_pods.go:1182] "Clean up orphaned pod cgroups"
Sep 15 20:49:26 kind-worker3 kubelet[589656]: I0915 20:49:26.509699  589656 kubelet.go:2168] "SyncLoop (housekeeping) end"
Sep 15 20:49:27 kind-worker3 kubelet[589656]: I0915 20:49:27.181250  589656 generic.go:155] "GenericPLEG" podUID=f602fc75-3d22-475f-8c0a-de933744ab4e containerID="5432e78771d09f84901cf4700d2078034e73119a187802ac085fa1e2e4829a62" oldState=unknown newState=running
Sep 15 20:49:27 kind-worker3 kubelet[589656]: I0915 20:49:27.183193  589656 kuberuntime_manager.go:1037] "getSandboxIDByPodUID got sandbox IDs for pod" podSandboxID=[b553881ecd35bacb71b6c14fb9ca775d38c625d547bf3c076902f1ed25c4d0c1] pod="default/nginx-deployment-66f58bff7c-7kkk5"
Sep 15 20:49:27 kind-worker3 kubelet[589656]: I0915 20:49:27.185166  589656 generic.go:421] "PLEG: Write status" pod="default/nginx-deployment-66f58bff7c-7kkk5"
Sep 15 20:49:27 kind-worker3 kubelet[589656]: I0915 20:49:27.185420  589656 kubelet.go:2110] "SyncLoop (PLEG): event for pod" pod="default/nginx-deployment-66f58bff7c-7kkk5" event=&{ID:f602fc75-3d22-475f-8c0a-de933744ab4e Type:ContainerStarted Data:5432e78771d09f84901cf4700d2078034e73119a187802ac085fa1e2e4829a62}
Sep 15 20:49:27 kind-worker3 kubelet[589656]: I0915 20:49:27.185484  589656 kubelet.go:1501] "syncPod enter" pod="default/nginx-deployment-66f58bff7c-7kkk5" podUID=f602fc75-3d22-475f-8c0a-de933744ab4e
Sep 15 20:49:27 kind-worker3 kubelet[589656]: I0915 20:49:27.185777  589656 kubelet_pods.go:1432] "Generating pod status" pod="default/nginx-deployment-66f58bff7c-7kkk5"
Sep 15 20:49:27 kind-worker3 kubelet[589656]: I0915 20:49:27.185959  589656 kubelet_pods.go:1444] "Got phase for pod" pod="default/nginx-deployment-66f58bff7c-7kkk5" oldPhase=Pending phase=Running
Sep 15 20:49:27 kind-worker3 kubelet[589656]: I0915 20:49:27.186603  589656 volume_manager.go:404] "Waiting for volumes to attach and mount for pod" pod="default/nginx-deployment-66f58bff7c-7kkk5"
Sep 15 20:49:27 kind-worker3 kubelet[589656]: I0915 20:49:27.186829  589656 volume_manager.go:435] "All volumes are attached and mounted for pod" pod="default/nginx-deployment-66f58bff7c-7kkk5"
Sep 15 20:49:27 kind-worker3 kubelet[589656]: I0915 20:49:27.187141  589656 kuberuntime_manager.go:714] "computePodActions got for pod" podActions={KillPod:false CreateSandbox:false SandboxID:b553881ecd35bacb71b6c14fb9ca775d38c625d547bf3c076902f1ed25c4d0c1 Attempt:0 NextInitContainerToStart:nil ContainersToStart:[] ContainersToKill:map[] EphemeralContainersToStart:[]} pod="default/nginx-deployment-66f58bff7c-7kkk5"
Sep 15 20:49:27 kind-worker3 kubelet[589656]: I0915 20:49:27.187473  589656 kubelet.go:1503] "syncPod exit" pod="default/nginx-deployment-66f58bff7c-7kkk5" podUID=f602fc75-3d22-475f-8c0a-de933744ab4e isTerminal=false
Sep 15 20:49:27 kind-worker3 kubelet[589656]: I0915 20:49:27.187669  589656 pod_workers.go:988] "Processing pod event done" pod="default/nginx-deployment-66f58bff7c-7kkk5" podUID=f602fc75-3d22-475f-8c0a-de933744ab4e updateType=0
Sep 15 20:49:27 kind-worker3 kubelet[589656]: I0915 20:49:27.187827  589656 pod_workers.go:888] "Processing pod event" pod="default/nginx-deployment-66f58bff7c-7kkk5" podUID=f602fc75-3d22-475f-8c0a-de933744ab4e updateType=0
Sep 15 20:49:27 kind-worker3 kubelet[589656]: I0915 20:49:27.222648  589656 config.go:279] "Setting pods for source" source="api"
Sep 15 20:49:27 kind-worker3 kubelet[589656]: I0915 20:49:27.223011  589656 kubelet.go:2085] "SyncLoop RECONCILE" source="api" pods=[default/nginx-deployment-66f58bff7c-7kkk5]
Sep 15 20:49:27 kind-worker3 kubelet[589656]: I0915 20:49:27.224225  589656 status_manager.go:685] "Patch status for pod" pod="default/nginx-deployment-66f58bff7c-7kkk5" patch="{\"metadata\":{\"uid\":\"f602fc75-3d22-475f-8c0a-de933744ab4e\"},\"status\":{\"$setElementOrder/conditions\":[{\"type\":\"Initialized\"},{\"type\":\"Ready\"},{\"type\":\"ContainersReady\"},{\"type\":\"PodScheduled\"}],\"conditions\":[{\"lastTransitionTime\":\"2023-09-15T20:49:27Z\",\"message\":null,\"reason\":null,\"status\":\"True\",\"type\":\"Ready\"},{\"lastTransitionTime\":\"2023-09-15T20:49:27Z\",\"message\":null,\"reason\":null,\"status\":\"True\",\"type\":\"ContainersReady\"}],\"containerStatuses\":[{\"containerID\":\"containerd://5432e78771d09f84901cf4700d2078034e73119a187802ac085fa1e2e4829a62\",\"image\":\"docker.io/library/nginx:1.14.2\",\"imageID\":\"docker.io/library/nginx@sha256:f7988fb6c02e0ce69257d9bd9cf37ae20a60f1df7563c3a2a6abe24160306b8d\",\"lastState\":{},\"name\":\"nginx\",\"ready\":true,\"restartCount\":0,\"started\":true,\"state\":{\"running\":{\"startedAt\":\"2023-09-15T20:49:26Z\"}}}],\"phase\":\"Running\",\"podIP\":\"10.244.3.71\",\"podIPs\":[{\"ip\":\"10.244.3.71\"}]}}"
Sep 15 20:49:27 kind-worker3 kubelet[589656]: I0915 20:49:27.224391  589656 status_manager.go:694] "Status for pod updated successfully" pod="default/nginx-deployment-66f58bff7c-7kkk5" statusVersion=2 status={Phase:Running Conditions:[{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-09-15 20:49:23 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-09-15 20:49:27 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-09-15 20:49:27 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-09-15 20:49:23 +0000 UTC Reason: Message:}] Message: Reason: NominatedNodeName: HostIP:172.18.0.4 PodIP:10.244.3.71 PodIPs:[{IP:10.244.3.71}] StartTime:2023-09-15 20:49:23 +0000 UTC InitContainerStatuses:[] ContainerStatuses:[{Name:nginx State:{Waiting:nil Running:&ContainerStateRunning{StartedAt:2023-09-15 20:49:26 +0000 UTC,} Terminated:nil} LastTerminationState:{Waiting:nil Running:nil Terminated:nil} Ready:true RestartCount:0 Image:docker.io/library/nginx:1.14.2 ImageID:docker.io/library/nginx@sha256:f7988fb6c02e0ce69257d9bd9cf37ae20a60f1df7563c3a2a6abe24160306b8d ContainerID:containerd://5432e78771d09f84901cf4700d2078034e73119a187802ac085fa1e2e4829a62 Started:0xc001391ed9}] QOSClass:Burstable EphemeralContainerStatuses:[]}
Sep 15 20:49:27 kind-worker3 kubelet[589656]: I0915 20:49:27.281352  589656 desired_state_of_world_populator.go:309] "Added volume to desired state" pod="default/nginx-deployment-66f58bff7c-7kkk5" volumeName="kube-api-access-kgpd5" volumeSpecName="kube-api-access-kgpd5"
Sep 15 20:49:27 kind-worker3 kubelet[589656]: I0915 20:49:27.309515  589656 reconciler.go:243] "Starting operationExecutor.MountVolume for volume \"kube-api-access-kgpd5\" (UniqueName: \"kubernetes.io/projected/f602fc75-3d22-475f-8c0a-de933744ab4e-kube-api-access-kgpd5\") pod \"nginx-deployment-66f58bff7c-7kkk5\" (UID: \"f602fc75-3d22-475f-8c0a-de933744ab4e\") Volume is already mounted to pod, but remount was requested." pod="default/nginx-deployment-66f58bff7c-7kkk5"
Sep 15 20:49:27 kind-worker3 kubelet[589656]: I0915 20:49:27.309696  589656 projected.go:183] Setting up volume kube-api-access-kgpd5 for pod f602fc75-3d22-475f-8c0a-de933744ab4e at /var/lib/kubelet/pods/f602fc75-3d22-475f-8c0a-de933744ab4e/volumes/kubernetes.io~projected/kube-api-access-kgpd5
Sep 15 20:49:27 kind-worker3 kubelet[589656]: I0915 20:49:27.310149  589656 atomic_writer.go:161] pod default/nginx-deployment-66f58bff7c-7kkk5 volume kube-api-access-kgpd5: no update required for target directory /var/lib/kubelet/pods/f602fc75-3d22-475f-8c0a-de933744ab4e/volumes/kubernetes.io~projected/kube-api-access-kgpd5
Sep 15 20:49:27 kind-worker3 kubelet[589656]: I0915 20:49:27.310206  589656 operation_generator.go:703] "MountVolume.SetUp succeeded for volume \"kube-api-access-kgpd5\" (UniqueName: \"kubernetes.io/projected/f602fc75-3d22-475f-8c0a-de933744ab4e-kube-api-access-kgpd5\") pod \"nginx-deployment-66f58bff7c-7kkk5\" (UID: \"f602fc75-3d22-475f-8c0a-de933744ab4e\") " pod="default/nginx-deployment-66f58bff7c-7kkk5"
Sep 15 20:49:28 kind-worker3 kubelet[589656]: I0915 20:49:28.188056  589656 kubelet.go:1501] "syncPod enter" pod="default/nginx-deployment-66f58bff7c-7kkk5" podUID=f602fc75-3d22-475f-8c0a-de933744ab4e
Sep 15 20:49:28 kind-worker3 kubelet[589656]: I0915 20:49:28.188132  589656 kubelet_pods.go:1432] "Generating pod status" pod="default/nginx-deployment-66f58bff7c-7kkk5"
Sep 15 20:49:28 kind-worker3 kubelet[589656]: I0915 20:49:28.188239  589656 kubelet_pods.go:1444] "Got phase for pod" pod="default/nginx-deployment-66f58bff7c-7kkk5" oldPhase=Running phase=Running
Sep 15 20:49:28 kind-worker3 kubelet[589656]: I0915 20:49:28.188503  589656 status_manager.go:535] "Ignoring same status for pod" pod="default/nginx-deployment-66f58bff7c-7kkk5" status={Phase:Running Conditions:[{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-09-15 20:49:23 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-09-15 20:49:27 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-09-15 20:49:27 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-09-15 20:49:23 +0000 UTC Reason: Message:}] Message: Reason: NominatedNodeName: HostIP:172.18.0.4 PodIP:10.244.3.71 PodIPs:[{IP:10.244.3.71}] StartTime:2023-09-15 20:49:23 +0000 UTC InitContainerStatuses:[] ContainerStatuses:[{Name:nginx State:{Waiting:nil Running:&ContainerStateRunning{StartedAt:2023-09-15 20:49:26 +0000 UTC,} Terminated:nil} LastTerminationState:{Waiting:nil Running:nil Terminated:nil} Ready:true RestartCount:0 Image:docker.io/library/nginx:1.14.2 ImageID:docker.io/library/nginx@sha256:f7988fb6c02e0ce69257d9bd9cf37ae20a60f1df7563c3a2a6abe24160306b8d ContainerID:containerd://5432e78771d09f84901cf4700d2078034e73119a187802ac085fa1e2e4829a62 Started:0xc00172049c}] QOSClass:Burstable EphemeralContainerStatuses:[]}
Sep 15 20:49:28 kind-worker3 kubelet[589656]: I0915 20:49:28.189165  589656 volume_manager.go:404] "Waiting for volumes to attach and mount for pod" pod="default/nginx-deployment-66f58bff7c-7kkk5"
Sep 15 20:49:28 kind-worker3 kubelet[589656]: I0915 20:49:28.189230  589656 volume_manager.go:435] "All volumes are attached and mounted for pod" pod="default/nginx-deployment-66f58bff7c-7kkk5"
Sep 15 20:49:28 kind-worker3 kubelet[589656]: I0915 20:49:28.189515  589656 kuberuntime_manager.go:714] "computePodActions got for pod" podActions={KillPod:false CreateSandbox:false SandboxID:b553881ecd35bacb71b6c14fb9ca775d38c625d547bf3c076902f1ed25c4d0c1 Attempt:0 NextInitContainerToStart:nil ContainersToStart:[] ContainersToKill:map[] EphemeralContainersToStart:[]} pod="default/nginx-deployment-66f58bff7c-7kkk5"
Sep 15 20:49:28 kind-worker3 kubelet[589656]: I0915 20:49:28.189721  589656 kubelet.go:1503] "syncPod exit" pod="default/nginx-deployment-66f58bff7c-7kkk5" podUID=f602fc75-3d22-475f-8c0a-de933744ab4e isTerminal=false
Sep 15 20:49:28 kind-worker3 kubelet[589656]: I0915 20:49:28.189795  589656 pod_workers.go:988] "Processing pod event done" pod="default/nginx-deployment-66f58bff7c-7kkk5" podUID=f602fc75-3d22-475f-8c0a-de933744ab4e updateType=0
Sep 15 20:49:28 kind-worker3 kubelet[589656]: I0915 20:49:28.287059  589656 desired_state_of_world_populator.go:309] "Added volume to desired state" pod="default/nginx-deployment-66f58bff7c-7kkk5" volumeName="kube-api-access-kgpd5" volumeSpecName="kube-api-access-kgpd5"
Sep 15 20:49:28 kind-worker3 kubelet[589656]: I0915 20:49:28.316460  589656 reconciler.go:243] "Starting operationExecutor.MountVolume for volume \"kube-api-access-kgpd5\" (UniqueName: \"kubernetes.io/projected/f602fc75-3d22-475f-8c0a-de933744ab4e-kube-api-access-kgpd5\") pod \"nginx-deployment-66f58bff7c-7kkk5\" (UID: \"f602fc75-3d22-475f-8c0a-de933744ab4e\") Volume is already mounted to pod, but remount was requested." pod="default/nginx-deployment-66f58bff7c-7kkk5"
Sep 15 20:49:28 kind-worker3 kubelet[589656]: I0915 20:49:28.317018  589656 projected.go:183] Setting up volume kube-api-access-kgpd5 for pod f602fc75-3d22-475f-8c0a-de933744ab4e at /var/lib/kubelet/pods/f602fc75-3d22-475f-8c0a-de933744ab4e/volumes/kubernetes.io~projected/kube-api-access-kgpd5
Sep 15 20:49:28 kind-worker3 kubelet[589656]: I0915 20:49:28.318422  589656 atomic_writer.go:161] pod default/nginx-deployment-66f58bff7c-7kkk5 volume kube-api-access-kgpd5: no update required for target directory /var/lib/kubelet/pods/f602fc75-3d22-475f-8c0a-de933744ab4e/volumes/kubernetes.io~projected/kube-api-access-kgpd5
Sep 15 20:49:28 kind-worker3 kubelet[589656]: I0915 20:49:28.318692  589656 operation_generator.go:703] "MountVolume.SetUp succeeded for volume \"kube-api-access-kgpd5\" (UniqueName: \"kubernetes.io/projected/f602fc75-3d22-475f-8c0a-de933744ab4e-kube-api-access-kgpd5\") pod \"nginx-deployment-66f58bff7c-7kkk5\" (UID: \"f602fc75-3d22-475f-8c0a-de933744ab4e\") " pod="default/nginx-deployment-66f58bff7c-7kkk5"
Sep 15 20:49:28 kind-worker3 kubelet[589656]: I0915 20:49:28.497845  589656 kubelet.go:2160] "SyncLoop (housekeeping)"
Sep 15 20:49:28 kind-worker3 kubelet[589656]: I0915 20:49:28.506161  589656 kubelet_pods.go:1079] "Clean up pod workers for terminated pods"
Sep 15 20:49:28 kind-worker3 kubelet[589656]: I0915 20:49:28.506440  589656 kubelet_pods.go:1108] "Clean up probes for terminated pods"
Sep 15 20:49:28 kind-worker3 kubelet[589656]: I0915 20:49:28.508248  589656 kubelet_pods.go:1145] "Clean up orphaned pod statuses"
Sep 15 20:49:28 kind-worker3 kubelet[589656]: I0915 20:49:28.509602  589656 kubelet_pods.go:1164] "Clean up orphaned pod directories"
Sep 15 20:49:28 kind-worker3 kubelet[589656]: I0915 20:49:28.509901  589656 kubelet_pods.go:1175] "Clean up orphaned mirror pods"
Sep 15 20:49:28 kind-worker3 kubelet[589656]: I0915 20:49:28.510067  589656 kubelet_pods.go:1182] "Clean up orphaned pod cgroups"
Sep 15 20:49:28 kind-worker3 kubelet[589656]: I0915 20:49:28.510236  589656 kubelet.go:2168] "SyncLoop (housekeeping) end"
Sep 15 20:49:29 kind-worker3 kubelet[589656]: I0915 20:49:29.387683  589656 httplog.go:131] "HTTP" verb="GET" URI="/metrics/resource" latency="25.538371ms" userAgent="metrics-server/v0.6.3 (linux/amd64) kubernetes/a938798" audit-ID="" srcIP="172.18.0.3:35538" resp=200
Sep 15 20:49:29 kind-worker3 kubelet[589656]: I0915 20:49:29.967839  589656 kubelet.go:2346] "Container runtime status" status="Runtime Conditions: RuntimeReady=true reason: message:, NetworkReady=true reason: message:"
Sep 15 20:49:30 kind-worker3 kubelet[589656]: I0915 20:49:30.497610  589656 kubelet.go:2160] "SyncLoop (housekeeping)"
Sep 15 20:49:30 kind-worker3 kubelet[589656]: I0915 20:49:30.513272  589656 kubelet_pods.go:1079] "Clean up pod workers for terminated pods"
Sep 15 20:49:30 kind-worker3 kubelet[589656]: I0915 20:49:30.513574  589656 kubelet_pods.go:1108] "Clean up probes for terminated pods"
Sep 15 20:49:30 kind-worker3 kubelet[589656]: I0915 20:49:30.515579  589656 kubelet_pods.go:1145] "Clean up orphaned pod statuses"
Sep 15 20:49:30 kind-worker3 kubelet[589656]: I0915 20:49:30.516992  589656 kubelet_pods.go:1164] "Clean up orphaned pod directories"
Sep 15 20:49:30 kind-worker3 kubelet[589656]: I0915 20:49:30.517334  589656 kubelet_pods.go:1175] "Clean up orphaned mirror pods"
Sep 15 20:49:30 kind-worker3 kubelet[589656]: I0915 20:49:30.517410  589656 kubelet_pods.go:1182] "Clean up orphaned pod cgroups"
Sep 15 20:49:30 kind-worker3 kubelet[589656]: I0915 20:49:30.517466  589656 kubelet.go:2168] "SyncLoop (housekeeping) end"
Sep 15 20:49:32 kind-worker3 kubelet[589656]: I0915 20:49:32.498334  589656 kubelet.go:2160] "SyncLoop (housekeeping)"
Sep 15 20:49:32 kind-worker3 kubelet[589656]: I0915 20:49:32.506430  589656 kubelet_pods.go:1079] "Clean up pod workers for terminated pods"
Sep 15 20:49:32 kind-worker3 kubelet[589656]: I0915 20:49:32.506499  589656 kubelet_pods.go:1108] "Clean up probes for terminated pods"
Sep 15 20:49:32 kind-worker3 kubelet[589656]: I0915 20:49:32.506525  589656 kubelet_pods.go:1145] "Clean up orphaned pod statuses"
Sep 15 20:49:32 kind-worker3 kubelet[589656]: I0915 20:49:32.508306  589656 kubelet_pods.go:1164] "Clean up orphaned pod directories"
Sep 15 20:49:32 kind-worker3 kubelet[589656]: I0915 20:49:32.508450  589656 kubelet_pods.go:1175] "Clean up orphaned mirror pods"
Sep 15 20:49:32 kind-worker3 kubelet[589656]: I0915 20:49:32.508479  589656 kubelet_pods.go:1182] "Clean up orphaned pod cgroups"
Sep 15 20:49:32 kind-worker3 kubelet[589656]: I0915 20:49:32.508509  589656 kubelet.go:2168] "SyncLoop (housekeeping) end"
Sep 15 20:49:32 kind-worker3 kubelet[589656]: I0915 20:49:32.778862  589656 setters.go:88] "Using node IP" IP="172.18.0.4"
Sep 15 20:49:34 kind-worker3 kubelet[589656]: I0915 20:49:34.311961  589656 eviction_manager.go:237] "Eviction manager: synchronize housekeeping"
Sep 15 20:49:34 kind-worker3 kubelet[589656]: I0915 20:49:34.325164  589656 cri_stats_provider.go:525] "Unable to find network stats for sandbox" sandboxID="d0f4d02598fe0e9a32081b1554ae85df2b4224eb9a378fdcf99aa7c0035d33dc"
Sep 15 20:49:34 kind-worker3 kubelet[589656]: I0915 20:49:34.325612  589656 cri_stats_provider.go:525] "Unable to find network stats for sandbox" sandboxID="b477a0e3bdd1b445ce34dc6f173590a56dbfec252950ee838d5af2a2515a773b"
Sep 15 20:49:34 kind-worker3 kubelet[589656]: I0915 20:49:34.328196  589656 helpers.go:775] "Eviction manager:" log="observations" signal=allocatableMemory.available resourceName="8093024Ki" capacity="8166760Ki" time="2023-09-15 20:49:34.327987156 +0000 UTC m=+2146438.250812334"
Sep 15 20:49:34 kind-worker3 kubelet[589656]: I0915 20:49:34.328335  589656 helpers.go:775] "Eviction manager:" log="observations" signal=nodefs.available resourceName="7781364Ki" capacity="51341792Ki" time="2023-09-15 20:49:34.314590138 +0000 UTC m=+2146438.237415293"
Sep 15 20:49:34 kind-worker3 kubelet[589656]: I0915 20:49:34.328384  589656 helpers.go:775] "Eviction manager:" log="observations" signal=nodefs.inodesFree resourceName="2345622" capacity="3276800" time="2023-09-15 20:49:34.314590138 +0000 UTC m=+2146438.237415293"
Sep 15 20:49:34 kind-worker3 kubelet[589656]: I0915 20:49:34.328427  589656 helpers.go:775] "Eviction manager:" log="observations" signal=imagefs.available resourceName="7781364Ki" capacity="51341792Ki" time="2023-09-15 20:49:28.905216962 +0000 UTC"
Sep 15 20:49:34 kind-worker3 kubelet[589656]: I0915 20:49:34.328458  589656 helpers.go:775] "Eviction manager:" log="observations" signal=imagefs.inodesFree resourceName="2345622" capacity="3276800" time="2023-09-15 20:49:28.905216962 +0000 UTC"
Sep 15 20:49:34 kind-worker3 kubelet[589656]: I0915 20:49:34.328489  589656 helpers.go:775] "Eviction manager:" log="observations" signal=pid.available resourceName="62158" capacity="63272" time="2023-09-15 20:49:34.326118625 +0000 UTC m=+2146438.248943766"
Sep 15 20:49:34 kind-worker3 kubelet[589656]: I0915 20:49:34.328517  589656 helpers.go:775] "Eviction manager:" log="observations" signal=memory.available resourceName="7879868Ki" capacity="8166760Ki" time="2023-09-15 20:49:34.314590138 +0000 UTC m=+2146438.237415293"
Sep 15 20:49:34 kind-worker3 kubelet[589656]: I0915 20:49:34.328562  589656 eviction_manager.go:328] "Eviction manager: no resources are starved"
Sep 15 20:49:34 kind-worker3 kubelet[589656]: I0915 20:49:34.498623  589656 kubelet.go:2129] "SyncLoop (SYNC) pods" total=1 pods=[kube-system/kindnet-mxmhl]
Sep 15 20:49:34 kind-worker3 kubelet[589656]: I0915 20:49:34.498812  589656 kubelet.go:2160] "SyncLoop (housekeeping)"
Sep 15 20:49:34 kind-worker3 kubelet[589656]: I0915 20:49:34.499145  589656 pod_workers.go:888] "Processing pod event" pod="kube-system/kindnet-mxmhl" podUID=d2a8b1e2-f8ec-4685-881d-a4d1c26134c2 updateType=0
Sep 15 20:49:34 kind-worker3 kubelet[589656]: I0915 20:49:34.499348  589656 kubelet.go:1501] "syncPod enter" pod="kube-system/kindnet-mxmhl" podUID=d2a8b1e2-f8ec-4685-881d-a4d1c26134c2
Sep 15 20:49:34 kind-worker3 kubelet[589656]: I0915 20:49:34.499522  589656 kubelet_pods.go:1432] "Generating pod status" pod="kube-system/kindnet-mxmhl"
Sep 15 20:49:34 kind-worker3 kubelet[589656]: I0915 20:49:34.499799  589656 kubelet_pods.go:1444] "Got phase for pod" pod="kube-system/kindnet-mxmhl" oldPhase=Running phase=Running
Sep 15 20:49:34 kind-worker3 kubelet[589656]: I0915 20:49:34.500162  589656 status_manager.go:535] "Ignoring same status for pod" pod="kube-system/kindnet-mxmhl" status={Phase:Running Conditions:[{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-14 00:07:50 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-07-15 14:56:50 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-07-15 14:56:50 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-14 00:07:47 +0000 UTC Reason: Message:}] Message: Reason: NominatedNodeName: HostIP:172.18.0.4 PodIP:172.18.0.4 PodIPs:[{IP:172.18.0.4}] StartTime:2023-04-14 00:07:50 +0000 UTC InitContainerStatuses:[] ContainerStatuses:[{Name:kindnet-cni State:{Waiting:nil Running:&ContainerStateRunning{StartedAt:2023-07-15 14:56:49 +0000 UTC,} Terminated:nil} LastTerminationState:{Waiting:nil Running:nil Terminated:&ContainerStateTerminated{ExitCode:255,Signal:0,Reason:Unknown,Message:,StartedAt:2023-05-13 23:24:24 +0000 UTC,FinishedAt:2023-07-15 14:56:13 +0000 UTC,ContainerID:containerd://f98e00c8217d4308a58d79ba51534150a7f921ba9587fc5badea4fb5300ee3b7,}} Ready:true RestartCount:2 Image:docker.io/kindest/kindnetd:v20221004-44d545d1 ImageID:sha256:d6e3e26021b60c625f0ef5b2dd3f9e22d2d398e05bccc4fdd7d59fbbb6a04d3f ContainerID:containerd://ec9b47aba6f0d651c6da6e8282ad0e4f699e83e716938f3c1f3f34bb4edc2aa2 Started:0xc00168ceec}] QOSClass:Guaranteed EphemeralContainerStatuses:[]}
Sep 15 20:49:34 kind-worker3 kubelet[589656]: I0915 20:49:34.500786  589656 volume_manager.go:404] "Waiting for volumes to attach and mount for pod" pod="kube-system/kindnet-mxmhl"
Sep 15 20:49:34 kind-worker3 kubelet[589656]: I0915 20:49:34.500974  589656 volume_manager.go:435] "All volumes are attached and mounted for pod" pod="kube-system/kindnet-mxmhl"
Sep 15 20:49:34 kind-worker3 kubelet[589656]: I0915 20:49:34.501417  589656 kuberuntime_manager.go:714] "computePodActions got for pod" podActions={KillPod:false CreateSandbox:false SandboxID:b477a0e3bdd1b445ce34dc6f173590a56dbfec252950ee838d5af2a2515a773b Attempt:2 NextInitContainerToStart:nil ContainersToStart:[] ContainersToKill:map[] EphemeralContainersToStart:[]} pod="kube-system/kindnet-mxmhl"
Sep 15 20:49:34 kind-worker3 kubelet[589656]: I0915 20:49:34.501728  589656 kubelet.go:1503] "syncPod exit" pod="kube-system/kindnet-mxmhl" podUID=d2a8b1e2-f8ec-4685-881d-a4d1c26134c2 isTerminal=false
Sep 15 20:49:34 kind-worker3 kubelet[589656]: I0915 20:49:34.501911  589656 pod_workers.go:988] "Processing pod event done" pod="kube-system/kindnet-mxmhl" podUID=d2a8b1e2-f8ec-4685-881d-a4d1c26134c2 updateType=0
Sep 15 20:49:34 kind-worker3 kubelet[589656]: I0915 20:49:34.506572  589656 kubelet_pods.go:1079] "Clean up pod workers for terminated pods"
Sep 15 20:49:34 kind-worker3 kubelet[589656]: I0915 20:49:34.506644  589656 kubelet_pods.go:1108] "Clean up probes for terminated pods"
Sep 15 20:49:34 kind-worker3 kubelet[589656]: I0915 20:49:34.508553  589656 kubelet_pods.go:1145] "Clean up orphaned pod statuses"
Sep 15 20:49:34 kind-worker3 kubelet[589656]: I0915 20:49:34.513697  589656 kubelet_pods.go:1164] "Clean up orphaned pod directories"
Sep 15 20:49:34 kind-worker3 kubelet[589656]: I0915 20:49:34.514057  589656 kubelet_pods.go:1175] "Clean up orphaned mirror pods"
Sep 15 20:49:34 kind-worker3 kubelet[589656]: I0915 20:49:34.514295  589656 kubelet_pods.go:1182] "Clean up orphaned pod cgroups"
Sep 15 20:49:34 kind-worker3 kubelet[589656]: I0915 20:49:34.514484  589656 kubelet.go:2168] "SyncLoop (housekeeping) end"
Sep 15 20:49:34 kind-worker3 kubelet[589656]: I0915 20:49:34.528132  589656 desired_state_of_world_populator.go:309] "Added volume to desired state" pod="kube-system/kindnet-mxmhl" volumeName="cni-cfg" volumeSpecName="cni-cfg"
Sep 15 20:49:34 kind-worker3 kubelet[589656]: I0915 20:49:34.528257  589656 desired_state_of_world_populator.go:309] "Added volume to desired state" pod="kube-system/kindnet-mxmhl" volumeName="xtables-lock" volumeSpecName="xtables-lock"
Sep 15 20:49:34 kind-worker3 kubelet[589656]: I0915 20:49:34.528348  589656 desired_state_of_world_populator.go:309] "Added volume to desired state" pod="kube-system/kindnet-mxmhl" volumeName="lib-modules" volumeSpecName="lib-modules"
Sep 15 20:49:34 kind-worker3 kubelet[589656]: I0915 20:49:34.528486  589656 desired_state_of_world_populator.go:309] "Added volume to desired state" pod="kube-system/kindnet-mxmhl" volumeName="kube-api-access-2d7bz" volumeSpecName="kube-api-access-2d7bz"
Sep 15 20:49:34 kind-worker3 kubelet[589656]: I0915 20:49:34.557292  589656 reconciler.go:243] "Starting operationExecutor.MountVolume for volume \"kube-api-access-2d7bz\" (UniqueName: \"kubernetes.io/projected/d2a8b1e2-f8ec-4685-881d-a4d1c26134c2-kube-api-access-2d7bz\") pod \"kindnet-mxmhl\" (UID: \"d2a8b1e2-f8ec-4685-881d-a4d1c26134c2\") Volume is already mounted to pod, but remount was requested." pod="kube-system/kindnet-mxmhl"
Sep 15 20:49:34 kind-worker3 kubelet[589656]: I0915 20:49:34.557761  589656 projected.go:183] Setting up volume kube-api-access-2d7bz for pod d2a8b1e2-f8ec-4685-881d-a4d1c26134c2 at /var/lib/kubelet/pods/d2a8b1e2-f8ec-4685-881d-a4d1c26134c2/volumes/kubernetes.io~projected/kube-api-access-2d7bz
Sep 15 20:49:34 kind-worker3 kubelet[589656]: I0915 20:49:34.558382  589656 atomic_writer.go:161] pod kube-system/kindnet-mxmhl volume kube-api-access-2d7bz: no update required for target directory /var/lib/kubelet/pods/d2a8b1e2-f8ec-4685-881d-a4d1c26134c2/volumes/kubernetes.io~projected/kube-api-access-2d7bz
Sep 15 20:49:34 kind-worker3 kubelet[589656]: I0915 20:49:34.558568  589656 operation_generator.go:703] "MountVolume.SetUp succeeded for volume \"kube-api-access-2d7bz\" (UniqueName: \"kubernetes.io/projected/d2a8b1e2-f8ec-4685-881d-a4d1c26134c2-kube-api-access-2d7bz\") pod \"kindnet-mxmhl\" (UID: \"d2a8b1e2-f8ec-4685-881d-a4d1c26134c2\") " pod="kube-system/kindnet-mxmhl"
Sep 15 20:49:34 kind-worker3 kubelet[589656]: I0915 20:49:34.969283  589656 kubelet.go:2346] "Container runtime status" status="Runtime Conditions: RuntimeReady=true reason: message:, NetworkReady=true reason: message:"
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.256451  589656 config.go:279] "Setting pods for source" source="file"
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.497757  589656 kubelet.go:2160] "SyncLoop (housekeeping)"
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.506572  589656 kubelet_pods.go:1079] "Clean up pod workers for terminated pods"
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.506935  589656 kubelet_pods.go:1108] "Clean up probes for terminated pods"
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.512158  589656 kubelet_pods.go:1145] "Clean up orphaned pod statuses"
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.513502  589656 kubelet_pods.go:1164] "Clean up orphaned pod directories"
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.513683  589656 kubelet_pods.go:1175] "Clean up orphaned mirror pods"
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.513743  589656 kubelet_pods.go:1182] "Clean up orphaned pod cgroups"
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.513823  589656 kubelet.go:2168] "SyncLoop (housekeeping) end"
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.517728  589656 factory.go:251] Error trying to work out if we can handle /docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267: failed to load container: container "ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267" in namespace "k8s.io": not found
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.517771  589656 factory.go:262] Factory "containerd" was unable to handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267"
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.517805  589656 factory.go:262] Factory "systemd" was unable to handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267"
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.517829  589656 factory.go:255] Factory "raw" can handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267", but ignoring.
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.517852  589656 manager.go:925] ignoring container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267"
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.517873  589656 factory.go:262] Factory "containerd" was unable to handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/system.slice/system-modprobe.slice"
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.517892  589656 factory.go:262] Factory "systemd" was unable to handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/system.slice/system-modprobe.slice"
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.517912  589656 factory.go:255] Factory "raw" can handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/system.slice/system-modprobe.slice", but ignoring.
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.517933  589656 manager.go:925] ignoring container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/system.slice/system-modprobe.slice"
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.518693  589656 factory.go:258] Using factory "containerd" for container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-podf602fc75_3d22_475f_8c0a_de933744ab4e.slice/cri-containerd-5432e78771d09f84901cf4700d2078034e73119a187802ac085fa1e2e4829a62.scope"
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.523079  589656 manager.go:988] Added container: "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-podf602fc75_3d22_475f_8c0a_de933744ab4e.slice/cri-containerd-5432e78771d09f84901cf4700d2078034e73119a187802ac085fa1e2e4829a62.scope" (aliases: [5432e78771d09f84901cf4700d2078034e73119a187802ac085fa1e2e4829a62 /docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-podf602fc75_3d22_475f_8c0a_de933744ab4e.slice/cri-containerd-5432e78771d09f84901cf4700d2078034e73119a187802ac085fa1e2e4829a62.scope], namespace: "containerd")
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.523734  589656 handler.go:325] Added event &{/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-podf602fc75_3d22_475f_8c0a_de933744ab4e.slice/cri-containerd-5432e78771d09f84901cf4700d2078034e73119a187802ac085fa1e2e4829a62.scope 2023-09-15 20:49:25.778563985 +0000 UTC containerCreation {<nil>}}
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.523801  589656 factory.go:262] Factory "containerd" was unable to handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/dev-hugepages.mount"
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.523827  589656 factory.go:255] Factory "systemd" can handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/dev-hugepages.mount", but ignoring.
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.523849  589656 manager.go:925] ignoring container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/dev-hugepages.mount"
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.523869  589656 factory.go:262] Factory "containerd" was unable to handle container "/system.slice/systemd-journald.service"
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.523884  589656 factory.go:262] Factory "systemd" was unable to handle container "/system.slice/systemd-journald.service"
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.523902  589656 factory.go:255] Factory "raw" can handle container "/system.slice/systemd-journald.service", but ignoring.
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.523923  589656 manager.go:925] ignoring container "/system.slice/systemd-journald.service"
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.523918  589656 container.go:530] Start housekeeping for container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-podf602fc75_3d22_475f_8c0a_de933744ab4e.slice/cri-containerd-5432e78771d09f84901cf4700d2078034e73119a187802ac085fa1e2e4829a62.scope"
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.523941  589656 factory.go:262] Factory "containerd" was unable to handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/system.slice/systemd-journald.service"
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.524074  589656 factory.go:262] Factory "systemd" was unable to handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/system.slice/systemd-journald.service"
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.524114  589656 factory.go:255] Factory "raw" can handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/system.slice/systemd-journald.service", but ignoring.
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.524152  589656 manager.go:925] ignoring container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/system.slice/systemd-journald.service"
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.524197  589656 factory.go:262] Factory "containerd" was unable to handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet.slice"
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.524227  589656 factory.go:262] Factory "systemd" was unable to handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet.slice"
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.524258  589656 factory.go:255] Factory "raw" can handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet.slice", but ignoring.
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.524295  589656 manager.go:925] ignoring container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet.slice"
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.524415  589656 factory.go:262] Factory "containerd" was unable to handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-besteffort.slice/kubelet-kubepods-besteffort-pod6b53eb8b_e28c_454a_92e9_b342af428fa5.slice"
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.524459  589656 factory.go:262] Factory "systemd" was unable to handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-besteffort.slice/kubelet-kubepods-besteffort-pod6b53eb8b_e28c_454a_92e9_b342af428fa5.slice"
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.524505  589656 factory.go:255] Factory "raw" can handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-besteffort.slice/kubelet-kubepods-besteffort-pod6b53eb8b_e28c_454a_92e9_b342af428fa5.slice", but ignoring.
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.524569  589656 manager.go:925] ignoring container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-besteffort.slice/kubelet-kubepods-besteffort-pod6b53eb8b_e28c_454a_92e9_b342af428fa5.slice"
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.524620  589656 factory.go:262] Factory "containerd" was unable to handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/docker"
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.524656  589656 factory.go:262] Factory "systemd" was unable to handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/docker"
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.524691  589656 factory.go:255] Factory "raw" can handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/docker", but ignoring.
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.524738  589656 manager.go:925] ignoring container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/docker"
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.524770  589656 factory.go:262] Factory "containerd" was unable to handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/system.slice"
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.524808  589656 factory.go:262] Factory "systemd" was unable to handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/system.slice"
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.524844  589656 factory.go:255] Factory "raw" can handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/system.slice", but ignoring.
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.524879  589656 manager.go:925] ignoring container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/system.slice"
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.524911  589656 factory.go:262] Factory "containerd" was unable to handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-besteffort.slice"
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.524945  589656 factory.go:262] Factory "systemd" was unable to handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-besteffort.slice"
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.524980  589656 factory.go:255] Factory "raw" can handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-besteffort.slice", but ignoring.
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.525015  589656 manager.go:925] ignoring container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-besteffort.slice"
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.525065  589656 factory.go:262] Factory "containerd" was unable to handle container "/dev-hugepages.mount"
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.525149  589656 factory.go:255] Factory "systemd" can handle container "/dev-hugepages.mount", but ignoring.
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.525198  589656 manager.go:925] ignoring container "/dev-hugepages.mount"
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.525230  589656 factory.go:262] Factory "containerd" was unable to handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/sys-fs-fuse-connections.mount"
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.525291  589656 factory.go:255] Factory "systemd" can handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/sys-fs-fuse-connections.mount", but ignoring.
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.525331  589656 manager.go:925] ignoring container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/sys-fs-fuse-connections.mount"
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.525368  589656 factory.go:262] Factory "containerd" was unable to handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/sys-kernel-debug.mount"
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.525401  589656 factory.go:255] Factory "systemd" can handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/sys-kernel-debug.mount", but ignoring.
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.525440  589656 manager.go:925] ignoring container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/sys-kernel-debug.mount"
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.525475  589656 factory.go:262] Factory "containerd" was unable to handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/sys-kernel-tracing.mount"
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.525509  589656 factory.go:255] Factory "systemd" can handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/sys-kernel-tracing.mount", but ignoring.
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.525546  589656 manager.go:925] ignoring container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/sys-kernel-tracing.mount"
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.525582  589656 factory.go:262] Factory "containerd" was unable to handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet.slice/kubelet-kubepods.slice"
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.525614  589656 factory.go:262] Factory "systemd" was unable to handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet.slice/kubelet-kubepods.slice"
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.525650  589656 factory.go:255] Factory "raw" can handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet.slice/kubelet-kubepods.slice", but ignoring.
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.525687  589656 manager.go:925] ignoring container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet.slice/kubelet-kubepods.slice"
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.525741  589656 factory.go:262] Factory "containerd" was unable to handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-podf602fc75_3d22_475f_8c0a_de933744ab4e.slice"
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.525789  589656 factory.go:262] Factory "systemd" was unable to handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-podf602fc75_3d22_475f_8c0a_de933744ab4e.slice"
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.525832  589656 factory.go:255] Factory "raw" can handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-podf602fc75_3d22_475f_8c0a_de933744ab4e.slice", but ignoring.
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.525871  589656 manager.go:925] ignoring container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-podf602fc75_3d22_475f_8c0a_de933744ab4e.slice"
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.525912  589656 factory.go:262] Factory "containerd" was unable to handle container "/system.slice/system-modprobe.slice"
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.525942  589656 factory.go:262] Factory "systemd" was unable to handle container "/system.slice/system-modprobe.slice"
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.525975  589656 factory.go:255] Factory "raw" can handle container "/system.slice/system-modprobe.slice", but ignoring.
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.526009  589656 manager.go:925] ignoring container "/system.slice/system-modprobe.slice"
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.526044  589656 factory.go:262] Factory "containerd" was unable to handle container "/docker"
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.526075  589656 factory.go:262] Factory "systemd" was unable to handle container "/docker"
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.526106  589656 factory.go:255] Factory "raw" can handle container "/docker", but ignoring.
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.526139  589656 manager.go:925] ignoring container "/docker"
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.527180  589656 factory.go:258] Using factory "containerd" for container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-podf602fc75_3d22_475f_8c0a_de933744ab4e.slice/cri-containerd-b553881ecd35bacb71b6c14fb9ca775d38c625d547bf3c076902f1ed25c4d0c1.scope"
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.531291  589656 manager.go:988] Added container: "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-podf602fc75_3d22_475f_8c0a_de933744ab4e.slice/cri-containerd-b553881ecd35bacb71b6c14fb9ca775d38c625d547bf3c076902f1ed25c4d0c1.scope" (aliases: [b553881ecd35bacb71b6c14fb9ca775d38c625d547bf3c076902f1ed25c4d0c1 /docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-podf602fc75_3d22_475f_8c0a_de933744ab4e.slice/cri-containerd-b553881ecd35bacb71b6c14fb9ca775d38c625d547bf3c076902f1ed25c4d0c1.scope], namespace: "containerd")
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.532196  589656 handler.go:325] Added event &{/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-podf602fc75_3d22_475f_8c0a_de933744ab4e.slice/cri-containerd-b553881ecd35bacb71b6c14fb9ca775d38c625d547bf3c076902f1ed25c4d0c1.scope 2023-09-15 20:49:24.906569306 +0000 UTC containerCreation {<nil>}}
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.532285  589656 factory.go:262] Factory "containerd" was unable to handle container "/system.slice"
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.532311  589656 factory.go:262] Factory "systemd" was unable to handle container "/system.slice"
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.532330  589656 factory.go:255] Factory "raw" can handle container "/system.slice", but ignoring.
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.532350  589656 manager.go:925] ignoring container "/system.slice"
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.532367  589656 factory.go:262] Factory "containerd" was unable to handle container "/kubelet.slice/kubelet.service"
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.532389  589656 factory.go:262] Factory "systemd" was unable to handle container "/kubelet.slice/kubelet.service"
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.532406  589656 container.go:530] Start housekeeping for container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-podf602fc75_3d22_475f_8c0a_de933744ab4e.slice/cri-containerd-b553881ecd35bacb71b6c14fb9ca775d38c625d547bf3c076902f1ed25c4d0c1.scope"
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.532421  589656 factory.go:255] Factory "raw" can handle container "/kubelet.slice/kubelet.service", but ignoring.
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.532576  589656 manager.go:925] ignoring container "/kubelet.slice/kubelet.service"
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.533709  589656 factory.go:251] Error trying to work out if we can handle /docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267: failed to load container: container "ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267" in namespace "k8s.io": not found
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.533745  589656 factory.go:262] Factory "containerd" was unable to handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267"
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.533787  589656 factory.go:262] Factory "systemd" was unable to handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267"
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.533841  589656 factory.go:255] Factory "raw" can handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267", but ignoring.
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.533882  589656 manager.go:925] ignoring container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267"
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.533913  589656 factory.go:262] Factory "containerd" was unable to handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/system.slice/containerd.service"
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.533947  589656 factory.go:262] Factory "systemd" was unable to handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/system.slice/containerd.service"
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.533977  589656 factory.go:255] Factory "raw" can handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/system.slice/containerd.service", but ignoring.
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.534126  589656 manager.go:925] ignoring container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/system.slice/containerd.service"
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.534278  589656 factory.go:262] Factory "containerd" was unable to handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-podd2a8b1e2_f8ec_4685_881d_a4d1c26134c2.slice"
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.534307  589656 factory.go:262] Factory "systemd" was unable to handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-podd2a8b1e2_f8ec_4685_881d_a4d1c26134c2.slice"
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.534330  589656 factory.go:255] Factory "raw" can handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-podd2a8b1e2_f8ec_4685_881d_a4d1c26134c2.slice", but ignoring.
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.534354  589656 manager.go:925] ignoring container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-podd2a8b1e2_f8ec_4685_881d_a4d1c26134c2.slice"
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.534375  589656 factory.go:262] Factory "containerd" was unable to handle container "/system.slice/containerd.service"
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.534395  589656 factory.go:262] Factory "systemd" was unable to handle container "/system.slice/containerd.service"
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.534574  589656 factory.go:255] Factory "raw" can handle container "/system.slice/containerd.service", but ignoring.
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.534633  589656 manager.go:925] ignoring container "/system.slice/containerd.service"
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.534660  589656 factory.go:262] Factory "containerd" was unable to handle container "/sys-fs-fuse-connections.mount"
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.534678  589656 factory.go:255] Factory "systemd" can handle container "/sys-fs-fuse-connections.mount", but ignoring.
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.534701  589656 manager.go:925] ignoring container "/sys-fs-fuse-connections.mount"
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.534720  589656 factory.go:262] Factory "containerd" was unable to handle container "/sys-kernel-debug.mount"
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.534752  589656 factory.go:255] Factory "systemd" can handle container "/sys-kernel-debug.mount", but ignoring.
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.534784  589656 manager.go:925] ignoring container "/sys-kernel-debug.mount"
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.534807  589656 factory.go:262] Factory "containerd" was unable to handle container "/kubelet"
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.534823  589656 factory.go:262] Factory "systemd" was unable to handle container "/kubelet"
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.534845  589656 factory.go:255] Factory "raw" can handle container "/kubelet", but ignoring.
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.534879  589656 manager.go:925] ignoring container "/kubelet"
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.534906  589656 factory.go:262] Factory "containerd" was unable to handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice"
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.534945  589656 factory.go:262] Factory "systemd" was unable to handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice"
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.534979  589656 factory.go:255] Factory "raw" can handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice", but ignoring.
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.535020  589656 manager.go:925] ignoring container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice"
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.535053  589656 factory.go:262] Factory "containerd" was unable to handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet"
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.535086  589656 factory.go:262] Factory "systemd" was unable to handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet"
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.535115  589656 factory.go:255] Factory "raw" can handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet", but ignoring.
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.535147  589656 manager.go:925] ignoring container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet"
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.535184  589656 factory.go:262] Factory "containerd" was unable to handle container "/sys-kernel-tracing.mount"
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.535213  589656 factory.go:255] Factory "systemd" can handle container "/sys-kernel-tracing.mount", but ignoring.
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.535247  589656 manager.go:925] ignoring container "/sys-kernel-tracing.mount"
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.535273  589656 factory.go:262] Factory "containerd" was unable to handle container "/kubelet.slice"
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.535295  589656 factory.go:262] Factory "systemd" was unable to handle container "/kubelet.slice"
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.535319  589656 factory.go:255] Factory "raw" can handle container "/kubelet.slice", but ignoring.
Sep 15 20:49:36 kind-worker3 kubelet[589656]: I0915 20:49:36.535473  589656 manager.go:925] ignoring container "/kubelet.slice"
Sep 15 20:49:38 kind-worker3 kubelet[589656]: I0915 20:49:38.497816  589656 kubelet.go:2160] "SyncLoop (housekeeping)"
Sep 15 20:49:38 kind-worker3 kubelet[589656]: I0915 20:49:38.505635  589656 kubelet_pods.go:1079] "Clean up pod workers for terminated pods"
Sep 15 20:49:38 kind-worker3 kubelet[589656]: I0915 20:49:38.505694  589656 kubelet_pods.go:1108] "Clean up probes for terminated pods"
Sep 15 20:49:38 kind-worker3 kubelet[589656]: I0915 20:49:38.505720  589656 kubelet_pods.go:1145] "Clean up orphaned pod statuses"
Sep 15 20:49:38 kind-worker3 kubelet[589656]: I0915 20:49:38.507493  589656 kubelet_pods.go:1164] "Clean up orphaned pod directories"
Sep 15 20:49:38 kind-worker3 kubelet[589656]: I0915 20:49:38.507625  589656 kubelet_pods.go:1175] "Clean up orphaned mirror pods"
Sep 15 20:49:38 kind-worker3 kubelet[589656]: I0915 20:49:38.507653  589656 kubelet_pods.go:1182] "Clean up orphaned pod cgroups"
Sep 15 20:49:38 kind-worker3 kubelet[589656]: I0915 20:49:38.507682  589656 kubelet.go:2168] "SyncLoop (housekeeping) end"
Sep 15 20:49:38 kind-worker3 kubelet[589656]: I0915 20:49:38.602177  589656 handler.go:293] error while reading "/proc/589656/fd/38" link: readlink /proc/589656/fd/38: no such file or directory
Sep 15 20:49:39 kind-worker3 kubelet[589656]: I0915 20:49:39.440356  589656 cri_stats_provider.go:347] "Unable to find cadvisor stats for container" containerID="5432e78771d09f84901cf4700d2078034e73119a187802ac085fa1e2e4829a62"
Sep 15 20:49:39 kind-worker3 kubelet[589656]: I0915 20:49:39.459505  589656 httplog.go:131] "HTTP" verb="GET" URI="/metrics/resource" latency="70.522394ms" userAgent="metrics-server/v0.6.3 (linux/amd64) kubernetes/a938798" audit-ID="" srcIP="172.18.0.3:35538" resp=200
Sep 15 20:49:39 kind-worker3 kubelet[589656]: I0915 20:49:39.571507  589656 kubelet.go:1280] "Container garbage collection succeeded"
Sep 15 20:49:39 kind-worker3 kubelet[589656]: I0915 20:49:39.971307  589656 kubelet.go:2346] "Container runtime status" status="Runtime Conditions: RuntimeReady=true reason: message:, NetworkReady=true reason: message:"
Sep 15 20:49:40 kind-worker3 kubelet[589656]: I0915 20:49:40.498122  589656 kubelet.go:2160] "SyncLoop (housekeeping)"
Sep 15 20:49:40 kind-worker3 kubelet[589656]: I0915 20:49:40.505922  589656 kubelet_pods.go:1079] "Clean up pod workers for terminated pods"
Sep 15 20:49:40 kind-worker3 kubelet[589656]: I0915 20:49:40.505982  589656 kubelet_pods.go:1108] "Clean up probes for terminated pods"
Sep 15 20:49:40 kind-worker3 kubelet[589656]: I0915 20:49:40.507662  589656 kubelet_pods.go:1145] "Clean up orphaned pod statuses"
Sep 15 20:49:40 kind-worker3 kubelet[589656]: I0915 20:49:40.509947  589656 kubelet_pods.go:1164] "Clean up orphaned pod directories"
Sep 15 20:49:40 kind-worker3 kubelet[589656]: I0915 20:49:40.510112  589656 kubelet_pods.go:1175] "Clean up orphaned mirror pods"
Sep 15 20:49:40 kind-worker3 kubelet[589656]: I0915 20:49:40.510145  589656 kubelet_pods.go:1182] "Clean up orphaned pod cgroups"
Sep 15 20:49:40 kind-worker3 kubelet[589656]: I0915 20:49:40.510178  589656 kubelet.go:2168] "SyncLoop (housekeeping) end"
Sep 15 20:49:42 kind-worker3 kubelet[589656]: I0915 20:49:42.498168  589656 kubelet.go:2160] "SyncLoop (housekeeping)"
Sep 15 20:49:42 kind-worker3 kubelet[589656]: I0915 20:49:42.509264  589656 kubelet_pods.go:1079] "Clean up pod workers for terminated pods"
Sep 15 20:49:42 kind-worker3 kubelet[589656]: I0915 20:49:42.509360  589656 kubelet_pods.go:1108] "Clean up probes for terminated pods"
Sep 15 20:49:42 kind-worker3 kubelet[589656]: I0915 20:49:42.510958  589656 kubelet_pods.go:1145] "Clean up orphaned pod statuses"
Sep 15 20:49:42 kind-worker3 kubelet[589656]: I0915 20:49:42.511988  589656 kubelet_pods.go:1164] "Clean up orphaned pod directories"
Sep 15 20:49:42 kind-worker3 kubelet[589656]: I0915 20:49:42.512150  589656 kubelet_pods.go:1175] "Clean up orphaned mirror pods"
Sep 15 20:49:42 kind-worker3 kubelet[589656]: I0915 20:49:42.512179  589656 kubelet_pods.go:1182] "Clean up orphaned pod cgroups"
Sep 15 20:49:42 kind-worker3 kubelet[589656]: I0915 20:49:42.512210  589656 kubelet.go:2168] "SyncLoop (housekeeping) end"
Sep 15 20:49:42 kind-worker3 kubelet[589656]: I0915 20:49:42.954917  589656 setters.go:88] "Using node IP" IP="172.18.0.4"
Sep 15 20:49:44 kind-worker3 kubelet[589656]: I0915 20:49:44.328737  589656 eviction_manager.go:237] "Eviction manager: synchronize housekeeping"
Sep 15 20:49:44 kind-worker3 kubelet[589656]: I0915 20:49:44.350675  589656 cri_stats_provider.go:525] "Unable to find network stats for sandbox" sandboxID="b477a0e3bdd1b445ce34dc6f173590a56dbfec252950ee838d5af2a2515a773b"
Sep 15 20:49:44 kind-worker3 kubelet[589656]: I0915 20:49:44.350900  589656 cri_stats_provider.go:525] "Unable to find network stats for sandbox" sandboxID="b553881ecd35bacb71b6c14fb9ca775d38c625d547bf3c076902f1ed25c4d0c1"
Sep 15 20:49:44 kind-worker3 kubelet[589656]: I0915 20:49:44.351143  589656 cri_stats_provider.go:525] "Unable to find network stats for sandbox" sandboxID="d0f4d02598fe0e9a32081b1554ae85df2b4224eb9a378fdcf99aa7c0035d33dc"
Sep 15 20:49:44 kind-worker3 kubelet[589656]: I0915 20:49:44.356831  589656 helpers.go:775] "Eviction manager:" log="observations" signal=memory.available resourceName="7878752Ki" capacity="8166760Ki" time="2023-09-15 20:49:44.331834526 +0000 UTC m=+2146448.254659729"
Sep 15 20:49:44 kind-worker3 kubelet[589656]: I0915 20:49:44.356929  589656 helpers.go:775] "Eviction manager:" log="observations" signal=allocatableMemory.available resourceName="8092960Ki" capacity="8166760Ki" time="2023-09-15 20:49:44.356180499 +0000 UTC m=+2146448.279005700"
Sep 15 20:49:44 kind-worker3 kubelet[589656]: I0915 20:49:44.356985  589656 helpers.go:775] "Eviction manager:" log="observations" signal=nodefs.available resourceName="7776564Ki" capacity="51341792Ki" time="2023-09-15 20:49:44.331834526 +0000 UTC m=+2146448.254659729"
Sep 15 20:49:44 kind-worker3 kubelet[589656]: I0915 20:49:44.357041  589656 helpers.go:775] "Eviction manager:" log="observations" signal=nodefs.inodesFree resourceName="2345622" capacity="3276800" time="2023-09-15 20:49:44.331834526 +0000 UTC m=+2146448.254659729"
Sep 15 20:49:44 kind-worker3 kubelet[589656]: I0915 20:49:44.357143  589656 helpers.go:775] "Eviction manager:" log="observations" signal=imagefs.available resourceName="7776564Ki" capacity="51341792Ki" time="2023-09-15 20:49:38.906834207 +0000 UTC"
Sep 15 20:49:44 kind-worker3 kubelet[589656]: I0915 20:49:44.357200  589656 helpers.go:775] "Eviction manager:" log="observations" signal=imagefs.inodesFree resourceName="2345622" capacity="3276800" time="2023-09-15 20:49:38.906834207 +0000 UTC"
Sep 15 20:49:44 kind-worker3 kubelet[589656]: I0915 20:49:44.357251  589656 helpers.go:775] "Eviction manager:" log="observations" signal=pid.available resourceName="62210" capacity="63272" time="2023-09-15 20:49:44.351820434 +0000 UTC m=+2146448.274645580"
Sep 15 20:49:44 kind-worker3 kubelet[589656]: I0915 20:49:44.357323  589656 eviction_manager.go:328] "Eviction manager: no resources are starved"
Sep 15 20:49:44 kind-worker3 kubelet[589656]: I0915 20:49:44.498243  589656 kubelet.go:2160] "SyncLoop (housekeeping)"
Sep 15 20:49:44 kind-worker3 kubelet[589656]: I0915 20:49:44.510462  589656 kubelet_pods.go:1079] "Clean up pod workers for terminated pods"
Sep 15 20:49:44 kind-worker3 kubelet[589656]: I0915 20:49:44.510544  589656 kubelet_pods.go:1108] "Clean up probes for terminated pods"
Sep 15 20:49:44 kind-worker3 kubelet[589656]: I0915 20:49:44.512350  589656 kubelet_pods.go:1145] "Clean up orphaned pod statuses"
Sep 15 20:49:44 kind-worker3 kubelet[589656]: I0915 20:49:44.514049  589656 kubelet_pods.go:1164] "Clean up orphaned pod directories"
Sep 15 20:49:44 kind-worker3 kubelet[589656]: I0915 20:49:44.514255  589656 kubelet_pods.go:1175] "Clean up orphaned mirror pods"
Sep 15 20:49:44 kind-worker3 kubelet[589656]: I0915 20:49:44.514297  589656 kubelet_pods.go:1182] "Clean up orphaned pod cgroups"
Sep 15 20:49:44 kind-worker3 kubelet[589656]: I0915 20:49:44.514345  589656 kubelet.go:2168] "SyncLoop (housekeeping) end"
Sep 15 20:49:44 kind-worker3 kubelet[589656]: I0915 20:49:44.972956  589656 kubelet.go:2346] "Container runtime status" status="Runtime Conditions: RuntimeReady=true reason: message:, NetworkReady=true reason: message:"
Sep 15 20:49:46 kind-worker3 kubelet[589656]: I0915 20:49:46.497790  589656 kubelet.go:2160] "SyncLoop (housekeeping)"
Sep 15 20:49:46 kind-worker3 kubelet[589656]: I0915 20:49:46.505989  589656 kubelet_pods.go:1079] "Clean up pod workers for terminated pods"
Sep 15 20:49:46 kind-worker3 kubelet[589656]: I0915 20:49:46.506045  589656 kubelet_pods.go:1108] "Clean up probes for terminated pods"
Sep 15 20:49:46 kind-worker3 kubelet[589656]: I0915 20:49:46.506071  589656 kubelet_pods.go:1145] "Clean up orphaned pod statuses"
Sep 15 20:49:46 kind-worker3 kubelet[589656]: I0915 20:49:46.507782  589656 kubelet_pods.go:1164] "Clean up orphaned pod directories"
Sep 15 20:49:46 kind-worker3 kubelet[589656]: I0915 20:49:46.507947  589656 kubelet_pods.go:1175] "Clean up orphaned mirror pods"
Sep 15 20:49:46 kind-worker3 kubelet[589656]: I0915 20:49:46.507975  589656 kubelet_pods.go:1182] "Clean up orphaned pod cgroups"
Sep 15 20:49:46 kind-worker3 kubelet[589656]: I0915 20:49:46.508006  589656 kubelet.go:2168] "SyncLoop (housekeeping) end"
Sep 15 20:49:48 kind-worker3 kubelet[589656]: I0915 20:49:48.498190  589656 kubelet.go:2160] "SyncLoop (housekeeping)"
Sep 15 20:49:48 kind-worker3 kubelet[589656]: I0915 20:49:48.505655  589656 kubelet_pods.go:1079] "Clean up pod workers for terminated pods"
Sep 15 20:49:48 kind-worker3 kubelet[589656]: I0915 20:49:48.505711  589656 kubelet_pods.go:1108] "Clean up probes for terminated pods"
Sep 15 20:49:48 kind-worker3 kubelet[589656]: I0915 20:49:48.507545  589656 kubelet_pods.go:1145] "Clean up orphaned pod statuses"
Sep 15 20:49:48 kind-worker3 kubelet[589656]: I0915 20:49:48.508592  589656 kubelet_pods.go:1164] "Clean up orphaned pod directories"
Sep 15 20:49:48 kind-worker3 kubelet[589656]: I0915 20:49:48.508771  589656 kubelet_pods.go:1175] "Clean up orphaned mirror pods"
Sep 15 20:49:48 kind-worker3 kubelet[589656]: I0915 20:49:48.508814  589656 kubelet_pods.go:1182] "Clean up orphaned pod cgroups"
Sep 15 20:49:48 kind-worker3 kubelet[589656]: I0915 20:49:48.508849  589656 kubelet.go:2168] "SyncLoop (housekeeping) end"
Sep 15 20:49:49 kind-worker3 kubelet[589656]: I0915 20:49:49.415247  589656 httplog.go:131] "HTTP" verb="GET" URI="/metrics/resource" latency="44.847345ms" userAgent="metrics-server/v0.6.3 (linux/amd64) kubernetes/a938798" audit-ID="" srcIP="172.18.0.3:35538" resp=200
Sep 15 20:49:49 kind-worker3 kubelet[589656]: I0915 20:49:49.974231  589656 kubelet.go:2346] "Container runtime status" status="Runtime Conditions: RuntimeReady=true reason: message:, NetworkReady=true reason: message:"
Sep 15 20:49:50 kind-worker3 kubelet[589656]: I0915 20:49:50.498550  589656 kubelet.go:2160] "SyncLoop (housekeeping)"
Sep 15 20:49:50 kind-worker3 kubelet[589656]: I0915 20:49:50.507121  589656 kubelet_pods.go:1079] "Clean up pod workers for terminated pods"
Sep 15 20:49:50 kind-worker3 kubelet[589656]: I0915 20:49:50.507177  589656 kubelet_pods.go:1108] "Clean up probes for terminated pods"
Sep 15 20:49:50 kind-worker3 kubelet[589656]: I0915 20:49:50.509230  589656 kubelet_pods.go:1145] "Clean up orphaned pod statuses"
Sep 15 20:49:50 kind-worker3 kubelet[589656]: I0915 20:49:50.510964  589656 kubelet_pods.go:1164] "Clean up orphaned pod directories"
Sep 15 20:49:50 kind-worker3 kubelet[589656]: I0915 20:49:50.511163  589656 kubelet_pods.go:1175] "Clean up orphaned mirror pods"
Sep 15 20:49:50 kind-worker3 kubelet[589656]: I0915 20:49:50.511230  589656 kubelet_pods.go:1182] "Clean up orphaned pod cgroups"
Sep 15 20:49:50 kind-worker3 kubelet[589656]: I0915 20:49:50.511291  589656 kubelet.go:2168] "SyncLoop (housekeeping) end"
Sep 15 20:49:52 kind-worker3 kubelet[589656]: I0915 20:49:52.498466  589656 kubelet.go:2160] "SyncLoop (housekeeping)"
Sep 15 20:49:52 kind-worker3 kubelet[589656]: I0915 20:49:52.506393  589656 kubelet_pods.go:1079] "Clean up pod workers for terminated pods"
Sep 15 20:49:52 kind-worker3 kubelet[589656]: I0915 20:49:52.506444  589656 kubelet_pods.go:1108] "Clean up probes for terminated pods"
Sep 15 20:49:52 kind-worker3 kubelet[589656]: I0915 20:49:52.506469  589656 kubelet_pods.go:1145] "Clean up orphaned pod statuses"
Sep 15 20:49:52 kind-worker3 kubelet[589656]: I0915 20:49:52.508230  589656 kubelet_pods.go:1164] "Clean up orphaned pod directories"
Sep 15 20:49:52 kind-worker3 kubelet[589656]: I0915 20:49:52.508379  589656 kubelet_pods.go:1175] "Clean up orphaned mirror pods"
Sep 15 20:49:52 kind-worker3 kubelet[589656]: I0915 20:49:52.508423  589656 kubelet_pods.go:1182] "Clean up orphaned pod cgroups"
Sep 15 20:49:52 kind-worker3 kubelet[589656]: I0915 20:49:52.508454  589656 kubelet.go:2168] "SyncLoop (housekeeping) end"
Sep 15 20:49:53 kind-worker3 kubelet[589656]: I0915 20:49:53.080924  589656 setters.go:88] "Using node IP" IP="172.18.0.4"
Sep 15 20:49:54 kind-worker3 kubelet[589656]: I0915 20:49:54.357812  589656 eviction_manager.go:237] "Eviction manager: synchronize housekeeping"
Sep 15 20:49:54 kind-worker3 kubelet[589656]: I0915 20:49:54.372651  589656 cri_stats_provider.go:525] "Unable to find network stats for sandbox" sandboxID="b477a0e3bdd1b445ce34dc6f173590a56dbfec252950ee838d5af2a2515a773b"
Sep 15 20:49:54 kind-worker3 kubelet[589656]: I0915 20:49:54.372879  589656 cri_stats_provider.go:525] "Unable to find network stats for sandbox" sandboxID="b553881ecd35bacb71b6c14fb9ca775d38c625d547bf3c076902f1ed25c4d0c1"
Sep 15 20:49:54 kind-worker3 kubelet[589656]: I0915 20:49:54.373035  589656 cri_stats_provider.go:525] "Unable to find network stats for sandbox" sandboxID="d0f4d02598fe0e9a32081b1554ae85df2b4224eb9a378fdcf99aa7c0035d33dc"
Sep 15 20:49:54 kind-worker3 kubelet[589656]: I0915 20:49:54.375448  589656 helpers.go:775] "Eviction manager:" log="observations" signal=imagefs.inodesFree resourceName="2345622" capacity="3276800" time="2023-09-15 20:49:48.905875818 +0000 UTC"
Sep 15 20:49:54 kind-worker3 kubelet[589656]: I0915 20:49:54.375497  589656 helpers.go:775] "Eviction manager:" log="observations" signal=pid.available resourceName="62173" capacity="63272" time="2023-09-15 20:49:54.373448249 +0000 UTC m=+2146458.296273381"
Sep 15 20:49:54 kind-worker3 kubelet[589656]: I0915 20:49:54.375543  589656 helpers.go:775] "Eviction manager:" log="observations" signal=memory.available resourceName="7892996Ki" capacity="8166760Ki" time="2023-09-15 20:49:54.359749601 +0000 UTC m=+2146458.282574760"
Sep 15 20:49:54 kind-worker3 kubelet[589656]: I0915 20:49:54.375587  589656 helpers.go:775] "Eviction manager:" log="observations" signal=allocatableMemory.available resourceName="8106364Ki" capacity="8166760Ki" time="2023-09-15 20:49:54.37526849 +0000 UTC m=+2146458.298093645"
Sep 15 20:49:54 kind-worker3 kubelet[589656]: I0915 20:49:54.375617  589656 helpers.go:775] "Eviction manager:" log="observations" signal=nodefs.available resourceName="7771812Ki" capacity="51341792Ki" time="2023-09-15 20:49:54.359749601 +0000 UTC m=+2146458.282574760"
Sep 15 20:49:54 kind-worker3 kubelet[589656]: I0915 20:49:54.375642  589656 helpers.go:775] "Eviction manager:" log="observations" signal=nodefs.inodesFree resourceName="2345622" capacity="3276800" time="2023-09-15 20:49:54.359749601 +0000 UTC m=+2146458.282574760"
Sep 15 20:49:54 kind-worker3 kubelet[589656]: I0915 20:49:54.375666  589656 helpers.go:775] "Eviction manager:" log="observations" signal=imagefs.available resourceName="7771812Ki" capacity="51341792Ki" time="2023-09-15 20:49:48.905875818 +0000 UTC"
Sep 15 20:49:54 kind-worker3 kubelet[589656]: I0915 20:49:54.375712  589656 eviction_manager.go:328] "Eviction manager: no resources are starved"
Sep 15 20:49:54 kind-worker3 kubelet[589656]: I0915 20:49:54.498278  589656 kubelet.go:2160] "SyncLoop (housekeeping)"
Sep 15 20:49:54 kind-worker3 kubelet[589656]: I0915 20:49:54.508154  589656 kubelet_pods.go:1079] "Clean up pod workers for terminated pods"
Sep 15 20:49:54 kind-worker3 kubelet[589656]: I0915 20:49:54.508205  589656 kubelet_pods.go:1108] "Clean up probes for terminated pods"
Sep 15 20:49:54 kind-worker3 kubelet[589656]: I0915 20:49:54.510179  589656 kubelet_pods.go:1145] "Clean up orphaned pod statuses"
Sep 15 20:49:54 kind-worker3 kubelet[589656]: I0915 20:49:54.512282  589656 kubelet_pods.go:1164] "Clean up orphaned pod directories"
Sep 15 20:49:54 kind-worker3 kubelet[589656]: I0915 20:49:54.512424  589656 kubelet_pods.go:1175] "Clean up orphaned mirror pods"
Sep 15 20:49:54 kind-worker3 kubelet[589656]: I0915 20:49:54.512452  589656 kubelet_pods.go:1182] "Clean up orphaned pod cgroups"
Sep 15 20:49:54 kind-worker3 kubelet[589656]: I0915 20:49:54.512481  589656 kubelet.go:2168] "SyncLoop (housekeeping) end"
Sep 15 20:49:54 kind-worker3 kubelet[589656]: I0915 20:49:54.602480  589656 config.go:279] "Setting pods for source" source="api"
Sep 15 20:49:54 kind-worker3 kubelet[589656]: I0915 20:49:54.602917  589656 kubelet.go:2088] "SyncLoop DELETE" source="api" pods=[default/nginx-deployment-66f58bff7c-7kkk5]
Sep 15 20:49:54 kind-worker3 kubelet[589656]: I0915 20:49:54.603012  589656 pod_workers.go:625] "Pod is marked for graceful deletion, begin teardown" pod="default/nginx-deployment-66f58bff7c-7kkk5" podUID=f602fc75-3d22-475f-8c0a-de933744ab4e
Sep 15 20:49:54 kind-worker3 kubelet[589656]: I0915 20:49:54.603141  589656 pod_workers.go:888] "Processing pod event" pod="default/nginx-deployment-66f58bff7c-7kkk5" podUID=f602fc75-3d22-475f-8c0a-de933744ab4e updateType=1
Sep 15 20:49:54 kind-worker3 kubelet[589656]: I0915 20:49:54.603211  589656 pod_workers.go:1005] "Pod worker has observed request to terminate" pod="default/nginx-deployment-66f58bff7c-7kkk5" podUID=f602fc75-3d22-475f-8c0a-de933744ab4e
Sep 15 20:49:54 kind-worker3 kubelet[589656]: I0915 20:49:54.603264  589656 kubelet.go:1743] "syncTerminatingPod enter" pod="default/nginx-deployment-66f58bff7c-7kkk5" podUID=f602fc75-3d22-475f-8c0a-de933744ab4e
Sep 15 20:49:54 kind-worker3 kubelet[589656]: I0915 20:49:54.603314  589656 kubelet_pods.go:1432] "Generating pod status" pod="default/nginx-deployment-66f58bff7c-7kkk5"
Sep 15 20:49:54 kind-worker3 kubelet[589656]: I0915 20:49:54.603450  589656 kubelet_pods.go:1444] "Got phase for pod" pod="default/nginx-deployment-66f58bff7c-7kkk5" oldPhase=Running phase=Running
Sep 15 20:49:54 kind-worker3 kubelet[589656]: I0915 20:49:54.603677  589656 kubelet.go:1773] "Pod terminating with grace period" pod="default/nginx-deployment-66f58bff7c-7kkk5" podUID=f602fc75-3d22-475f-8c0a-de933744ab4e gracePeriod=30
Sep 15 20:49:54 kind-worker3 kubelet[589656]: I0915 20:49:54.603824  589656 kuberuntime_container.go:718] "Killing container with a grace period override" pod="default/nginx-deployment-66f58bff7c-7kkk5" podUID=f602fc75-3d22-475f-8c0a-de933744ab4e containerName="nginx" containerID="containerd://5432e78771d09f84901cf4700d2078034e73119a187802ac085fa1e2e4829a62" gracePeriod=30
Sep 15 20:49:54 kind-worker3 kubelet[589656]: I0915 20:49:54.603918  589656 kuberuntime_container.go:722] "Killing container with a grace period" pod="default/nginx-deployment-66f58bff7c-7kkk5" podUID=f602fc75-3d22-475f-8c0a-de933744ab4e containerName="nginx" containerID="containerd://5432e78771d09f84901cf4700d2078034e73119a187802ac085fa1e2e4829a62" gracePeriod=30
Sep 15 20:49:54 kind-worker3 kubelet[589656]: I0915 20:49:54.604185  589656 event.go:294] "Event occurred" object="default/nginx-deployment-66f58bff7c-7kkk5" fieldPath="spec.containers{nginx}" kind="Pod" apiVersion="v1" type="Normal" reason="Killing" message="Stopping container nginx"
Sep 15 20:49:54 kind-worker3 kubelet[589656]: I0915 20:49:54.724847  589656 status_manager.go:685] "Patch status for pod" pod="default/nginx-deployment-66f58bff7c-7kkk5" patch="{\"metadata\":{\"uid\":\"f602fc75-3d22-475f-8c0a-de933744ab4e\"}}"
Sep 15 20:49:54 kind-worker3 kubelet[589656]: I0915 20:49:54.724928  589656 status_manager.go:692] "Status for pod is up-to-date" pod="default/nginx-deployment-66f58bff7c-7kkk5" statusVersion=3
Sep 15 20:49:54 kind-worker3 kubelet[589656]: I0915 20:49:54.724979  589656 kubelet_pods.go:929] "Pod is terminated, but some containers are still running" pod="default/nginx-deployment-66f58bff7c-7kkk5"
Sep 15 20:49:54 kind-worker3 kubelet[589656]: I0915 20:49:54.823227  589656 manager.go:1044] Destroyed container: "/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-podf602fc75_3d22_475f_8c0a_de933744ab4e.slice/cri-containerd-5432e78771d09f84901cf4700d2078034e73119a187802ac085fa1e2e4829a62.scope" (aliases: [5432e78771d09f84901cf4700d2078034e73119a187802ac085fa1e2e4829a62 /kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-podf602fc75_3d22_475f_8c0a_de933744ab4e.slice/cri-containerd-5432e78771d09f84901cf4700d2078034e73119a187802ac085fa1e2e4829a62.scope], namespace: "containerd")
Sep 15 20:49:54 kind-worker3 kubelet[589656]: I0915 20:49:54.823365  589656 handler.go:325] Added event &{/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-podf602fc75_3d22_475f_8c0a_de933744ab4e.slice/cri-containerd-5432e78771d09f84901cf4700d2078034e73119a187802ac085fa1e2e4829a62.scope 2023-09-15 20:49:54.823346268 +0000 UTC m=+2146458.746171406 containerDeletion {<nil>}}
Sep 15 20:49:54 kind-worker3 kubelet[589656]: I0915 20:49:54.977474  589656 kubelet.go:2346] "Container runtime status" status="Runtime Conditions: RuntimeReady=true reason: message:, NetworkReady=true reason: message:"
Sep 15 20:49:55 kind-worker3 kubelet[589656]: I0915 20:49:55.571242  589656 kuberuntime_container.go:731] "Container exited normally" pod="default/nginx-deployment-66f58bff7c-7kkk5" podUID=f602fc75-3d22-475f-8c0a-de933744ab4e containerName="nginx" containerID="containerd://5432e78771d09f84901cf4700d2078034e73119a187802ac085fa1e2e4829a62"
Sep 15 20:49:55 kind-worker3 kubelet[589656]: I0915 20:49:55.720466  589656 manager.go:1044] Destroyed container: "/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-podf602fc75_3d22_475f_8c0a_de933744ab4e.slice/cri-containerd-b553881ecd35bacb71b6c14fb9ca775d38c625d547bf3c076902f1ed25c4d0c1.scope" (aliases: [b553881ecd35bacb71b6c14fb9ca775d38c625d547bf3c076902f1ed25c4d0c1 /kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-podf602fc75_3d22_475f_8c0a_de933744ab4e.slice/cri-containerd-b553881ecd35bacb71b6c14fb9ca775d38c625d547bf3c076902f1ed25c4d0c1.scope], namespace: "containerd")
Sep 15 20:49:55 kind-worker3 kubelet[589656]: I0915 20:49:55.720560  589656 handler.go:325] Added event &{/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-podf602fc75_3d22_475f_8c0a_de933744ab4e.slice/cri-containerd-b553881ecd35bacb71b6c14fb9ca775d38c625d547bf3c076902f1ed25c4d0c1.scope 2023-09-15 20:49:55.720545205 +0000 UTC m=+2146459.643370327 containerDeletion {<nil>}}
Sep 15 20:49:56 kind-worker3 kubelet[589656]: I0915 20:49:56.217724  589656 qos_container_manager_linux.go:379] "Updated QoS cgroup configuration"
Sep 15 20:49:56 kind-worker3 kubelet[589656]: I0915 20:49:56.218941  589656 kuberuntime_manager.go:1037] "getSandboxIDByPodUID got sandbox IDs for pod" podSandboxID=[b553881ecd35bacb71b6c14fb9ca775d38c625d547bf3c076902f1ed25c4d0c1] pod="default/nginx-deployment-66f58bff7c-7kkk5"
Sep 15 20:49:56 kind-worker3 kubelet[589656]: I0915 20:49:56.221943  589656 kubelet.go:1824] "Post-termination container state" pod="default/nginx-deployment-66f58bff7c-7kkk5" podUID=f602fc75-3d22-475f-8c0a-de933744ab4e containers=[{Name:nginx State:exited ExitCode:0 FinishedAt:2023-09-15T20:49:54.743995825Z}]
Sep 15 20:49:56 kind-worker3 kubelet[589656]: I0915 20:49:56.221986  589656 kubelet.go:1831] "Pod termination stopped all running containers" pod="default/nginx-deployment-66f58bff7c-7kkk5" podUID=f602fc75-3d22-475f-8c0a-de933744ab4e
Sep 15 20:49:56 kind-worker3 kubelet[589656]: I0915 20:49:56.222016  589656 kubelet.go:1833] "syncTerminatingPod exit" pod="default/nginx-deployment-66f58bff7c-7kkk5" podUID=f602fc75-3d22-475f-8c0a-de933744ab4e
Sep 15 20:49:56 kind-worker3 kubelet[589656]: I0915 20:49:56.222041  589656 pod_workers.go:1050] "Pod terminated all containers successfully" pod="default/nginx-deployment-66f58bff7c-7kkk5" podUID=f602fc75-3d22-475f-8c0a-de933744ab4e
Sep 15 20:49:56 kind-worker3 kubelet[589656]: I0915 20:49:56.222081  589656 pod_workers.go:988] "Processing pod event done" pod="default/nginx-deployment-66f58bff7c-7kkk5" podUID=f602fc75-3d22-475f-8c0a-de933744ab4e updateType=1
Sep 15 20:49:56 kind-worker3 kubelet[589656]: I0915 20:49:56.222103  589656 pod_workers.go:888] "Processing pod event" pod="default/nginx-deployment-66f58bff7c-7kkk5" podUID=f602fc75-3d22-475f-8c0a-de933744ab4e updateType=2
Sep 15 20:49:56 kind-worker3 kubelet[589656]: I0915 20:49:56.256717  589656 config.go:279] "Setting pods for source" source="file"
Sep 15 20:49:56 kind-worker3 kubelet[589656]: I0915 20:49:56.279303  589656 generic.go:155] "GenericPLEG" podUID=f602fc75-3d22-475f-8c0a-de933744ab4e containerID="5432e78771d09f84901cf4700d2078034e73119a187802ac085fa1e2e4829a62" oldState=running newState=exited
Sep 15 20:49:56 kind-worker3 kubelet[589656]: I0915 20:49:56.279351  589656 generic.go:155] "GenericPLEG" podUID=f602fc75-3d22-475f-8c0a-de933744ab4e containerID="b553881ecd35bacb71b6c14fb9ca775d38c625d547bf3c076902f1ed25c4d0c1" oldState=running newState=exited
Sep 15 20:49:56 kind-worker3 kubelet[589656]: I0915 20:49:56.280419  589656 kuberuntime_manager.go:1037] "getSandboxIDByPodUID got sandbox IDs for pod" podSandboxID=[b553881ecd35bacb71b6c14fb9ca775d38c625d547bf3c076902f1ed25c4d0c1] pod="default/nginx-deployment-66f58bff7c-7kkk5"
Sep 15 20:49:56 kind-worker3 kubelet[589656]: I0915 20:49:56.281047  589656 desired_state_of_world_populator.go:253] "Removing volume from desired state" pod="default/nginx-deployment-66f58bff7c-7kkk5" podUID=f602fc75-3d22-475f-8c0a-de933744ab4e volumeName="kube-api-access-kgpd5"
Sep 15 20:49:56 kind-worker3 kubelet[589656]: I0915 20:49:56.286921  589656 generic.go:421] "PLEG: Write status" pod="default/nginx-deployment-66f58bff7c-7kkk5"
Sep 15 20:49:56 kind-worker3 kubelet[589656]: I0915 20:49:56.287024  589656 generic.go:296] "Generic (PLEG): container finished" podID=f602fc75-3d22-475f-8c0a-de933744ab4e containerID="5432e78771d09f84901cf4700d2078034e73119a187802ac085fa1e2e4829a62" exitCode=0
Sep 15 20:49:56 kind-worker3 kubelet[589656]: I0915 20:49:56.287102  589656 kubelet.go:2110] "SyncLoop (PLEG): event for pod" pod="default/nginx-deployment-66f58bff7c-7kkk5" event=&{ID:f602fc75-3d22-475f-8c0a-de933744ab4e Type:ContainerDied Data:5432e78771d09f84901cf4700d2078034e73119a187802ac085fa1e2e4829a62}
Sep 15 20:49:56 kind-worker3 kubelet[589656]: I0915 20:49:56.287167  589656 kubelet.go:2110] "SyncLoop (PLEG): event for pod" pod="default/nginx-deployment-66f58bff7c-7kkk5" event=&{ID:f602fc75-3d22-475f-8c0a-de933744ab4e Type:ContainerDied Data:b553881ecd35bacb71b6c14fb9ca775d38c625d547bf3c076902f1ed25c4d0c1}
Sep 15 20:49:56 kind-worker3 kubelet[589656]: I0915 20:49:56.287208  589656 kuberuntime_container.go:950] "Removing container" containerID="5432e78771d09f84901cf4700d2078034e73119a187802ac085fa1e2e4829a62"
Sep 15 20:49:56 kind-worker3 kubelet[589656]: I0915 20:49:56.287241  589656 scope.go:110] "RemoveContainer" containerID="5432e78771d09f84901cf4700d2078034e73119a187802ac085fa1e2e4829a62"
Sep 15 20:49:56 kind-worker3 kubelet[589656]: I0915 20:49:56.287425  589656 kubelet.go:1841] "syncTerminatedPod enter" pod="default/nginx-deployment-66f58bff7c-7kkk5" podUID=f602fc75-3d22-475f-8c0a-de933744ab4e
Sep 15 20:49:56 kind-worker3 kubelet[589656]: I0915 20:49:56.287456  589656 kubelet_pods.go:1432] "Generating pod status" pod="default/nginx-deployment-66f58bff7c-7kkk5"
Sep 15 20:49:56 kind-worker3 kubelet[589656]: I0915 20:49:56.287520  589656 kubelet_pods.go:1444] "Got phase for pod" pod="default/nginx-deployment-66f58bff7c-7kkk5" oldPhase=Running phase=Running
Sep 15 20:49:56 kind-worker3 kubelet[589656]: I0915 20:49:56.287616  589656 volume_manager.go:444] "Waiting for volumes to unmount for pod" pod="default/nginx-deployment-66f58bff7c-7kkk5"
Sep 15 20:49:56 kind-worker3 kubelet[589656]: I0915 20:49:56.305499  589656 status_manager.go:685] "Patch status for pod" pod="default/nginx-deployment-66f58bff7c-7kkk5" patch="{\"metadata\":{\"uid\":\"f602fc75-3d22-475f-8c0a-de933744ab4e\"},\"status\":{\"$setElementOrder/conditions\":[{\"type\":\"Initialized\"},{\"type\":\"Ready\"},{\"type\":\"ContainersReady\"},{\"type\":\"PodScheduled\"}],\"conditions\":[{\"lastTransitionTime\":\"2023-09-15T20:49:56Z\",\"message\":\"containers with unready status: [nginx]\",\"reason\":\"ContainersNotReady\",\"status\":\"False\",\"type\":\"Ready\"},{\"lastTransitionTime\":\"2023-09-15T20:49:56Z\",\"message\":\"containers with unready status: [nginx]\",\"reason\":\"ContainersNotReady\",\"status\":\"False\",\"type\":\"ContainersReady\"}],\"containerStatuses\":[{\"containerID\":\"containerd://5432e78771d09f84901cf4700d2078034e73119a187802ac085fa1e2e4829a62\",\"image\":\"docker.io/library/nginx:1.14.2\",\"imageID\":\"docker.io/library/nginx@sha256:f7988fb6c02e0ce69257d9bd9cf37ae20a60f1df7563c3a2a6abe24160306b8d\",\"lastState\":{},\"name\":\"nginx\",\"ready\":false,\"restartCount\":0,\"started\":false,\"state\":{\"terminated\":{\"containerID\":\"containerd://5432e78771d09f84901cf4700d2078034e73119a187802ac085fa1e2e4829a62\",\"exitCode\":0,\"finishedAt\":\"2023-09-15T20:49:54Z\",\"reason\":\"Completed\",\"startedAt\":\"2023-09-15T20:49:26Z\"}}}]}}"
Sep 15 20:49:56 kind-worker3 kubelet[589656]: I0915 20:49:56.305700  589656 status_manager.go:694] "Status for pod updated successfully" pod="default/nginx-deployment-66f58bff7c-7kkk5" statusVersion=4 status={Phase:Running Conditions:[{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-09-15 20:49:23 +0000 UTC Reason: Message:} {Type:Ready Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-09-15 20:49:56 +0000 UTC Reason:ContainersNotReady Message:containers with unready status: [nginx]} {Type:ContainersReady Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-09-15 20:49:56 +0000 UTC Reason:ContainersNotReady Message:containers with unready status: [nginx]} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-09-15 20:49:23 +0000 UTC Reason: Message:}] Message: Reason: NominatedNodeName: HostIP:172.18.0.4 PodIP:10.244.3.71 PodIPs:[{IP:10.244.3.71}] StartTime:2023-09-15 20:49:23 +0000 UTC InitContainerStatuses:[] ContainerStatuses:[{Name:nginx State:{Waiting:nil Running:nil Terminated:&ContainerStateTerminated{ExitCode:0,Signal:0,Reason:Completed,Message:,StartedAt:2023-09-15 20:49:26 +0000 UTC,FinishedAt:2023-09-15 20:49:54 +0000 UTC,ContainerID:containerd://5432e78771d09f84901cf4700d2078034e73119a187802ac085fa1e2e4829a62,}} LastTerminationState:{Waiting:nil Running:nil Terminated:nil} Ready:false RestartCount:0 Image:docker.io/library/nginx:1.14.2 ImageID:docker.io/library/nginx@sha256:f7988fb6c02e0ce69257d9bd9cf37ae20a60f1df7563c3a2a6abe24160306b8d ContainerID:containerd://5432e78771d09f84901cf4700d2078034e73119a187802ac085fa1e2e4829a62 Started:0xc001990b7c}] QOSClass:Burstable EphemeralContainerStatuses:[]}
Sep 15 20:49:56 kind-worker3 kubelet[589656]: I0915 20:49:56.305772  589656 kubelet_pods.go:940] "Pod is terminated, but some volumes have not been cleaned up" pod="default/nginx-deployment-66f58bff7c-7kkk5"
Sep 15 20:49:56 kind-worker3 kubelet[589656]: I0915 20:49:56.306918  589656 config.go:279] "Setting pods for source" source="api"
Sep 15 20:49:56 kind-worker3 kubelet[589656]: I0915 20:49:56.307194  589656 kubelet.go:2085] "SyncLoop RECONCILE" source="api" pods=[default/nginx-deployment-66f58bff7c-7kkk5]
Sep 15 20:49:56 kind-worker3 kubelet[589656]: I0915 20:49:56.325156  589656 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"kube-api-access-kgpd5\" (UniqueName: \"kubernetes.io/projected/f602fc75-3d22-475f-8c0a-de933744ab4e-kube-api-access-kgpd5\") pod \"f602fc75-3d22-475f-8c0a-de933744ab4e\" (UID: \"f602fc75-3d22-475f-8c0a-de933744ab4e\") "
Sep 15 20:49:56 kind-worker3 kubelet[589656]: I0915 20:49:56.325246  589656 subpath_linux.go:244] Cleaning up subpath mounts for /var/lib/kubelet/pods/f602fc75-3d22-475f-8c0a-de933744ab4e/volume-subpaths/kube-api-access-kgpd5
Sep 15 20:49:56 kind-worker3 kubelet[589656]: I0915 20:49:56.325310  589656 projected.go:366] Tearing down volume kube-api-access-kgpd5 for pod f602fc75-3d22-475f-8c0a-de933744ab4e at /var/lib/kubelet/pods/f602fc75-3d22-475f-8c0a-de933744ab4e/volumes/kubernetes.io~projected/kube-api-access-kgpd5
Sep 15 20:49:56 kind-worker3 kubelet[589656]: I0915 20:49:56.325622  589656 empty_dir_linux.go:99] Statfs_t of /var/lib/kubelet/pods/f602fc75-3d22-475f-8c0a-de933744ab4e/volumes/kubernetes.io~projected/kube-api-access-kgpd5: {Type:16914836 Bsize:4096 Blocks:2041690 Bfree:2041687 Bavail:2041687 Files:1020845 Ffree:1020836 Fsid:{Val:[0 0]} Namelen:255 Frsize:4096 Flags:4128 Spare:[0 0 0 0]}
Sep 15 20:49:56 kind-worker3 kubelet[589656]: I0915 20:49:56.325694  589656 mount_linux.go:294] Unmounting /var/lib/kubelet/pods/f602fc75-3d22-475f-8c0a-de933744ab4e/volumes/kubernetes.io~projected/kube-api-access-kgpd5
Sep 15 20:49:56 kind-worker3 kubelet[589656]: I0915 20:49:56.357808  589656 operation_generator.go:863] UnmountVolume.TearDown succeeded for volume "kubernetes.io/projected/f602fc75-3d22-475f-8c0a-de933744ab4e-kube-api-access-kgpd5" (OuterVolumeSpecName: "kube-api-access-kgpd5") pod "f602fc75-3d22-475f-8c0a-de933744ab4e" (UID: "f602fc75-3d22-475f-8c0a-de933744ab4e"). InnerVolumeSpecName "kube-api-access-kgpd5". PluginName "kubernetes.io/projected", VolumeGidValue ""
Sep 15 20:49:56 kind-worker3 kubelet[589656]: I0915 20:49:56.426240  589656 reconciler.go:384] "Volume detached for volume \"kube-api-access-kgpd5\" (UniqueName: \"kubernetes.io/projected/f602fc75-3d22-475f-8c0a-de933744ab4e-kube-api-access-kgpd5\") on node \"kind-worker3\" DevicePath \"\""
Sep 15 20:49:56 kind-worker3 kubelet[589656]: I0915 20:49:56.479045  589656 kuberuntime_container.go:950] "Removing container" containerID="5432e78771d09f84901cf4700d2078034e73119a187802ac085fa1e2e4829a62"
Sep 15 20:49:56 kind-worker3 kubelet[589656]: I0915 20:49:56.479150  589656 scope.go:110] "RemoveContainer" containerID="5432e78771d09f84901cf4700d2078034e73119a187802ac085fa1e2e4829a62"
Sep 15 20:49:56 kind-worker3 kubelet[589656]: E0915 20:49:56.481417  589656 remote_runtime.go:604] "ContainerStatus from runtime service failed" err="rpc error: code = NotFound desc = an error occurred when try to find container \"5432e78771d09f84901cf4700d2078034e73119a187802ac085fa1e2e4829a62\": not found" containerID="5432e78771d09f84901cf4700d2078034e73119a187802ac085fa1e2e4829a62"
Sep 15 20:49:56 kind-worker3 kubelet[589656]: I0915 20:49:56.481500  589656 pod_container_deletor.go:52] "DeleteContainer returned error" containerID={Type:containerd ID:5432e78771d09f84901cf4700d2078034e73119a187802ac085fa1e2e4829a62} err="failed to get container status \"5432e78771d09f84901cf4700d2078034e73119a187802ac085fa1e2e4829a62\": rpc error: code = NotFound desc = an error occurred when try to find container \"5432e78771d09f84901cf4700d2078034e73119a187802ac085fa1e2e4829a62\": not found"
Sep 15 20:49:56 kind-worker3 kubelet[589656]: I0915 20:49:56.498347  589656 kubelet.go:2129] "SyncLoop (SYNC) pods" total=1 pods=[default/nginx-deployment-66f58bff7c-7kkk5]
Sep 15 20:49:56 kind-worker3 kubelet[589656]: I0915 20:49:56.498449  589656 kubelet.go:2160] "SyncLoop (housekeeping)"
Sep 15 20:49:56 kind-worker3 kubelet[589656]: I0915 20:49:56.499851  589656 kubelet_pods.go:946] "Pod is terminated, but pod cgroup sandbox has not been cleaned up" pod="default/nginx-deployment-66f58bff7c-7kkk5"
Sep 15 20:49:56 kind-worker3 kubelet[589656]: I0915 20:49:56.506925  589656 kubelet_pods.go:1079] "Clean up pod workers for terminated pods"
Sep 15 20:49:56 kind-worker3 kubelet[589656]: I0915 20:49:56.506982  589656 kubelet_pods.go:1108] "Clean up probes for terminated pods"
Sep 15 20:49:56 kind-worker3 kubelet[589656]: I0915 20:49:56.507017  589656 kubelet_pods.go:1145] "Clean up orphaned pod statuses"
Sep 15 20:49:56 kind-worker3 kubelet[589656]: I0915 20:49:56.509545  589656 kubelet_pods.go:1164] "Clean up orphaned pod directories"
Sep 15 20:49:56 kind-worker3 kubelet[589656]: I0915 20:49:56.509786  589656 kubelet_pods.go:1175] "Clean up orphaned mirror pods"
Sep 15 20:49:56 kind-worker3 kubelet[589656]: I0915 20:49:56.509825  589656 kubelet_pods.go:1182] "Clean up orphaned pod cgroups"
Sep 15 20:49:56 kind-worker3 kubelet[589656]: I0915 20:49:56.509992  589656 kubelet_pods.go:1972] "Orphaned pod found, removing pod cgroups" podUID=f602fc75-3d22-475f-8c0a-de933744ab4e
Sep 15 20:49:56 kind-worker3 kubelet[589656]: I0915 20:49:56.510072  589656 kubelet.go:2168] "SyncLoop (housekeeping) end"
Sep 15 20:49:56 kind-worker3 kubelet[589656]: I0915 20:49:56.524020  589656 manager.go:1044] Destroyed container: "/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-podf602fc75_3d22_475f_8c0a_de933744ab4e.slice" (aliases: [], namespace: "")
Sep 15 20:49:56 kind-worker3 kubelet[589656]: I0915 20:49:56.524071  589656 handler.go:325] Added event &{/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-podf602fc75_3d22_475f_8c0a_de933744ab4e.slice 2023-09-15 20:49:56.524060003 +0000 UTC m=+2146460.446885123 containerDeletion {<nil>}}
Sep 15 20:49:56 kind-worker3 kubelet[589656]: I0915 20:49:56.588554  589656 volume_manager.go:471] "All volumes are unmounted for pod" pod="default/nginx-deployment-66f58bff7c-7kkk5"
Sep 15 20:49:56 kind-worker3 kubelet[589656]: I0915 20:49:56.588628  589656 kubelet.go:1854] "Pod termination unmounted volumes" pod="default/nginx-deployment-66f58bff7c-7kkk5" podUID=f602fc75-3d22-475f-8c0a-de933744ab4e
Sep 15 20:49:56 kind-worker3 kubelet[589656]: I0915 20:49:56.589316  589656 reflector.go:225] Stopping reflector *v1.ConfigMap (0s) from object-"default"/"kube-root-ca.crt"
Sep 15 20:49:56 kind-worker3 kubelet[589656]: I0915 20:49:56.594407  589656 kubelet.go:1875] "Pod termination removed cgroups" pod="default/nginx-deployment-66f58bff7c-7kkk5" podUID=f602fc75-3d22-475f-8c0a-de933744ab4e
Sep 15 20:49:56 kind-worker3 kubelet[589656]: I0915 20:49:56.594646  589656 kubelet.go:1880] "Pod is terminated and will need no more status updates" pod="default/nginx-deployment-66f58bff7c-7kkk5" podUID=f602fc75-3d22-475f-8c0a-de933744ab4e
Sep 15 20:49:56 kind-worker3 kubelet[589656]: I0915 20:49:56.594704  589656 kubelet.go:1882] "syncTerminatedPod exit" pod="default/nginx-deployment-66f58bff7c-7kkk5" podUID=f602fc75-3d22-475f-8c0a-de933744ab4e
Sep 15 20:49:56 kind-worker3 kubelet[589656]: I0915 20:49:56.594747  589656 pod_workers.go:1105] "Pod is complete and the worker can now stop" pod="default/nginx-deployment-66f58bff7c-7kkk5" podUID=f602fc75-3d22-475f-8c0a-de933744ab4e
Sep 15 20:49:56 kind-worker3 kubelet[589656]: I0915 20:49:56.594808  589656 pod_workers.go:959] "Processing pod event done" pod="default/nginx-deployment-66f58bff7c-7kkk5" podUID=f602fc75-3d22-475f-8c0a-de933744ab4e updateType=2
Sep 15 20:49:56 kind-worker3 kubelet[589656]: I0915 20:49:56.638693  589656 status_manager.go:685] "Patch status for pod" pod="default/nginx-deployment-66f58bff7c-7kkk5" patch="{\"metadata\":{\"uid\":\"f602fc75-3d22-475f-8c0a-de933744ab4e\"}}"
Sep 15 20:49:56 kind-worker3 kubelet[589656]: I0915 20:49:56.638773  589656 status_manager.go:692] "Status for pod is up-to-date" pod="default/nginx-deployment-66f58bff7c-7kkk5" statusVersion=5
Sep 15 20:49:56 kind-worker3 kubelet[589656]: I0915 20:49:56.639157  589656 kubelet_pods.go:955] "Pod is terminated and all resources are reclaimed" pod="default/nginx-deployment-66f58bff7c-7kkk5"
Sep 15 20:49:56 kind-worker3 kubelet[589656]: I0915 20:49:56.663475  589656 config.go:279] "Setting pods for source" source="api"
Sep 15 20:49:56 kind-worker3 kubelet[589656]: I0915 20:49:56.663771  589656 kubelet.go:2088] "SyncLoop DELETE" source="api" pods=[default/nginx-deployment-66f58bff7c-7kkk5]
Sep 15 20:49:56 kind-worker3 kubelet[589656]: I0915 20:49:56.663860  589656 pod_workers.go:611] "Pod is finished processing, no further updates" pod="default/nginx-deployment-66f58bff7c-7kkk5" podUID=f602fc75-3d22-475f-8c0a-de933744ab4e
Sep 15 20:49:56 kind-worker3 kubelet[589656]: I0915 20:49:56.694202  589656 config.go:279] "Setting pods for source" source="api"
Sep 15 20:49:56 kind-worker3 kubelet[589656]: I0915 20:49:56.694231  589656 status_manager.go:713] "Pod fully terminated and removed from etcd" pod="default/nginx-deployment-66f58bff7c-7kkk5"
Sep 15 20:49:56 kind-worker3 kubelet[589656]: I0915 20:49:56.694480  589656 kubelet.go:2082] "SyncLoop REMOVE" source="api" pods=[default/nginx-deployment-66f58bff7c-7kkk5]
Sep 15 20:49:56 kind-worker3 kubelet[589656]: I0915 20:49:56.694561  589656 kubelet.go:1927] "Pod has been deleted and must be killed" pod="default/nginx-deployment-66f58bff7c-7kkk5" podUID=f602fc75-3d22-475f-8c0a-de933744ab4e
Sep 15 20:49:56 kind-worker3 kubelet[589656]: I0915 20:49:56.694657  589656 pod_workers.go:611] "Pod is finished processing, no further updates" pod="default/nginx-deployment-66f58bff7c-7kkk5" podUID=f602fc75-3d22-475f-8c0a-de933744ab4e
Sep 15 20:49:57 kind-worker3 kubelet[589656]: I0915 20:49:57.289270  589656 generic.go:155] "GenericPLEG" podUID=f602fc75-3d22-475f-8c0a-de933744ab4e containerID="5432e78771d09f84901cf4700d2078034e73119a187802ac085fa1e2e4829a62" oldState=exited newState=non-existent
Sep 15 20:49:57 kind-worker3 kubelet[589656]: I0915 20:49:57.289883  589656 kuberuntime_manager.go:1037] "getSandboxIDByPodUID got sandbox IDs for pod" podSandboxID=[b553881ecd35bacb71b6c14fb9ca775d38c625d547bf3c076902f1ed25c4d0c1] pod="default/nginx-deployment-66f58bff7c-7kkk5"
Sep 15 20:49:57 kind-worker3 kubelet[589656]: I0915 20:49:57.291004  589656 generic.go:421] "PLEG: Write status" pod="default/nginx-deployment-66f58bff7c-7kkk5"
Sep 15 20:49:57 kind-worker3 kubelet[589656]: I0915 20:49:57.715442  589656 handler.go:293] error while reading "/proc/589656/fd/38" link: readlink /proc/589656/fd/38: no such file or directory
Sep 15 20:49:58 kind-worker3 kubelet[589656]: I0915 20:49:58.498544  589656 kubelet.go:2160] "SyncLoop (housekeeping)"
Sep 15 20:49:58 kind-worker3 kubelet[589656]: I0915 20:49:58.506062  589656 kubelet_pods.go:1079] "Clean up pod workers for terminated pods"
Sep 15 20:49:58 kind-worker3 kubelet[589656]: I0915 20:49:58.506125  589656 pod_workers.go:1258] "Pod has been terminated and is no longer known to the kubelet, remove all history" podUID=f602fc75-3d22-475f-8c0a-de933744ab4e
Sep 15 20:49:58 kind-worker3 kubelet[589656]: I0915 20:49:58.506152  589656 kubelet_pods.go:1108] "Clean up probes for terminated pods"
Sep 15 20:49:58 kind-worker3 kubelet[589656]: I0915 20:49:58.508249  589656 kubelet_pods.go:1145] "Clean up orphaned pod statuses"
Sep 15 20:49:58 kind-worker3 kubelet[589656]: I0915 20:49:58.509604  589656 kubelet_pods.go:1164] "Clean up orphaned pod directories"
Sep 15 20:49:58 kind-worker3 kubelet[589656]: I0915 20:49:58.510295  589656 kubelet_volumes.go:160] "Cleaned up orphaned pod volumes dir" podUID=f602fc75-3d22-475f-8c0a-de933744ab4e path="/var/lib/kubelet/pods/f602fc75-3d22-475f-8c0a-de933744ab4e/volumes"
Sep 15 20:49:58 kind-worker3 kubelet[589656]: I0915 20:49:58.511203  589656 kubelet_volumes.go:236] "Orphaned pod found, removing" podUID=f602fc75-3d22-475f-8c0a-de933744ab4e
Sep 15 20:49:58 kind-worker3 kubelet[589656]: I0915 20:49:58.511319  589656 kubelet_pods.go:1175] "Clean up orphaned mirror pods"
Sep 15 20:49:58 kind-worker3 kubelet[589656]: I0915 20:49:58.511357  589656 kubelet_pods.go:1182] "Clean up orphaned pod cgroups"
Sep 15 20:49:58 kind-worker3 kubelet[589656]: I0915 20:49:58.511396  589656 kubelet.go:2168] "SyncLoop (housekeeping) end"
Sep 15 20:49:59 kind-worker3 kubelet[589656]: I0915 20:49:59.395243  589656 httplog.go:131] "HTTP" verb="GET" URI="/metrics/resource" latency="29.997398ms" userAgent="metrics-server/v0.6.3 (linux/amd64) kubernetes/a938798" audit-ID="" srcIP="172.18.0.3:35538" resp=200
Sep 15 20:49:59 kind-worker3 kubelet[589656]: I0915 20:49:59.979249  589656 kubelet.go:2346] "Container runtime status" status="Runtime Conditions: RuntimeReady=true reason: message:, NetworkReady=true reason: message:"
Sep 15 20:50:00 kind-worker3 kubelet[589656]: I0915 20:50:00.498317  589656 kubelet.go:2160] "SyncLoop (housekeeping)"
Sep 15 20:50:00 kind-worker3 kubelet[589656]: I0915 20:50:00.508956  589656 kubelet_pods.go:1079] "Clean up pod workers for terminated pods"
Sep 15 20:50:00 kind-worker3 kubelet[589656]: I0915 20:50:00.509015  589656 kubelet_pods.go:1108] "Clean up probes for terminated pods"
Sep 15 20:50:00 kind-worker3 kubelet[589656]: I0915 20:50:00.510951  589656 kubelet_pods.go:1145] "Clean up orphaned pod statuses"
Sep 15 20:50:00 kind-worker3 kubelet[589656]: I0915 20:50:00.512381  589656 kubelet_pods.go:1164] "Clean up orphaned pod directories"
Sep 15 20:50:00 kind-worker3 kubelet[589656]: I0915 20:50:00.512539  589656 kubelet_pods.go:1175] "Clean up orphaned mirror pods"
Sep 15 20:50:00 kind-worker3 kubelet[589656]: I0915 20:50:00.512569  589656 kubelet_pods.go:1182] "Clean up orphaned pod cgroups"
Sep 15 20:50:00 kind-worker3 kubelet[589656]: I0915 20:50:00.512598  589656 kubelet.go:2168] "SyncLoop (housekeeping) end"
Sep 15 20:50:01 kind-worker3 kubelet[589656]: I0915 20:50:01.244313  589656 handler.go:124] Unable to get network stats from pid 980178: couldn't read network stats: failure opening /proc/980178/net/dev: open /proc/980178/net/dev: no such file or directory
Sep 15 20:50:01 kind-worker3 kubelet[589656]: I0915 20:50:01.244416  589656 handler.go:179] Unable to get Process Stats: couldn't open cpu cgroup procs file /sys/fs/cgroup/cpu,cpuacct/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-podf602fc75_3d22_475f_8c0a_de933744ab4e.slice/cri-containerd-b553881ecd35bacb71b6c14fb9ca775d38c625d547bf3c076902f1ed25c4d0c1.scope/cgroup.procs : open /sys/fs/cgroup/cpu,cpuacct/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-podf602fc75_3d22_475f_8c0a_de933744ab4e.slice/cri-containerd-b553881ecd35bacb71b6c14fb9ca775d38c625d547bf3c076902f1ed25c4d0c1.scope/cgroup.procs: no such file or directory
Sep 15 20:50:02 kind-worker3 kubelet[589656]: I0915 20:50:02.497725  589656 kubelet.go:2160] "SyncLoop (housekeeping)"
Sep 15 20:50:02 kind-worker3 kubelet[589656]: I0915 20:50:02.506856  589656 kubelet_pods.go:1079] "Clean up pod workers for terminated pods"
Sep 15 20:50:02 kind-worker3 kubelet[589656]: I0915 20:50:02.506921  589656 kubelet_pods.go:1108] "Clean up probes for terminated pods"
Sep 15 20:50:02 kind-worker3 kubelet[589656]: I0915 20:50:02.506960  589656 kubelet_pods.go:1145] "Clean up orphaned pod statuses"
Sep 15 20:50:02 kind-worker3 kubelet[589656]: I0915 20:50:02.508494  589656 kubelet_pods.go:1164] "Clean up orphaned pod directories"
Sep 15 20:50:02 kind-worker3 kubelet[589656]: I0915 20:50:02.508680  589656 kubelet_pods.go:1175] "Clean up orphaned mirror pods"
Sep 15 20:50:02 kind-worker3 kubelet[589656]: I0915 20:50:02.508729  589656 kubelet_pods.go:1182] "Clean up orphaned pod cgroups"
Sep 15 20:50:02 kind-worker3 kubelet[589656]: I0915 20:50:02.508784  589656 kubelet.go:2168] "SyncLoop (housekeeping) end"
Sep 15 20:50:03 kind-worker3 kubelet[589656]: I0915 20:50:03.175888  589656 setters.go:88] "Using node IP" IP="172.18.0.4"
Sep 15 20:50:03 kind-worker3 kubelet[589656]: I0915 20:50:03.904898  589656 config.go:279] "Setting pods for source" source="api"
Sep 15 20:50:03 kind-worker3 kubelet[589656]: I0915 20:50:03.905225  589656 config.go:384] "Receiving a new pod" pod="default/nginx-deployment-66f58bff7c-nbvst"
Sep 15 20:50:03 kind-worker3 kubelet[589656]: I0915 20:50:03.905594  589656 kubelet.go:2072] "SyncLoop ADD" source="api" pods=[default/nginx-deployment-66f58bff7c-nbvst]
Sep 15 20:50:03 kind-worker3 kubelet[589656]: I0915 20:50:03.905717  589656 topology_manager.go:200] "Topology Admit Handler"
Sep 15 20:50:03 kind-worker3 kubelet[589656]: I0915 20:50:03.905832  589656 manager.go:914] "Looking for needed resources" needed=1 resourceName="cpu"
Sep 15 20:50:03 kind-worker3 kubelet[589656]: E0915 20:50:03.906008  589656 cpu_manager.go:394] "RemoveStaleState: removing container" podUID="f602fc75-3d22-475f-8c0a-de933744ab4e" containerName="nginx"
Sep 15 20:50:03 kind-worker3 kubelet[589656]: I0915 20:50:03.906051  589656 state_mem.go:107] "Deleted CPUSet assignment" podUID="f602fc75-3d22-475f-8c0a-de933744ab4e" containerName="nginx"
Sep 15 20:50:03 kind-worker3 kubelet[589656]: I0915 20:50:03.906219  589656 memory_manager.go:345] "RemoveStaleState removing state" podUID="f602fc75-3d22-475f-8c0a-de933744ab4e" containerName="nginx"
Sep 15 20:50:03 kind-worker3 kubelet[589656]: I0915 20:50:03.906535  589656 pod_workers.go:571] "Pod is being synced for the first time" pod="default/nginx-deployment-66f58bff7c-nbvst" podUID=bf0ad039-0154-4821-ac30-f54e4366ba44
Sep 15 20:50:03 kind-worker3 kubelet[589656]: I0915 20:50:03.906900  589656 pod_workers.go:888] "Processing pod event" pod="default/nginx-deployment-66f58bff7c-nbvst" podUID=bf0ad039-0154-4821-ac30-f54e4366ba44 updateType=0
Sep 15 20:50:03 kind-worker3 kubelet[589656]: I0915 20:50:03.907032  589656 kubelet.go:1501] "syncPod enter" pod="default/nginx-deployment-66f58bff7c-nbvst" podUID=bf0ad039-0154-4821-ac30-f54e4366ba44
Sep 15 20:50:03 kind-worker3 kubelet[589656]: I0915 20:50:03.907139  589656 kubelet_pods.go:1432] "Generating pod status" pod="default/nginx-deployment-66f58bff7c-nbvst"
Sep 15 20:50:03 kind-worker3 kubelet[589656]: I0915 20:50:03.907412  589656 kubelet_pods.go:1444] "Got phase for pod" pod="default/nginx-deployment-66f58bff7c-nbvst" oldPhase=Pending phase=Pending
Sep 15 20:50:03 kind-worker3 kubelet[589656]: I0915 20:50:03.907905  589656 reflector.go:219] Starting reflector *v1.ConfigMap (0s) from object-"default"/"kube-root-ca.crt"
Sep 15 20:50:03 kind-worker3 kubelet[589656]: I0915 20:50:03.907943  589656 reflector.go:255] Listing and watching *v1.ConfigMap from object-"default"/"kube-root-ca.crt"
Sep 15 20:50:03 kind-worker3 kubelet[589656]: I0915 20:50:03.919529  589656 qos_container_manager_linux.go:379] "Updated QoS cgroup configuration"
Sep 15 20:50:03 kind-worker3 kubelet[589656]: I0915 20:50:03.926429  589656 factory.go:262] Factory "containerd" was unable to handle container "/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-podbf0ad039_0154_4821_ac30_f54e4366ba44.slice"
Sep 15 20:50:03 kind-worker3 kubelet[589656]: I0915 20:50:03.926494  589656 factory.go:262] Factory "systemd" was unable to handle container "/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-podbf0ad039_0154_4821_ac30_f54e4366ba44.slice"
Sep 15 20:50:03 kind-worker3 kubelet[589656]: I0915 20:50:03.926535  589656 factory.go:258] Using factory "raw" for container "/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-podbf0ad039_0154_4821_ac30_f54e4366ba44.slice"
Sep 15 20:50:03 kind-worker3 kubelet[589656]: I0915 20:50:03.927823  589656 manager.go:988] Added container: "/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-podbf0ad039_0154_4821_ac30_f54e4366ba44.slice" (aliases: [], namespace: "")
Sep 15 20:50:03 kind-worker3 kubelet[589656]: I0915 20:50:03.928540  589656 handler.go:325] Added event &{/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-podbf0ad039_0154_4821_ac30_f54e4366ba44.slice 2023-09-15 20:50:03.922331564 +0000 UTC containerCreation {<nil>}}
Sep 15 20:50:03 kind-worker3 kubelet[589656]: I0915 20:50:03.928626  589656 container.go:530] Start housekeeping for container "/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-podbf0ad039_0154_4821_ac30_f54e4366ba44.slice"
Sep 15 20:50:03 kind-worker3 kubelet[589656]: I0915 20:50:03.930584  589656 desired_state_of_world_populator.go:309] "Added volume to desired state" pod="default/nginx-deployment-66f58bff7c-nbvst" volumeName="kube-api-access-95zbj" volumeSpecName="kube-api-access-95zbj"
Sep 15 20:50:03 kind-worker3 kubelet[589656]: I0915 20:50:03.932829  589656 volume_manager.go:404] "Waiting for volumes to attach and mount for pod" pod="default/nginx-deployment-66f58bff7c-nbvst"
Sep 15 20:50:03 kind-worker3 kubelet[589656]: I0915 20:50:03.974965  589656 reconciler.go:342] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-95zbj\" (UniqueName: \"kubernetes.io/projected/bf0ad039-0154-4821-ac30-f54e4366ba44-kube-api-access-95zbj\") pod \"nginx-deployment-66f58bff7c-nbvst\" (UID: \"bf0ad039-0154-4821-ac30-f54e4366ba44\") " pod="default/nginx-deployment-66f58bff7c-nbvst"
Sep 15 20:50:04 kind-worker3 kubelet[589656]: I0915 20:50:04.031313  589656 desired_state_of_world_populator.go:309] "Added volume to desired state" pod="default/nginx-deployment-66f58bff7c-nbvst" volumeName="kube-api-access-95zbj" volumeSpecName="kube-api-access-95zbj"
Sep 15 20:50:04 kind-worker3 kubelet[589656]: I0915 20:50:04.038657  589656 config.go:279] "Setting pods for source" source="api"
Sep 15 20:50:04 kind-worker3 kubelet[589656]: I0915 20:50:04.038958  589656 kubelet.go:2085] "SyncLoop RECONCILE" source="api" pods=[default/nginx-deployment-66f58bff7c-nbvst]
Sep 15 20:50:04 kind-worker3 kubelet[589656]: I0915 20:50:04.040461  589656 status_manager.go:685] "Patch status for pod" pod="default/nginx-deployment-66f58bff7c-nbvst" patch="{\"metadata\":{\"uid\":\"bf0ad039-0154-4821-ac30-f54e4366ba44\"},\"status\":{\"$setElementOrder/conditions\":[{\"type\":\"Initialized\"},{\"type\":\"Ready\"},{\"type\":\"ContainersReady\"},{\"type\":\"PodScheduled\"}],\"conditions\":[{\"lastProbeTime\":null,\"lastTransitionTime\":\"2023-09-15T20:50:03Z\",\"status\":\"True\",\"type\":\"Initialized\"},{\"lastProbeTime\":null,\"lastTransitionTime\":\"2023-09-15T20:50:03Z\",\"message\":\"containers with unready status: [nginx]\",\"reason\":\"ContainersNotReady\",\"status\":\"False\",\"type\":\"Ready\"},{\"lastProbeTime\":null,\"lastTransitionTime\":\"2023-09-15T20:50:03Z\",\"message\":\"containers with unready status: [nginx]\",\"reason\":\"ContainersNotReady\",\"status\":\"False\",\"type\":\"ContainersReady\"}],\"containerStatuses\":[{\"image\":\"nginx:1.14.2\",\"imageID\":\"\",\"lastState\":{},\"name\":\"nginx\",\"ready\":false,\"restartCount\":0,\"started\":false,\"state\":{\"waiting\":{\"reason\":\"ContainerCreating\"}}}],\"hostIP\":\"172.18.0.4\",\"startTime\":\"2023-09-15T20:50:03Z\"}}"
Sep 15 20:50:04 kind-worker3 kubelet[589656]: I0915 20:50:04.040579  589656 status_manager.go:694] "Status for pod updated successfully" pod="default/nginx-deployment-66f58bff7c-nbvst" statusVersion=1 status={Phase:Pending Conditions:[{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-09-15 20:50:03 +0000 UTC Reason: Message:} {Type:Ready Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-09-15 20:50:03 +0000 UTC Reason:ContainersNotReady Message:containers with unready status: [nginx]} {Type:ContainersReady Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-09-15 20:50:03 +0000 UTC Reason:ContainersNotReady Message:containers with unready status: [nginx]} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-09-15 20:50:03 +0000 UTC Reason: Message:}] Message: Reason: NominatedNodeName: HostIP:172.18.0.4 PodIP: PodIPs:[] StartTime:2023-09-15 20:50:03 +0000 UTC InitContainerStatuses:[] ContainerStatuses:[{Name:nginx State:{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,} Running:nil Terminated:nil} LastTerminationState:{Waiting:nil Running:nil Terminated:nil} Ready:false RestartCount:0 Image:nginx:1.14.2 ImageID: ContainerID: Started:0xc0019056ac}] QOSClass:Burstable EphemeralContainerStatuses:[]}
Sep 15 20:50:04 kind-worker3 kubelet[589656]: I0915 20:50:04.075671  589656 reconciler.go:243] "Starting operationExecutor.MountVolume for volume \"kube-api-access-95zbj\" (UniqueName: \"kubernetes.io/projected/bf0ad039-0154-4821-ac30-f54e4366ba44-kube-api-access-95zbj\") pod \"nginx-deployment-66f58bff7c-nbvst\" (UID: \"bf0ad039-0154-4821-ac30-f54e4366ba44\") " pod="default/nginx-deployment-66f58bff7c-nbvst"
Sep 15 20:50:04 kind-worker3 kubelet[589656]: I0915 20:50:04.075802  589656 reconciler.go:254] "operationExecutor.MountVolume started for volume \"kube-api-access-95zbj\" (UniqueName: \"kubernetes.io/projected/bf0ad039-0154-4821-ac30-f54e4366ba44-kube-api-access-95zbj\") pod \"nginx-deployment-66f58bff7c-nbvst\" (UID: \"bf0ad039-0154-4821-ac30-f54e4366ba44\") " pod="default/nginx-deployment-66f58bff7c-nbvst"
Sep 15 20:50:04 kind-worker3 kubelet[589656]: I0915 20:50:04.075917  589656 projected.go:183] Setting up volume kube-api-access-95zbj for pod bf0ad039-0154-4821-ac30-f54e4366ba44 at /var/lib/kubelet/pods/bf0ad039-0154-4821-ac30-f54e4366ba44/volumes/kubernetes.io~projected/kube-api-access-95zbj
Sep 15 20:50:04 kind-worker3 kubelet[589656]: I0915 20:50:04.107734  589656 empty_dir_linux.go:99] Statfs_t of /var/lib/kubelet/pods/bf0ad039-0154-4821-ac30-f54e4366ba44/volumes/kubernetes.io~projected/kube-api-access-95zbj: {Type:61267 Bsize:4096 Blocks:12835448 Bfree:2601384 Bavail:1941954 Files:3276800 Ffree:2345696 Fsid:{Val:[-2136087178 982747248]} Namelen:255 Frsize:4096 Flags:4128 Spare:[0 0 0 0]}
Sep 15 20:50:04 kind-worker3 kubelet[589656]: I0915 20:50:04.107826  589656 empty_dir.go:334] pod bf0ad039-0154-4821-ac30-f54e4366ba44: mounting tmpfs for volume wrapped_kube-api-access-95zbj
Sep 15 20:50:04 kind-worker3 kubelet[589656]: I0915 20:50:04.107879  589656 mount_linux.go:183] Mounting cmd (mount) with arguments (-t tmpfs -o size=8362762240 tmpfs /var/lib/kubelet/pods/bf0ad039-0154-4821-ac30-f54e4366ba44/volumes/kubernetes.io~projected/kube-api-access-95zbj)
Sep 15 20:50:04 kind-worker3 kubelet[589656]: I0915 20:50:04.113928  589656 atomic_writer.go:181] pod default/nginx-deployment-66f58bff7c-nbvst volume kube-api-access-95zbj: performed write of new data to ts data directory: /var/lib/kubelet/pods/bf0ad039-0154-4821-ac30-f54e4366ba44/volumes/kubernetes.io~projected/kube-api-access-95zbj/..2023_09_15_20_50_04.933677534
Sep 15 20:50:04 kind-worker3 kubelet[589656]: I0915 20:50:04.114242  589656 operation_generator.go:703] "MountVolume.SetUp succeeded for volume \"kube-api-access-95zbj\" (UniqueName: \"kubernetes.io/projected/bf0ad039-0154-4821-ac30-f54e4366ba44-kube-api-access-95zbj\") pod \"nginx-deployment-66f58bff7c-nbvst\" (UID: \"bf0ad039-0154-4821-ac30-f54e4366ba44\") " pod="default/nginx-deployment-66f58bff7c-nbvst"
Sep 15 20:50:04 kind-worker3 kubelet[589656]: I0915 20:50:04.233388  589656 volume_manager.go:435] "All volumes are attached and mounted for pod" pod="default/nginx-deployment-66f58bff7c-nbvst"
Sep 15 20:50:04 kind-worker3 kubelet[589656]: I0915 20:50:04.233475  589656 kuberuntime_manager.go:469] "No sandbox for pod can be found. Need to start a new one" pod="default/nginx-deployment-66f58bff7c-nbvst"
Sep 15 20:50:04 kind-worker3 kubelet[589656]: I0915 20:50:04.233531  589656 kuberuntime_manager.go:714] "computePodActions got for pod" podActions={KillPod:true CreateSandbox:true SandboxID: Attempt:0 NextInitContainerToStart:nil ContainersToStart:[0] ContainersToKill:map[] EphemeralContainersToStart:[]} pod="default/nginx-deployment-66f58bff7c-nbvst"
Sep 15 20:50:04 kind-worker3 kubelet[589656]: I0915 20:50:04.233573  589656 kuberuntime_manager.go:723] "SyncPod received new pod, will create a sandbox for it" pod="default/nginx-deployment-66f58bff7c-nbvst"
Sep 15 20:50:04 kind-worker3 kubelet[589656]: I0915 20:50:04.233609  589656 kuberuntime_manager.go:730] "Stopping PodSandbox for pod, will start new one" pod="default/nginx-deployment-66f58bff7c-nbvst"
Sep 15 20:50:04 kind-worker3 kubelet[589656]: I0915 20:50:04.233645  589656 kuberuntime_manager.go:785] "Creating PodSandbox for pod" pod="default/nginx-deployment-66f58bff7c-nbvst"
Sep 15 20:50:04 kind-worker3 kubelet[589656]: I0915 20:50:04.376398  589656 eviction_manager.go:237] "Eviction manager: synchronize housekeeping"
Sep 15 20:50:04 kind-worker3 kubelet[589656]: I0915 20:50:04.399679  589656 cri_stats_provider.go:525] "Unable to find network stats for sandbox" sandboxID="b477a0e3bdd1b445ce34dc6f173590a56dbfec252950ee838d5af2a2515a773b"
Sep 15 20:50:04 kind-worker3 kubelet[589656]: I0915 20:50:04.400109  589656 cri_stats_provider.go:525] "Unable to find network stats for sandbox" sandboxID="d0f4d02598fe0e9a32081b1554ae85df2b4224eb9a378fdcf99aa7c0035d33dc"
Sep 15 20:50:04 kind-worker3 kubelet[589656]: I0915 20:50:04.406306  589656 helpers.go:775] "Eviction manager:" log="observations" signal=nodefs.available resourceName="7767436Ki" capacity="51341792Ki" time="2023-09-15 20:50:04.378427501 +0000 UTC m=+2146468.301252678"
Sep 15 20:50:04 kind-worker3 kubelet[589656]: I0915 20:50:04.406360  589656 helpers.go:775] "Eviction manager:" log="observations" signal=nodefs.inodesFree resourceName="2345683" capacity="3276800" time="2023-09-15 20:50:04.378427501 +0000 UTC m=+2146468.301252678"
Sep 15 20:50:04 kind-worker3 kubelet[589656]: I0915 20:50:04.406389  589656 helpers.go:775] "Eviction manager:" log="observations" signal=imagefs.available resourceName="7767436Ki" capacity="51341792Ki" time="2023-09-15 20:49:58.904376237 +0000 UTC"
Sep 15 20:50:04 kind-worker3 kubelet[589656]: I0915 20:50:04.406415  589656 helpers.go:775] "Eviction manager:" log="observations" signal=imagefs.inodesFree resourceName="2345683" capacity="3276800" time="2023-09-15 20:49:58.904376237 +0000 UTC"
Sep 15 20:50:04 kind-worker3 kubelet[589656]: I0915 20:50:04.406440  589656 helpers.go:775] "Eviction manager:" log="observations" signal=pid.available resourceName="62218" capacity="63272" time="2023-09-15 20:50:04.401091501 +0000 UTC m=+2146468.323916645"
Sep 15 20:50:04 kind-worker3 kubelet[589656]: I0915 20:50:04.406470  589656 helpers.go:775] "Eviction manager:" log="observations" signal=memory.available resourceName="7900204Ki" capacity="8166760Ki" time="2023-09-15 20:50:04.378427501 +0000 UTC m=+2146468.301252678"
Sep 15 20:50:04 kind-worker3 kubelet[589656]: I0915 20:50:04.406496  589656 helpers.go:775] "Eviction manager:" log="observations" signal=allocatableMemory.available resourceName="8110372Ki" capacity="8166760Ki" time="2023-09-15 20:50:04.406057469 +0000 UTC m=+2146468.328882629"
Sep 15 20:50:04 kind-worker3 kubelet[589656]: I0915 20:50:04.406558  589656 eviction_manager.go:328] "Eviction manager: no resources are starved"
Sep 15 20:50:04 kind-worker3 kubelet[589656]: I0915 20:50:04.497805  589656 kubelet.go:2160] "SyncLoop (housekeeping)"
Sep 15 20:50:04 kind-worker3 kubelet[589656]: I0915 20:50:04.505622  589656 kubelet_pods.go:1079] "Clean up pod workers for terminated pods"
Sep 15 20:50:04 kind-worker3 kubelet[589656]: I0915 20:50:04.505680  589656 kubelet_pods.go:1108] "Clean up probes for terminated pods"
Sep 15 20:50:04 kind-worker3 kubelet[589656]: I0915 20:50:04.507510  589656 kubelet_pods.go:1145] "Clean up orphaned pod statuses"
Sep 15 20:50:04 kind-worker3 kubelet[589656]: I0915 20:50:04.508988  589656 kubelet_pods.go:1164] "Clean up orphaned pod directories"
Sep 15 20:50:04 kind-worker3 kubelet[589656]: I0915 20:50:04.509243  589656 kubelet_pods.go:1175] "Clean up orphaned mirror pods"
Sep 15 20:50:04 kind-worker3 kubelet[589656]: I0915 20:50:04.509281  589656 kubelet_pods.go:1182] "Clean up orphaned pod cgroups"
Sep 15 20:50:04 kind-worker3 kubelet[589656]: I0915 20:50:04.509316  589656 kubelet.go:2168] "SyncLoop (housekeeping) end"
Sep 15 20:50:04 kind-worker3 kubelet[589656]: I0915 20:50:04.980412  589656 kubelet.go:2346] "Container runtime status" status="Runtime Conditions: RuntimeReady=true reason: message:, NetworkReady=true reason: message:"
Sep 15 20:50:05 kind-worker3 kubelet[589656]: I0915 20:50:05.192903  589656 factory.go:258] Using factory "containerd" for container "/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-podbf0ad039_0154_4821_ac30_f54e4366ba44.slice/cri-containerd-83b4ac624e9b1f62481346831f7105bdc5f161d3f48256bad09a5f08986e6a98.scope"
Sep 15 20:50:05 kind-worker3 kubelet[589656]: I0915 20:50:05.387577  589656 manager.go:988] Added container: "/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-podbf0ad039_0154_4821_ac30_f54e4366ba44.slice/cri-containerd-83b4ac624e9b1f62481346831f7105bdc5f161d3f48256bad09a5f08986e6a98.scope" (aliases: [83b4ac624e9b1f62481346831f7105bdc5f161d3f48256bad09a5f08986e6a98 /kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-podbf0ad039_0154_4821_ac30_f54e4366ba44.slice/cri-containerd-83b4ac624e9b1f62481346831f7105bdc5f161d3f48256bad09a5f08986e6a98.scope], namespace: "containerd")
Sep 15 20:50:05 kind-worker3 kubelet[589656]: I0915 20:50:05.388642  589656 handler.go:325] Added event &{/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-podbf0ad039_0154_4821_ac30_f54e4366ba44.slice/cri-containerd-83b4ac624e9b1f62481346831f7105bdc5f161d3f48256bad09a5f08986e6a98.scope 2023-09-15 20:50:05.186323871 +0000 UTC containerCreation {<nil>}}
Sep 15 20:50:05 kind-worker3 kubelet[589656]: I0915 20:50:05.388760  589656 container.go:530] Start housekeeping for container "/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-podbf0ad039_0154_4821_ac30_f54e4366ba44.slice/cri-containerd-83b4ac624e9b1f62481346831f7105bdc5f161d3f48256bad09a5f08986e6a98.scope"
Sep 15 20:50:05 kind-worker3 kubelet[589656]: I0915 20:50:05.431277  589656 kuberuntime_manager.go:823] "Created PodSandbox for pod" podSandboxID="83b4ac624e9b1f62481346831f7105bdc5f161d3f48256bad09a5f08986e6a98" pod="default/nginx-deployment-66f58bff7c-nbvst"
Sep 15 20:50:05 kind-worker3 kubelet[589656]: I0915 20:50:05.432440  589656 kuberuntime_manager.go:846] "Determined the ip for pod after sandbox changed" IPs=[10.244.3.72] pod="default/nginx-deployment-66f58bff7c-nbvst"
Sep 15 20:50:05 kind-worker3 kubelet[589656]: I0915 20:50:05.432686  589656 kuberuntime_manager.go:889] "Creating container in pod" containerType="container" container="&Container{Name:nginx,Image:nginx:1.14.2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{ContainerPort{Name:,HostPort:0,ContainerPort:80,Protocol:TCP,HostIP:,},},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{cpu: {{500 -3} {<nil>} 500m DecimalSI},},Requests:ResourceList{cpu: {{200 -3} {<nil>} 200m DecimalSI},},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-95zbj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,}" pod="default/nginx-deployment-66f58bff7c-nbvst"
Sep 15 20:50:05 kind-worker3 kubelet[589656]: I0915 20:50:05.434047  589656 kubelet_pods.go:161] "Creating hosts mount for container" pod="default/nginx-deployment-66f58bff7c-nbvst" containerName="nginx" podIPs=[10.244.3.72] path=true
Sep 15 20:50:05 kind-worker3 kubelet[589656]: I0915 20:50:05.434355  589656 event.go:294] "Event occurred" object="default/nginx-deployment-66f58bff7c-nbvst" fieldPath="spec.containers{nginx}" kind="Pod" apiVersion="v1" type="Normal" reason="Pulled" message="Container image \"nginx:1.14.2\" already present on machine"
Sep 15 20:50:06 kind-worker3 kubelet[589656]: I0915 20:50:06.078791  589656 event.go:294] "Event occurred" object="default/nginx-deployment-66f58bff7c-nbvst" fieldPath="spec.containers{nginx}" kind="Pod" apiVersion="v1" type="Normal" reason="Created" message="Created container nginx"
Sep 15 20:50:06 kind-worker3 kubelet[589656]: I0915 20:50:06.164453  589656 factory.go:258] Using factory "containerd" for container "/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-podbf0ad039_0154_4821_ac30_f54e4366ba44.slice/cri-containerd-44ca9b8d7d34d1d46a7dc77e9f5257d12c4f6d1670c45041be6079b15affd771.scope"
Sep 15 20:50:06 kind-worker3 kubelet[589656]: I0915 20:50:06.316480  589656 generic.go:155] "GenericPLEG" podUID=bf0ad039-0154-4821-ac30-f54e4366ba44 containerID="44ca9b8d7d34d1d46a7dc77e9f5257d12c4f6d1670c45041be6079b15affd771" oldState=non-existent newState=unknown
Sep 15 20:50:06 kind-worker3 kubelet[589656]: I0915 20:50:06.316550  589656 generic.go:155] "GenericPLEG" podUID=bf0ad039-0154-4821-ac30-f54e4366ba44 containerID="83b4ac624e9b1f62481346831f7105bdc5f161d3f48256bad09a5f08986e6a98" oldState=non-existent newState=running
Sep 15 20:50:06 kind-worker3 kubelet[589656]: I0915 20:50:06.317254  589656 kuberuntime_manager.go:1037] "getSandboxIDByPodUID got sandbox IDs for pod" podSandboxID=[83b4ac624e9b1f62481346831f7105bdc5f161d3f48256bad09a5f08986e6a98] pod="default/nginx-deployment-66f58bff7c-nbvst"
Sep 15 20:50:06 kind-worker3 kubelet[589656]: I0915 20:50:06.328259  589656 generic.go:421] "PLEG: Write status" pod="default/nginx-deployment-66f58bff7c-nbvst"
Sep 15 20:50:06 kind-worker3 kubelet[589656]: I0915 20:50:06.328654  589656 kubelet.go:2110] "SyncLoop (PLEG): event for pod" pod="default/nginx-deployment-66f58bff7c-nbvst" event=&{ID:bf0ad039-0154-4821-ac30-f54e4366ba44 Type:ContainerStarted Data:83b4ac624e9b1f62481346831f7105bdc5f161d3f48256bad09a5f08986e6a98}
Sep 15 20:50:06 kind-worker3 kubelet[589656]: I0915 20:50:06.454264  589656 manager.go:988] Added container: "/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-podbf0ad039_0154_4821_ac30_f54e4366ba44.slice/cri-containerd-44ca9b8d7d34d1d46a7dc77e9f5257d12c4f6d1670c45041be6079b15affd771.scope" (aliases: [44ca9b8d7d34d1d46a7dc77e9f5257d12c4f6d1670c45041be6079b15affd771 /kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-podbf0ad039_0154_4821_ac30_f54e4366ba44.slice/cri-containerd-44ca9b8d7d34d1d46a7dc77e9f5257d12c4f6d1670c45041be6079b15affd771.scope], namespace: "containerd")
Sep 15 20:50:06 kind-worker3 kubelet[589656]: I0915 20:50:06.455212  589656 handler.go:325] Added event &{/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-podbf0ad039_0154_4821_ac30_f54e4366ba44.slice/cri-containerd-44ca9b8d7d34d1d46a7dc77e9f5257d12c4f6d1670c45041be6079b15affd771.scope 2023-09-15 20:50:06.158317956 +0000 UTC containerCreation {<nil>}}
Sep 15 20:50:06 kind-worker3 kubelet[589656]: I0915 20:50:06.455333  589656 container.go:530] Start housekeeping for container "/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-podbf0ad039_0154_4821_ac30_f54e4366ba44.slice/cri-containerd-44ca9b8d7d34d1d46a7dc77e9f5257d12c4f6d1670c45041be6079b15affd771.scope"
Sep 15 20:50:06 kind-worker3 kubelet[589656]: I0915 20:50:06.498558  589656 kubelet.go:2160] "SyncLoop (housekeeping)"
Sep 15 20:50:06 kind-worker3 kubelet[589656]: I0915 20:50:06.513105  589656 kubelet_pods.go:1079] "Clean up pod workers for terminated pods"
Sep 15 20:50:06 kind-worker3 kubelet[589656]: I0915 20:50:06.513175  589656 kubelet_pods.go:1108] "Clean up probes for terminated pods"
Sep 15 20:50:06 kind-worker3 kubelet[589656]: I0915 20:50:06.514909  589656 kubelet.go:1503] "syncPod exit" pod="default/nginx-deployment-66f58bff7c-nbvst" podUID=bf0ad039-0154-4821-ac30-f54e4366ba44 isTerminal=false
Sep 15 20:50:06 kind-worker3 kubelet[589656]: I0915 20:50:06.515191  589656 pod_workers.go:988] "Processing pod event done" pod="default/nginx-deployment-66f58bff7c-nbvst" podUID=bf0ad039-0154-4821-ac30-f54e4366ba44 updateType=0
Sep 15 20:50:06 kind-worker3 kubelet[589656]: I0915 20:50:06.515357  589656 pod_workers.go:888] "Processing pod event" pod="default/nginx-deployment-66f58bff7c-nbvst" podUID=bf0ad039-0154-4821-ac30-f54e4366ba44 updateType=0
Sep 15 20:50:06 kind-worker3 kubelet[589656]: I0915 20:50:06.515539  589656 event.go:294] "Event occurred" object="default/nginx-deployment-66f58bff7c-nbvst" fieldPath="spec.containers{nginx}" kind="Pod" apiVersion="v1" type="Normal" reason="Started" message="Started container nginx"
Sep 15 20:50:06 kind-worker3 kubelet[589656]: I0915 20:50:06.517524  589656 kubelet_pods.go:1145] "Clean up orphaned pod statuses"
Sep 15 20:50:06 kind-worker3 kubelet[589656]: I0915 20:50:06.522704  589656 kubelet_pods.go:1164] "Clean up orphaned pod directories"
Sep 15 20:50:06 kind-worker3 kubelet[589656]: I0915 20:50:06.523072  589656 kubelet_pods.go:1175] "Clean up orphaned mirror pods"
Sep 15 20:50:06 kind-worker3 kubelet[589656]: I0915 20:50:06.523251  589656 kubelet_pods.go:1182] "Clean up orphaned pod cgroups"
Sep 15 20:50:06 kind-worker3 kubelet[589656]: I0915 20:50:06.523523  589656 kubelet.go:2168] "SyncLoop (housekeeping) end"
Sep 15 20:50:07 kind-worker3 kubelet[589656]: I0915 20:50:07.334928  589656 generic.go:155] "GenericPLEG" podUID=bf0ad039-0154-4821-ac30-f54e4366ba44 containerID="44ca9b8d7d34d1d46a7dc77e9f5257d12c4f6d1670c45041be6079b15affd771" oldState=unknown newState=running
Sep 15 20:50:07 kind-worker3 kubelet[589656]: I0915 20:50:07.336152  589656 kuberuntime_manager.go:1037] "getSandboxIDByPodUID got sandbox IDs for pod" podSandboxID=[83b4ac624e9b1f62481346831f7105bdc5f161d3f48256bad09a5f08986e6a98] pod="default/nginx-deployment-66f58bff7c-nbvst"
Sep 15 20:50:07 kind-worker3 kubelet[589656]: I0915 20:50:07.338148  589656 generic.go:421] "PLEG: Write status" pod="default/nginx-deployment-66f58bff7c-nbvst"
Sep 15 20:50:07 kind-worker3 kubelet[589656]: I0915 20:50:07.338229  589656 kubelet.go:2110] "SyncLoop (PLEG): event for pod" pod="default/nginx-deployment-66f58bff7c-nbvst" event=&{ID:bf0ad039-0154-4821-ac30-f54e4366ba44 Type:ContainerStarted Data:44ca9b8d7d34d1d46a7dc77e9f5257d12c4f6d1670c45041be6079b15affd771}
Sep 15 20:50:07 kind-worker3 kubelet[589656]: I0915 20:50:07.338284  589656 kubelet.go:1501] "syncPod enter" pod="default/nginx-deployment-66f58bff7c-nbvst" podUID=bf0ad039-0154-4821-ac30-f54e4366ba44
Sep 15 20:50:07 kind-worker3 kubelet[589656]: I0915 20:50:07.338350  589656 kubelet_pods.go:1432] "Generating pod status" pod="default/nginx-deployment-66f58bff7c-nbvst"
Sep 15 20:50:07 kind-worker3 kubelet[589656]: I0915 20:50:07.338407  589656 kubelet_pods.go:1444] "Got phase for pod" pod="default/nginx-deployment-66f58bff7c-nbvst" oldPhase=Pending phase=Running
Sep 15 20:50:07 kind-worker3 kubelet[589656]: I0915 20:50:07.338932  589656 volume_manager.go:404] "Waiting for volumes to attach and mount for pod" pod="default/nginx-deployment-66f58bff7c-nbvst"
Sep 15 20:50:07 kind-worker3 kubelet[589656]: I0915 20:50:07.338985  589656 volume_manager.go:435] "All volumes are attached and mounted for pod" pod="default/nginx-deployment-66f58bff7c-nbvst"
Sep 15 20:50:07 kind-worker3 kubelet[589656]: I0915 20:50:07.339144  589656 kuberuntime_manager.go:714] "computePodActions got for pod" podActions={KillPod:false CreateSandbox:false SandboxID:83b4ac624e9b1f62481346831f7105bdc5f161d3f48256bad09a5f08986e6a98 Attempt:0 NextInitContainerToStart:nil ContainersToStart:[] ContainersToKill:map[] EphemeralContainersToStart:[]} pod="default/nginx-deployment-66f58bff7c-nbvst"
Sep 15 20:50:07 kind-worker3 kubelet[589656]: I0915 20:50:07.339279  589656 kubelet.go:1503] "syncPod exit" pod="default/nginx-deployment-66f58bff7c-nbvst" podUID=bf0ad039-0154-4821-ac30-f54e4366ba44 isTerminal=false
Sep 15 20:50:07 kind-worker3 kubelet[589656]: I0915 20:50:07.339338  589656 pod_workers.go:988] "Processing pod event done" pod="default/nginx-deployment-66f58bff7c-nbvst" podUID=bf0ad039-0154-4821-ac30-f54e4366ba44 updateType=0
Sep 15 20:50:07 kind-worker3 kubelet[589656]: I0915 20:50:07.339363  589656 pod_workers.go:888] "Processing pod event" pod="default/nginx-deployment-66f58bff7c-nbvst" podUID=bf0ad039-0154-4821-ac30-f54e4366ba44 updateType=0
Sep 15 20:50:07 kind-worker3 kubelet[589656]: I0915 20:50:07.369454  589656 desired_state_of_world_populator.go:309] "Added volume to desired state" pod="default/nginx-deployment-66f58bff7c-nbvst" volumeName="kube-api-access-95zbj" volumeSpecName="kube-api-access-95zbj"
Sep 15 20:50:07 kind-worker3 kubelet[589656]: I0915 20:50:07.375963  589656 config.go:279] "Setting pods for source" source="api"
Sep 15 20:50:07 kind-worker3 kubelet[589656]: I0915 20:50:07.376333  589656 kubelet.go:2085] "SyncLoop RECONCILE" source="api" pods=[default/nginx-deployment-66f58bff7c-nbvst]
Sep 15 20:50:07 kind-worker3 kubelet[589656]: I0915 20:50:07.377177  589656 status_manager.go:685] "Patch status for pod" pod="default/nginx-deployment-66f58bff7c-nbvst" patch="{\"metadata\":{\"uid\":\"bf0ad039-0154-4821-ac30-f54e4366ba44\"},\"status\":{\"$setElementOrder/conditions\":[{\"type\":\"Initialized\"},{\"type\":\"Ready\"},{\"type\":\"ContainersReady\"},{\"type\":\"PodScheduled\"}],\"conditions\":[{\"lastTransitionTime\":\"2023-09-15T20:50:07Z\",\"message\":null,\"reason\":null,\"status\":\"True\",\"type\":\"Ready\"},{\"lastTransitionTime\":\"2023-09-15T20:50:07Z\",\"message\":null,\"reason\":null,\"status\":\"True\",\"type\":\"ContainersReady\"}],\"containerStatuses\":[{\"containerID\":\"containerd://44ca9b8d7d34d1d46a7dc77e9f5257d12c4f6d1670c45041be6079b15affd771\",\"image\":\"docker.io/library/nginx:1.14.2\",\"imageID\":\"docker.io/library/nginx@sha256:f7988fb6c02e0ce69257d9bd9cf37ae20a60f1df7563c3a2a6abe24160306b8d\",\"lastState\":{},\"name\":\"nginx\",\"ready\":true,\"restartCount\":0,\"started\":true,\"state\":{\"running\":{\"startedAt\":\"2023-09-15T20:50:06Z\"}}}],\"phase\":\"Running\",\"podIP\":\"10.244.3.72\",\"podIPs\":[{\"ip\":\"10.244.3.72\"}]}}"
Sep 15 20:50:07 kind-worker3 kubelet[589656]: I0915 20:50:07.377386  589656 status_manager.go:694] "Status for pod updated successfully" pod="default/nginx-deployment-66f58bff7c-nbvst" statusVersion=2 status={Phase:Running Conditions:[{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-09-15 20:50:03 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-09-15 20:50:07 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-09-15 20:50:07 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-09-15 20:50:03 +0000 UTC Reason: Message:}] Message: Reason: NominatedNodeName: HostIP:172.18.0.4 PodIP:10.244.3.72 PodIPs:[{IP:10.244.3.72}] StartTime:2023-09-15 20:50:03 +0000 UTC InitContainerStatuses:[] ContainerStatuses:[{Name:nginx State:{Waiting:nil Running:&ContainerStateRunning{StartedAt:2023-09-15 20:50:06 +0000 UTC,} Terminated:nil} LastTerminationState:{Waiting:nil Running:nil Terminated:nil} Ready:true RestartCount:0 Image:docker.io/library/nginx:1.14.2 ImageID:docker.io/library/nginx@sha256:f7988fb6c02e0ce69257d9bd9cf37ae20a60f1df7563c3a2a6abe24160306b8d ContainerID:containerd://44ca9b8d7d34d1d46a7dc77e9f5257d12c4f6d1670c45041be6079b15affd771 Started:0xc00154c53c}] QOSClass:Burstable EphemeralContainerStatuses:[]}
Sep 15 20:50:07 kind-worker3 kubelet[589656]: I0915 20:50:07.419367  589656 reconciler.go:243] "Starting operationExecutor.MountVolume for volume \"kube-api-access-95zbj\" (UniqueName: \"kubernetes.io/projected/bf0ad039-0154-4821-ac30-f54e4366ba44-kube-api-access-95zbj\") pod \"nginx-deployment-66f58bff7c-nbvst\" (UID: \"bf0ad039-0154-4821-ac30-f54e4366ba44\") Volume is already mounted to pod, but remount was requested." pod="default/nginx-deployment-66f58bff7c-nbvst"
Sep 15 20:50:07 kind-worker3 kubelet[589656]: I0915 20:50:07.419624  589656 projected.go:183] Setting up volume kube-api-access-95zbj for pod bf0ad039-0154-4821-ac30-f54e4366ba44 at /var/lib/kubelet/pods/bf0ad039-0154-4821-ac30-f54e4366ba44/volumes/kubernetes.io~projected/kube-api-access-95zbj
Sep 15 20:50:07 kind-worker3 kubelet[589656]: I0915 20:50:07.420314  589656 atomic_writer.go:161] pod default/nginx-deployment-66f58bff7c-nbvst volume kube-api-access-95zbj: no update required for target directory /var/lib/kubelet/pods/bf0ad039-0154-4821-ac30-f54e4366ba44/volumes/kubernetes.io~projected/kube-api-access-95zbj
Sep 15 20:50:07 kind-worker3 kubelet[589656]: I0915 20:50:07.420407  589656 operation_generator.go:703] "MountVolume.SetUp succeeded for volume \"kube-api-access-95zbj\" (UniqueName: \"kubernetes.io/projected/bf0ad039-0154-4821-ac30-f54e4366ba44-kube-api-access-95zbj\") pod \"nginx-deployment-66f58bff7c-nbvst\" (UID: \"bf0ad039-0154-4821-ac30-f54e4366ba44\") " pod="default/nginx-deployment-66f58bff7c-nbvst"
Sep 15 20:50:08 kind-worker3 kubelet[589656]: I0915 20:50:08.264892  589656 handler.go:293] error while reading "/proc/589656/fd/38" link: readlink /proc/589656/fd/38: no such file or directory
Sep 15 20:50:08 kind-worker3 kubelet[589656]: I0915 20:50:08.340183  589656 kubelet.go:1501] "syncPod enter" pod="default/nginx-deployment-66f58bff7c-nbvst" podUID=bf0ad039-0154-4821-ac30-f54e4366ba44
Sep 15 20:50:08 kind-worker3 kubelet[589656]: I0915 20:50:08.340244  589656 kubelet_pods.go:1432] "Generating pod status" pod="default/nginx-deployment-66f58bff7c-nbvst"
Sep 15 20:50:08 kind-worker3 kubelet[589656]: I0915 20:50:08.340317  589656 kubelet_pods.go:1444] "Got phase for pod" pod="default/nginx-deployment-66f58bff7c-nbvst" oldPhase=Running phase=Running
Sep 15 20:50:08 kind-worker3 kubelet[589656]: I0915 20:50:08.340568  589656 status_manager.go:535] "Ignoring same status for pod" pod="default/nginx-deployment-66f58bff7c-nbvst" status={Phase:Running Conditions:[{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-09-15 20:50:03 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-09-15 20:50:07 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-09-15 20:50:07 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-09-15 20:50:03 +0000 UTC Reason: Message:}] Message: Reason: NominatedNodeName: HostIP:172.18.0.4 PodIP:10.244.3.72 PodIPs:[{IP:10.244.3.72}] StartTime:2023-09-15 20:50:03 +0000 UTC InitContainerStatuses:[] ContainerStatuses:[{Name:nginx State:{Waiting:nil Running:&ContainerStateRunning{StartedAt:2023-09-15 20:50:06 +0000 UTC,} Terminated:nil} LastTerminationState:{Waiting:nil Running:nil Terminated:nil} Ready:true RestartCount:0 Image:docker.io/library/nginx:1.14.2 ImageID:docker.io/library/nginx@sha256:f7988fb6c02e0ce69257d9bd9cf37ae20a60f1df7563c3a2a6abe24160306b8d ContainerID:containerd://44ca9b8d7d34d1d46a7dc77e9f5257d12c4f6d1670c45041be6079b15affd771 Started:0xc001394fdc}] QOSClass:Burstable EphemeralContainerStatuses:[]}
Sep 15 20:50:08 kind-worker3 kubelet[589656]: I0915 20:50:08.340987  589656 volume_manager.go:404] "Waiting for volumes to attach and mount for pod" pod="default/nginx-deployment-66f58bff7c-nbvst"
Sep 15 20:50:08 kind-worker3 kubelet[589656]: I0915 20:50:08.341038  589656 volume_manager.go:435] "All volumes are attached and mounted for pod" pod="default/nginx-deployment-66f58bff7c-nbvst"
Sep 15 20:50:08 kind-worker3 kubelet[589656]: I0915 20:50:08.341281  589656 kuberuntime_manager.go:714] "computePodActions got for pod" podActions={KillPod:false CreateSandbox:false SandboxID:83b4ac624e9b1f62481346831f7105bdc5f161d3f48256bad09a5f08986e6a98 Attempt:0 NextInitContainerToStart:nil ContainersToStart:[] ContainersToKill:map[] EphemeralContainersToStart:[]} pod="default/nginx-deployment-66f58bff7c-nbvst"
Sep 15 20:50:08 kind-worker3 kubelet[589656]: I0915 20:50:08.341446  589656 kubelet.go:1503] "syncPod exit" pod="default/nginx-deployment-66f58bff7c-nbvst" podUID=bf0ad039-0154-4821-ac30-f54e4366ba44 isTerminal=false
Sep 15 20:50:08 kind-worker3 kubelet[589656]: I0915 20:50:08.341498  589656 pod_workers.go:988] "Processing pod event done" pod="default/nginx-deployment-66f58bff7c-nbvst" podUID=bf0ad039-0154-4821-ac30-f54e4366ba44 updateType=0
Sep 15 20:50:08 kind-worker3 kubelet[589656]: I0915 20:50:08.376358  589656 desired_state_of_world_populator.go:309] "Added volume to desired state" pod="default/nginx-deployment-66f58bff7c-nbvst" volumeName="kube-api-access-95zbj" volumeSpecName="kube-api-access-95zbj"
Sep 15 20:50:08 kind-worker3 kubelet[589656]: I0915 20:50:08.426594  589656 reconciler.go:243] "Starting operationExecutor.MountVolume for volume \"kube-api-access-95zbj\" (UniqueName: \"kubernetes.io/projected/bf0ad039-0154-4821-ac30-f54e4366ba44-kube-api-access-95zbj\") pod \"nginx-deployment-66f58bff7c-nbvst\" (UID: \"bf0ad039-0154-4821-ac30-f54e4366ba44\") Volume is already mounted to pod, but remount was requested." pod="default/nginx-deployment-66f58bff7c-nbvst"
Sep 15 20:50:08 kind-worker3 kubelet[589656]: I0915 20:50:08.426836  589656 projected.go:183] Setting up volume kube-api-access-95zbj for pod bf0ad039-0154-4821-ac30-f54e4366ba44 at /var/lib/kubelet/pods/bf0ad039-0154-4821-ac30-f54e4366ba44/volumes/kubernetes.io~projected/kube-api-access-95zbj
Sep 15 20:50:08 kind-worker3 kubelet[589656]: I0915 20:50:08.427308  589656 atomic_writer.go:161] pod default/nginx-deployment-66f58bff7c-nbvst volume kube-api-access-95zbj: no update required for target directory /var/lib/kubelet/pods/bf0ad039-0154-4821-ac30-f54e4366ba44/volumes/kubernetes.io~projected/kube-api-access-95zbj
Sep 15 20:50:08 kind-worker3 kubelet[589656]: I0915 20:50:08.427375  589656 operation_generator.go:703] "MountVolume.SetUp succeeded for volume \"kube-api-access-95zbj\" (UniqueName: \"kubernetes.io/projected/bf0ad039-0154-4821-ac30-f54e4366ba44-kube-api-access-95zbj\") pod \"nginx-deployment-66f58bff7c-nbvst\" (UID: \"bf0ad039-0154-4821-ac30-f54e4366ba44\") " pod="default/nginx-deployment-66f58bff7c-nbvst"
Sep 15 20:50:08 kind-worker3 kubelet[589656]: I0915 20:50:08.497830  589656 kubelet.go:2160] "SyncLoop (housekeeping)"
Sep 15 20:50:08 kind-worker3 kubelet[589656]: I0915 20:50:08.509408  589656 kubelet_pods.go:1079] "Clean up pod workers for terminated pods"
Sep 15 20:50:08 kind-worker3 kubelet[589656]: I0915 20:50:08.509464  589656 kubelet_pods.go:1108] "Clean up probes for terminated pods"
Sep 15 20:50:08 kind-worker3 kubelet[589656]: I0915 20:50:08.509493  589656 kubelet_pods.go:1145] "Clean up orphaned pod statuses"
Sep 15 20:50:08 kind-worker3 kubelet[589656]: I0915 20:50:08.512219  589656 kubelet_pods.go:1164] "Clean up orphaned pod directories"
Sep 15 20:50:08 kind-worker3 kubelet[589656]: I0915 20:50:08.512459  589656 kubelet_pods.go:1175] "Clean up orphaned mirror pods"
Sep 15 20:50:08 kind-worker3 kubelet[589656]: I0915 20:50:08.512505  589656 kubelet_pods.go:1182] "Clean up orphaned pod cgroups"
Sep 15 20:50:08 kind-worker3 kubelet[589656]: I0915 20:50:08.512551  589656 kubelet.go:2168] "SyncLoop (housekeeping) end"
Sep 15 20:50:08 kind-worker3 kubelet[589656]: I0915 20:50:08.960258  589656 handler.go:124] Unable to get network stats from pid 980210: couldn't read network stats: failure opening /proc/980210/net/dev: open /proc/980210/net/dev: no such file or directory
Sep 15 20:50:08 kind-worker3 kubelet[589656]: I0915 20:50:08.960405  589656 handler.go:179] Unable to get Process Stats: couldn't open cpu cgroup procs file /sys/fs/cgroup/cpu,cpuacct/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-podf602fc75_3d22_475f_8c0a_de933744ab4e.slice/cri-containerd-5432e78771d09f84901cf4700d2078034e73119a187802ac085fa1e2e4829a62.scope/cgroup.procs : open /sys/fs/cgroup/cpu,cpuacct/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-podf602fc75_3d22_475f_8c0a_de933744ab4e.slice/cri-containerd-5432e78771d09f84901cf4700d2078034e73119a187802ac085fa1e2e4829a62.scope/cgroup.procs: no such file or directory
Sep 15 20:50:09 kind-worker3 kubelet[589656]: I0915 20:50:09.408276  589656 httplog.go:131] "HTTP" verb="GET" URI="/metrics/resource" latency="29.649864ms" userAgent="metrics-server/v0.6.3 (linux/amd64) kubernetes/a938798" audit-ID="" srcIP="172.18.0.3:35538" resp=200
Sep 15 20:50:09 kind-worker3 kubelet[589656]: I0915 20:50:09.982768  589656 kubelet.go:2346] "Container runtime status" status="Runtime Conditions: RuntimeReady=true reason: message:, NetworkReady=true reason: message:"
Sep 15 20:50:10 kind-worker3 kubelet[589656]: I0915 20:50:10.498239  589656 kubelet.go:2160] "SyncLoop (housekeeping)"
Sep 15 20:50:10 kind-worker3 kubelet[589656]: I0915 20:50:10.516202  589656 kubelet_pods.go:1079] "Clean up pod workers for terminated pods"
Sep 15 20:50:10 kind-worker3 kubelet[589656]: I0915 20:50:10.516283  589656 kubelet_pods.go:1108] "Clean up probes for terminated pods"
Sep 15 20:50:10 kind-worker3 kubelet[589656]: I0915 20:50:10.518690  589656 kubelet_pods.go:1145] "Clean up orphaned pod statuses"
Sep 15 20:50:10 kind-worker3 kubelet[589656]: I0915 20:50:10.519903  589656 kubelet_pods.go:1164] "Clean up orphaned pod directories"
Sep 15 20:50:10 kind-worker3 kubelet[589656]: I0915 20:50:10.520049  589656 kubelet_pods.go:1175] "Clean up orphaned mirror pods"
Sep 15 20:50:10 kind-worker3 kubelet[589656]: I0915 20:50:10.520076  589656 kubelet_pods.go:1182] "Clean up orphaned pod cgroups"
Sep 15 20:50:10 kind-worker3 kubelet[589656]: I0915 20:50:10.520105  589656 kubelet.go:2168] "SyncLoop (housekeeping) end"
Sep 15 20:50:12 kind-worker3 kubelet[589656]: I0915 20:50:12.497655  589656 kubelet.go:2160] "SyncLoop (housekeeping)"
Sep 15 20:50:12 kind-worker3 kubelet[589656]: I0915 20:50:12.510147  589656 kubelet_pods.go:1079] "Clean up pod workers for terminated pods"
Sep 15 20:50:12 kind-worker3 kubelet[589656]: I0915 20:50:12.510339  589656 kubelet_pods.go:1108] "Clean up probes for terminated pods"
Sep 15 20:50:12 kind-worker3 kubelet[589656]: I0915 20:50:12.510431  589656 kubelet_pods.go:1145] "Clean up orphaned pod statuses"
Sep 15 20:50:12 kind-worker3 kubelet[589656]: I0915 20:50:12.512666  589656 kubelet_pods.go:1164] "Clean up orphaned pod directories"
Sep 15 20:50:12 kind-worker3 kubelet[589656]: I0915 20:50:12.512846  589656 kubelet_pods.go:1175] "Clean up orphaned mirror pods"
Sep 15 20:50:12 kind-worker3 kubelet[589656]: I0915 20:50:12.512900  589656 kubelet_pods.go:1182] "Clean up orphaned pod cgroups"
Sep 15 20:50:12 kind-worker3 kubelet[589656]: I0915 20:50:12.512934  589656 kubelet.go:2168] "SyncLoop (housekeeping) end"
Sep 15 20:50:13 kind-worker3 kubelet[589656]: I0915 20:50:13.369879  589656 setters.go:88] "Using node IP" IP="172.18.0.4"
Sep 15 20:50:13 kind-worker3 kubelet[589656]: I0915 20:50:13.554869  589656 handler.go:124] Unable to get network stats from pid 980178: couldn't read network stats: failure opening /proc/980178/net/dev: open /proc/980178/net/dev: no such file or directory
Sep 15 20:50:13 kind-worker3 kubelet[589656]: I0915 20:50:13.555006  589656 handler.go:179] Unable to get Process Stats: couldn't open cpu cgroup procs file /sys/fs/cgroup/cpu,cpuacct/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-podf602fc75_3d22_475f_8c0a_de933744ab4e.slice/cri-containerd-b553881ecd35bacb71b6c14fb9ca775d38c625d547bf3c076902f1ed25c4d0c1.scope/cgroup.procs : open /sys/fs/cgroup/cpu,cpuacct/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-podf602fc75_3d22_475f_8c0a_de933744ab4e.slice/cri-containerd-b553881ecd35bacb71b6c14fb9ca775d38c625d547bf3c076902f1ed25c4d0c1.scope/cgroup.procs: no such file or directory
Sep 15 20:50:14 kind-worker3 kubelet[589656]: I0915 20:50:14.407655  589656 eviction_manager.go:237] "Eviction manager: synchronize housekeeping"
Sep 15 20:50:14 kind-worker3 kubelet[589656]: I0915 20:50:14.437531  589656 cri_stats_provider.go:525] "Unable to find network stats for sandbox" sandboxID="d0f4d02598fe0e9a32081b1554ae85df2b4224eb9a378fdcf99aa7c0035d33dc"
Sep 15 20:50:14 kind-worker3 kubelet[589656]: I0915 20:50:14.438110  589656 cri_stats_provider.go:525] "Unable to find network stats for sandbox" sandboxID="b477a0e3bdd1b445ce34dc6f173590a56dbfec252950ee838d5af2a2515a773b"
Sep 15 20:50:14 kind-worker3 kubelet[589656]: I0915 20:50:14.440421  589656 helpers.go:775] "Eviction manager:" log="observations" signal=nodefs.inodesFree resourceName="2345592" capacity="3276800" time="2023-09-15 20:50:14.410364634 +0000 UTC m=+2146478.333189854"
Sep 15 20:50:14 kind-worker3 kubelet[589656]: I0915 20:50:14.440476  589656 helpers.go:775] "Eviction manager:" log="observations" signal=imagefs.available resourceName="7762668Ki" capacity="51341792Ki" time="2023-09-15 20:50:08.905880031 +0000 UTC"
Sep 15 20:50:14 kind-worker3 kubelet[589656]: I0915 20:50:14.440504  589656 helpers.go:775] "Eviction manager:" log="observations" signal=imagefs.inodesFree resourceName="2345592" capacity="3276800" time="2023-09-15 20:50:08.905880031 +0000 UTC"
Sep 15 20:50:14 kind-worker3 kubelet[589656]: I0915 20:50:14.440531  589656 helpers.go:775] "Eviction manager:" log="observations" signal=pid.available resourceName="62151" capacity="63272" time="2023-09-15 20:50:14.438470141 +0000 UTC m=+2146478.361295282"
Sep 15 20:50:14 kind-worker3 kubelet[589656]: I0915 20:50:14.440558  589656 helpers.go:775] "Eviction manager:" log="observations" signal=memory.available resourceName="7891384Ki" capacity="8166760Ki" time="2023-09-15 20:50:14.410364634 +0000 UTC m=+2146478.333189854"
Sep 15 20:50:14 kind-worker3 kubelet[589656]: I0915 20:50:14.440584  589656 helpers.go:775] "Eviction manager:" log="observations" signal=allocatableMemory.available resourceName="8106284Ki" capacity="8166760Ki" time="2023-09-15 20:50:14.440228377 +0000 UTC m=+2146478.363053513"
Sep 15 20:50:14 kind-worker3 kubelet[589656]: I0915 20:50:14.440610  589656 helpers.go:775] "Eviction manager:" log="observations" signal=nodefs.available resourceName="7762668Ki" capacity="51341792Ki" time="2023-09-15 20:50:14.410364634 +0000 UTC m=+2146478.333189854"
Sep 15 20:50:14 kind-worker3 kubelet[589656]: I0915 20:50:14.440668  589656 eviction_manager.go:328] "Eviction manager: no resources are starved"
Sep 15 20:50:14 kind-worker3 kubelet[589656]: I0915 20:50:14.499463  589656 kubelet.go:2160] "SyncLoop (housekeeping)"
Sep 15 20:50:14 kind-worker3 kubelet[589656]: I0915 20:50:14.507068  589656 kubelet_pods.go:1079] "Clean up pod workers for terminated pods"
Sep 15 20:50:14 kind-worker3 kubelet[589656]: I0915 20:50:14.507132  589656 kubelet_pods.go:1108] "Clean up probes for terminated pods"
Sep 15 20:50:14 kind-worker3 kubelet[589656]: I0915 20:50:14.509205  589656 kubelet_pods.go:1145] "Clean up orphaned pod statuses"
Sep 15 20:50:14 kind-worker3 kubelet[589656]: I0915 20:50:14.510401  589656 kubelet_pods.go:1164] "Clean up orphaned pod directories"
Sep 15 20:50:14 kind-worker3 kubelet[589656]: I0915 20:50:14.510713  589656 kubelet_pods.go:1175] "Clean up orphaned mirror pods"
Sep 15 20:50:14 kind-worker3 kubelet[589656]: I0915 20:50:14.510879  589656 kubelet_pods.go:1182] "Clean up orphaned pod cgroups"
Sep 15 20:50:14 kind-worker3 kubelet[589656]: I0915 20:50:14.511068  589656 kubelet.go:2168] "SyncLoop (housekeeping) end"
Sep 15 20:50:14 kind-worker3 kubelet[589656]: I0915 20:50:14.984179  589656 kubelet.go:2346] "Container runtime status" status="Runtime Conditions: RuntimeReady=true reason: message:, NetworkReady=true reason: message:"
Sep 15 20:50:16 kind-worker3 kubelet[589656]: I0915 20:50:16.256211  589656 config.go:279] "Setting pods for source" source="file"
Sep 15 20:50:16 kind-worker3 kubelet[589656]: I0915 20:50:16.497717  589656 kubelet.go:2160] "SyncLoop (housekeeping)"
Sep 15 20:50:16 kind-worker3 kubelet[589656]: I0915 20:50:16.505699  589656 kubelet_pods.go:1079] "Clean up pod workers for terminated pods"
Sep 15 20:50:16 kind-worker3 kubelet[589656]: I0915 20:50:16.505760  589656 kubelet_pods.go:1108] "Clean up probes for terminated pods"
Sep 15 20:50:16 kind-worker3 kubelet[589656]: I0915 20:50:16.505791  589656 kubelet_pods.go:1145] "Clean up orphaned pod statuses"
Sep 15 20:50:16 kind-worker3 kubelet[589656]: I0915 20:50:16.507537  589656 kubelet_pods.go:1164] "Clean up orphaned pod directories"
Sep 15 20:50:16 kind-worker3 kubelet[589656]: I0915 20:50:16.507672  589656 kubelet_pods.go:1175] "Clean up orphaned mirror pods"
Sep 15 20:50:16 kind-worker3 kubelet[589656]: I0915 20:50:16.507700  589656 kubelet_pods.go:1182] "Clean up orphaned pod cgroups"
Sep 15 20:50:16 kind-worker3 kubelet[589656]: I0915 20:50:16.507734  589656 kubelet.go:2168] "SyncLoop (housekeeping) end"
Sep 15 20:50:18 kind-worker3 kubelet[589656]: I0915 20:50:18.497590  589656 kubelet.go:2160] "SyncLoop (housekeeping)"
Sep 15 20:50:18 kind-worker3 kubelet[589656]: I0915 20:50:18.505756  589656 kubelet_pods.go:1079] "Clean up pod workers for terminated pods"
Sep 15 20:50:18 kind-worker3 kubelet[589656]: I0915 20:50:18.505815  589656 kubelet_pods.go:1108] "Clean up probes for terminated pods"
Sep 15 20:50:18 kind-worker3 kubelet[589656]: I0915 20:50:18.507634  589656 kubelet_pods.go:1145] "Clean up orphaned pod statuses"
Sep 15 20:50:18 kind-worker3 kubelet[589656]: I0915 20:50:18.508823  589656 kubelet_pods.go:1164] "Clean up orphaned pod directories"
Sep 15 20:50:18 kind-worker3 kubelet[589656]: I0915 20:50:18.509001  589656 kubelet_pods.go:1175] "Clean up orphaned mirror pods"
Sep 15 20:50:18 kind-worker3 kubelet[589656]: I0915 20:50:18.509032  589656 kubelet_pods.go:1182] "Clean up orphaned pod cgroups"
Sep 15 20:50:18 kind-worker3 kubelet[589656]: I0915 20:50:18.509100  589656 kubelet.go:2168] "SyncLoop (housekeeping) end"
Sep 15 20:50:19 kind-worker3 kubelet[589656]: I0915 20:50:19.379915  589656 httplog.go:131] "HTTP" verb="GET" URI="/metrics/resource" latency="10.161573ms" userAgent="metrics-server/v0.6.3 (linux/amd64) kubernetes/a938798" audit-ID="" srcIP="172.18.0.3:35538" resp=200
Sep 15 20:50:19 kind-worker3 kubelet[589656]: I0915 20:50:19.985930  589656 kubelet.go:2346] "Container runtime status" status="Runtime Conditions: RuntimeReady=true reason: message:, NetworkReady=true reason: message:"
Sep 15 20:50:20 kind-worker3 kubelet[589656]: I0915 20:50:20.498507  589656 kubelet.go:2160] "SyncLoop (housekeeping)"
Sep 15 20:50:20 kind-worker3 kubelet[589656]: I0915 20:50:20.508496  589656 kubelet_pods.go:1079] "Clean up pod workers for terminated pods"
Sep 15 20:50:20 kind-worker3 kubelet[589656]: I0915 20:50:20.508559  589656 kubelet_pods.go:1108] "Clean up probes for terminated pods"
Sep 15 20:50:20 kind-worker3 kubelet[589656]: I0915 20:50:20.510739  589656 kubelet_pods.go:1145] "Clean up orphaned pod statuses"
Sep 15 20:50:20 kind-worker3 kubelet[589656]: I0915 20:50:20.512446  589656 kubelet_pods.go:1164] "Clean up orphaned pod directories"
Sep 15 20:50:20 kind-worker3 kubelet[589656]: I0915 20:50:20.512683  589656 kubelet_pods.go:1175] "Clean up orphaned mirror pods"
Sep 15 20:50:20 kind-worker3 kubelet[589656]: I0915 20:50:20.512736  589656 kubelet_pods.go:1182] "Clean up orphaned pod cgroups"
Sep 15 20:50:20 kind-worker3 kubelet[589656]: I0915 20:50:20.512785  589656 kubelet.go:2168] "SyncLoop (housekeeping) end"
Sep 15 20:50:20 kind-worker3 kubelet[589656]: I0915 20:50:20.903124  589656 qos_container_manager_linux.go:379] "Updated QoS cgroup configuration"
Sep 15 20:50:21 kind-worker3 kubelet[589656]: I0915 20:50:21.497978  589656 kubelet.go:2129] "SyncLoop (SYNC) pods" total=1 pods=[kube-system/kube-proxy-zvz6f]
Sep 15 20:50:21 kind-worker3 kubelet[589656]: I0915 20:50:21.498126  589656 pod_workers.go:888] "Processing pod event" pod="kube-system/kube-proxy-zvz6f" podUID=6b53eb8b-e28c-454a-92e9-b342af428fa5 updateType=0
Sep 15 20:50:21 kind-worker3 kubelet[589656]: I0915 20:50:21.498191  589656 kubelet.go:1501] "syncPod enter" pod="kube-system/kube-proxy-zvz6f" podUID=6b53eb8b-e28c-454a-92e9-b342af428fa5
Sep 15 20:50:21 kind-worker3 kubelet[589656]: I0915 20:50:21.498224  589656 kubelet_pods.go:1432] "Generating pod status" pod="kube-system/kube-proxy-zvz6f"
Sep 15 20:50:21 kind-worker3 kubelet[589656]: I0915 20:50:21.498301  589656 kubelet_pods.go:1444] "Got phase for pod" pod="kube-system/kube-proxy-zvz6f" oldPhase=Running phase=Running
Sep 15 20:50:21 kind-worker3 kubelet[589656]: I0915 20:50:21.498527  589656 status_manager.go:535] "Ignoring same status for pod" pod="kube-system/kube-proxy-zvz6f" status={Phase:Running Conditions:[{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-14 00:07:50 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-07-15 14:56:49 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-07-15 14:56:49 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-14 00:07:47 +0000 UTC Reason: Message:}] Message: Reason: NominatedNodeName: HostIP:172.18.0.4 PodIP:172.18.0.4 PodIPs:[{IP:172.18.0.4}] StartTime:2023-04-14 00:07:50 +0000 UTC InitContainerStatuses:[] ContainerStatuses:[{Name:kube-proxy State:{Waiting:nil Running:&ContainerStateRunning{StartedAt:2023-07-15 14:56:47 +0000 UTC,} Terminated:nil} LastTerminationState:{Waiting:nil Running:nil Terminated:&ContainerStateTerminated{ExitCode:255,Signal:0,Reason:Unknown,Message:,StartedAt:2023-05-13 23:24:22 +0000 UTC,FinishedAt:2023-07-15 14:56:13 +0000 UTC,ContainerID:containerd://1a7bfc39de99704091c5fdcafe31a31e1284778b198adb62ae3b794474907627,}} Ready:true RestartCount:2 Image:k8s.gcr.io/kube-proxy:v1.24.7 ImageID:docker.io/library/import-2022-10-26@sha256:82fa4ddf64d5be44671118fb9b86c454a222ff7ea6e48863ed7e5daeeca3ea42 ContainerID:containerd://041c9bf8c11670337ae7ecef4cae6277cbe6623488dc925c5412e6b4a494b7f0 Started:0xc00175865c}] QOSClass:BestEffort EphemeralContainerStatuses:[]}
Sep 15 20:50:21 kind-worker3 kubelet[589656]: I0915 20:50:21.498990  589656 volume_manager.go:404] "Waiting for volumes to attach and mount for pod" pod="kube-system/kube-proxy-zvz6f"
Sep 15 20:50:21 kind-worker3 kubelet[589656]: I0915 20:50:21.499046  589656 volume_manager.go:435] "All volumes are attached and mounted for pod" pod="kube-system/kube-proxy-zvz6f"
Sep 15 20:50:21 kind-worker3 kubelet[589656]: I0915 20:50:21.499286  589656 kuberuntime_manager.go:714] "computePodActions got for pod" podActions={KillPod:false CreateSandbox:false SandboxID:d0f4d02598fe0e9a32081b1554ae85df2b4224eb9a378fdcf99aa7c0035d33dc Attempt:2 NextInitContainerToStart:nil ContainersToStart:[] ContainersToKill:map[] EphemeralContainersToStart:[]} pod="kube-system/kube-proxy-zvz6f"
Sep 15 20:50:21 kind-worker3 kubelet[589656]: I0915 20:50:21.499469  589656 kubelet.go:1503] "syncPod exit" pod="kube-system/kube-proxy-zvz6f" podUID=6b53eb8b-e28c-454a-92e9-b342af428fa5 isTerminal=false
Sep 15 20:50:21 kind-worker3 kubelet[589656]: I0915 20:50:21.499522  589656 pod_workers.go:988] "Processing pod event done" pod="kube-system/kube-proxy-zvz6f" podUID=6b53eb8b-e28c-454a-92e9-b342af428fa5 updateType=0
Sep 15 20:50:21 kind-worker3 kubelet[589656]: I0915 20:50:21.572633  589656 desired_state_of_world_populator.go:309] "Added volume to desired state" pod="kube-system/kube-proxy-zvz6f" volumeName="kube-proxy" volumeSpecName="kube-proxy"
Sep 15 20:50:21 kind-worker3 kubelet[589656]: I0915 20:50:21.572737  589656 desired_state_of_world_populator.go:309] "Added volume to desired state" pod="kube-system/kube-proxy-zvz6f" volumeName="xtables-lock" volumeSpecName="xtables-lock"
Sep 15 20:50:21 kind-worker3 kubelet[589656]: I0915 20:50:21.572798  589656 desired_state_of_world_populator.go:309] "Added volume to desired state" pod="kube-system/kube-proxy-zvz6f" volumeName="lib-modules" volumeSpecName="lib-modules"
Sep 15 20:50:21 kind-worker3 kubelet[589656]: I0915 20:50:21.572901  589656 desired_state_of_world_populator.go:309] "Added volume to desired state" pod="kube-system/kube-proxy-zvz6f" volumeName="kube-api-access-psmb2" volumeSpecName="kube-api-access-psmb2"
Sep 15 20:50:21 kind-worker3 kubelet[589656]: I0915 20:50:21.626828  589656 reconciler.go:243] "Starting operationExecutor.MountVolume for volume \"kube-proxy\" (UniqueName: \"kubernetes.io/configmap/6b53eb8b-e28c-454a-92e9-b342af428fa5-kube-proxy\") pod \"kube-proxy-zvz6f\" (UID: \"6b53eb8b-e28c-454a-92e9-b342af428fa5\") Volume is already mounted to pod, but remount was requested." pod="kube-system/kube-proxy-zvz6f"
Sep 15 20:50:21 kind-worker3 kubelet[589656]: I0915 20:50:21.627032  589656 reconciler.go:243] "Starting operationExecutor.MountVolume for volume \"kube-api-access-psmb2\" (UniqueName: \"kubernetes.io/projected/6b53eb8b-e28c-454a-92e9-b342af428fa5-kube-api-access-psmb2\") pod \"kube-proxy-zvz6f\" (UID: \"6b53eb8b-e28c-454a-92e9-b342af428fa5\") Volume is already mounted to pod, but remount was requested." pod="kube-system/kube-proxy-zvz6f"
Sep 15 20:50:21 kind-worker3 kubelet[589656]: I0915 20:50:21.627171  589656 configmap.go:181] Setting up volume kube-proxy for pod 6b53eb8b-e28c-454a-92e9-b342af428fa5 at /var/lib/kubelet/pods/6b53eb8b-e28c-454a-92e9-b342af428fa5/volumes/kubernetes.io~configmap/kube-proxy
Sep 15 20:50:21 kind-worker3 kubelet[589656]: I0915 20:50:21.627269  589656 configmap.go:205] Received configMap kube-system/kube-proxy containing (2) pieces of data, 1466 total bytes
Sep 15 20:50:21 kind-worker3 kubelet[589656]: I0915 20:50:21.627178  589656 projected.go:183] Setting up volume kube-api-access-psmb2 for pod 6b53eb8b-e28c-454a-92e9-b342af428fa5 at /var/lib/kubelet/pods/6b53eb8b-e28c-454a-92e9-b342af428fa5/volumes/kubernetes.io~projected/kube-api-access-psmb2
Sep 15 20:50:21 kind-worker3 kubelet[589656]: I0915 20:50:21.627415  589656 quota_linux.go:271] SupportsQuotas called, but quotas disabled
Sep 15 20:50:21 kind-worker3 kubelet[589656]: I0915 20:50:21.627745  589656 atomic_writer.go:161] pod kube-system/kube-proxy-zvz6f volume kube-proxy: no update required for target directory /var/lib/kubelet/pods/6b53eb8b-e28c-454a-92e9-b342af428fa5/volumes/kubernetes.io~configmap/kube-proxy
Sep 15 20:50:21 kind-worker3 kubelet[589656]: I0915 20:50:21.627795  589656 operation_generator.go:703] "MountVolume.SetUp succeeded for volume \"kube-proxy\" (UniqueName: \"kubernetes.io/configmap/6b53eb8b-e28c-454a-92e9-b342af428fa5-kube-proxy\") pod \"kube-proxy-zvz6f\" (UID: \"6b53eb8b-e28c-454a-92e9-b342af428fa5\") " pod="kube-system/kube-proxy-zvz6f"
Sep 15 20:50:21 kind-worker3 kubelet[589656]: I0915 20:50:21.627937  589656 atomic_writer.go:161] pod kube-system/kube-proxy-zvz6f volume kube-api-access-psmb2: no update required for target directory /var/lib/kubelet/pods/6b53eb8b-e28c-454a-92e9-b342af428fa5/volumes/kubernetes.io~projected/kube-api-access-psmb2
Sep 15 20:50:21 kind-worker3 kubelet[589656]: I0915 20:50:21.628030  589656 operation_generator.go:703] "MountVolume.SetUp succeeded for volume \"kube-api-access-psmb2\" (UniqueName: \"kubernetes.io/projected/6b53eb8b-e28c-454a-92e9-b342af428fa5-kube-api-access-psmb2\") pod \"kube-proxy-zvz6f\" (UID: \"6b53eb8b-e28c-454a-92e9-b342af428fa5\") " pod="kube-system/kube-proxy-zvz6f"
Sep 15 20:50:21 kind-worker3 kubelet[589656]: I0915 20:50:21.775144  589656 handler.go:293] error while reading "/proc/589656/fd/38" link: readlink /proc/589656/fd/38: no such file or directory
Sep 15 20:50:22 kind-worker3 kubelet[589656]: I0915 20:50:22.497665  589656 kubelet.go:2160] "SyncLoop (housekeeping)"
Sep 15 20:50:22 kind-worker3 kubelet[589656]: I0915 20:50:22.506803  589656 kubelet_pods.go:1079] "Clean up pod workers for terminated pods"
Sep 15 20:50:22 kind-worker3 kubelet[589656]: I0915 20:50:22.506882  589656 kubelet_pods.go:1108] "Clean up probes for terminated pods"
Sep 15 20:50:22 kind-worker3 kubelet[589656]: I0915 20:50:22.506910  589656 kubelet_pods.go:1145] "Clean up orphaned pod statuses"
Sep 15 20:50:22 kind-worker3 kubelet[589656]: I0915 20:50:22.508527  589656 kubelet_pods.go:1164] "Clean up orphaned pod directories"
Sep 15 20:50:22 kind-worker3 kubelet[589656]: I0915 20:50:22.508715  589656 kubelet_pods.go:1175] "Clean up orphaned mirror pods"
Sep 15 20:50:22 kind-worker3 kubelet[589656]: I0915 20:50:22.508784  589656 kubelet_pods.go:1182] "Clean up orphaned pod cgroups"
Sep 15 20:50:22 kind-worker3 kubelet[589656]: I0915 20:50:22.508819  589656 kubelet.go:2168] "SyncLoop (housekeeping) end"
Sep 15 20:50:23 kind-worker3 kubelet[589656]: I0915 20:50:23.600898  589656 setters.go:88] "Using node IP" IP="172.18.0.4"
Sep 15 20:50:24 kind-worker3 kubelet[589656]: I0915 20:50:24.292713  589656 handler.go:124] Unable to get network stats from pid 980210: couldn't read network stats: failure opening /proc/980210/net/dev: open /proc/980210/net/dev: no such file or directory
Sep 15 20:50:24 kind-worker3 kubelet[589656]: I0915 20:50:24.292818  589656 handler.go:179] Unable to get Process Stats: couldn't open cpu cgroup procs file /sys/fs/cgroup/cpu,cpuacct/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-podf602fc75_3d22_475f_8c0a_de933744ab4e.slice/cri-containerd-5432e78771d09f84901cf4700d2078034e73119a187802ac085fa1e2e4829a62.scope/cgroup.procs : open /sys/fs/cgroup/cpu,cpuacct/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-podf602fc75_3d22_475f_8c0a_de933744ab4e.slice/cri-containerd-5432e78771d09f84901cf4700d2078034e73119a187802ac085fa1e2e4829a62.scope/cgroup.procs: no such file or directory
Sep 15 20:50:24 kind-worker3 kubelet[589656]: I0915 20:50:24.441606  589656 eviction_manager.go:237] "Eviction manager: synchronize housekeeping"
Sep 15 20:50:24 kind-worker3 kubelet[589656]: I0915 20:50:24.476670  589656 cri_stats_provider.go:525] "Unable to find network stats for sandbox" sandboxID="d0f4d02598fe0e9a32081b1554ae85df2b4224eb9a378fdcf99aa7c0035d33dc"
Sep 15 20:50:24 kind-worker3 kubelet[589656]: I0915 20:50:24.477984  589656 cri_stats_provider.go:525] "Unable to find network stats for sandbox" sandboxID="b477a0e3bdd1b445ce34dc6f173590a56dbfec252950ee838d5af2a2515a773b"
Sep 15 20:50:24 kind-worker3 kubelet[589656]: I0915 20:50:24.482718  589656 helpers.go:775] "Eviction manager:" log="observations" signal=pid.available resourceName="62193" capacity="63272" time="2023-09-15 20:50:24.478820989 +0000 UTC m=+2146488.401646164"
Sep 15 20:50:24 kind-worker3 kubelet[589656]: I0915 20:50:24.483011  589656 helpers.go:775] "Eviction manager:" log="observations" signal=memory.available resourceName="7892116Ki" capacity="8166760Ki" time="2023-09-15 20:50:24.443609216 +0000 UTC m=+2146488.366434385"
Sep 15 20:50:24 kind-worker3 kubelet[589656]: I0915 20:50:24.483274  589656 helpers.go:775] "Eviction manager:" log="observations" signal=allocatableMemory.available resourceName="8106240Ki" capacity="8166760Ki" time="2023-09-15 20:50:24.482349176 +0000 UTC m=+2146488.405174367"
Sep 15 20:50:24 kind-worker3 kubelet[589656]: I0915 20:50:24.483542  589656 helpers.go:775] "Eviction manager:" log="observations" signal=nodefs.available resourceName="7757864Ki" capacity="51341792Ki" time="2023-09-15 20:50:24.443609216 +0000 UTC m=+2146488.366434385"
Sep 15 20:50:24 kind-worker3 kubelet[589656]: I0915 20:50:24.483802  589656 helpers.go:775] "Eviction manager:" log="observations" signal=nodefs.inodesFree resourceName="2345592" capacity="3276800" time="2023-09-15 20:50:24.443609216 +0000 UTC m=+2146488.366434385"
Sep 15 20:50:24 kind-worker3 kubelet[589656]: I0915 20:50:24.484052  589656 helpers.go:775] "Eviction manager:" log="observations" signal=imagefs.available resourceName="7757864Ki" capacity="51341792Ki" time="2023-09-15 20:50:18.905009201 +0000 UTC"
Sep 15 20:50:24 kind-worker3 kubelet[589656]: I0915 20:50:24.484301  589656 helpers.go:775] "Eviction manager:" log="observations" signal=imagefs.inodesFree resourceName="2345592" capacity="3276800" time="2023-09-15 20:50:18.905009201 +0000 UTC"
Sep 15 20:50:24 kind-worker3 kubelet[589656]: I0915 20:50:24.484553  589656 eviction_manager.go:328] "Eviction manager: no resources are starved"
Sep 15 20:50:24 kind-worker3 kubelet[589656]: I0915 20:50:24.498098  589656 kubelet.go:2160] "SyncLoop (housekeeping)"
Sep 15 20:50:24 kind-worker3 kubelet[589656]: I0915 20:50:24.505919  589656 kubelet_pods.go:1079] "Clean up pod workers for terminated pods"
Sep 15 20:50:24 kind-worker3 kubelet[589656]: I0915 20:50:24.505978  589656 kubelet_pods.go:1108] "Clean up probes for terminated pods"
Sep 15 20:50:24 kind-worker3 kubelet[589656]: I0915 20:50:24.507706  589656 kubelet_pods.go:1145] "Clean up orphaned pod statuses"
Sep 15 20:50:24 kind-worker3 kubelet[589656]: I0915 20:50:24.509108  589656 kubelet_pods.go:1164] "Clean up orphaned pod directories"
Sep 15 20:50:24 kind-worker3 kubelet[589656]: I0915 20:50:24.509320  589656 kubelet_pods.go:1175] "Clean up orphaned mirror pods"
Sep 15 20:50:24 kind-worker3 kubelet[589656]: I0915 20:50:24.509362  589656 kubelet_pods.go:1182] "Clean up orphaned pod cgroups"
Sep 15 20:50:24 kind-worker3 kubelet[589656]: I0915 20:50:24.509409  589656 kubelet.go:2168] "SyncLoop (housekeeping) end"
Sep 15 20:50:24 kind-worker3 kubelet[589656]: I0915 20:50:24.987752  589656 kubelet.go:2346] "Container runtime status" status="Runtime Conditions: RuntimeReady=true reason: message:, NetworkReady=true reason: message:"
Sep 15 20:50:26 kind-worker3 kubelet[589656]: I0915 20:50:26.498482  589656 kubelet.go:2160] "SyncLoop (housekeeping)"
Sep 15 20:50:26 kind-worker3 kubelet[589656]: I0915 20:50:26.508471  589656 kubelet_pods.go:1079] "Clean up pod workers for terminated pods"
Sep 15 20:50:26 kind-worker3 kubelet[589656]: I0915 20:50:26.508548  589656 kubelet_pods.go:1108] "Clean up probes for terminated pods"
Sep 15 20:50:26 kind-worker3 kubelet[589656]: I0915 20:50:26.510958  589656 kubelet_pods.go:1145] "Clean up orphaned pod statuses"
Sep 15 20:50:26 kind-worker3 kubelet[589656]: I0915 20:50:26.512316  589656 kubelet_pods.go:1164] "Clean up orphaned pod directories"
Sep 15 20:50:26 kind-worker3 kubelet[589656]: I0915 20:50:26.512491  589656 kubelet_pods.go:1175] "Clean up orphaned mirror pods"
Sep 15 20:50:26 kind-worker3 kubelet[589656]: I0915 20:50:26.512542  589656 kubelet_pods.go:1182] "Clean up orphaned pod cgroups"
Sep 15 20:50:26 kind-worker3 kubelet[589656]: I0915 20:50:26.512590  589656 kubelet.go:2168] "SyncLoop (housekeeping) end"
Sep 15 20:50:28 kind-worker3 kubelet[589656]: I0915 20:50:28.498467  589656 kubelet.go:2160] "SyncLoop (housekeeping)"
Sep 15 20:50:28 kind-worker3 kubelet[589656]: I0915 20:50:28.506849  589656 kubelet_pods.go:1079] "Clean up pod workers for terminated pods"
Sep 15 20:50:28 kind-worker3 kubelet[589656]: I0915 20:50:28.507079  589656 kubelet_pods.go:1108] "Clean up probes for terminated pods"
Sep 15 20:50:28 kind-worker3 kubelet[589656]: I0915 20:50:28.507260  589656 kubelet_pods.go:1145] "Clean up orphaned pod statuses"
Sep 15 20:50:28 kind-worker3 kubelet[589656]: I0915 20:50:28.511853  589656 kubelet_pods.go:1164] "Clean up orphaned pod directories"
Sep 15 20:50:28 kind-worker3 kubelet[589656]: I0915 20:50:28.512201  589656 kubelet_pods.go:1175] "Clean up orphaned mirror pods"
Sep 15 20:50:28 kind-worker3 kubelet[589656]: I0915 20:50:28.512365  589656 kubelet_pods.go:1182] "Clean up orphaned pod cgroups"
Sep 15 20:50:28 kind-worker3 kubelet[589656]: I0915 20:50:28.512529  589656 kubelet.go:2168] "SyncLoop (housekeeping) end"
Sep 15 20:50:29 kind-worker3 kubelet[589656]: I0915 20:50:29.203461  589656 handler.go:124] Unable to get network stats from pid 980178: couldn't read network stats: failure opening /proc/980178/net/dev: open /proc/980178/net/dev: no such file or directory
Sep 15 20:50:29 kind-worker3 kubelet[589656]: I0915 20:50:29.203566  589656 handler.go:179] Unable to get Process Stats: couldn't open cpu cgroup procs file /sys/fs/cgroup/cpu,cpuacct/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-podf602fc75_3d22_475f_8c0a_de933744ab4e.slice/cri-containerd-b553881ecd35bacb71b6c14fb9ca775d38c625d547bf3c076902f1ed25c4d0c1.scope/cgroup.procs : open /sys/fs/cgroup/cpu,cpuacct/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-podf602fc75_3d22_475f_8c0a_de933744ab4e.slice/cri-containerd-b553881ecd35bacb71b6c14fb9ca775d38c625d547bf3c076902f1ed25c4d0c1.scope/cgroup.procs: no such file or directory
Sep 15 20:50:29 kind-worker3 kubelet[589656]: I0915 20:50:29.380437  589656 httplog.go:131] "HTTP" verb="GET" URI="/metrics/resource" latency="12.435759ms" userAgent="metrics-server/v0.6.3 (linux/amd64) kubernetes/a938798" audit-ID="" srcIP="172.18.0.3:35538" resp=200
Sep 15 20:50:29 kind-worker3 kubelet[589656]: I0915 20:50:29.989700  589656 kubelet.go:2346] "Container runtime status" status="Runtime Conditions: RuntimeReady=true reason: message:, NetworkReady=true reason: message:"
Sep 15 20:50:30 kind-worker3 kubelet[589656]: I0915 20:50:30.498335  589656 kubelet.go:2160] "SyncLoop (housekeeping)"
Sep 15 20:50:30 kind-worker3 kubelet[589656]: I0915 20:50:30.510573  589656 kubelet_pods.go:1079] "Clean up pod workers for terminated pods"
Sep 15 20:50:30 kind-worker3 kubelet[589656]: I0915 20:50:30.510684  589656 kubelet_pods.go:1108] "Clean up probes for terminated pods"
Sep 15 20:50:30 kind-worker3 kubelet[589656]: I0915 20:50:30.512722  589656 kubelet_pods.go:1145] "Clean up orphaned pod statuses"
Sep 15 20:50:30 kind-worker3 kubelet[589656]: I0915 20:50:30.513887  589656 kubelet_pods.go:1164] "Clean up orphaned pod directories"
Sep 15 20:50:30 kind-worker3 kubelet[589656]: I0915 20:50:30.514078  589656 kubelet_pods.go:1175] "Clean up orphaned mirror pods"
Sep 15 20:50:30 kind-worker3 kubelet[589656]: I0915 20:50:30.514135  589656 kubelet_pods.go:1182] "Clean up orphaned pod cgroups"
Sep 15 20:50:30 kind-worker3 kubelet[589656]: I0915 20:50:30.514175  589656 kubelet.go:2168] "SyncLoop (housekeeping) end"
Sep 15 20:50:32 kind-worker3 kubelet[589656]: I0915 20:50:32.498004  589656 kubelet.go:2160] "SyncLoop (housekeeping)"
Sep 15 20:50:32 kind-worker3 kubelet[589656]: I0915 20:50:32.505603  589656 kubelet_pods.go:1079] "Clean up pod workers for terminated pods"
Sep 15 20:50:32 kind-worker3 kubelet[589656]: I0915 20:50:32.505667  589656 kubelet_pods.go:1108] "Clean up probes for terminated pods"
Sep 15 20:50:32 kind-worker3 kubelet[589656]: I0915 20:50:32.505693  589656 kubelet_pods.go:1145] "Clean up orphaned pod statuses"
Sep 15 20:50:32 kind-worker3 kubelet[589656]: I0915 20:50:32.507985  589656 kubelet_pods.go:1164] "Clean up orphaned pod directories"
Sep 15 20:50:32 kind-worker3 kubelet[589656]: I0915 20:50:32.508119  589656 kubelet_pods.go:1175] "Clean up orphaned mirror pods"
Sep 15 20:50:32 kind-worker3 kubelet[589656]: I0915 20:50:32.508145  589656 kubelet_pods.go:1182] "Clean up orphaned pod cgroups"
Sep 15 20:50:32 kind-worker3 kubelet[589656]: I0915 20:50:32.508174  589656 kubelet.go:2168] "SyncLoop (housekeeping) end"
Sep 15 20:50:33 kind-worker3 kubelet[589656]: I0915 20:50:33.809723  589656 setters.go:88] "Using node IP" IP="172.18.0.4"
Sep 15 20:50:34 kind-worker3 kubelet[589656]: I0915 20:50:34.485570  589656 eviction_manager.go:237] "Eviction manager: synchronize housekeeping"
Sep 15 20:50:34 kind-worker3 kubelet[589656]: I0915 20:50:34.498356  589656 kubelet.go:2160] "SyncLoop (housekeeping)"
Sep 15 20:50:34 kind-worker3 kubelet[589656]: I0915 20:50:34.507938  589656 kubelet_pods.go:1079] "Clean up pod workers for terminated pods"
Sep 15 20:50:34 kind-worker3 kubelet[589656]: I0915 20:50:34.508023  589656 kubelet_pods.go:1108] "Clean up probes for terminated pods"
Sep 15 20:50:34 kind-worker3 kubelet[589656]: I0915 20:50:34.509681  589656 kubelet_pods.go:1145] "Clean up orphaned pod statuses"
Sep 15 20:50:34 kind-worker3 kubelet[589656]: I0915 20:50:34.512163  589656 kubelet_pods.go:1164] "Clean up orphaned pod directories"
Sep 15 20:50:34 kind-worker3 kubelet[589656]: I0915 20:50:34.512350  589656 kubelet_pods.go:1175] "Clean up orphaned mirror pods"
Sep 15 20:50:34 kind-worker3 kubelet[589656]: I0915 20:50:34.512391  589656 kubelet_pods.go:1182] "Clean up orphaned pod cgroups"
Sep 15 20:50:34 kind-worker3 kubelet[589656]: I0915 20:50:34.512437  589656 kubelet.go:2168] "SyncLoop (housekeeping) end"
Sep 15 20:50:34 kind-worker3 kubelet[589656]: I0915 20:50:34.518419  589656 cri_stats_provider.go:525] "Unable to find network stats for sandbox" sandboxID="d0f4d02598fe0e9a32081b1554ae85df2b4224eb9a378fdcf99aa7c0035d33dc"
Sep 15 20:50:34 kind-worker3 kubelet[589656]: I0915 20:50:34.518907  589656 cri_stats_provider.go:525] "Unable to find network stats for sandbox" sandboxID="b477a0e3bdd1b445ce34dc6f173590a56dbfec252950ee838d5af2a2515a773b"
Sep 15 20:50:34 kind-worker3 kubelet[589656]: I0915 20:50:34.521655  589656 helpers.go:775] "Eviction manager:" log="observations" signal=allocatableMemory.available resourceName="8106236Ki" capacity="8166760Ki" time="2023-09-15 20:50:34.521453678 +0000 UTC m=+2146498.444278832"
Sep 15 20:50:34 kind-worker3 kubelet[589656]: I0915 20:50:34.521709  589656 helpers.go:775] "Eviction manager:" log="observations" signal=nodefs.available resourceName="7753108Ki" capacity="51341792Ki" time="2023-09-15 20:50:34.487555917 +0000 UTC m=+2146498.410381061"
Sep 15 20:50:34 kind-worker3 kubelet[589656]: I0915 20:50:34.521739  589656 helpers.go:775] "Eviction manager:" log="observations" signal=nodefs.inodesFree resourceName="2345607" capacity="3276800" time="2023-09-15 20:50:34.487555917 +0000 UTC m=+2146498.410381061"
Sep 15 20:50:34 kind-worker3 kubelet[589656]: I0915 20:50:34.521765  589656 helpers.go:775] "Eviction manager:" log="observations" signal=imagefs.available resourceName="7753108Ki" capacity="51341792Ki" time="2023-09-15 20:50:28.906353957 +0000 UTC"
Sep 15 20:50:34 kind-worker3 kubelet[589656]: I0915 20:50:34.521790  589656 helpers.go:775] "Eviction manager:" log="observations" signal=imagefs.inodesFree resourceName="2345607" capacity="3276800" time="2023-09-15 20:50:28.906353957 +0000 UTC"
Sep 15 20:50:34 kind-worker3 kubelet[589656]: I0915 20:50:34.521815  589656 helpers.go:775] "Eviction manager:" log="observations" signal=pid.available resourceName="62207" capacity="63272" time="2023-09-15 20:50:34.519388055 +0000 UTC m=+2146498.442213187"
Sep 15 20:50:34 kind-worker3 kubelet[589656]: I0915 20:50:34.521843  589656 helpers.go:775] "Eviction manager:" log="observations" signal=memory.available resourceName="7891456Ki" capacity="8166760Ki" time="2023-09-15 20:50:34.487555917 +0000 UTC m=+2146498.410381061"
Sep 15 20:50:34 kind-worker3 kubelet[589656]: I0915 20:50:34.521909  589656 eviction_manager.go:328] "Eviction manager: no resources are starved"
Sep 15 20:50:34 kind-worker3 kubelet[589656]: I0915 20:50:34.991462  589656 kubelet.go:2346] "Container runtime status" status="Runtime Conditions: RuntimeReady=true reason: message:, NetworkReady=true reason: message:"
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.256919  589656 config.go:279] "Setting pods for source" source="file"
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.497606  589656 kubelet.go:2160] "SyncLoop (housekeeping)"
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.519464  589656 kubelet_pods.go:1079] "Clean up pod workers for terminated pods"
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.519822  589656 kubelet_pods.go:1108] "Clean up probes for terminated pods"
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.521894  589656 kubelet_pods.go:1145] "Clean up orphaned pod statuses"
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.523111  589656 kubelet_pods.go:1164] "Clean up orphaned pod directories"
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.523444  589656 kubelet_pods.go:1175] "Clean up orphaned mirror pods"
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.523683  589656 kubelet_pods.go:1182] "Clean up orphaned pod cgroups"
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.523933  589656 kubelet.go:2168] "SyncLoop (housekeeping) end"
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.523209  589656 factory.go:262] Factory "containerd" was unable to handle container "/sys-kernel-debug.mount"
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.524334  589656 factory.go:255] Factory "systemd" can handle container "/sys-kernel-debug.mount", but ignoring.
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.524555  589656 manager.go:925] ignoring container "/sys-kernel-debug.mount"
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.524740  589656 factory.go:262] Factory "containerd" was unable to handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-podd2a8b1e2_f8ec_4685_881d_a4d1c26134c2.slice"
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.524991  589656 factory.go:262] Factory "systemd" was unable to handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-podd2a8b1e2_f8ec_4685_881d_a4d1c26134c2.slice"
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.525201  589656 factory.go:255] Factory "raw" can handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-podd2a8b1e2_f8ec_4685_881d_a4d1c26134c2.slice", but ignoring.
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.525361  589656 manager.go:925] ignoring container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-podd2a8b1e2_f8ec_4685_881d_a4d1c26134c2.slice"
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.525520  589656 factory.go:262] Factory "containerd" was unable to handle container "/sys-fs-fuse-connections.mount"
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.525694  589656 factory.go:255] Factory "systemd" can handle container "/sys-fs-fuse-connections.mount", but ignoring.
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.525846  589656 manager.go:925] ignoring container "/sys-fs-fuse-connections.mount"
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.526088  589656 factory.go:262] Factory "containerd" was unable to handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/sys-kernel-tracing.mount"
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.526475  589656 factory.go:255] Factory "systemd" can handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/sys-kernel-tracing.mount", but ignoring.
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.526757  589656 manager.go:925] ignoring container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/sys-kernel-tracing.mount"
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.527100  589656 factory.go:262] Factory "containerd" was unable to handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-besteffort.slice/kubelet-kubepods-besteffort-pod6b53eb8b_e28c_454a_92e9_b342af428fa5.slice"
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.527367  589656 factory.go:262] Factory "systemd" was unable to handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-besteffort.slice/kubelet-kubepods-besteffort-pod6b53eb8b_e28c_454a_92e9_b342af428fa5.slice"
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.527685  589656 factory.go:255] Factory "raw" can handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-besteffort.slice/kubelet-kubepods-besteffort-pod6b53eb8b_e28c_454a_92e9_b342af428fa5.slice", but ignoring.
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.527914  589656 manager.go:925] ignoring container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-besteffort.slice/kubelet-kubepods-besteffort-pod6b53eb8b_e28c_454a_92e9_b342af428fa5.slice"
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.528128  589656 factory.go:262] Factory "containerd" was unable to handle container "/sys-kernel-tracing.mount"
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.528400  589656 factory.go:255] Factory "systemd" can handle container "/sys-kernel-tracing.mount", but ignoring.
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.528668  589656 manager.go:925] ignoring container "/sys-kernel-tracing.mount"
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.528929  589656 factory.go:262] Factory "containerd" was unable to handle container "/system.slice/system-modprobe.slice"
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.529222  589656 factory.go:262] Factory "systemd" was unable to handle container "/system.slice/system-modprobe.slice"
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.529411  589656 factory.go:255] Factory "raw" can handle container "/system.slice/system-modprobe.slice", but ignoring.
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.529575  589656 manager.go:925] ignoring container "/system.slice/system-modprobe.slice"
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.529799  589656 factory.go:262] Factory "containerd" was unable to handle container "/system.slice/systemd-journald.service"
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.530031  589656 factory.go:262] Factory "systemd" was unable to handle container "/system.slice/systemd-journald.service"
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.530269  589656 factory.go:255] Factory "raw" can handle container "/system.slice/systemd-journald.service", but ignoring.
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.530519  589656 manager.go:925] ignoring container "/system.slice/systemd-journald.service"
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.530791  589656 factory.go:262] Factory "containerd" was unable to handle container "/kubelet.slice"
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.532745  589656 factory.go:262] Factory "systemd" was unable to handle container "/kubelet.slice"
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.533057  589656 factory.go:255] Factory "raw" can handle container "/kubelet.slice", but ignoring.
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.533274  589656 manager.go:925] ignoring container "/kubelet.slice"
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.533530  589656 factory.go:262] Factory "containerd" was unable to handle container "/docker"
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.533763  589656 factory.go:262] Factory "systemd" was unable to handle container "/docker"
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.534029  589656 factory.go:255] Factory "raw" can handle container "/docker", but ignoring.
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.534280  589656 manager.go:925] ignoring container "/docker"
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.534528  589656 factory.go:262] Factory "containerd" was unable to handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/docker"
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.534775  589656 factory.go:262] Factory "systemd" was unable to handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/docker"
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.535018  589656 factory.go:255] Factory "raw" can handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/docker", but ignoring.
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.535228  589656 manager.go:925] ignoring container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/docker"
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.535418  589656 factory.go:262] Factory "containerd" was unable to handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/system.slice"
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.535603  589656 factory.go:262] Factory "systemd" was unable to handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/system.slice"
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.535887  589656 factory.go:255] Factory "raw" can handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/system.slice", but ignoring.
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.536041  589656 manager.go:925] ignoring container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/system.slice"
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.537279  589656 factory.go:251] Error trying to work out if we can handle /docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267: failed to load container: container "ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267" in namespace "k8s.io": not found
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.537337  589656 factory.go:262] Factory "containerd" was unable to handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267"
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.537381  589656 factory.go:262] Factory "systemd" was unable to handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267"
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.537418  589656 factory.go:255] Factory "raw" can handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267", but ignoring.
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.537460  589656 manager.go:925] ignoring container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267"
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.537495  589656 factory.go:262] Factory "containerd" was unable to handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-besteffort.slice"
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.537525  589656 factory.go:262] Factory "systemd" was unable to handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-besteffort.slice"
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.537557  589656 factory.go:255] Factory "raw" can handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-besteffort.slice", but ignoring.
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.537595  589656 manager.go:925] ignoring container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-besteffort.slice"
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.537631  589656 factory.go:262] Factory "containerd" was unable to handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet"
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.537675  589656 factory.go:262] Factory "systemd" was unable to handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet"
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.537709  589656 factory.go:255] Factory "raw" can handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet", but ignoring.
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.537741  589656 manager.go:925] ignoring container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet"
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.537772  589656 factory.go:262] Factory "containerd" was unable to handle container "/kubelet.slice/kubelet.service"
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.537805  589656 factory.go:262] Factory "systemd" was unable to handle container "/kubelet.slice/kubelet.service"
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.537837  589656 factory.go:255] Factory "raw" can handle container "/kubelet.slice/kubelet.service", but ignoring.
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.537874  589656 manager.go:925] ignoring container "/kubelet.slice/kubelet.service"
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.537906  589656 factory.go:262] Factory "containerd" was unable to handle container "/kubelet"
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.537938  589656 factory.go:262] Factory "systemd" was unable to handle container "/kubelet"
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.537969  589656 factory.go:255] Factory "raw" can handle container "/kubelet", but ignoring.
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.538004  589656 manager.go:925] ignoring container "/kubelet"
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.538040  589656 factory.go:262] Factory "containerd" was unable to handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/sys-kernel-debug.mount"
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.538090  589656 factory.go:255] Factory "systemd" can handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/sys-kernel-debug.mount", but ignoring.
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.538150  589656 manager.go:925] ignoring container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/sys-kernel-debug.mount"
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.538190  589656 factory.go:262] Factory "containerd" was unable to handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/system.slice/containerd.service"
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.538259  589656 factory.go:262] Factory "systemd" was unable to handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/system.slice/containerd.service"
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.538293  589656 factory.go:255] Factory "raw" can handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/system.slice/containerd.service", but ignoring.
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.538330  589656 manager.go:925] ignoring container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/system.slice/containerd.service"
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.539546  589656 factory.go:258] Using factory "containerd" for container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-podbf0ad039_0154_4821_ac30_f54e4366ba44.slice/cri-containerd-83b4ac624e9b1f62481346831f7105bdc5f161d3f48256bad09a5f08986e6a98.scope"
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.543306  589656 manager.go:988] Added container: "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-podbf0ad039_0154_4821_ac30_f54e4366ba44.slice/cri-containerd-83b4ac624e9b1f62481346831f7105bdc5f161d3f48256bad09a5f08986e6a98.scope" (aliases: [83b4ac624e9b1f62481346831f7105bdc5f161d3f48256bad09a5f08986e6a98 /docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-podbf0ad039_0154_4821_ac30_f54e4366ba44.slice/cri-containerd-83b4ac624e9b1f62481346831f7105bdc5f161d3f48256bad09a5f08986e6a98.scope], namespace: "containerd")
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.543982  589656 handler.go:325] Added event &{/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-podbf0ad039_0154_4821_ac30_f54e4366ba44.slice/cri-containerd-83b4ac624e9b1f62481346831f7105bdc5f161d3f48256bad09a5f08986e6a98.scope 2023-09-15 20:50:05.186323871 +0000 UTC containerCreation {<nil>}}
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.544139  589656 container.go:530] Start housekeeping for container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-podbf0ad039_0154_4821_ac30_f54e4366ba44.slice/cri-containerd-83b4ac624e9b1f62481346831f7105bdc5f161d3f48256bad09a5f08986e6a98.scope"
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.548018  589656 factory.go:258] Using factory "containerd" for container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-podbf0ad039_0154_4821_ac30_f54e4366ba44.slice/cri-containerd-44ca9b8d7d34d1d46a7dc77e9f5257d12c4f6d1670c45041be6079b15affd771.scope"
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.553245  589656 manager.go:988] Added container: "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-podbf0ad039_0154_4821_ac30_f54e4366ba44.slice/cri-containerd-44ca9b8d7d34d1d46a7dc77e9f5257d12c4f6d1670c45041be6079b15affd771.scope" (aliases: [44ca9b8d7d34d1d46a7dc77e9f5257d12c4f6d1670c45041be6079b15affd771 /docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-podbf0ad039_0154_4821_ac30_f54e4366ba44.slice/cri-containerd-44ca9b8d7d34d1d46a7dc77e9f5257d12c4f6d1670c45041be6079b15affd771.scope], namespace: "containerd")
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.553949  589656 handler.go:325] Added event &{/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-podbf0ad039_0154_4821_ac30_f54e4366ba44.slice/cri-containerd-44ca9b8d7d34d1d46a7dc77e9f5257d12c4f6d1670c45041be6079b15affd771.scope 2023-09-15 20:50:06.158317956 +0000 UTC containerCreation {<nil>}}
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.554017  589656 factory.go:262] Factory "containerd" was unable to handle container "/system.slice/containerd.service"
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.554044  589656 factory.go:262] Factory "systemd" was unable to handle container "/system.slice/containerd.service"
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.554065  589656 factory.go:255] Factory "raw" can handle container "/system.slice/containerd.service", but ignoring.
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.554090  589656 manager.go:925] ignoring container "/system.slice/containerd.service"
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.554127  589656 factory.go:262] Factory "containerd" was unable to handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet.slice"
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.554169  589656 factory.go:262] Factory "systemd" was unable to handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet.slice"
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.554191  589656 factory.go:255] Factory "raw" can handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet.slice", but ignoring.
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.554212  589656 manager.go:925] ignoring container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet.slice"
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.554230  589656 factory.go:262] Factory "containerd" was unable to handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet.slice/kubelet-kubepods.slice"
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.554248  589656 factory.go:262] Factory "systemd" was unable to handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet.slice/kubelet-kubepods.slice"
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.554268  589656 factory.go:255] Factory "raw" can handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet.slice/kubelet-kubepods.slice", but ignoring.
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.554287  589656 manager.go:925] ignoring container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet.slice/kubelet-kubepods.slice"
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.554318  589656 factory.go:262] Factory "containerd" was unable to handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-podbf0ad039_0154_4821_ac30_f54e4366ba44.slice"
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.554339  589656 factory.go:262] Factory "systemd" was unable to handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-podbf0ad039_0154_4821_ac30_f54e4366ba44.slice"
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.554363  589656 factory.go:255] Factory "raw" can handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-podbf0ad039_0154_4821_ac30_f54e4366ba44.slice", but ignoring.
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.554386  589656 manager.go:925] ignoring container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-podbf0ad039_0154_4821_ac30_f54e4366ba44.slice"
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.554407  589656 factory.go:262] Factory "containerd" was unable to handle container "/dev-hugepages.mount"
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.554425  589656 factory.go:255] Factory "systemd" can handle container "/dev-hugepages.mount", but ignoring.
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.554442  589656 manager.go:925] ignoring container "/dev-hugepages.mount"
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.554458  589656 factory.go:262] Factory "containerd" was unable to handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/system.slice/system-modprobe.slice"
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.554477  589656 factory.go:262] Factory "systemd" was unable to handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/system.slice/system-modprobe.slice"
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.554496  589656 factory.go:255] Factory "raw" can handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/system.slice/system-modprobe.slice", but ignoring.
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.554523  589656 manager.go:925] ignoring container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/system.slice/system-modprobe.slice"
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.554542  589656 factory.go:262] Factory "containerd" was unable to handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/dev-hugepages.mount"
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.554561  589656 factory.go:255] Factory "systemd" can handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/dev-hugepages.mount", but ignoring.
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.554621  589656 manager.go:925] ignoring container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/dev-hugepages.mount"
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.554647  589656 factory.go:262] Factory "containerd" was unable to handle container "/system.slice"
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.554663  589656 factory.go:262] Factory "systemd" was unable to handle container "/system.slice"
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.554680  589656 factory.go:255] Factory "raw" can handle container "/system.slice", but ignoring.
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.554701  589656 manager.go:925] ignoring container "/system.slice"
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.554804  589656 container.go:530] Start housekeeping for container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-podbf0ad039_0154_4821_ac30_f54e4366ba44.slice/cri-containerd-44ca9b8d7d34d1d46a7dc77e9f5257d12c4f6d1670c45041be6079b15affd771.scope"
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.555404  589656 factory.go:251] Error trying to work out if we can handle /docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267: failed to load container: container "ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267" in namespace "k8s.io": not found
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.555434  589656 factory.go:262] Factory "containerd" was unable to handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267"
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.555456  589656 factory.go:262] Factory "systemd" was unable to handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267"
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.555479  589656 factory.go:255] Factory "raw" can handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267", but ignoring.
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.555500  589656 manager.go:925] ignoring container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267"
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.555520  589656 factory.go:262] Factory "containerd" was unable to handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/sys-fs-fuse-connections.mount"
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.555539  589656 factory.go:255] Factory "systemd" can handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/sys-fs-fuse-connections.mount", but ignoring.
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.555561  589656 manager.go:925] ignoring container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/sys-fs-fuse-connections.mount"
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.555579  589656 factory.go:262] Factory "containerd" was unable to handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/system.slice/systemd-journald.service"
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.555597  589656 factory.go:262] Factory "systemd" was unable to handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/system.slice/systemd-journald.service"
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.555619  589656 factory.go:255] Factory "raw" can handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/system.slice/systemd-journald.service", but ignoring.
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.555640  589656 manager.go:925] ignoring container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/system.slice/systemd-journald.service"
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.555658  589656 factory.go:262] Factory "containerd" was unable to handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice"
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.555677  589656 factory.go:262] Factory "systemd" was unable to handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice"
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.555697  589656 factory.go:255] Factory "raw" can handle container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice", but ignoring.
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.555718  589656 manager.go:925] ignoring container "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice"
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.555743  589656 manager.go:1044] Destroyed container: "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-podf602fc75_3d22_475f_8c0a_de933744ab4e.slice/cri-containerd-5432e78771d09f84901cf4700d2078034e73119a187802ac085fa1e2e4829a62.scope" (aliases: [5432e78771d09f84901cf4700d2078034e73119a187802ac085fa1e2e4829a62 /docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-podf602fc75_3d22_475f_8c0a_de933744ab4e.slice/cri-containerd-5432e78771d09f84901cf4700d2078034e73119a187802ac085fa1e2e4829a62.scope], namespace: "containerd")
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.555796  589656 handler.go:325] Added event &{/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-podf602fc75_3d22_475f_8c0a_de933744ab4e.slice/cri-containerd-5432e78771d09f84901cf4700d2078034e73119a187802ac085fa1e2e4829a62.scope 2023-09-15 20:50:36.555787619 +0000 UTC m=+2146500.478612730 containerDeletion {<nil>}}
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.555834  589656 manager.go:1044] Destroyed container: "/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-podf602fc75_3d22_475f_8c0a_de933744ab4e.slice/cri-containerd-b553881ecd35bacb71b6c14fb9ca775d38c625d547bf3c076902f1ed25c4d0c1.scope" (aliases: [b553881ecd35bacb71b6c14fb9ca775d38c625d547bf3c076902f1ed25c4d0c1 /docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-podf602fc75_3d22_475f_8c0a_de933744ab4e.slice/cri-containerd-b553881ecd35bacb71b6c14fb9ca775d38c625d547bf3c076902f1ed25c4d0c1.scope], namespace: "containerd")
Sep 15 20:50:36 kind-worker3 kubelet[589656]: I0915 20:50:36.555863  589656 handler.go:325] Added event &{/docker/ce808bf2ae79438010845e5fe580f24e6b776922424627b084acf4ca06a6d267/kubelet.slice/kubelet-kubepods.slice/kubelet-kubepods-burstable.slice/kubelet-kubepods-burstable-podf602fc75_3d22_475f_8c0a_de933744ab4e.slice/cri-containerd-b553881ecd35bacb71b6c14fb9ca775d38c625d547bf3c076902f1ed25c4d0c1.scope 2023-09-15 20:50:36.555856848 +0000 UTC m=+2146500.478681954 containerDeletion {<nil>}}
Sep 15 20:50:38 kind-worker3 kubelet[589656]: I0915 20:50:38.498068  589656 kubelet.go:2160] "SyncLoop (housekeeping)"
Sep 15 20:50:38 kind-worker3 kubelet[589656]: I0915 20:50:38.507406  589656 kubelet_pods.go:1079] "Clean up pod workers for terminated pods"
Sep 15 20:50:38 kind-worker3 kubelet[589656]: I0915 20:50:38.507944  589656 kubelet_pods.go:1108] "Clean up probes for terminated pods"
Sep 15 20:50:38 kind-worker3 kubelet[589656]: I0915 20:50:38.508213  589656 kubelet_pods.go:1145] "Clean up orphaned pod statuses"
Sep 15 20:50:38 kind-worker3 kubelet[589656]: I0915 20:50:38.512290  589656 kubelet_pods.go:1164] "Clean up orphaned pod directories"
Sep 15 20:50:38 kind-worker3 kubelet[589656]: I0915 20:50:38.512446  589656 kubelet_pods.go:1175] "Clean up orphaned mirror pods"
Sep 15 20:50:38 kind-worker3 kubelet[589656]: I0915 20:50:38.512475  589656 kubelet_pods.go:1182] "Clean up orphaned pod cgroups"
Sep 15 20:50:38 kind-worker3 kubelet[589656]: I0915 20:50:38.512505  589656 kubelet.go:2168] "SyncLoop (housekeeping) end"
Sep 15 20:50:39 kind-worker3 kubelet[589656]: I0915 20:50:39.409387  589656 httplog.go:131] "HTTP" verb="GET" URI="/metrics/resource" latency="17.756933ms" userAgent="metrics-server/v0.6.3 (linux/amd64) kubernetes/a938798" audit-ID="" srcIP="172.18.0.3:35538" resp=200
Sep 15 20:50:39 kind-worker3 kubelet[589656]: I0915 20:50:39.574834  589656 kuberuntime_gc.go:171] "Removing sandbox" sandboxID="b553881ecd35bacb71b6c14fb9ca775d38c625d547bf3c076902f1ed25c4d0c1"
Sep 15 20:50:39 kind-worker3 kubelet[589656]: I0915 20:50:39.698167  589656 kuberuntime_gc.go:343] "Removing pod logs" podUID=f602fc75-3d22-475f-8c0a-de933744ab4e
Sep 15 20:50:39 kind-worker3 kubelet[589656]: I0915 20:50:39.698808  589656 kubelet.go:1280] "Container garbage collection succeeded"
Sep 15 20:50:39 kind-worker3 kubelet[589656]: I0915 20:50:39.993533  589656 kubelet.go:2346] "Container runtime status" status="Runtime Conditions: RuntimeReady=true reason: message:, NetworkReady=true reason: message:"
Sep 15 20:50:40 kind-worker3 kubelet[589656]: I0915 20:50:40.433958  589656 generic.go:155] "GenericPLEG" podUID=f602fc75-3d22-475f-8c0a-de933744ab4e containerID="b553881ecd35bacb71b6c14fb9ca775d38c625d547bf3c076902f1ed25c4d0c1" oldState=exited newState=non-existent
Sep 15 20:50:40 kind-worker3 kubelet[589656]: I0915 20:50:40.434038  589656 generic.go:399] "PLEG: Delete status for pod" podUID="f602fc75-3d22-475f-8c0a-de933744ab4e"
Sep 15 20:50:40 kind-worker3 kubelet[589656]: I0915 20:50:40.498542  589656 kubelet.go:2160] "SyncLoop (housekeeping)"
Sep 15 20:50:40 kind-worker3 kubelet[589656]: I0915 20:50:40.509804  589656 kubelet_pods.go:1079] "Clean up pod workers for terminated pods"
Sep 15 20:50:40 kind-worker3 kubelet[589656]: I0915 20:50:40.509876  589656 kubelet_pods.go:1108] "Clean up probes for terminated pods"
Sep 15 20:50:40 kind-worker3 kubelet[589656]: I0915 20:50:40.511766  589656 kubelet_pods.go:1145] "Clean up orphaned pod statuses"
Sep 15 20:50:40 kind-worker3 kubelet[589656]: I0915 20:50:40.512971  589656 kubelet_pods.go:1164] "Clean up orphaned pod directories"
Sep 15 20:50:40 kind-worker3 kubelet[589656]: I0915 20:50:40.513236  589656 kubelet_pods.go:1175] "Clean up orphaned mirror pods"
Sep 15 20:50:40 kind-worker3 kubelet[589656]: I0915 20:50:40.513275  589656 kubelet_pods.go:1182] "Clean up orphaned pod cgroups"
Sep 15 20:50:40 kind-worker3 kubelet[589656]: I0915 20:50:40.513318  589656 kubelet.go:2168] "SyncLoop (housekeeping) end"
Sep 15 20:50:41 kind-worker3 kubelet[589656]: I0915 20:50:41.482112  589656 handler.go:293] error while reading "/proc/589656/fd/38" link: readlink /proc/589656/fd/38: no such file or directory
Sep 15 20:50:42 kind-worker3 kubelet[589656]: I0915 20:50:42.498554  589656 kubelet.go:2160] "SyncLoop (housekeeping)"
Sep 15 20:50:42 kind-worker3 kubelet[589656]: I0915 20:50:42.506062  589656 kubelet_pods.go:1079] "Clean up pod workers for terminated pods"
Sep 15 20:50:42 kind-worker3 kubelet[589656]: I0915 20:50:42.506114  589656 kubelet_pods.go:1108] "Clean up probes for terminated pods"
Sep 15 20:50:42 kind-worker3 kubelet[589656]: I0915 20:50:42.506139  589656 kubelet_pods.go:1145] "Clean up orphaned pod statuses"
Sep 15 20:50:42 kind-worker3 kubelet[589656]: I0915 20:50:42.507855  589656 kubelet_pods.go:1164] "Clean up orphaned pod directories"
Sep 15 20:50:42 kind-worker3 kubelet[589656]: I0915 20:50:42.508008  589656 kubelet_pods.go:1175] "Clean up orphaned mirror pods"
Sep 15 20:50:42 kind-worker3 kubelet[589656]: I0915 20:50:42.508045  589656 kubelet_pods.go:1182] "Clean up orphaned pod cgroups"
Sep 15 20:50:42 kind-worker3 kubelet[589656]: I0915 20:50:42.508076  589656 kubelet.go:2168] "SyncLoop (housekeeping) end"
Sep 15 20:50:44 kind-worker3 kubelet[589656]: I0915 20:50:44.049703  589656 setters.go:88] "Using node IP" IP="172.18.0.4"
Sep 15 20:50:44 kind-worker3 kubelet[589656]: I0915 20:50:44.501593  589656 kubelet.go:2160] "SyncLoop (housekeeping)"
Sep 15 20:50:44 kind-worker3 kubelet[589656]: I0915 20:50:44.510145  589656 kubelet_pods.go:1079] "Clean up pod workers for terminated pods"
Sep 15 20:50:44 kind-worker3 kubelet[589656]: I0915 20:50:44.510207  589656 kubelet_pods.go:1108] "Clean up probes for terminated pods"
Sep 15 20:50:44 kind-worker3 kubelet[589656]: I0915 20:50:44.512015  589656 kubelet_pods.go:1145] "Clean up orphaned pod statuses"
Sep 15 20:50:44 kind-worker3 kubelet[589656]: I0915 20:50:44.513106  589656 kubelet_pods.go:1164] "Clean up orphaned pod directories"
Sep 15 20:50:44 kind-worker3 kubelet[589656]: I0915 20:50:44.513249  589656 kubelet_pods.go:1175] "Clean up orphaned mirror pods"
Sep 15 20:50:44 kind-worker3 kubelet[589656]: I0915 20:50:44.513301  589656 kubelet_pods.go:1182] "Clean up orphaned pod cgroups"
Sep 15 20:50:44 kind-worker3 kubelet[589656]: I0915 20:50:44.513334  589656 kubelet.go:2168] "SyncLoop (housekeeping) end"
Sep 15 20:50:44 kind-worker3 kubelet[589656]: I0915 20:50:44.522932  589656 eviction_manager.go:237] "Eviction manager: synchronize housekeeping"
Sep 15 20:50:44 kind-worker3 kubelet[589656]: I0915 20:50:44.554892  589656 cri_stats_provider.go:525] "Unable to find network stats for sandbox" sandboxID="b477a0e3bdd1b445ce34dc6f173590a56dbfec252950ee838d5af2a2515a773b"
Sep 15 20:50:44 kind-worker3 kubelet[589656]: I0915 20:50:44.555069  589656 cri_stats_provider.go:525] "Unable to find network stats for sandbox" sandboxID="83b4ac624e9b1f62481346831f7105bdc5f161d3f48256bad09a5f08986e6a98"
Sep 15 20:50:44 kind-worker3 kubelet[589656]: I0915 20:50:44.555235  589656 cri_stats_provider.go:525] "Unable to find network stats for sandbox" sandboxID="d0f4d02598fe0e9a32081b1554ae85df2b4224eb9a378fdcf99aa7c0035d33dc"
Sep 15 20:50:44 kind-worker3 kubelet[589656]: I0915 20:50:44.558109  589656 helpers.go:775] "Eviction manager:" log="observations" signal=memory.available resourceName="7889728Ki" capacity="8166760Ki" time="2023-09-15 20:50:44.524879824 +0000 UTC m=+2146508.447704979"
Sep 15 20:50:44 kind-worker3 kubelet[589656]: I0915 20:50:44.558159  589656 helpers.go:775] "Eviction manager:" log="observations" signal=allocatableMemory.available resourceName="8105988Ki" capacity="8166760Ki" time="2023-09-15 20:50:44.557915247 +0000 UTC m=+2146508.480740397"
Sep 15 20:50:44 kind-worker3 kubelet[589656]: I0915 20:50:44.558188  589656 helpers.go:775] "Eviction manager:" log="observations" signal=nodefs.available resourceName="7748388Ki" capacity="51341792Ki" time="2023-09-15 20:50:44.524879824 +0000 UTC m=+2146508.447704979"
Sep 15 20:50:44 kind-worker3 kubelet[589656]: I0915 20:50:44.558216  589656 helpers.go:775] "Eviction manager:" log="observations" signal=nodefs.inodesFree resourceName="2345622" capacity="3276800" time="2023-09-15 20:50:44.524879824 +0000 UTC m=+2146508.447704979"
Sep 15 20:50:44 kind-worker3 kubelet[589656]: I0915 20:50:44.558273  589656 helpers.go:775] "Eviction manager:" log="observations" signal=imagefs.available resourceName="7748388Ki" capacity="51341792Ki" time="2023-09-15 20:50:38.906537336 +0000 UTC"
Sep 15 20:50:44 kind-worker3 kubelet[589656]: I0915 20:50:44.558302  589656 helpers.go:775] "Eviction manager:" log="observations" signal=imagefs.inodesFree resourceName="2345622" capacity="3276800" time="2023-09-15 20:50:38.906537336 +0000 UTC"
Sep 15 20:50:44 kind-worker3 kubelet[589656]: I0915 20:50:44.558329  589656 helpers.go:775] "Eviction manager:" log="observations" signal=pid.available resourceName="62190" capacity="63272" time="2023-09-15 20:50:44.555717948 +0000 UTC m=+2146508.478543101"
Sep 15 20:50:44 kind-worker3 kubelet[589656]: I0915 20:50:44.558378  589656 eviction_manager.go:328] "Eviction manager: no resources are starved"
Sep 15 20:50:44 kind-worker3 kubelet[589656]: I0915 20:50:44.995602  589656 kubelet.go:2346] "Container runtime status" status="Runtime Conditions: RuntimeReady=true reason: message:, NetworkReady=true reason: message:"
Sep 15 20:50:45 kind-worker3 kubelet[589656]: I0915 20:50:45.414178  589656 oom_linux.go:66] attempting to set "/proc/589656/oom_score_adj" to "-999"
Sep 15 20:50:46 kind-worker3 kubelet[589656]: I0915 20:50:46.498050  589656 kubelet.go:2160] "SyncLoop (housekeeping)"
Sep 15 20:50:46 kind-worker3 kubelet[589656]: I0915 20:50:46.505940  589656 kubelet_pods.go:1079] "Clean up pod workers for terminated pods"
Sep 15 20:50:46 kind-worker3 kubelet[589656]: I0915 20:50:46.505988  589656 kubelet_pods.go:1108] "Clean up probes for terminated pods"
Sep 15 20:50:46 kind-worker3 kubelet[589656]: I0915 20:50:46.506013  589656 kubelet_pods.go:1145] "Clean up orphaned pod statuses"
Sep 15 20:50:46 kind-worker3 kubelet[589656]: I0915 20:50:46.509381  589656 kubelet_pods.go:1164] "Clean up orphaned pod directories"
Sep 15 20:50:46 kind-worker3 kubelet[589656]: I0915 20:50:46.509573  589656 kubelet_pods.go:1175] "Clean up orphaned mirror pods"
Sep 15 20:50:46 kind-worker3 kubelet[589656]: I0915 20:50:46.509606  589656 kubelet_pods.go:1182] "Clean up orphaned pod cgroups"
Sep 15 20:50:46 kind-worker3 kubelet[589656]: I0915 20:50:46.509655  589656 kubelet.go:2168] "SyncLoop (housekeeping) end"
Sep 15 20:50:48 kind-worker3 kubelet[589656]: I0915 20:50:48.498382  589656 kubelet.go:2160] "SyncLoop (housekeeping)"
Sep 15 20:50:48 kind-worker3 kubelet[589656]: I0915 20:50:48.506338  589656 kubelet_pods.go:1079] "Clean up pod workers for terminated pods"
Sep 15 20:50:48 kind-worker3 kubelet[589656]: I0915 20:50:48.506404  589656 kubelet_pods.go:1108] "Clean up probes for terminated pods"
Sep 15 20:50:48 kind-worker3 kubelet[589656]: I0915 20:50:48.508721  589656 kubelet_pods.go:1145] "Clean up orphaned pod statuses"
Sep 15 20:50:48 kind-worker3 kubelet[589656]: I0915 20:50:48.510774  589656 kubelet_pods.go:1164] "Clean up orphaned pod directories"
Sep 15 20:50:48 kind-worker3 kubelet[589656]: I0915 20:50:48.510945  589656 kubelet_pods.go:1175] "Clean up orphaned mirror pods"
Sep 15 20:50:48 kind-worker3 kubelet[589656]: I0915 20:50:48.510974  589656 kubelet_pods.go:1182] "Clean up orphaned pod cgroups"
Sep 15 20:50:48 kind-worker3 kubelet[589656]: I0915 20:50:48.511005  589656 kubelet.go:2168] "SyncLoop (housekeeping) end"
Sep 15 20:50:49 kind-worker3 kubelet[589656]: I0915 20:50:49.395113  589656 cri_stats_provider.go:347] "Unable to find cadvisor stats for container" containerID="44ca9b8d7d34d1d46a7dc77e9f5257d12c4f6d1670c45041be6079b15affd771"
Sep 15 20:50:49 kind-worker3 kubelet[589656]: I0915 20:50:49.397192  589656 httplog.go:131] "HTTP" verb="GET" URI="/metrics/resource" latency="13.485741ms" userAgent="metrics-server/v0.6.3 (linux/amd64) kubernetes/a938798" audit-ID="" srcIP="172.18.0.3:35538" resp=200
Sep 15 20:50:49 kind-worker3 kubelet[589656]: I0915 20:50:49.997488  589656 kubelet.go:2346] "Container runtime status" status="Runtime Conditions: RuntimeReady=true reason: message:, NetworkReady=true reason: message:"
Sep 15 20:50:50 kind-worker3 kubelet[589656]: I0915 20:50:50.498038  589656 kubelet.go:2160] "SyncLoop (housekeeping)"
Sep 15 20:50:50 kind-worker3 kubelet[589656]: I0915 20:50:50.511656  589656 kubelet_pods.go:1079] "Clean up pod workers for terminated pods"
Sep 15 20:50:50 kind-worker3 kubelet[589656]: I0915 20:50:50.511739  589656 kubelet_pods.go:1108] "Clean up probes for terminated pods"
Sep 15 20:50:50 kind-worker3 kubelet[589656]: I0915 20:50:50.513422  589656 kubelet_pods.go:1145] "Clean up orphaned pod statuses"
Sep 15 20:50:50 kind-worker3 kubelet[589656]: I0915 20:50:50.514917  589656 kubelet_pods.go:1164] "Clean up orphaned pod directories"
Sep 15 20:50:50 kind-worker3 kubelet[589656]: I0915 20:50:50.515120  589656 kubelet_pods.go:1175] "Clean up orphaned mirror pods"
Sep 15 20:50:50 kind-worker3 kubelet[589656]: I0915 20:50:50.515160  589656 kubelet_pods.go:1182] "Clean up orphaned pod cgroups"
Sep 15 20:50:50 kind-worker3 kubelet[589656]: I0915 20:50:50.515195  589656 kubelet.go:2168] "SyncLoop (housekeeping) end"
Sep 15 20:50:52 kind-worker3 kubelet[589656]: I0915 20:50:52.497996  589656 kubelet.go:2160] "SyncLoop (housekeeping)"
Sep 15 20:50:52 kind-worker3 kubelet[589656]: I0915 20:50:52.511294  589656 kubelet_pods.go:1079] "Clean up pod workers for terminated pods"
Sep 15 20:50:52 kind-worker3 kubelet[589656]: I0915 20:50:52.511381  589656 kubelet_pods.go:1108] "Clean up probes for terminated pods"
Sep 15 20:50:52 kind-worker3 kubelet[589656]: I0915 20:50:52.511423  589656 kubelet_pods.go:1145] "Clean up orphaned pod statuses"
Sep 15 20:50:52 kind-worker3 kubelet[589656]: I0915 20:50:52.515368  589656 kubelet_pods.go:1164] "Clean up orphaned pod directories"
Sep 15 20:50:52 kind-worker3 kubelet[589656]: I0915 20:50:52.515574  589656 kubelet_pods.go:1175] "Clean up orphaned mirror pods"
Sep 15 20:50:52 kind-worker3 kubelet[589656]: I0915 20:50:52.515634  589656 kubelet_pods.go:1182] "Clean up orphaned pod cgroups"
Sep 15 20:50:52 kind-worker3 kubelet[589656]: I0915 20:50:52.515694  589656 kubelet.go:2168] "SyncLoop (housekeeping) end"
Sep 15 20:50:54 kind-worker3 kubelet[589656]: I0915 20:50:54.425209  589656 setters.go:88] "Using node IP" IP="172.18.0.4"
Sep 15 20:50:54 kind-worker3 kubelet[589656]: I0915 20:50:54.498276  589656 kubelet.go:2129] "SyncLoop (SYNC) pods" total=1 pods=[kube-system/kindnet-mxmhl]
Sep 15 20:50:54 kind-worker3 kubelet[589656]: I0915 20:50:54.498421  589656 kubelet.go:2160] "SyncLoop (housekeeping)"
Sep 15 20:50:54 kind-worker3 kubelet[589656]: I0915 20:50:54.499816  589656 pod_workers.go:888] "Processing pod event" pod="kube-system/kindnet-mxmhl" podUID=d2a8b1e2-f8ec-4685-881d-a4d1c26134c2 updateType=0
Sep 15 20:50:54 kind-worker3 kubelet[589656]: I0915 20:50:54.499886  589656 kubelet.go:1501] "syncPod enter" pod="kube-system/kindnet-mxmhl" podUID=d2a8b1e2-f8ec-4685-881d-a4d1c26134c2
Sep 15 20:50:54 kind-worker3 kubelet[589656]: I0915 20:50:54.499938  589656 kubelet_pods.go:1432] "Generating pod status" pod="kube-system/kindnet-mxmhl"
Sep 15 20:50:54 kind-worker3 kubelet[589656]: I0915 20:50:54.500040  589656 kubelet_pods.go:1444] "Got phase for pod" pod="kube-system/kindnet-mxmhl" oldPhase=Running phase=Running
Sep 15 20:50:54 kind-worker3 kubelet[589656]: I0915 20:50:54.500288  589656 status_manager.go:535] "Ignoring same status for pod" pod="kube-system/kindnet-mxmhl" status={Phase:Running Conditions:[{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-14 00:07:50 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-07-15 14:56:50 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-07-15 14:56:50 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-04-14 00:07:47 +0000 UTC Reason: Message:}] Message: Reason: NominatedNodeName: HostIP:172.18.0.4 PodIP:172.18.0.4 PodIPs:[{IP:172.18.0.4}] StartTime:2023-04-14 00:07:50 +0000 UTC InitContainerStatuses:[] ContainerStatuses:[{Name:kindnet-cni State:{Waiting:nil Running:&ContainerStateRunning{StartedAt:2023-07-15 14:56:49 +0000 UTC,} Terminated:nil} LastTerminationState:{Waiting:nil Running:nil Terminated:&ContainerStateTerminated{ExitCode:255,Signal:0,Reason:Unknown,Message:,StartedAt:2023-05-13 23:24:24 +0000 UTC,FinishedAt:2023-07-15 14:56:13 +0000 UTC,ContainerID:containerd://f98e00c8217d4308a58d79ba51534150a7f921ba9587fc5badea4fb5300ee3b7,}} Ready:true RestartCount:2 Image:docker.io/kindest/kindnetd:v20221004-44d545d1 ImageID:sha256:d6e3e26021b60c625f0ef5b2dd3f9e22d2d398e05bccc4fdd7d59fbbb6a04d3f ContainerID:containerd://ec9b47aba6f0d651c6da6e8282ad0e4f699e83e716938f3c1f3f34bb4edc2aa2 Started:0xc000599499}] QOSClass:Guaranteed EphemeralContainerStatuses:[]}
Sep 15 20:50:54 kind-worker3 kubelet[589656]: I0915 20:50:54.500679  589656 volume_manager.go:404] "Waiting for volumes to attach and mount for pod" pod="kube-system/kindnet-mxmhl"
Sep 15 20:50:54 kind-worker3 kubelet[589656]: I0915 20:50:54.500733  589656 volume_manager.go:435] "All volumes are attached and mounted for pod" pod="kube-system/kindnet-mxmhl"
Sep 15 20:50:54 kind-worker3 kubelet[589656]: I0915 20:50:54.501090  589656 kuberuntime_manager.go:714] "computePodActions got for pod" podActions={KillPod:false CreateSandbox:false SandboxID:b477a0e3bdd1b445ce34dc6f173590a56dbfec252950ee838d5af2a2515a773b Attempt:2 NextInitContainerToStart:nil ContainersToStart:[] ContainersToKill:map[] EphemeralContainersToStart:[]} pod="kube-system/kindnet-mxmhl"
Sep 15 20:50:54 kind-worker3 kubelet[589656]: I0915 20:50:54.501256  589656 kubelet.go:1503] "syncPod exit" pod="kube-system/kindnet-mxmhl" podUID=d2a8b1e2-f8ec-4685-881d-a4d1c26134c2 isTerminal=false
Sep 15 20:50:54 kind-worker3 kubelet[589656]: I0915 20:50:54.501308  589656 pod_workers.go:988] "Processing pod event done" pod="kube-system/kindnet-mxmhl" podUID=d2a8b1e2-f8ec-4685-881d-a4d1c26134c2 updateType=0
Sep 15 20:50:54 kind-worker3 kubelet[589656]: I0915 20:50:54.508275  589656 kubelet_pods.go:1079] "Clean up pod workers for terminated pods"
Sep 15 20:50:54 kind-worker3 kubelet[589656]: I0915 20:50:54.508325  589656 kubelet_pods.go:1108] "Clean up probes for terminated pods"
Sep 15 20:50:54 kind-worker3 kubelet[589656]: I0915 20:50:54.509577  589656 desired_state_of_world_populator.go:309] "Added volume to desired state" pod="kube-system/kindnet-mxmhl" volumeName="cni-cfg" volumeSpecName="cni-cfg"
Sep 15 20:50:54 kind-worker3 kubelet[589656]: I0915 20:50:54.509715  589656 desired_state_of_world_populator.go:309] "Added volume to desired state" pod="kube-system/kindnet-mxmhl" volumeName="xtables-lock" volumeSpecName="xtables-lock"
Sep 15 20:50:54 kind-worker3 kubelet[589656]: I0915 20:50:54.509834  589656 desired_state_of_world_populator.go:309] "Added volume to desired state" pod="kube-system/kindnet-mxmhl" volumeName="lib-modules" volumeSpecName="lib-modules"
Sep 15 20:50:54 kind-worker3 kubelet[589656]: I0915 20:50:54.509901  589656 kubelet_pods.go:1145] "Clean up orphaned pod statuses"
Sep 15 20:50:54 kind-worker3 kubelet[589656]: I0915 20:50:54.510017  589656 desired_state_of_world_populator.go:309] "Added volume to desired state" pod="kube-system/kindnet-mxmhl" volumeName="kube-api-access-2d7bz" volumeSpecName="kube-api-access-2d7bz"
Sep 15 20:50:54 kind-worker3 kubelet[589656]: I0915 20:50:54.511194  589656 kubelet_pods.go:1164] "Clean up orphaned pod directories"
Sep 15 20:50:54 kind-worker3 kubelet[589656]: I0915 20:50:54.511405  589656 kubelet_pods.go:1175] "Clean up orphaned mirror pods"
Sep 15 20:50:54 kind-worker3 kubelet[589656]: I0915 20:50:54.511470  589656 kubelet_pods.go:1182] "Clean up orphaned pod cgroups"
Sep 15 20:50:54 kind-worker3 kubelet[589656]: I0915 20:50:54.511522  589656 kubelet.go:2168] "SyncLoop (housekeeping) end"
Sep 15 20:50:54 kind-worker3 kubelet[589656]: I0915 20:50:54.559450  589656 eviction_manager.go:237] "Eviction manager: synchronize housekeeping"
Sep 15 20:50:54 kind-worker3 kubelet[589656]: I0915 20:50:54.565773  589656 reconciler.go:243] "Starting operationExecutor.MountVolume for volume \"kube-api-access-2d7bz\" (UniqueName: \"kubernetes.io/projected/d2a8b1e2-f8ec-4685-881d-a4d1c26134c2-kube-api-access-2d7bz\") pod \"kindnet-mxmhl\" (UID: \"d2a8b1e2-f8ec-4685-881d-a4d1c26134c2\") Volume is already mounted to pod, but remount was requested." pod="kube-system/kindnet-mxmhl"
Sep 15 20:50:54 kind-worker3 kubelet[589656]: I0915 20:50:54.566292  589656 projected.go:183] Setting up volume kube-api-access-2d7bz for pod d2a8b1e2-f8ec-4685-881d-a4d1c26134c2 at /var/lib/kubelet/pods/d2a8b1e2-f8ec-4685-881d-a4d1c26134c2/volumes/kubernetes.io~projected/kube-api-access-2d7bz
Sep 15 20:50:54 kind-worker3 kubelet[589656]: I0915 20:50:54.567455  589656 atomic_writer.go:161] pod kube-system/kindnet-mxmhl volume kube-api-access-2d7bz: no update required for target directory /var/lib/kubelet/pods/d2a8b1e2-f8ec-4685-881d-a4d1c26134c2/volumes/kubernetes.io~projected/kube-api-access-2d7bz
Sep 15 20:50:54 kind-worker3 kubelet[589656]: I0915 20:50:54.567779  589656 operation_generator.go:703] "MountVolume.SetUp succeeded for volume \"kube-api-access-2d7bz\" (UniqueName: \"kubernetes.io/projected/d2a8b1e2-f8ec-4685-881d-a4d1c26134c2-kube-api-access-2d7bz\") pod \"kindnet-mxmhl\" (UID: \"d2a8b1e2-f8ec-4685-881d-a4d1c26134c2\") " pod="kube-system/kindnet-mxmhl"
Sep 15 20:50:54 kind-worker3 kubelet[589656]: I0915 20:50:54.600160  589656 cri_stats_provider.go:525] "Unable to find network stats for sandbox" sandboxID="b477a0e3bdd1b445ce34dc6f173590a56dbfec252950ee838d5af2a2515a773b"
Sep 15 20:50:54 kind-worker3 kubelet[589656]: I0915 20:50:54.600310  589656 cri_stats_provider.go:525] "Unable to find network stats for sandbox" sandboxID="83b4ac624e9b1f62481346831f7105bdc5f161d3f48256bad09a5f08986e6a98"
Sep 15 20:50:54 kind-worker3 kubelet[589656]: I0915 20:50:54.600487  589656 cri_stats_provider.go:525] "Unable to find network stats for sandbox" sandboxID="d0f4d02598fe0e9a32081b1554ae85df2b4224eb9a378fdcf99aa7c0035d33dc"
Sep 15 20:50:54 kind-worker3 kubelet[589656]: I0915 20:50:54.603201  589656 helpers.go:775] "Eviction manager:" log="observations" signal=imagefs.available resourceName="7743844Ki" capacity="51341792Ki" time="2023-09-15 20:50:48.905154586 +0000 UTC"
Sep 15 20:50:54 kind-worker3 kubelet[589656]: I0915 20:50:54.603250  589656 helpers.go:775] "Eviction manager:" log="observations" signal=imagefs.inodesFree resourceName="2345622" capacity="3276800" time="2023-09-15 20:50:48.905154586 +0000 UTC"
Sep 15 20:50:54 kind-worker3 kubelet[589656]: I0915 20:50:54.603280  589656 helpers.go:775] "Eviction manager:" log="observations" signal=pid.available resourceName="62201" capacity="63272" time="2023-09-15 20:50:54.600884826 +0000 UTC m=+2146518.523709947"
Sep 15 20:50:54 kind-worker3 kubelet[589656]: I0915 20:50:54.603308  589656 helpers.go:775] "Eviction manager:" log="observations" signal=memory.available resourceName="7892764Ki" capacity="8166760Ki" time="2023-09-15 20:50:54.561653933 +0000 UTC m=+2146518.484479129"
Sep 15 20:50:54 kind-worker3 kubelet[589656]: I0915 20:50:54.603334  589656 helpers.go:775] "Eviction manager:" log="observations" signal=allocatableMemory.available resourceName="8105980Ki" capacity="8166760Ki" time="2023-09-15 20:50:54.602991422 +0000 UTC m=+2146518.525816584"
Sep 15 20:50:54 kind-worker3 kubelet[589656]: I0915 20:50:54.603363  589656 helpers.go:775] "Eviction manager:" log="observations" signal=nodefs.available resourceName="7743844Ki" capacity="51341792Ki" time="2023-09-15 20:50:54.561653933 +0000 UTC m=+2146518.484479129"
Sep 15 20:50:54 kind-worker3 kubelet[589656]: I0915 20:50:54.603388  589656 helpers.go:775] "Eviction manager:" log="observations" signal=nodefs.inodesFree resourceName="2345622" capacity="3276800" time="2023-09-15 20:50:54.561653933 +0000 UTC m=+2146518.484479129"
Sep 15 20:50:54 kind-worker3 kubelet[589656]: I0915 20:50:54.603432  589656 eviction_manager.go:328] "Eviction manager: no resources are starved"
Sep 15 20:50:54 kind-worker3 kubelet[589656]: I0915 20:50:54.999697  589656 kubelet.go:2346] "Container runtime status" status="Runtime Conditions: RuntimeReady=true reason: message:, NetworkReady=true reason: message:"
Sep 15 20:50:56 kind-worker3 kubelet[589656]: I0915 20:50:56.256877  589656 config.go:279] "Setting pods for source" source="file"
Sep 15 20:50:56 kind-worker3 kubelet[589656]: I0915 20:50:56.498466  589656 kubelet.go:2160] "SyncLoop (housekeeping)"
Sep 15 20:50:56 kind-worker3 kubelet[589656]: I0915 20:50:56.521450  589656 kubelet_pods.go:1079] "Clean up pod workers for terminated pods"
Sep 15 20:50:56 kind-worker3 kubelet[589656]: I0915 20:50:56.521523  589656 kubelet_pods.go:1108] "Clean up probes for terminated pods"
Sep 15 20:50:56 kind-worker3 kubelet[589656]: I0915 20:50:56.525890  589656 kubelet_pods.go:1145] "Clean up orphaned pod statuses"
Sep 15 20:50:56 kind-worker3 kubelet[589656]: I0915 20:50:56.527975  589656 kubelet_pods.go:1164] "Clean up orphaned pod directories"
Sep 15 20:50:56 kind-worker3 kubelet[589656]: I0915 20:50:56.528420  589656 kubelet_pods.go:1175] "Clean up orphaned mirror pods"
Sep 15 20:50:56 kind-worker3 kubelet[589656]: I0915 20:50:56.528799  589656 kubelet_pods.go:1182] "Clean up orphaned pod cgroups"
Sep 15 20:50:56 kind-worker3 kubelet[589656]: I0915 20:50:56.529257  589656 kubelet.go:2168] "SyncLoop (housekeeping) end"
Sep 15 20:50:58 kind-worker3 kubelet[589656]: I0915 20:50:58.498354  589656 kubelet.go:2160] "SyncLoop (housekeeping)"
Sep 15 20:50:58 kind-worker3 kubelet[589656]: I0915 20:50:58.508107  589656 kubelet_pods.go:1079] "Clean up pod workers for terminated pods"
Sep 15 20:50:58 kind-worker3 kubelet[589656]: I0915 20:50:58.508160  589656 kubelet_pods.go:1108] "Clean up probes for terminated pods"
Sep 15 20:50:58 kind-worker3 kubelet[589656]: I0915 20:50:58.508184  589656 kubelet_pods.go:1145] "Clean up orphaned pod statuses"
Sep 15 20:50:58 kind-worker3 kubelet[589656]: I0915 20:50:58.510235  589656 kubelet_pods.go:1164] "Clean up orphaned pod directories"
Sep 15 20:50:58 kind-worker3 kubelet[589656]: I0915 20:50:58.510496  589656 kubelet_pods.go:1175] "Clean up orphaned mirror pods"
Sep 15 20:50:58 kind-worker3 kubelet[589656]: I0915 20:50:58.510537  589656 kubelet_pods.go:1182] "Clean up orphaned pod cgroups"
Sep 15 20:50:58 kind-worker3 kubelet[589656]: I0915 20:50:58.510569  589656 kubelet.go:2168] "SyncLoop (housekeeping) end"
Sep 15 20:50:59 kind-worker3 kubelet[589656]: I0915 20:50:59.438069  589656 cri_stats_provider.go:347] "Unable to find cadvisor stats for container" containerID="44ca9b8d7d34d1d46a7dc77e9f5257d12c4f6d1670c45041be6079b15affd771"
Sep 15 20:50:59 kind-worker3 kubelet[589656]: I0915 20:50:59.439299  589656 httplog.go:131] "HTTP" verb="GET" URI="/metrics/resource" latency="59.502066ms" userAgent="metrics-server/v0.6.3 (linux/amd64) kubernetes/a938798" audit-ID="" srcIP="172.18.0.3:35538" resp=200
