Apr 14 00:06:35 kind-worker2 systemd[1]: Condition check resulted in kubelet: The Kubernetes Node Agent being skipped.
Apr 14 00:07:33 kind-worker2 systemd[1]: Starting kubelet: The Kubernetes Node Agent...
Apr 14 00:07:33 kind-worker2 systemd[1]: Started kubelet: The Kubernetes Node Agent.
Apr 14 00:07:33 kind-worker2 kubelet[297]: Flag --container-runtime has been deprecated, will be removed in 1.27 as the only valid value is 'remote'
Apr 14 00:07:33 kind-worker2 kubelet[297]: Flag --pod-infra-container-image has been deprecated, will be removed in 1.27. Image garbage collector will get sandbox image information from CRI.
Apr 14 00:07:33 kind-worker2 kubelet[297]: Flag --provider-id has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Apr 14 00:07:33 kind-worker2 kubelet[297]: Flag --fail-swap-on has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Apr 14 00:07:33 kind-worker2 kubelet[297]: Flag --cgroup-root has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Apr 14 00:07:33 kind-worker2 kubelet[297]: I0414 00:07:33.327993     297 server.go:193] "--pod-infra-container-image will not be pruned by the image garbage collector in kubelet and should also be set in the remote runtime"
Apr 14 00:07:33 kind-worker2 kubelet[297]: Flag --container-runtime has been deprecated, will be removed in 1.27 as the only valid value is 'remote'
Apr 14 00:07:33 kind-worker2 kubelet[297]: Flag --pod-infra-container-image has been deprecated, will be removed in 1.27. Image garbage collector will get sandbox image information from CRI.
Apr 14 00:07:33 kind-worker2 kubelet[297]: Flag --provider-id has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Apr 14 00:07:33 kind-worker2 kubelet[297]: Flag --fail-swap-on has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Apr 14 00:07:33 kind-worker2 kubelet[297]: Flag --cgroup-root has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
Apr 14 00:07:33 kind-worker2 kubelet[297]: I0414 00:07:33.795310     297 server.go:399] "Kubelet version" kubeletVersion="v1.24.7"
Apr 14 00:07:33 kind-worker2 kubelet[297]: I0414 00:07:33.795370     297 server.go:401] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
Apr 14 00:07:33 kind-worker2 kubelet[297]: I0414 00:07:33.800671     297 server.go:813] "Client rotation is on, will bootstrap in background"
Apr 14 00:07:33 kind-worker2 kubelet[297]: I0414 00:07:33.850707     297 dynamic_cafile_content.go:157] "Starting controller" name="client-ca-bundle::/etc/kubernetes/pki/ca.crt"
Apr 14 00:07:33 kind-worker2 kubelet[297]: I0414 00:07:33.872228     297 container_manager_linux.go:262] "Container manager verified user specified cgroup-root exists" cgroupRoot=[kubelet]
Apr 14 00:07:33 kind-worker2 kubelet[297]: I0414 00:07:33.872416     297 container_manager_linux.go:267] "Creating Container Manager object based on Node Config" nodeConfig={RuntimeCgroupsName: SystemCgroupsName: KubeletCgroupsName: KubeletOOMScoreAdj:-999 ContainerRuntime: CgroupsPerQOS:true CgroupRoot:/kubelet CgroupDriver:systemd KubeletRootDir:/var/lib/kubelet ProtectKernelDefaults:false NodeAllocatableConfig:{KubeReservedCgroupName: SystemReservedCgroupName: ReservedSystemCPUs: EnforceNodeAllocatable:map[pods:{}] KubeReserved:map[] SystemReserved:map[] HardEvictionThresholds:[]} QOSReserved:map[] ExperimentalCPUManagerPolicy:none ExperimentalCPUManagerPolicyOptions:map[] ExperimentalTopologyManagerScope:container ExperimentalCPUManagerReconcilePeriod:10s ExperimentalMemoryManagerPolicy:None ExperimentalMemoryManagerReservedMemory:[] ExperimentalPodPidsLimit:-1 EnforceCPULimits:true CPUCFSQuotaPeriod:100ms ExperimentalTopologyManagerPolicy:none}
Apr 14 00:07:33 kind-worker2 kubelet[297]: I0414 00:07:33.872726     297 topology_manager.go:133] "Creating topology manager with policy per scope" topologyPolicyName="none" topologyScopeName="container"
Apr 14 00:07:33 kind-worker2 kubelet[297]: I0414 00:07:33.872776     297 container_manager_linux.go:302] "Creating device plugin manager" devicePluginEnabled=true
Apr 14 00:07:33 kind-worker2 kubelet[297]: I0414 00:07:33.873063     297 state_mem.go:36] "Initialized new in-memory state store"
Apr 14 00:07:33 kind-worker2 kubelet[297]: I0414 00:07:33.889856     297 kubelet.go:376] "Attempting to sync node with API server"
Apr 14 00:07:33 kind-worker2 kubelet[297]: I0414 00:07:33.889945     297 kubelet.go:267] "Adding static pod path" path="/etc/kubernetes/manifests"
Apr 14 00:07:33 kind-worker2 kubelet[297]: I0414 00:07:33.890044     297 kubelet.go:278] "Adding apiserver pod source"
Apr 14 00:07:33 kind-worker2 kubelet[297]: I0414 00:07:33.890133     297 apiserver.go:42] "Waiting for node sync before watching apiserver pods"
Apr 14 00:07:33 kind-worker2 kubelet[297]: I0414 00:07:33.893657     297 kuberuntime_manager.go:239] "Container runtime initialized" containerRuntime="containerd" version="v1.6.9" apiVersion="v1"
Apr 14 00:07:33 kind-worker2 kubelet[297]: W0414 00:07:33.894333     297 probe.go:268] Flexvolume plugin directory at /usr/libexec/kubernetes/kubelet-plugins/volume/exec/ does not exist. Recreating.
Apr 14 00:07:33 kind-worker2 kubelet[297]: I0414 00:07:33.895372     297 server.go:1181] "Started kubelet"
Apr 14 00:07:33 kind-worker2 kubelet[297]: I0414 00:07:33.907498     297 server.go:150] "Starting to listen" address="0.0.0.0" port=10250
Apr 14 00:07:33 kind-worker2 kubelet[297]: I0414 00:07:33.910789     297 server.go:410] "Adding debug handlers to kubelet server"
Apr 14 00:07:33 kind-worker2 kubelet[297]: E0414 00:07:33.919433     297 event.go:267] Server rejected event '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kind-worker2.1755a473f8cf82ca", GenerateName:"", Namespace:"default", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ZZZ_DeprecatedClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Node", Namespace:"", Name:"kind-worker2", UID:"kind-worker2", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"Starting", Message:"Starting kubelet.", Source:v1.EventSource{Component:"kubelet", Host:"kind-worker2"}, FirstTimestamp:time.Date(2023, time.April, 14, 0, 7, 33, 895291594, time.Local), LastTimestamp:time.Date(2023, time.April, 14, 0, 7, 33, 895291594, time.Local), Count:1, Type:"Normal", EventTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'events is forbidden: User "system:anonymous" cannot create resource "events" in API group "" in the namespace "default"' (will not retry!)
Apr 14 00:07:33 kind-worker2 kubelet[297]: W0414 00:07:33.919840     297 reflector.go:324] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.Service: services is forbidden: User "system:anonymous" cannot list resource "services" in API group "" at the cluster scope
Apr 14 00:07:33 kind-worker2 kubelet[297]: E0414 00:07:33.919951     297 reflector.go:138] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Service: failed to list *v1.Service: services is forbidden: User "system:anonymous" cannot list resource "services" in API group "" at the cluster scope
Apr 14 00:07:33 kind-worker2 kubelet[297]: W0414 00:07:33.920041     297 reflector.go:324] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.Node: nodes "kind-worker2" is forbidden: User "system:anonymous" cannot list resource "nodes" in API group "" at the cluster scope
Apr 14 00:07:33 kind-worker2 kubelet[297]: E0414 00:07:33.920085     297 reflector.go:138] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Node: failed to list *v1.Node: nodes "kind-worker2" is forbidden: User "system:anonymous" cannot list resource "nodes" in API group "" at the cluster scope
Apr 14 00:07:33 kind-worker2 kubelet[297]: I0414 00:07:33.922660     297 fs_resource_analyzer.go:67] "Starting FS ResourceAnalyzer"
Apr 14 00:07:33 kind-worker2 kubelet[297]: I0414 00:07:33.923446     297 volume_manager.go:289] "Starting Kubelet Volume Manager"
Apr 14 00:07:33 kind-worker2 kubelet[297]: I0414 00:07:33.923704     297 desired_state_of_world_populator.go:145] "Desired state populator starts to run"
Apr 14 00:07:33 kind-worker2 kubelet[297]: E0414 00:07:33.926238     297 controller.go:144] failed to ensure lease exists, will retry in 200ms, error: leases.coordination.k8s.io "kind-worker2" is forbidden: User "system:anonymous" cannot get resource "leases" in API group "coordination.k8s.io" in the namespace "kube-node-lease"
Apr 14 00:07:33 kind-worker2 kubelet[297]: E0414 00:07:33.932057     297 kubelet.go:2349] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Apr 14 00:07:33 kind-worker2 kubelet[297]: W0414 00:07:33.934211     297 reflector.go:324] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.CSIDriver: csidrivers.storage.k8s.io is forbidden: User "system:anonymous" cannot list resource "csidrivers" in API group "storage.k8s.io" at the cluster scope
Apr 14 00:07:33 kind-worker2 kubelet[297]: E0414 00:07:33.934257     297 reflector.go:138] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.CSIDriver: failed to list *v1.CSIDriver: csidrivers.storage.k8s.io is forbidden: User "system:anonymous" cannot list resource "csidrivers" in API group "storage.k8s.io" at the cluster scope
Apr 14 00:07:34 kind-worker2 kubelet[297]: I0414 00:07:34.012916     297 cpu_manager.go:213] "Starting CPU manager" policy="none"
Apr 14 00:07:34 kind-worker2 kubelet[297]: I0414 00:07:34.012981     297 cpu_manager.go:214] "Reconciling" reconcilePeriod="10s"
Apr 14 00:07:34 kind-worker2 kubelet[297]: I0414 00:07:34.013054     297 state_mem.go:36] "Initialized new in-memory state store"
Apr 14 00:07:34 kind-worker2 kubelet[297]: E0414 00:07:34.013944     297 event.go:267] Server rejected event '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kind-worker2.1755a473ffb9d1bc", GenerateName:"", Namespace:"default", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ZZZ_DeprecatedClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Node", Namespace:"", Name:"kind-worker2", UID:"kind-worker2", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"NodeHasSufficientMemory", Message:"Node kind-worker2 status is now: NodeHasSufficientMemory", Source:v1.EventSource{Component:"kubelet", Host:"kind-worker2"}, FirstTimestamp:time.Date(2023, time.April, 14, 0, 7, 34, 11310524, time.Local), LastTimestamp:time.Date(2023, time.April, 14, 0, 7, 34, 11310524, time.Local), Count:1, Type:"Normal", EventTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'events is forbidden: User "system:anonymous" cannot create resource "events" in API group "" in the namespace "default"' (will not retry!)
Apr 14 00:07:34 kind-worker2 kubelet[297]: E0414 00:07:34.015826     297 event.go:267] Server rejected event '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kind-worker2.1755a473ffba504a", GenerateName:"", Namespace:"default", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ZZZ_DeprecatedClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Node", Namespace:"", Name:"kind-worker2", UID:"kind-worker2", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"NodeHasNoDiskPressure", Message:"Node kind-worker2 status is now: NodeHasNoDiskPressure", Source:v1.EventSource{Component:"kubelet", Host:"kind-worker2"}, FirstTimestamp:time.Date(2023, time.April, 14, 0, 7, 34, 11342922, time.Local), LastTimestamp:time.Date(2023, time.April, 14, 0, 7, 34, 11342922, time.Local), Count:1, Type:"Normal", EventTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'events is forbidden: User "system:anonymous" cannot create resource "events" in API group "" in the namespace "default"' (will not retry!)
Apr 14 00:07:34 kind-worker2 kubelet[297]: E0414 00:07:34.017593     297 event.go:267] Server rejected event '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kind-worker2.1755a473ffba6f1f", GenerateName:"", Namespace:"default", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ZZZ_DeprecatedClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Node", Namespace:"", Name:"kind-worker2", UID:"kind-worker2", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"NodeHasSufficientPID", Message:"Node kind-worker2 status is now: NodeHasSufficientPID", Source:v1.EventSource{Component:"kubelet", Host:"kind-worker2"}, FirstTimestamp:time.Date(2023, time.April, 14, 0, 7, 34, 11350815, time.Local), LastTimestamp:time.Date(2023, time.April, 14, 0, 7, 34, 11350815, time.Local), Count:1, Type:"Normal", EventTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'events is forbidden: User "system:anonymous" cannot create resource "events" in API group "" in the namespace "default"' (will not retry!)
Apr 14 00:07:34 kind-worker2 kubelet[297]: E0414 00:07:34.023742     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:34 kind-worker2 kubelet[297]: I0414 00:07:34.025272     297 kubelet_node_status.go:70] "Attempting to register node" node="kind-worker2"
Apr 14 00:07:34 kind-worker2 kubelet[297]: E0414 00:07:34.026954     297 kubelet_node_status.go:92] "Unable to register node with API server" err="nodes is forbidden: User \"system:anonymous\" cannot create resource \"nodes\" in API group \"\" at the cluster scope" node="kind-worker2"
Apr 14 00:07:34 kind-worker2 kubelet[297]: E0414 00:07:34.027901     297 event.go:267] Server rejected event '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kind-worker2.1755a473ffb9d1bc", GenerateName:"", Namespace:"default", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ZZZ_DeprecatedClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Node", Namespace:"", Name:"kind-worker2", UID:"kind-worker2", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"NodeHasSufficientMemory", Message:"Node kind-worker2 status is now: NodeHasSufficientMemory", Source:v1.EventSource{Component:"kubelet", Host:"kind-worker2"}, FirstTimestamp:time.Date(2023, time.April, 14, 0, 7, 34, 11310524, time.Local), LastTimestamp:time.Date(2023, time.April, 14, 0, 7, 34, 24926360, time.Local), Count:2, Type:"Normal", EventTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'events "kind-worker2.1755a473ffb9d1bc" is forbidden: User "system:anonymous" cannot patch resource "events" in API group "" in the namespace "default"' (will not retry!)
Apr 14 00:07:34 kind-worker2 kubelet[297]: E0414 00:07:34.030335     297 event.go:267] Server rejected event '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kind-worker2.1755a473ffba504a", GenerateName:"", Namespace:"default", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ZZZ_DeprecatedClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Node", Namespace:"", Name:"kind-worker2", UID:"kind-worker2", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"NodeHasNoDiskPressure", Message:"Node kind-worker2 status is now: NodeHasNoDiskPressure", Source:v1.EventSource{Component:"kubelet", Host:"kind-worker2"}, FirstTimestamp:time.Date(2023, time.April, 14, 0, 7, 34, 11342922, time.Local), LastTimestamp:time.Date(2023, time.April, 14, 0, 7, 34, 24934793, time.Local), Count:2, Type:"Normal", EventTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'events "kind-worker2.1755a473ffba504a" is forbidden: User "system:anonymous" cannot patch resource "events" in API group "" in the namespace "default"' (will not retry!)
Apr 14 00:07:34 kind-worker2 kubelet[297]: E0414 00:07:34.032197     297 event.go:267] Server rejected event '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kind-worker2.1755a473ffba6f1f", GenerateName:"", Namespace:"default", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ZZZ_DeprecatedClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Node", Namespace:"", Name:"kind-worker2", UID:"kind-worker2", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"NodeHasSufficientPID", Message:"Node kind-worker2 status is now: NodeHasSufficientPID", Source:v1.EventSource{Component:"kubelet", Host:"kind-worker2"}, FirstTimestamp:time.Date(2023, time.April, 14, 0, 7, 34, 11350815, time.Local), LastTimestamp:time.Date(2023, time.April, 14, 0, 7, 34, 24941440, time.Local), Count:2, Type:"Normal", EventTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'events "kind-worker2.1755a473ffba6f1f" is forbidden: User "system:anonymous" cannot patch resource "events" in API group "" in the namespace "default"' (will not retry!)
Apr 14 00:07:34 kind-worker2 kubelet[297]: I0414 00:07:34.051245     297 policy_none.go:49] "None policy: Start"
Apr 14 00:07:34 kind-worker2 kubelet[297]: I0414 00:07:34.052805     297 memory_manager.go:168] "Starting memorymanager" policy="None"
Apr 14 00:07:34 kind-worker2 kubelet[297]: I0414 00:07:34.053017     297 state_mem.go:35] "Initializing new in-memory state store"
Apr 14 00:07:34 kind-worker2 kubelet[297]: E0414 00:07:34.125159     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:34 kind-worker2 kubelet[297]: E0414 00:07:34.132503     297 controller.go:144] failed to ensure lease exists, will retry in 400ms, error: leases.coordination.k8s.io "kind-worker2" is forbidden: User "system:anonymous" cannot get resource "leases" in API group "coordination.k8s.io" in the namespace "kube-node-lease"
Apr 14 00:07:34 kind-worker2 kubelet[297]: I0414 00:07:34.161096     297 manager.go:610] "Failed to read data from checkpoint" checkpoint="kubelet_internal_checkpoint" err="checkpoint is not found"
Apr 14 00:07:34 kind-worker2 kubelet[297]: I0414 00:07:34.163775     297 plugin_manager.go:114] "Starting Kubelet Plugin Manager"
Apr 14 00:07:34 kind-worker2 kubelet[297]: E0414 00:07:34.165788     297 eviction_manager.go:254] "Eviction manager: failed to get summary stats" err="failed to get node info: node \"kind-worker2\" not found"
Apr 14 00:07:34 kind-worker2 kubelet[297]: E0414 00:07:34.167688     297 event.go:267] Server rejected event '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kind-worker2.1755a47408e13e7d", GenerateName:"", Namespace:"default", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ZZZ_DeprecatedClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Node", Namespace:"", Name:"kind-worker2", UID:"kind-worker2", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"NodeAllocatableEnforced", Message:"Updated Node Allocatable limit across pods", Source:v1.EventSource{Component:"kubelet", Host:"kind-worker2"}, FirstTimestamp:time.Date(2023, time.April, 14, 0, 7, 34, 164889213, time.Local), LastTimestamp:time.Date(2023, time.April, 14, 0, 7, 34, 164889213, time.Local), Count:1, Type:"Normal", EventTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'events is forbidden: User "system:anonymous" cannot create resource "events" in API group "" in the namespace "default"' (will not retry!)
Apr 14 00:07:34 kind-worker2 kubelet[297]: I0414 00:07:34.171791     297 kubelet_network_linux.go:76] "Initialized protocol iptables rules." protocol=IPv4
Apr 14 00:07:34 kind-worker2 kubelet[297]: E0414 00:07:34.225677     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:34 kind-worker2 kubelet[297]: I0414 00:07:34.229543     297 kubelet_node_status.go:70] "Attempting to register node" node="kind-worker2"
Apr 14 00:07:34 kind-worker2 kubelet[297]: E0414 00:07:34.232078     297 kubelet_node_status.go:92] "Unable to register node with API server" err="nodes is forbidden: User \"system:anonymous\" cannot create resource \"nodes\" in API group \"\" at the cluster scope" node="kind-worker2"
Apr 14 00:07:34 kind-worker2 kubelet[297]: E0414 00:07:34.233149     297 event.go:267] Server rejected event '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kind-worker2.1755a473ffb9d1bc", GenerateName:"", Namespace:"default", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ZZZ_DeprecatedClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Node", Namespace:"", Name:"kind-worker2", UID:"kind-worker2", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"NodeHasSufficientMemory", Message:"Node kind-worker2 status is now: NodeHasSufficientMemory", Source:v1.EventSource{Component:"kubelet", Host:"kind-worker2"}, FirstTimestamp:time.Date(2023, time.April, 14, 0, 7, 34, 11310524, time.Local), LastTimestamp:time.Date(2023, time.April, 14, 0, 7, 34, 229423886, time.Local), Count:3, Type:"Normal", EventTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'events "kind-worker2.1755a473ffb9d1bc" is forbidden: User "system:anonymous" cannot patch resource "events" in API group "" in the namespace "default"' (will not retry!)
Apr 14 00:07:34 kind-worker2 kubelet[297]: E0414 00:07:34.234717     297 event.go:267] Server rejected event '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kind-worker2.1755a473ffba504a", GenerateName:"", Namespace:"default", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ZZZ_DeprecatedClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Node", Namespace:"", Name:"kind-worker2", UID:"kind-worker2", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"NodeHasNoDiskPressure", Message:"Node kind-worker2 status is now: NodeHasNoDiskPressure", Source:v1.EventSource{Component:"kubelet", Host:"kind-worker2"}, FirstTimestamp:time.Date(2023, time.April, 14, 0, 7, 34, 11342922, time.Local), LastTimestamp:time.Date(2023, time.April, 14, 0, 7, 34, 229477140, time.Local), Count:3, Type:"Normal", EventTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'events "kind-worker2.1755a473ffba504a" is forbidden: User "system:anonymous" cannot patch resource "events" in API group "" in the namespace "default"' (will not retry!)
Apr 14 00:07:34 kind-worker2 kubelet[297]: E0414 00:07:34.236464     297 event.go:267] Server rejected event '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kind-worker2.1755a473ffba6f1f", GenerateName:"", Namespace:"default", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ZZZ_DeprecatedClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Node", Namespace:"", Name:"kind-worker2", UID:"kind-worker2", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"NodeHasSufficientPID", Message:"Node kind-worker2 status is now: NodeHasSufficientPID", Source:v1.EventSource{Component:"kubelet", Host:"kind-worker2"}, FirstTimestamp:time.Date(2023, time.April, 14, 0, 7, 34, 11350815, time.Local), LastTimestamp:time.Date(2023, time.April, 14, 0, 7, 34, 229488789, time.Local), Count:3, Type:"Normal", EventTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'events "kind-worker2.1755a473ffba6f1f" is forbidden: User "system:anonymous" cannot patch resource "events" in API group "" in the namespace "default"' (will not retry!)
Apr 14 00:07:34 kind-worker2 kubelet[297]: E0414 00:07:34.326836     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:34 kind-worker2 kubelet[297]: E0414 00:07:34.427185     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:34 kind-worker2 kubelet[297]: E0414 00:07:34.527871     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:34 kind-worker2 kubelet[297]: E0414 00:07:34.539461     297 controller.go:144] failed to ensure lease exists, will retry in 800ms, error: leases.coordination.k8s.io "kind-worker2" is forbidden: User "system:anonymous" cannot get resource "leases" in API group "coordination.k8s.io" in the namespace "kube-node-lease"
Apr 14 00:07:34 kind-worker2 kubelet[297]: E0414 00:07:34.628088     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:34 kind-worker2 kubelet[297]: I0414 00:07:34.636637     297 kubelet_node_status.go:70] "Attempting to register node" node="kind-worker2"
Apr 14 00:07:34 kind-worker2 kubelet[297]: E0414 00:07:34.639186     297 event.go:267] Server rejected event '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kind-worker2.1755a473ffb9d1bc", GenerateName:"", Namespace:"default", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ZZZ_DeprecatedClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Node", Namespace:"", Name:"kind-worker2", UID:"kind-worker2", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"NodeHasSufficientMemory", Message:"Node kind-worker2 status is now: NodeHasSufficientMemory", Source:v1.EventSource{Component:"kubelet", Host:"kind-worker2"}, FirstTimestamp:time.Date(2023, time.April, 14, 0, 7, 34, 11310524, time.Local), LastTimestamp:time.Date(2023, time.April, 14, 0, 7, 34, 636569022, time.Local), Count:4, Type:"Normal", EventTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'events "kind-worker2.1755a473ffb9d1bc" is forbidden: User "system:anonymous" cannot patch resource "events" in API group "" in the namespace "default"' (will not retry!)
Apr 14 00:07:34 kind-worker2 kubelet[297]: E0414 00:07:34.639888     297 kubelet_node_status.go:92] "Unable to register node with API server" err="nodes is forbidden: User \"system:anonymous\" cannot create resource \"nodes\" in API group \"\" at the cluster scope" node="kind-worker2"
Apr 14 00:07:34 kind-worker2 kubelet[297]: E0414 00:07:34.641436     297 event.go:267] Server rejected event '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kind-worker2.1755a473ffba504a", GenerateName:"", Namespace:"default", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ZZZ_DeprecatedClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Node", Namespace:"", Name:"kind-worker2", UID:"kind-worker2", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"NodeHasNoDiskPressure", Message:"Node kind-worker2 status is now: NodeHasNoDiskPressure", Source:v1.EventSource{Component:"kubelet", Host:"kind-worker2"}, FirstTimestamp:time.Date(2023, time.April, 14, 0, 7, 34, 11342922, time.Local), LastTimestamp:time.Date(2023, time.April, 14, 0, 7, 34, 636577490, time.Local), Count:4, Type:"Normal", EventTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'events "kind-worker2.1755a473ffba504a" is forbidden: User "system:anonymous" cannot patch resource "events" in API group "" in the namespace "default"' (will not retry!)
Apr 14 00:07:34 kind-worker2 kubelet[297]: E0414 00:07:34.710290     297 event.go:267] Server rejected event '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kind-worker2.1755a473ffba6f1f", GenerateName:"", Namespace:"default", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ZZZ_DeprecatedClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Node", Namespace:"", Name:"kind-worker2", UID:"kind-worker2", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"NodeHasSufficientPID", Message:"Node kind-worker2 status is now: NodeHasSufficientPID", Source:v1.EventSource{Component:"kubelet", Host:"kind-worker2"}, FirstTimestamp:time.Date(2023, time.April, 14, 0, 7, 34, 11350815, time.Local), LastTimestamp:time.Date(2023, time.April, 14, 0, 7, 34, 636583872, time.Local), Count:4, Type:"Normal", EventTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'events "kind-worker2.1755a473ffba6f1f" is forbidden: User "system:anonymous" cannot patch resource "events" in API group "" in the namespace "default"' (will not retry!)
Apr 14 00:07:34 kind-worker2 kubelet[297]: E0414 00:07:34.729398     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:34 kind-worker2 kubelet[297]: I0414 00:07:34.798395     297 kubelet_network_linux.go:76] "Initialized protocol iptables rules." protocol=IPv6
Apr 14 00:07:34 kind-worker2 kubelet[297]: I0414 00:07:34.798518     297 status_manager.go:161] "Starting to sync pod status with apiserver"
Apr 14 00:07:34 kind-worker2 kubelet[297]: I0414 00:07:34.798588     297 kubelet.go:1986] "Starting kubelet main sync loop"
Apr 14 00:07:34 kind-worker2 kubelet[297]: E0414 00:07:34.798755     297 kubelet.go:2010] "Skipping pod synchronization" err="PLEG is not healthy: pleg has yet to be successful"
Apr 14 00:07:34 kind-worker2 kubelet[297]: W0414 00:07:34.809049     297 reflector.go:324] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.RuntimeClass: runtimeclasses.node.k8s.io is forbidden: User "system:anonymous" cannot list resource "runtimeclasses" in API group "node.k8s.io" at the cluster scope
Apr 14 00:07:34 kind-worker2 kubelet[297]: E0414 00:07:34.809105     297 reflector.go:138] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.RuntimeClass: failed to list *v1.RuntimeClass: runtimeclasses.node.k8s.io is forbidden: User "system:anonymous" cannot list resource "runtimeclasses" in API group "node.k8s.io" at the cluster scope
Apr 14 00:07:34 kind-worker2 kubelet[297]: E0414 00:07:34.829990     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:34 kind-worker2 kubelet[297]: E0414 00:07:34.930785     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:35 kind-worker2 kubelet[297]: E0414 00:07:35.031833     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:35 kind-worker2 kubelet[297]: E0414 00:07:35.132550     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:35 kind-worker2 kubelet[297]: E0414 00:07:35.233642     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:35 kind-worker2 kubelet[297]: W0414 00:07:35.253060     297 reflector.go:324] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.Service: services is forbidden: User "system:anonymous" cannot list resource "services" in API group "" at the cluster scope
Apr 14 00:07:35 kind-worker2 kubelet[297]: E0414 00:07:35.253165     297 reflector.go:138] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Service: failed to list *v1.Service: services is forbidden: User "system:anonymous" cannot list resource "services" in API group "" at the cluster scope
Apr 14 00:07:35 kind-worker2 kubelet[297]: E0414 00:07:35.333953     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:35 kind-worker2 kubelet[297]: E0414 00:07:35.343623     297 controller.go:144] failed to ensure lease exists, will retry in 1.6s, error: leases.coordination.k8s.io "kind-worker2" is forbidden: User "system:anonymous" cannot get resource "leases" in API group "coordination.k8s.io" in the namespace "kube-node-lease"
Apr 14 00:07:35 kind-worker2 kubelet[297]: W0414 00:07:35.353183     297 reflector.go:324] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.CSIDriver: csidrivers.storage.k8s.io is forbidden: User "system:anonymous" cannot list resource "csidrivers" in API group "storage.k8s.io" at the cluster scope
Apr 14 00:07:35 kind-worker2 kubelet[297]: E0414 00:07:35.353602     297 reflector.go:138] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.CSIDriver: failed to list *v1.CSIDriver: csidrivers.storage.k8s.io is forbidden: User "system:anonymous" cannot list resource "csidrivers" in API group "storage.k8s.io" at the cluster scope
Apr 14 00:07:35 kind-worker2 kubelet[297]: E0414 00:07:35.435058     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:35 kind-worker2 kubelet[297]: I0414 00:07:35.442519     297 kubelet_node_status.go:70] "Attempting to register node" node="kind-worker2"
Apr 14 00:07:35 kind-worker2 kubelet[297]: E0414 00:07:35.447057     297 kubelet_node_status.go:92] "Unable to register node with API server" err="nodes is forbidden: User \"system:anonymous\" cannot create resource \"nodes\" in API group \"\" at the cluster scope" node="kind-worker2"
Apr 14 00:07:35 kind-worker2 kubelet[297]: E0414 00:07:35.446969     297 event.go:267] Server rejected event '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kind-worker2.1755a473ffb9d1bc", GenerateName:"", Namespace:"default", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ZZZ_DeprecatedClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Node", Namespace:"", Name:"kind-worker2", UID:"kind-worker2", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"NodeHasSufficientMemory", Message:"Node kind-worker2 status is now: NodeHasSufficientMemory", Source:v1.EventSource{Component:"kubelet", Host:"kind-worker2"}, FirstTimestamp:time.Date(2023, time.April, 14, 0, 7, 34, 11310524, time.Local), LastTimestamp:time.Date(2023, time.April, 14, 0, 7, 35, 442350475, time.Local), Count:5, Type:"Normal", EventTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'events "kind-worker2.1755a473ffb9d1bc" is forbidden: User "system:anonymous" cannot patch resource "events" in API group "" in the namespace "default"' (will not retry!)
Apr 14 00:07:35 kind-worker2 kubelet[297]: E0414 00:07:35.450544     297 event.go:267] Server rejected event '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kind-worker2.1755a473ffba504a", GenerateName:"", Namespace:"default", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ZZZ_DeprecatedClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Node", Namespace:"", Name:"kind-worker2", UID:"kind-worker2", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"NodeHasNoDiskPressure", Message:"Node kind-worker2 status is now: NodeHasNoDiskPressure", Source:v1.EventSource{Component:"kubelet", Host:"kind-worker2"}, FirstTimestamp:time.Date(2023, time.April, 14, 0, 7, 34, 11342922, time.Local), LastTimestamp:time.Date(2023, time.April, 14, 0, 7, 35, 442401865, time.Local), Count:5, Type:"Normal", EventTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'events "kind-worker2.1755a473ffba504a" is forbidden: User "system:anonymous" cannot patch resource "events" in API group "" in the namespace "default"' (will not retry!)
Apr 14 00:07:35 kind-worker2 kubelet[297]: E0414 00:07:35.453327     297 event.go:267] Server rejected event '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kind-worker2.1755a473ffba6f1f", GenerateName:"", Namespace:"default", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ZZZ_DeprecatedClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Node", Namespace:"", Name:"kind-worker2", UID:"kind-worker2", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"NodeHasSufficientPID", Message:"Node kind-worker2 status is now: NodeHasSufficientPID", Source:v1.EventSource{Component:"kubelet", Host:"kind-worker2"}, FirstTimestamp:time.Date(2023, time.April, 14, 0, 7, 34, 11350815, time.Local), LastTimestamp:time.Date(2023, time.April, 14, 0, 7, 35, 442417495, time.Local), Count:5, Type:"Normal", EventTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'events "kind-worker2.1755a473ffba6f1f" is forbidden: User "system:anonymous" cannot patch resource "events" in API group "" in the namespace "default"' (will not retry!)
Apr 14 00:07:35 kind-worker2 kubelet[297]: W0414 00:07:35.461287     297 reflector.go:324] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.Node: nodes "kind-worker2" is forbidden: User "system:anonymous" cannot list resource "nodes" in API group "" at the cluster scope
Apr 14 00:07:35 kind-worker2 kubelet[297]: E0414 00:07:35.461414     297 reflector.go:138] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Node: failed to list *v1.Node: nodes "kind-worker2" is forbidden: User "system:anonymous" cannot list resource "nodes" in API group "" at the cluster scope
Apr 14 00:07:35 kind-worker2 kubelet[297]: E0414 00:07:35.536226     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:35 kind-worker2 kubelet[297]: E0414 00:07:35.637232     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:35 kind-worker2 kubelet[297]: E0414 00:07:35.738028     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:35 kind-worker2 kubelet[297]: W0414 00:07:35.787233     297 reflector.go:324] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.RuntimeClass: runtimeclasses.node.k8s.io is forbidden: User "system:anonymous" cannot list resource "runtimeclasses" in API group "node.k8s.io" at the cluster scope
Apr 14 00:07:35 kind-worker2 kubelet[297]: E0414 00:07:35.787346     297 reflector.go:138] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.RuntimeClass: failed to list *v1.RuntimeClass: runtimeclasses.node.k8s.io is forbidden: User "system:anonymous" cannot list resource "runtimeclasses" in API group "node.k8s.io" at the cluster scope
Apr 14 00:07:35 kind-worker2 kubelet[297]: E0414 00:07:35.838420     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:35 kind-worker2 kubelet[297]: E0414 00:07:35.938721     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:36 kind-worker2 kubelet[297]: E0414 00:07:36.039561     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:36 kind-worker2 kubelet[297]: E0414 00:07:36.140598     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:36 kind-worker2 kubelet[297]: E0414 00:07:36.241766     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:36 kind-worker2 kubelet[297]: E0414 00:07:36.342752     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:36 kind-worker2 kubelet[297]: E0414 00:07:36.443178     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:36 kind-worker2 kubelet[297]: E0414 00:07:36.544100     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:36 kind-worker2 kubelet[297]: E0414 00:07:36.644648     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:36 kind-worker2 kubelet[297]: E0414 00:07:36.745255     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:36 kind-worker2 kubelet[297]: E0414 00:07:36.845756     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:36 kind-worker2 kubelet[297]: E0414 00:07:36.946668     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:36 kind-worker2 kubelet[297]: E0414 00:07:36.947211     297 controller.go:144] failed to ensure lease exists, will retry in 3.2s, error: leases.coordination.k8s.io "kind-worker2" is forbidden: User "system:anonymous" cannot get resource "leases" in API group "coordination.k8s.io" in the namespace "kube-node-lease"
Apr 14 00:07:37 kind-worker2 kubelet[297]: E0414 00:07:37.047866     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:37 kind-worker2 kubelet[297]: I0414 00:07:37.050181     297 kubelet_node_status.go:70] "Attempting to register node" node="kind-worker2"
Apr 14 00:07:37 kind-worker2 kubelet[297]: E0414 00:07:37.055626     297 kubelet_node_status.go:92] "Unable to register node with API server" err="nodes is forbidden: User \"system:anonymous\" cannot create resource \"nodes\" in API group \"\" at the cluster scope" node="kind-worker2"
Apr 14 00:07:37 kind-worker2 kubelet[297]: E0414 00:07:37.055595     297 event.go:267] Server rejected event '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kind-worker2.1755a473ffb9d1bc", GenerateName:"", Namespace:"default", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ZZZ_DeprecatedClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Node", Namespace:"", Name:"kind-worker2", UID:"kind-worker2", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"NodeHasSufficientMemory", Message:"Node kind-worker2 status is now: NodeHasSufficientMemory", Source:v1.EventSource{Component:"kubelet", Host:"kind-worker2"}, FirstTimestamp:time.Date(2023, time.April, 14, 0, 7, 34, 11310524, time.Local), LastTimestamp:time.Date(2023, time.April, 14, 0, 7, 37, 50020742, time.Local), Count:6, Type:"Normal", EventTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'events "kind-worker2.1755a473ffb9d1bc" is forbidden: User "system:anonymous" cannot patch resource "events" in API group "" in the namespace "default"' (will not retry!)
Apr 14 00:07:37 kind-worker2 kubelet[297]: E0414 00:07:37.058187     297 event.go:267] Server rejected event '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kind-worker2.1755a473ffba504a", GenerateName:"", Namespace:"default", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ZZZ_DeprecatedClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Node", Namespace:"", Name:"kind-worker2", UID:"kind-worker2", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"NodeHasNoDiskPressure", Message:"Node kind-worker2 status is now: NodeHasNoDiskPressure", Source:v1.EventSource{Component:"kubelet", Host:"kind-worker2"}, FirstTimestamp:time.Date(2023, time.April, 14, 0, 7, 34, 11342922, time.Local), LastTimestamp:time.Date(2023, time.April, 14, 0, 7, 37, 50099448, time.Local), Count:6, Type:"Normal", EventTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'events "kind-worker2.1755a473ffba504a" is forbidden: User "system:anonymous" cannot patch resource "events" in API group "" in the namespace "default"' (will not retry!)
Apr 14 00:07:37 kind-worker2 kubelet[297]: E0414 00:07:37.060940     297 event.go:267] Server rejected event '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kind-worker2.1755a473ffba6f1f", GenerateName:"", Namespace:"default", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ZZZ_DeprecatedClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Node", Namespace:"", Name:"kind-worker2", UID:"kind-worker2", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"NodeHasSufficientPID", Message:"Node kind-worker2 status is now: NodeHasSufficientPID", Source:v1.EventSource{Component:"kubelet", Host:"kind-worker2"}, FirstTimestamp:time.Date(2023, time.April, 14, 0, 7, 34, 11350815, time.Local), LastTimestamp:time.Date(2023, time.April, 14, 0, 7, 37, 50112181, time.Local), Count:6, Type:"Normal", EventTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'events "kind-worker2.1755a473ffba6f1f" is forbidden: User "system:anonymous" cannot patch resource "events" in API group "" in the namespace "default"' (will not retry!)
Apr 14 00:07:37 kind-worker2 kubelet[297]: E0414 00:07:37.148686     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:37 kind-worker2 kubelet[297]: E0414 00:07:37.249281     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:37 kind-worker2 kubelet[297]: E0414 00:07:37.350222     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:37 kind-worker2 kubelet[297]: E0414 00:07:37.451346     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:37 kind-worker2 kubelet[297]: E0414 00:07:37.551513     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:37 kind-worker2 kubelet[297]: W0414 00:07:37.551758     297 reflector.go:324] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.CSIDriver: csidrivers.storage.k8s.io is forbidden: User "system:anonymous" cannot list resource "csidrivers" in API group "storage.k8s.io" at the cluster scope
Apr 14 00:07:37 kind-worker2 kubelet[297]: E0414 00:07:37.551857     297 reflector.go:138] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.CSIDriver: failed to list *v1.CSIDriver: csidrivers.storage.k8s.io is forbidden: User "system:anonymous" cannot list resource "csidrivers" in API group "storage.k8s.io" at the cluster scope
Apr 14 00:07:37 kind-worker2 kubelet[297]: E0414 00:07:37.652377     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:37 kind-worker2 kubelet[297]: E0414 00:07:37.752996     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:37 kind-worker2 kubelet[297]: E0414 00:07:37.853738     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:37 kind-worker2 kubelet[297]: E0414 00:07:37.954820     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:38 kind-worker2 kubelet[297]: E0414 00:07:38.055556     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:38 kind-worker2 kubelet[297]: E0414 00:07:38.156489     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:38 kind-worker2 kubelet[297]: W0414 00:07:38.201115     297 reflector.go:324] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.Node: nodes "kind-worker2" is forbidden: User "system:anonymous" cannot list resource "nodes" in API group "" at the cluster scope
Apr 14 00:07:38 kind-worker2 kubelet[297]: E0414 00:07:38.201205     297 reflector.go:138] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Node: failed to list *v1.Node: nodes "kind-worker2" is forbidden: User "system:anonymous" cannot list resource "nodes" in API group "" at the cluster scope
Apr 14 00:07:38 kind-worker2 kubelet[297]: W0414 00:07:38.243811     297 reflector.go:324] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.Service: services is forbidden: User "system:anonymous" cannot list resource "services" in API group "" at the cluster scope
Apr 14 00:07:38 kind-worker2 kubelet[297]: E0414 00:07:38.244030     297 reflector.go:138] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Service: failed to list *v1.Service: services is forbidden: User "system:anonymous" cannot list resource "services" in API group "" at the cluster scope
Apr 14 00:07:38 kind-worker2 kubelet[297]: E0414 00:07:38.257451     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:38 kind-worker2 kubelet[297]: E0414 00:07:38.357976     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:38 kind-worker2 kubelet[297]: W0414 00:07:38.419197     297 reflector.go:324] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.RuntimeClass: runtimeclasses.node.k8s.io is forbidden: User "system:anonymous" cannot list resource "runtimeclasses" in API group "node.k8s.io" at the cluster scope
Apr 14 00:07:38 kind-worker2 kubelet[297]: E0414 00:07:38.419279     297 reflector.go:138] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.RuntimeClass: failed to list *v1.RuntimeClass: runtimeclasses.node.k8s.io is forbidden: User "system:anonymous" cannot list resource "runtimeclasses" in API group "node.k8s.io" at the cluster scope
Apr 14 00:07:38 kind-worker2 kubelet[297]: E0414 00:07:38.458864     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:38 kind-worker2 kubelet[297]: E0414 00:07:38.559757     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:38 kind-worker2 kubelet[297]: E0414 00:07:38.660757     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:38 kind-worker2 kubelet[297]: E0414 00:07:38.761763     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:38 kind-worker2 kubelet[297]: E0414 00:07:38.862494     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:38 kind-worker2 kubelet[297]: E0414 00:07:38.963435     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:39 kind-worker2 kubelet[297]: E0414 00:07:39.064688     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:39 kind-worker2 kubelet[297]: E0414 00:07:39.165081     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:39 kind-worker2 kubelet[297]: E0414 00:07:39.166328     297 kubelet.go:2349] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Apr 14 00:07:39 kind-worker2 kubelet[297]: E0414 00:07:39.266009     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:39 kind-worker2 kubelet[297]: E0414 00:07:39.366507     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:39 kind-worker2 kubelet[297]: E0414 00:07:39.467697     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:39 kind-worker2 kubelet[297]: E0414 00:07:39.568876     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:39 kind-worker2 kubelet[297]: E0414 00:07:39.669230     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:39 kind-worker2 kubelet[297]: E0414 00:07:39.770367     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:39 kind-worker2 kubelet[297]: E0414 00:07:39.870559     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:39 kind-worker2 kubelet[297]: E0414 00:07:39.972069     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:40 kind-worker2 kubelet[297]: E0414 00:07:40.073254     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:40 kind-worker2 kubelet[297]: E0414 00:07:40.153318     297 controller.go:144] failed to ensure lease exists, will retry in 6.4s, error: leases.coordination.k8s.io "kind-worker2" is forbidden: User "system:anonymous" cannot get resource "leases" in API group "coordination.k8s.io" in the namespace "kube-node-lease"
Apr 14 00:07:40 kind-worker2 kubelet[297]: E0414 00:07:40.173410     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:40 kind-worker2 kubelet[297]: I0414 00:07:40.257679     297 kubelet_node_status.go:70] "Attempting to register node" node="kind-worker2"
Apr 14 00:07:40 kind-worker2 kubelet[297]: E0414 00:07:40.261779     297 kubelet_node_status.go:92] "Unable to register node with API server" err="nodes is forbidden: User \"system:anonymous\" cannot create resource \"nodes\" in API group \"\" at the cluster scope" node="kind-worker2"
Apr 14 00:07:40 kind-worker2 kubelet[297]: E0414 00:07:40.261740     297 event.go:267] Server rejected event '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kind-worker2.1755a473ffb9d1bc", GenerateName:"", Namespace:"default", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ZZZ_DeprecatedClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Node", Namespace:"", Name:"kind-worker2", UID:"kind-worker2", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"NodeHasSufficientMemory", Message:"Node kind-worker2 status is now: NodeHasSufficientMemory", Source:v1.EventSource{Component:"kubelet", Host:"kind-worker2"}, FirstTimestamp:time.Date(2023, time.April, 14, 0, 7, 34, 11310524, time.Local), LastTimestamp:time.Date(2023, time.April, 14, 0, 7, 40, 257576206, time.Local), Count:7, Type:"Normal", EventTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'events "kind-worker2.1755a473ffb9d1bc" is forbidden: User "system:anonymous" cannot patch resource "events" in API group "" in the namespace "default"' (will not retry!)
Apr 14 00:07:40 kind-worker2 kubelet[297]: E0414 00:07:40.263864     297 event.go:267] Server rejected event '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kind-worker2.1755a473ffba504a", GenerateName:"", Namespace:"default", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ZZZ_DeprecatedClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Node", Namespace:"", Name:"kind-worker2", UID:"kind-worker2", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"NodeHasNoDiskPressure", Message:"Node kind-worker2 status is now: NodeHasNoDiskPressure", Source:v1.EventSource{Component:"kubelet", Host:"kind-worker2"}, FirstTimestamp:time.Date(2023, time.April, 14, 0, 7, 34, 11342922, time.Local), LastTimestamp:time.Date(2023, time.April, 14, 0, 7, 40, 257614446, time.Local), Count:7, Type:"Normal", EventTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'events "kind-worker2.1755a473ffba504a" is forbidden: User "system:anonymous" cannot patch resource "events" in API group "" in the namespace "default"' (will not retry!)
Apr 14 00:07:40 kind-worker2 kubelet[297]: E0414 00:07:40.266083     297 event.go:267] Server rejected event '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kind-worker2.1755a473ffba6f1f", GenerateName:"", Namespace:"default", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ZZZ_DeprecatedClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Node", Namespace:"", Name:"kind-worker2", UID:"kind-worker2", APIVersion:"", ResourceVersion:"", FieldPath:""}, Reason:"NodeHasSufficientPID", Message:"Node kind-worker2 status is now: NodeHasSufficientPID", Source:v1.EventSource{Component:"kubelet", Host:"kind-worker2"}, FirstTimestamp:time.Date(2023, time.April, 14, 0, 7, 34, 11350815, time.Local), LastTimestamp:time.Date(2023, time.April, 14, 0, 7, 40, 257623086, time.Local), Count:7, Type:"Normal", EventTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"", ReportingInstance:""}': 'events "kind-worker2.1755a473ffba6f1f" is forbidden: User "system:anonymous" cannot patch resource "events" in API group "" in the namespace "default"' (will not retry!)
Apr 14 00:07:40 kind-worker2 kubelet[297]: E0414 00:07:40.274216     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:40 kind-worker2 kubelet[297]: E0414 00:07:40.374723     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:40 kind-worker2 kubelet[297]: E0414 00:07:40.475741     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:40 kind-worker2 kubelet[297]: E0414 00:07:40.576829     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:40 kind-worker2 kubelet[297]: E0414 00:07:40.678104     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:40 kind-worker2 kubelet[297]: E0414 00:07:40.778592     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:40 kind-worker2 kubelet[297]: E0414 00:07:40.879454     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:40 kind-worker2 kubelet[297]: E0414 00:07:40.980715     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:41 kind-worker2 kubelet[297]: E0414 00:07:41.081720     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:41 kind-worker2 kubelet[297]: E0414 00:07:41.182375     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:41 kind-worker2 kubelet[297]: W0414 00:07:41.183513     297 reflector.go:324] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.CSIDriver: csidrivers.storage.k8s.io is forbidden: User "system:anonymous" cannot list resource "csidrivers" in API group "storage.k8s.io" at the cluster scope
Apr 14 00:07:41 kind-worker2 kubelet[297]: E0414 00:07:41.183608     297 reflector.go:138] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.CSIDriver: failed to list *v1.CSIDriver: csidrivers.storage.k8s.io is forbidden: User "system:anonymous" cannot list resource "csidrivers" in API group "storage.k8s.io" at the cluster scope
Apr 14 00:07:41 kind-worker2 kubelet[297]: E0414 00:07:41.283502     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:41 kind-worker2 kubelet[297]: E0414 00:07:41.384088     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:41 kind-worker2 kubelet[297]: E0414 00:07:41.485348     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:41 kind-worker2 kubelet[297]: W0414 00:07:41.581877     297 reflector.go:324] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.Service: services is forbidden: User "system:anonymous" cannot list resource "services" in API group "" at the cluster scope
Apr 14 00:07:41 kind-worker2 kubelet[297]: E0414 00:07:41.581984     297 reflector.go:138] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Service: failed to list *v1.Service: services is forbidden: User "system:anonymous" cannot list resource "services" in API group "" at the cluster scope
Apr 14 00:07:41 kind-worker2 kubelet[297]: E0414 00:07:41.587047     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:41 kind-worker2 kubelet[297]: E0414 00:07:41.687748     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:41 kind-worker2 kubelet[297]: E0414 00:07:41.789045     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:41 kind-worker2 kubelet[297]: E0414 00:07:41.889798     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:41 kind-worker2 kubelet[297]: E0414 00:07:41.990797     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:42 kind-worker2 kubelet[297]: E0414 00:07:42.091829     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:42 kind-worker2 kubelet[297]: E0414 00:07:42.192752     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:42 kind-worker2 kubelet[297]: E0414 00:07:42.293000     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:42 kind-worker2 kubelet[297]: E0414 00:07:42.393753     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:42 kind-worker2 kubelet[297]: W0414 00:07:42.432296     297 reflector.go:324] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.RuntimeClass: runtimeclasses.node.k8s.io is forbidden: User "system:anonymous" cannot list resource "runtimeclasses" in API group "node.k8s.io" at the cluster scope
Apr 14 00:07:42 kind-worker2 kubelet[297]: E0414 00:07:42.432414     297 reflector.go:138] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.RuntimeClass: failed to list *v1.RuntimeClass: runtimeclasses.node.k8s.io is forbidden: User "system:anonymous" cannot list resource "runtimeclasses" in API group "node.k8s.io" at the cluster scope
Apr 14 00:07:42 kind-worker2 kubelet[297]: E0414 00:07:42.496199     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:42 kind-worker2 kubelet[297]: E0414 00:07:42.596402     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:42 kind-worker2 kubelet[297]: E0414 00:07:42.696755     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:42 kind-worker2 kubelet[297]: E0414 00:07:42.797876     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:42 kind-worker2 kubelet[297]: E0414 00:07:42.899019     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:43 kind-worker2 kubelet[297]: E0414 00:07:43.000008     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:43 kind-worker2 kubelet[297]: E0414 00:07:43.100856     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:43 kind-worker2 kubelet[297]: E0414 00:07:43.201065     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:43 kind-worker2 kubelet[297]: E0414 00:07:43.301275     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:43 kind-worker2 kubelet[297]: E0414 00:07:43.402425     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:43 kind-worker2 kubelet[297]: E0414 00:07:43.502578     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:43 kind-worker2 kubelet[297]: E0414 00:07:43.603701     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:43 kind-worker2 kubelet[297]: E0414 00:07:43.704530     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:43 kind-worker2 kubelet[297]: E0414 00:07:43.805300     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:43 kind-worker2 kubelet[297]: I0414 00:07:43.805555     297 transport.go:135] "Certificate rotation detected, shutting down client connections to start using new credentials"
Apr 14 00:07:43 kind-worker2 kubelet[297]: E0414 00:07:43.906337     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:44 kind-worker2 kubelet[297]: E0414 00:07:44.007334     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:44 kind-worker2 kubelet[297]: E0414 00:07:44.108004     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:44 kind-worker2 kubelet[297]: E0414 00:07:44.166051     297 eviction_manager.go:254] "Eviction manager: failed to get summary stats" err="failed to get node info: node \"kind-worker2\" not found"
Apr 14 00:07:44 kind-worker2 kubelet[297]: E0414 00:07:44.167583     297 kubelet.go:2349] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Apr 14 00:07:44 kind-worker2 kubelet[297]: E0414 00:07:44.208850     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:44 kind-worker2 kubelet[297]: E0414 00:07:44.309695     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:44 kind-worker2 kubelet[297]: E0414 00:07:44.337901     297 csi_plugin.go:297] Failed to initialize CSINode: error updating CSINode annotation: timed out waiting for the condition; caused by: nodes "kind-worker2" not found
Apr 14 00:07:44 kind-worker2 kubelet[297]: E0414 00:07:44.410946     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:44 kind-worker2 kubelet[297]: E0414 00:07:44.511515     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:44 kind-worker2 kubelet[297]: E0414 00:07:44.612524     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:44 kind-worker2 kubelet[297]: E0414 00:07:44.712725     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:44 kind-worker2 kubelet[297]: E0414 00:07:44.813571     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:44 kind-worker2 kubelet[297]: I0414 00:07:44.901213     297 apiserver.go:52] "Watching apiserver"
Apr 14 00:07:44 kind-worker2 kubelet[297]: E0414 00:07:44.914595     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:45 kind-worker2 kubelet[297]: E0414 00:07:45.015359     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:45 kind-worker2 kubelet[297]: E0414 00:07:45.116632     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:45 kind-worker2 kubelet[297]: E0414 00:07:45.217579     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:45 kind-worker2 kubelet[297]: I0414 00:07:45.291355     297 reconciler.go:159] "Reconciler: start to sync state"
Apr 14 00:07:45 kind-worker2 kubelet[297]: E0414 00:07:45.318573     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:45 kind-worker2 kubelet[297]: E0414 00:07:45.419220     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:45 kind-worker2 kubelet[297]: E0414 00:07:45.520283     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:45 kind-worker2 kubelet[297]: E0414 00:07:45.621217     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:45 kind-worker2 kubelet[297]: E0414 00:07:45.721696     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:45 kind-worker2 kubelet[297]: E0414 00:07:45.728746     297 csi_plugin.go:297] Failed to initialize CSINode: error updating CSINode annotation: timed out waiting for the condition; caused by: nodes "kind-worker2" not found
Apr 14 00:07:45 kind-worker2 kubelet[297]: E0414 00:07:45.821952     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:45 kind-worker2 kubelet[297]: E0414 00:07:45.922785     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:46 kind-worker2 kubelet[297]: E0414 00:07:46.023773     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:46 kind-worker2 kubelet[297]: E0414 00:07:46.124260     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:46 kind-worker2 kubelet[297]: E0414 00:07:46.224713     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:46 kind-worker2 kubelet[297]: E0414 00:07:46.325643     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:46 kind-worker2 kubelet[297]: E0414 00:07:46.426214     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:46 kind-worker2 kubelet[297]: E0414 00:07:46.527236     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:46 kind-worker2 kubelet[297]: E0414 00:07:46.628247     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:46 kind-worker2 kubelet[297]: E0414 00:07:46.631397     297 nodelease.go:49] "Failed to get node when trying to set owner ref to the node lease" err="nodes \"kind-worker2\" not found" node="kind-worker2"
Apr 14 00:07:46 kind-worker2 kubelet[297]: I0414 00:07:46.664439     297 kubelet_node_status.go:70] "Attempting to register node" node="kind-worker2"
Apr 14 00:07:46 kind-worker2 kubelet[297]: E0414 00:07:46.728932     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:46 kind-worker2 kubelet[297]: E0414 00:07:46.829547     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:46 kind-worker2 kubelet[297]: E0414 00:07:46.929947     297 kubelet.go:2424] "Error getting node" err="node \"kind-worker2\" not found"
Apr 14 00:07:46 kind-worker2 kubelet[297]: I0414 00:07:46.937956     297 kubelet_node_status.go:73] "Successfully registered node" node="kind-worker2"
Apr 14 00:07:47 kind-worker2 kubelet[297]: I0414 00:07:47.131162     297 kuberuntime_manager.go:1095] "Updating runtime config through cri with podcidr" CIDR="10.244.1.0/24"
Apr 14 00:07:47 kind-worker2 kubelet[297]: I0414 00:07:47.133240     297 kubelet_network.go:60] "Updating Pod CIDR" originalPodCIDR="" newPodCIDR="10.244.1.0/24"
Apr 14 00:07:47 kind-worker2 kubelet[297]: E0414 00:07:47.134299     297 kubelet.go:2349] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Apr 14 00:07:47 kind-worker2 kubelet[297]: I0414 00:07:47.231528     297 topology_manager.go:200] "Topology Admit Handler"
Apr 14 00:07:47 kind-worker2 kubelet[297]: I0414 00:07:47.232178     297 topology_manager.go:200] "Topology Admit Handler"
Apr 14 00:07:47 kind-worker2 kubelet[297]: I0414 00:07:47.307160     297 reconciler.go:342] "operationExecutor.VerifyControllerAttachedVolume started for volume \"xtables-lock\" (UniqueName: \"kubernetes.io/host-path/d3a95d69-5e47-4b3f-9ea3-fdb35ad5e044-xtables-lock\") pod \"kindnet-b427z\" (UID: \"d3a95d69-5e47-4b3f-9ea3-fdb35ad5e044\") " pod="kube-system/kindnet-b427z"
Apr 14 00:07:47 kind-worker2 kubelet[297]: I0414 00:07:47.307323     297 reconciler.go:342] "operationExecutor.VerifyControllerAttachedVolume started for volume \"lib-modules\" (UniqueName: \"kubernetes.io/host-path/d3a95d69-5e47-4b3f-9ea3-fdb35ad5e044-lib-modules\") pod \"kindnet-b427z\" (UID: \"d3a95d69-5e47-4b3f-9ea3-fdb35ad5e044\") " pod="kube-system/kindnet-b427z"
Apr 14 00:07:47 kind-worker2 kubelet[297]: I0414 00:07:47.307479     297 reconciler.go:342] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-fkc2k\" (UniqueName: \"kubernetes.io/projected/d3a95d69-5e47-4b3f-9ea3-fdb35ad5e044-kube-api-access-fkc2k\") pod \"kindnet-b427z\" (UID: \"d3a95d69-5e47-4b3f-9ea3-fdb35ad5e044\") " pod="kube-system/kindnet-b427z"
Apr 14 00:07:47 kind-worker2 kubelet[297]: I0414 00:07:47.307581     297 reconciler.go:342] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-proxy\" (UniqueName: \"kubernetes.io/configmap/4bda8518-0d54-449c-896a-55344c90cbdb-kube-proxy\") pod \"kube-proxy-qj9bm\" (UID: \"4bda8518-0d54-449c-896a-55344c90cbdb\") " pod="kube-system/kube-proxy-qj9bm"
Apr 14 00:07:47 kind-worker2 kubelet[297]: I0414 00:07:47.307715     297 reconciler.go:342] "operationExecutor.VerifyControllerAttachedVolume started for volume \"xtables-lock\" (UniqueName: \"kubernetes.io/host-path/4bda8518-0d54-449c-896a-55344c90cbdb-xtables-lock\") pod \"kube-proxy-qj9bm\" (UID: \"4bda8518-0d54-449c-896a-55344c90cbdb\") " pod="kube-system/kube-proxy-qj9bm"
Apr 14 00:07:47 kind-worker2 kubelet[297]: I0414 00:07:47.307788     297 reconciler.go:342] "operationExecutor.VerifyControllerAttachedVolume started for volume \"lib-modules\" (UniqueName: \"kubernetes.io/host-path/4bda8518-0d54-449c-896a-55344c90cbdb-lib-modules\") pod \"kube-proxy-qj9bm\" (UID: \"4bda8518-0d54-449c-896a-55344c90cbdb\") " pod="kube-system/kube-proxy-qj9bm"
Apr 14 00:07:47 kind-worker2 kubelet[297]: I0414 00:07:47.307906     297 reconciler.go:342] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-554wt\" (UniqueName: \"kubernetes.io/projected/4bda8518-0d54-449c-896a-55344c90cbdb-kube-api-access-554wt\") pod \"kube-proxy-qj9bm\" (UID: \"4bda8518-0d54-449c-896a-55344c90cbdb\") " pod="kube-system/kube-proxy-qj9bm"
Apr 14 00:07:47 kind-worker2 kubelet[297]: I0414 00:07:47.307986     297 reconciler.go:342] "operationExecutor.VerifyControllerAttachedVolume started for volume \"cni-cfg\" (UniqueName: \"kubernetes.io/host-path/d3a95d69-5e47-4b3f-9ea3-fdb35ad5e044-cni-cfg\") pod \"kindnet-b427z\" (UID: \"d3a95d69-5e47-4b3f-9ea3-fdb35ad5e044\") " pod="kube-system/kindnet-b427z"
Apr 14 00:07:49 kind-worker2 kubelet[297]: E0414 00:07:49.169607     297 kubelet.go:2349] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Apr 14 00:07:50 kind-worker2 kubelet[297]: E0414 00:07:50.102021     297 kuberuntime_manager.go:905] container &Container{Name:kube-proxy,Image:k8s.gcr.io/kube-proxy:v1.24.7,Command:[/usr/local/bin/kube-proxy --config=/var/lib/kube-proxy/config.conf --hostname-override=$(NODE_NAME)],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:NODE_NAME,Value:,ValueFrom:&EnvVarSource{FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:spec.nodeName,},ResourceFieldRef:nil,ConfigMapKeyRef:nil,SecretKeyRef:nil,},},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-proxy,ReadOnly:false,MountPath:/var/lib/kube-proxy,SubPath:,MountPropagation:nil,SubPathExpr:,},VolumeMount{Name:xtables-lock,ReadOnly:false,MountPath:/run/xtables.lock,SubPath:,MountPropagation:nil,SubPathExpr:,},VolumeMount{Name:lib-modules,ReadOnly:true,MountPath:/lib/modules,SubPath:,MountPropagation:nil,SubPathExpr:,},VolumeMount{Name:kube-api-access-554wt,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:*true,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,} start failed in pod kube-proxy-qj9bm_kube-system(4bda8518-0d54-449c-896a-55344c90cbdb): CreateContainerConfigError: services have not yet been read at least once, cannot construct envvars
Apr 14 00:07:50 kind-worker2 kubelet[297]: E0414 00:07:50.102151     297 pod_workers.go:951] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kube-proxy\" with CreateContainerConfigError: \"services have not yet been read at least once, cannot construct envvars\"" pod="kube-system/kube-proxy-qj9bm" podUID=4bda8518-0d54-449c-896a-55344c90cbdb
Apr 14 00:07:50 kind-worker2 kubelet[297]: E0414 00:07:50.600527     297 kuberuntime_manager.go:905] container &Container{Name:kindnet-cni,Image:docker.io/kindest/kindnetd:v20221004-44d545d1,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:HOST_IP,Value:,ValueFrom:&EnvVarSource{FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:status.hostIP,},ResourceFieldRef:nil,ConfigMapKeyRef:nil,SecretKeyRef:nil,},},EnvVar{Name:POD_IP,Value:,ValueFrom:&EnvVarSource{FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:status.podIP,},ResourceFieldRef:nil,ConfigMapKeyRef:nil,SecretKeyRef:nil,},},EnvVar{Name:POD_SUBNET,Value:10.244.0.0/16,ValueFrom:nil,},EnvVar{Name:CONTROL_PLANE_ENDPOINT,Value:kind-control-plane:6443,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{cpu: {{100 -3} {<nil>} 100m DecimalSI},memory: {{52428800 0} {<nil>} 50Mi BinarySI},},Requests:ResourceList{cpu: {{100 -3} {<nil>} 100m DecimalSI},memory: {{52428800 0} {<nil>} 50Mi BinarySI},},},VolumeMounts:[]VolumeMount{VolumeMount{Name:cni-cfg,ReadOnly:false,MountPath:/etc/cni/net.d,SubPath:,MountPropagation:nil,SubPathExpr:,},VolumeMount{Name:xtables-lock,ReadOnly:false,MountPath:/run/xtables.lock,SubPath:,MountPropagation:nil,SubPathExpr:,},VolumeMount{Name:lib-modules,ReadOnly:true,MountPath:/lib/modules,SubPath:,MountPropagation:nil,SubPathExpr:,},VolumeMount{Name:kube-api-access-fkc2k,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:&Capabilities{Add:[NET_RAW NET_ADMIN],Drop:[],},Privileged:*false,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,} start failed in pod kindnet-b427z_kube-system(d3a95d69-5e47-4b3f-9ea3-fdb35ad5e044): CreateContainerConfigError: services have not yet been read at least once, cannot construct envvars
Apr 14 00:07:50 kind-worker2 kubelet[297]: E0414 00:07:50.600624     297 pod_workers.go:951] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kindnet-cni\" with CreateContainerConfigError: \"services have not yet been read at least once, cannot construct envvars\"" pod="kube-system/kindnet-b427z" podUID=d3a95d69-5e47-4b3f-9ea3-fdb35ad5e044
Apr 14 00:07:50 kind-worker2 kubelet[297]: E0414 00:07:50.868921     297 kuberuntime_manager.go:905] container &Container{Name:kindnet-cni,Image:docker.io/kindest/kindnetd:v20221004-44d545d1,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:HOST_IP,Value:,ValueFrom:&EnvVarSource{FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:status.hostIP,},ResourceFieldRef:nil,ConfigMapKeyRef:nil,SecretKeyRef:nil,},},EnvVar{Name:POD_IP,Value:,ValueFrom:&EnvVarSource{FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:status.podIP,},ResourceFieldRef:nil,ConfigMapKeyRef:nil,SecretKeyRef:nil,},},EnvVar{Name:POD_SUBNET,Value:10.244.0.0/16,ValueFrom:nil,},EnvVar{Name:CONTROL_PLANE_ENDPOINT,Value:kind-control-plane:6443,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{cpu: {{100 -3} {<nil>} 100m DecimalSI},memory: {{52428800 0} {<nil>} 50Mi BinarySI},},Requests:ResourceList{cpu: {{100 -3} {<nil>} 100m DecimalSI},memory: {{52428800 0} {<nil>} 50Mi BinarySI},},},VolumeMounts:[]VolumeMount{VolumeMount{Name:cni-cfg,ReadOnly:false,MountPath:/etc/cni/net.d,SubPath:,MountPropagation:nil,SubPathExpr:,},VolumeMount{Name:xtables-lock,ReadOnly:false,MountPath:/run/xtables.lock,SubPath:,MountPropagation:nil,SubPathExpr:,},VolumeMount{Name:lib-modules,ReadOnly:true,MountPath:/lib/modules,SubPath:,MountPropagation:nil,SubPathExpr:,},VolumeMount{Name:kube-api-access-fkc2k,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:&Capabilities{Add:[NET_RAW NET_ADMIN],Drop:[],},Privileged:*false,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,} start failed in pod kindnet-b427z_kube-system(d3a95d69-5e47-4b3f-9ea3-fdb35ad5e044): CreateContainerConfigError: services have not yet been read at least once, cannot construct envvars
Apr 14 00:07:50 kind-worker2 kubelet[297]: E0414 00:07:50.869020     297 pod_workers.go:951] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kindnet-cni\" with CreateContainerConfigError: \"services have not yet been read at least once, cannot construct envvars\"" pod="kube-system/kindnet-b427z" podUID=d3a95d69-5e47-4b3f-9ea3-fdb35ad5e044
Apr 14 00:07:50 kind-worker2 kubelet[297]: E0414 00:07:50.870752     297 kuberuntime_manager.go:905] container &Container{Name:kube-proxy,Image:k8s.gcr.io/kube-proxy:v1.24.7,Command:[/usr/local/bin/kube-proxy --config=/var/lib/kube-proxy/config.conf --hostname-override=$(NODE_NAME)],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:NODE_NAME,Value:,ValueFrom:&EnvVarSource{FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:spec.nodeName,},ResourceFieldRef:nil,ConfigMapKeyRef:nil,SecretKeyRef:nil,},},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-proxy,ReadOnly:false,MountPath:/var/lib/kube-proxy,SubPath:,MountPropagation:nil,SubPathExpr:,},VolumeMount{Name:xtables-lock,ReadOnly:false,MountPath:/run/xtables.lock,SubPath:,MountPropagation:nil,SubPathExpr:,},VolumeMount{Name:lib-modules,ReadOnly:true,MountPath:/lib/modules,SubPath:,MountPropagation:nil,SubPathExpr:,},VolumeMount{Name:kube-api-access-554wt,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:*true,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,} start failed in pod kube-proxy-qj9bm_kube-system(4bda8518-0d54-449c-896a-55344c90cbdb): CreateContainerConfigError: services have not yet been read at least once, cannot construct envvars
Apr 14 00:07:50 kind-worker2 kubelet[297]: E0414 00:07:50.870837     297 pod_workers.go:951] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kube-proxy\" with CreateContainerConfigError: \"services have not yet been read at least once, cannot construct envvars\"" pod="kube-system/kube-proxy-qj9bm" podUID=4bda8518-0d54-449c-896a-55344c90cbdb
Apr 14 00:07:54 kind-worker2 kubelet[297]: E0414 00:07:54.171598     297 kubelet.go:2349] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Apr 14 00:07:59 kind-worker2 kubelet[297]: E0414 00:07:59.173516     297 kubelet.go:2349] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Apr 14 00:08:04 kind-worker2 kubelet[297]: E0414 00:08:04.174769     297 kubelet.go:2349] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Apr 14 00:08:09 kind-worker2 kubelet[297]: E0414 00:08:09.177230     297 kubelet.go:2349] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Apr 14 00:08:14 kind-worker2 kubelet[297]: E0414 00:08:14.179552     297 kubelet.go:2349] "Container runtime network not ready" networkReady="NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized"
Apr 20 00:03:11 kind-worker2 kubelet[297]: I0420 00:03:11.553687     297 topology_manager.go:200] "Topology Admit Handler"
Apr 20 00:03:11 kind-worker2 kubelet[297]: I0420 00:03:11.613994     297 reconciler.go:342] "operationExecutor.VerifyControllerAttachedVolume started for volume \"tmp-dir\" (UniqueName: \"kubernetes.io/empty-dir/212bd06d-b2f6-4ee4-97d1-65fe8f04ea3c-tmp-dir\") pod \"metrics-server-6bf466fbf5-rmmvd\" (UID: \"212bd06d-b2f6-4ee4-97d1-65fe8f04ea3c\") " pod="kube-system/metrics-server-6bf466fbf5-rmmvd"
Apr 20 00:03:11 kind-worker2 kubelet[297]: I0420 00:03:11.614198     297 reconciler.go:342] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-r27xd\" (UniqueName: \"kubernetes.io/projected/212bd06d-b2f6-4ee4-97d1-65fe8f04ea3c-kube-api-access-r27xd\") pod \"metrics-server-6bf466fbf5-rmmvd\" (UID: \"212bd06d-b2f6-4ee4-97d1-65fe8f04ea3c\") " pod="kube-system/metrics-server-6bf466fbf5-rmmvd"
Apr 20 00:03:24 kind-worker2 kubelet[297]: I0420 00:03:24.984173     297 log.go:195] http: TLS handshake error from 10.244.1.2:37082: remote error: tls: bad certificate
Apr 20 00:03:39 kind-worker2 kubelet[297]: I0420 00:03:39.992570     297 log.go:195] http: TLS handshake error from 10.244.1.2:37380: remote error: tls: bad certificate
Apr 20 00:03:55 kind-worker2 kubelet[297]: I0420 00:03:55.001244     297 log.go:195] http: TLS handshake error from 10.244.1.2:37668: remote error: tls: bad certificate
Apr 20 00:04:09 kind-worker2 kubelet[297]: I0420 00:04:09.983274     297 log.go:195] http: TLS handshake error from 10.244.1.2:37956: remote error: tls: bad certificate
Apr 20 00:04:25 kind-worker2 kubelet[297]: I0420 00:04:25.001974     297 log.go:195] http: TLS handshake error from 10.244.1.2:38240: remote error: tls: bad certificate
Apr 20 00:04:39 kind-worker2 kubelet[297]: I0420 00:04:39.998924     297 log.go:195] http: TLS handshake error from 10.244.1.2:38534: remote error: tls: bad certificate
Apr 20 00:04:55 kind-worker2 kubelet[297]: I0420 00:04:55.002648     297 log.go:195] http: TLS handshake error from 10.244.1.2:38818: remote error: tls: bad certificate
Apr 20 00:05:09 kind-worker2 kubelet[297]: I0420 00:05:09.986803     297 log.go:195] http: TLS handshake error from 10.244.1.2:39110: remote error: tls: bad certificate
Apr 20 00:05:24 kind-worker2 kubelet[297]: I0420 00:05:24.999578     297 log.go:195] http: TLS handshake error from 10.244.1.2:39394: remote error: tls: bad certificate
Apr 20 00:05:39 kind-worker2 kubelet[297]: I0420 00:05:39.983288     297 log.go:195] http: TLS handshake error from 10.244.1.2:39686: remote error: tls: bad certificate
Apr 20 00:05:54 kind-worker2 kubelet[297]: I0420 00:05:54.983253     297 log.go:195] http: TLS handshake error from 10.244.1.2:39970: remote error: tls: bad certificate
Apr 20 00:06:09 kind-worker2 kubelet[297]: I0420 00:06:09.988775     297 log.go:195] http: TLS handshake error from 10.244.1.2:40258: remote error: tls: bad certificate
Apr 20 00:06:24 kind-worker2 kubelet[297]: I0420 00:06:24.995908     297 log.go:195] http: TLS handshake error from 10.244.1.2:40618: remote error: tls: bad certificate
Apr 20 00:06:39 kind-worker2 kubelet[297]: I0420 00:06:39.984708     297 log.go:195] http: TLS handshake error from 10.244.1.2:40910: remote error: tls: bad certificate
Apr 20 00:06:55 kind-worker2 kubelet[297]: I0420 00:06:55.006876     297 log.go:195] http: TLS handshake error from 10.244.1.2:41192: remote error: tls: bad certificate
Apr 20 00:07:09 kind-worker2 kubelet[297]: I0420 00:07:09.982792     297 log.go:195] http: TLS handshake error from 10.244.1.2:41480: remote error: tls: bad certificate
Apr 20 00:07:24 kind-worker2 kubelet[297]: I0420 00:07:24.990190     297 log.go:195] http: TLS handshake error from 10.244.1.2:41776: remote error: tls: bad certificate
Apr 20 00:07:39 kind-worker2 kubelet[297]: I0420 00:07:39.984458     297 log.go:195] http: TLS handshake error from 10.244.1.2:42068: remote error: tls: bad certificate
Apr 20 00:07:42 kind-worker2 kubelet[297]: I0420 00:07:42.422820     297 topology_manager.go:200] "Topology Admit Handler"
Apr 20 00:07:42 kind-worker2 kubelet[297]: I0420 00:07:42.460790     297 reconciler.go:342] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-bzlmc\" (UniqueName: \"kubernetes.io/projected/21f18b4d-6bae-4640-81f4-6ef08f7a00b0-kube-api-access-bzlmc\") pod \"metrics-server-5744bdc4f4-kg8rc\" (UID: \"21f18b4d-6bae-4640-81f4-6ef08f7a00b0\") " pod="kube-system/metrics-server-5744bdc4f4-kg8rc"
Apr 20 00:07:42 kind-worker2 kubelet[297]: I0420 00:07:42.460892     297 reconciler.go:342] "operationExecutor.VerifyControllerAttachedVolume started for volume \"tmp-dir\" (UniqueName: \"kubernetes.io/empty-dir/21f18b4d-6bae-4640-81f4-6ef08f7a00b0-tmp-dir\") pod \"metrics-server-5744bdc4f4-kg8rc\" (UID: \"21f18b4d-6bae-4640-81f4-6ef08f7a00b0\") " pod="kube-system/metrics-server-5744bdc4f4-kg8rc"
Apr 20 00:07:54 kind-worker2 kubelet[297]: I0420 00:07:54.994088     297 log.go:195] http: TLS handshake error from 10.244.1.2:42362: remote error: tls: bad certificate
Apr 20 00:08:09 kind-worker2 kubelet[297]: I0420 00:08:09.982275     297 log.go:195] http: TLS handshake error from 10.244.1.2:42654: remote error: tls: bad certificate
Apr 20 00:08:13 kind-worker2 kubelet[297]: I0420 00:08:13.833506     297 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"kube-api-access-r27xd\" (UniqueName: \"kubernetes.io/projected/212bd06d-b2f6-4ee4-97d1-65fe8f04ea3c-kube-api-access-r27xd\") pod \"212bd06d-b2f6-4ee4-97d1-65fe8f04ea3c\" (UID: \"212bd06d-b2f6-4ee4-97d1-65fe8f04ea3c\") "
Apr 20 00:08:13 kind-worker2 kubelet[297]: I0420 00:08:13.833607     297 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"tmp-dir\" (UniqueName: \"kubernetes.io/empty-dir/212bd06d-b2f6-4ee4-97d1-65fe8f04ea3c-tmp-dir\") pod \"212bd06d-b2f6-4ee4-97d1-65fe8f04ea3c\" (UID: \"212bd06d-b2f6-4ee4-97d1-65fe8f04ea3c\") "
Apr 20 00:08:13 kind-worker2 kubelet[297]: W0420 00:08:13.834283     297 empty_dir.go:519] Warning: Failed to clear quota on /var/lib/kubelet/pods/212bd06d-b2f6-4ee4-97d1-65fe8f04ea3c/volumes/kubernetes.io~empty-dir/tmp-dir: clearQuota called, but quotas disabled
Apr 20 00:08:13 kind-worker2 kubelet[297]: I0420 00:08:13.834671     297 operation_generator.go:863] UnmountVolume.TearDown succeeded for volume "kubernetes.io/empty-dir/212bd06d-b2f6-4ee4-97d1-65fe8f04ea3c-tmp-dir" (OuterVolumeSpecName: "tmp-dir") pod "212bd06d-b2f6-4ee4-97d1-65fe8f04ea3c" (UID: "212bd06d-b2f6-4ee4-97d1-65fe8f04ea3c"). InnerVolumeSpecName "tmp-dir". PluginName "kubernetes.io/empty-dir", VolumeGidValue ""
Apr 20 00:08:13 kind-worker2 kubelet[297]: I0420 00:08:13.852264     297 operation_generator.go:863] UnmountVolume.TearDown succeeded for volume "kubernetes.io/projected/212bd06d-b2f6-4ee4-97d1-65fe8f04ea3c-kube-api-access-r27xd" (OuterVolumeSpecName: "kube-api-access-r27xd") pod "212bd06d-b2f6-4ee4-97d1-65fe8f04ea3c" (UID: "212bd06d-b2f6-4ee4-97d1-65fe8f04ea3c"). InnerVolumeSpecName "kube-api-access-r27xd". PluginName "kubernetes.io/projected", VolumeGidValue ""
Apr 20 00:08:13 kind-worker2 kubelet[297]: I0420 00:08:13.934819     297 reconciler.go:384] "Volume detached for volume \"kube-api-access-r27xd\" (UniqueName: \"kubernetes.io/projected/212bd06d-b2f6-4ee4-97d1-65fe8f04ea3c-kube-api-access-r27xd\") on node \"kind-worker2\" DevicePath \"\""
Apr 20 00:08:13 kind-worker2 kubelet[297]: I0420 00:08:13.934920     297 reconciler.go:384] "Volume detached for volume \"tmp-dir\" (UniqueName: \"kubernetes.io/empty-dir/212bd06d-b2f6-4ee4-97d1-65fe8f04ea3c-tmp-dir\") on node \"kind-worker2\" DevicePath \"\""
Apr 20 00:08:14 kind-worker2 kubelet[297]: I0420 00:08:14.269797     297 scope.go:110] "RemoveContainer" containerID="2a1c5a46ce27a6b95727bcfe7f71f65bd9a394727fc9b99f48ae75e03775862a"
Apr 20 00:08:14 kind-worker2 kubelet[297]: I0420 00:08:14.405825     297 scope.go:110] "RemoveContainer" containerID="2a1c5a46ce27a6b95727bcfe7f71f65bd9a394727fc9b99f48ae75e03775862a"
Apr 20 00:08:14 kind-worker2 kubelet[297]: E0420 00:08:14.407576     297 remote_runtime.go:604] "ContainerStatus from runtime service failed" err="rpc error: code = NotFound desc = an error occurred when try to find container \"2a1c5a46ce27a6b95727bcfe7f71f65bd9a394727fc9b99f48ae75e03775862a\": not found" containerID="2a1c5a46ce27a6b95727bcfe7f71f65bd9a394727fc9b99f48ae75e03775862a"
Apr 20 00:08:14 kind-worker2 kubelet[297]: I0420 00:08:14.407767     297 pod_container_deletor.go:52] "DeleteContainer returned error" containerID={Type:containerd ID:2a1c5a46ce27a6b95727bcfe7f71f65bd9a394727fc9b99f48ae75e03775862a} err="failed to get container status \"2a1c5a46ce27a6b95727bcfe7f71f65bd9a394727fc9b99f48ae75e03775862a\": rpc error: code = NotFound desc = an error occurred when try to find container \"2a1c5a46ce27a6b95727bcfe7f71f65bd9a394727fc9b99f48ae75e03775862a\": not found"
Apr 20 00:08:14 kind-worker2 kubelet[297]: I0420 00:08:14.816960     297 kubelet_volumes.go:160] "Cleaned up orphaned pod volumes dir" podUID=212bd06d-b2f6-4ee4-97d1-65fe8f04ea3c path="/var/lib/kubelet/pods/212bd06d-b2f6-4ee4-97d1-65fe8f04ea3c/volumes"
Apr 20 00:08:16 kind-worker2 kubelet[297]: W0420 00:08:16.154972     297 conversion.go:112] Could not get instant cpu stats: cumulative stats decrease
Apr 20 00:15:48 kind-worker2 kubelet[297]: I0420 00:15:48.420096     297 topology_manager.go:200] "Topology Admit Handler"
Apr 20 00:15:48 kind-worker2 kubelet[297]: E0420 00:15:48.420723     297 cpu_manager.go:394] "RemoveStaleState: removing container" podUID="212bd06d-b2f6-4ee4-97d1-65fe8f04ea3c" containerName="metrics-server"
Apr 20 00:15:48 kind-worker2 kubelet[297]: I0420 00:15:48.421127     297 memory_manager.go:345] "RemoveStaleState removing state" podUID="212bd06d-b2f6-4ee4-97d1-65fe8f04ea3c" containerName="metrics-server"
Apr 20 00:15:48 kind-worker2 kubelet[297]: I0420 00:15:48.537889     297 reconciler.go:342] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-9dj54\" (UniqueName: \"kubernetes.io/projected/644de0c7-a2c3-49f0-85f4-34d75bfff557-kube-api-access-9dj54\") pod \"load-generator\" (UID: \"644de0c7-a2c3-49f0-85f4-34d75bfff557\") " pod="default/load-generator"
Apr 20 00:15:49 kind-worker2 kubelet[297]: E0420 00:15:49.891805     297 remote_image.go:238] "PullImage from image service failed" err="rpc error: code = NotFound desc = failed to pull and unpack image \"docker.io/library/busybox:1.48\": failed to resolve reference \"docker.io/library/busybox:1.48\": docker.io/library/busybox:1.48: not found" image="busybox:1.48"
Apr 20 00:15:49 kind-worker2 kubelet[297]: E0420 00:15:49.892087     297 kuberuntime_image.go:51] "Failed to pull image" err="rpc error: code = NotFound desc = failed to pull and unpack image \"docker.io/library/busybox:1.48\": failed to resolve reference \"docker.io/library/busybox:1.48\": docker.io/library/busybox:1.48: not found" image="busybox:1.48"
Apr 20 00:15:49 kind-worker2 kubelet[297]: E0420 00:15:49.892511     297 kuberuntime_manager.go:905] container &Container{Name:load-generator,Image:busybox:1.48,Command:[],Args:[/bin/sh],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-9dj54,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:true,StdinOnce:true,TTY:true,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,} start failed in pod load-generator_default(644de0c7-a2c3-49f0-85f4-34d75bfff557): ErrImagePull: rpc error: code = NotFound desc = failed to pull and unpack image "docker.io/library/busybox:1.48": failed to resolve reference "docker.io/library/busybox:1.48": docker.io/library/busybox:1.48: not found
Apr 20 00:15:49 kind-worker2 kubelet[297]: E0420 00:15:49.892721     297 pod_workers.go:951] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"load-generator\" with ErrImagePull: \"rpc error: code = NotFound desc = failed to pull and unpack image \\\"docker.io/library/busybox:1.48\\\": failed to resolve reference \\\"docker.io/library/busybox:1.48\\\": docker.io/library/busybox:1.48: not found\"" pod="default/load-generator" podUID=644de0c7-a2c3-49f0-85f4-34d75bfff557
Apr 20 00:15:50 kind-worker2 kubelet[297]: E0420 00:15:50.741111     297 pod_workers.go:951] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"load-generator\" with ImagePullBackOff: \"Back-off pulling image \\\"busybox:1.48\\\"\"" pod="default/load-generator" podUID=644de0c7-a2c3-49f0-85f4-34d75bfff557
Apr 20 00:16:03 kind-worker2 kubelet[297]: I0420 00:16:03.653772     297 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"kube-api-access-9dj54\" (UniqueName: \"kubernetes.io/projected/644de0c7-a2c3-49f0-85f4-34d75bfff557-kube-api-access-9dj54\") pod \"644de0c7-a2c3-49f0-85f4-34d75bfff557\" (UID: \"644de0c7-a2c3-49f0-85f4-34d75bfff557\") "
Apr 20 00:16:03 kind-worker2 kubelet[297]: I0420 00:16:03.700051     297 operation_generator.go:863] UnmountVolume.TearDown succeeded for volume "kubernetes.io/projected/644de0c7-a2c3-49f0-85f4-34d75bfff557-kube-api-access-9dj54" (OuterVolumeSpecName: "kube-api-access-9dj54") pod "644de0c7-a2c3-49f0-85f4-34d75bfff557" (UID: "644de0c7-a2c3-49f0-85f4-34d75bfff557"). InnerVolumeSpecName "kube-api-access-9dj54". PluginName "kubernetes.io/projected", VolumeGidValue ""
Apr 20 00:16:03 kind-worker2 kubelet[297]: I0420 00:16:03.754412     297 reconciler.go:384] "Volume detached for volume \"kube-api-access-9dj54\" (UniqueName: \"kubernetes.io/projected/644de0c7-a2c3-49f0-85f4-34d75bfff557-kube-api-access-9dj54\") on node \"kind-worker2\" DevicePath \"\""
Apr 20 00:16:04 kind-worker2 kubelet[297]: I0420 00:16:04.814541     297 kubelet_volumes.go:160] "Cleaned up orphaned pod volumes dir" podUID=644de0c7-a2c3-49f0-85f4-34d75bfff557 path="/var/lib/kubelet/pods/644de0c7-a2c3-49f0-85f4-34d75bfff557/volumes"
Apr 20 00:17:36 kind-worker2 kubelet[297]: I0420 00:17:36.429599     297 topology_manager.go:200] "Topology Admit Handler"
Apr 20 00:17:36 kind-worker2 kubelet[297]: I0420 00:17:36.556329     297 reconciler.go:342] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-8fbr2\" (UniqueName: \"kubernetes.io/projected/f0de23db-b771-4c49-9086-dc08ee7d72af-kube-api-access-8fbr2\") pod \"load-generator\" (UID: \"f0de23db-b771-4c49-9086-dc08ee7d72af\") " pod="default/load-generator"
Apr 20 00:17:38 kind-worker2 kubelet[297]: E0420 00:17:38.053342     297 remote_image.go:238] "PullImage from image service failed" err="rpc error: code = NotFound desc = failed to pull and unpack image \"docker.io/library/busybox:1.48\": failed to resolve reference \"docker.io/library/busybox:1.48\": docker.io/library/busybox:1.48: not found" image="busybox:1.48"
Apr 20 00:17:38 kind-worker2 kubelet[297]: E0420 00:17:38.053475     297 kuberuntime_image.go:51] "Failed to pull image" err="rpc error: code = NotFound desc = failed to pull and unpack image \"docker.io/library/busybox:1.48\": failed to resolve reference \"docker.io/library/busybox:1.48\": docker.io/library/busybox:1.48: not found" image="busybox:1.48"
Apr 20 00:17:38 kind-worker2 kubelet[297]: E0420 00:17:38.053689     297 kuberuntime_manager.go:905] container &Container{Name:load-generator,Image:busybox:1.48,Command:[],Args:[/bin/sh],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-8fbr2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:true,StdinOnce:true,TTY:true,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,} start failed in pod load-generator_default(f0de23db-b771-4c49-9086-dc08ee7d72af): ErrImagePull: rpc error: code = NotFound desc = failed to pull and unpack image "docker.io/library/busybox:1.48": failed to resolve reference "docker.io/library/busybox:1.48": docker.io/library/busybox:1.48: not found
Apr 20 00:17:38 kind-worker2 kubelet[297]: E0420 00:17:38.053837     297 pod_workers.go:951] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"load-generator\" with ErrImagePull: \"rpc error: code = NotFound desc = failed to pull and unpack image \\\"docker.io/library/busybox:1.48\\\": failed to resolve reference \\\"docker.io/library/busybox:1.48\\\": docker.io/library/busybox:1.48: not found\"" pod="default/load-generator" podUID=f0de23db-b771-4c49-9086-dc08ee7d72af
Apr 20 00:17:38 kind-worker2 kubelet[297]: E0420 00:17:38.073664     297 pod_workers.go:951] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"load-generator\" with ImagePullBackOff: \"Back-off pulling image \\\"busybox:1.48\\\"\"" pod="default/load-generator" podUID=f0de23db-b771-4c49-9086-dc08ee7d72af
Apr 20 00:17:49 kind-worker2 kubelet[297]: E0420 00:17:49.115398     297 remote_image.go:238] "PullImage from image service failed" err="rpc error: code = NotFound desc = failed to pull and unpack image \"docker.io/library/busybox:1.48\": failed to resolve reference \"docker.io/library/busybox:1.48\": docker.io/library/busybox:1.48: not found" image="busybox:1.48"
Apr 20 00:17:49 kind-worker2 kubelet[297]: E0420 00:17:49.115566     297 kuberuntime_image.go:51] "Failed to pull image" err="rpc error: code = NotFound desc = failed to pull and unpack image \"docker.io/library/busybox:1.48\": failed to resolve reference \"docker.io/library/busybox:1.48\": docker.io/library/busybox:1.48: not found" image="busybox:1.48"
Apr 20 00:17:49 kind-worker2 kubelet[297]: E0420 00:17:49.115808     297 kuberuntime_manager.go:905] container &Container{Name:load-generator,Image:busybox:1.48,Command:[],Args:[/bin/sh],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-8fbr2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:true,StdinOnce:true,TTY:true,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,} start failed in pod load-generator_default(f0de23db-b771-4c49-9086-dc08ee7d72af): ErrImagePull: rpc error: code = NotFound desc = failed to pull and unpack image "docker.io/library/busybox:1.48": failed to resolve reference "docker.io/library/busybox:1.48": docker.io/library/busybox:1.48: not found
Apr 20 00:17:49 kind-worker2 kubelet[297]: E0420 00:17:49.116039     297 pod_workers.go:951] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"load-generator\" with ErrImagePull: \"rpc error: code = NotFound desc = failed to pull and unpack image \\\"docker.io/library/busybox:1.48\\\": failed to resolve reference \\\"docker.io/library/busybox:1.48\\\": docker.io/library/busybox:1.48: not found\"" pod="default/load-generator" podUID=f0de23db-b771-4c49-9086-dc08ee7d72af
Apr 20 00:18:00 kind-worker2 kubelet[297]: E0420 00:18:00.802913     297 pod_workers.go:951] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"load-generator\" with ImagePullBackOff: \"Back-off pulling image \\\"busybox:1.48\\\"\"" pod="default/load-generator" podUID=f0de23db-b771-4c49-9086-dc08ee7d72af
Apr 20 00:18:16 kind-worker2 kubelet[297]: E0420 00:18:16.062443     297 remote_image.go:238] "PullImage from image service failed" err="rpc error: code = NotFound desc = failed to pull and unpack image \"docker.io/library/busybox:1.48\": failed to resolve reference \"docker.io/library/busybox:1.48\": docker.io/library/busybox:1.48: not found" image="busybox:1.48"
Apr 20 00:18:16 kind-worker2 kubelet[297]: E0420 00:18:16.062538     297 kuberuntime_image.go:51] "Failed to pull image" err="rpc error: code = NotFound desc = failed to pull and unpack image \"docker.io/library/busybox:1.48\": failed to resolve reference \"docker.io/library/busybox:1.48\": docker.io/library/busybox:1.48: not found" image="busybox:1.48"
Apr 20 00:18:16 kind-worker2 kubelet[297]: E0420 00:18:16.062720     297 kuberuntime_manager.go:905] container &Container{Name:load-generator,Image:busybox:1.48,Command:[],Args:[/bin/sh],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-8fbr2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:true,StdinOnce:true,TTY:true,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,} start failed in pod load-generator_default(f0de23db-b771-4c49-9086-dc08ee7d72af): ErrImagePull: rpc error: code = NotFound desc = failed to pull and unpack image "docker.io/library/busybox:1.48": failed to resolve reference "docker.io/library/busybox:1.48": docker.io/library/busybox:1.48: not found
Apr 20 00:18:16 kind-worker2 kubelet[297]: E0420 00:18:16.062830     297 pod_workers.go:951] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"load-generator\" with ErrImagePull: \"rpc error: code = NotFound desc = failed to pull and unpack image \\\"docker.io/library/busybox:1.48\\\": failed to resolve reference \\\"docker.io/library/busybox:1.48\\\": docker.io/library/busybox:1.48: not found\"" pod="default/load-generator" podUID=f0de23db-b771-4c49-9086-dc08ee7d72af
Apr 20 00:18:27 kind-worker2 kubelet[297]: E0420 00:18:27.801641     297 pod_workers.go:951] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"load-generator\" with ImagePullBackOff: \"Back-off pulling image \\\"busybox:1.48\\\"\"" pod="default/load-generator" podUID=f0de23db-b771-4c49-9086-dc08ee7d72af
Apr 20 00:18:36 kind-worker2 kubelet[297]: I0420 00:18:36.902590     297 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"kube-api-access-8fbr2\" (UniqueName: \"kubernetes.io/projected/f0de23db-b771-4c49-9086-dc08ee7d72af-kube-api-access-8fbr2\") pod \"f0de23db-b771-4c49-9086-dc08ee7d72af\" (UID: \"f0de23db-b771-4c49-9086-dc08ee7d72af\") "
Apr 20 00:18:36 kind-worker2 kubelet[297]: I0420 00:18:36.940206     297 operation_generator.go:863] UnmountVolume.TearDown succeeded for volume "kubernetes.io/projected/f0de23db-b771-4c49-9086-dc08ee7d72af-kube-api-access-8fbr2" (OuterVolumeSpecName: "kube-api-access-8fbr2") pod "f0de23db-b771-4c49-9086-dc08ee7d72af" (UID: "f0de23db-b771-4c49-9086-dc08ee7d72af"). InnerVolumeSpecName "kube-api-access-8fbr2". PluginName "kubernetes.io/projected", VolumeGidValue ""
Apr 20 00:18:37 kind-worker2 kubelet[297]: I0420 00:18:37.004011     297 reconciler.go:384] "Volume detached for volume \"kube-api-access-8fbr2\" (UniqueName: \"kubernetes.io/projected/f0de23db-b771-4c49-9086-dc08ee7d72af-kube-api-access-8fbr2\") on node \"kind-worker2\" DevicePath \"\""
Apr 20 00:18:38 kind-worker2 kubelet[297]: I0420 00:18:38.817693     297 kubelet_volumes.go:160] "Cleaned up orphaned pod volumes dir" podUID=f0de23db-b771-4c49-9086-dc08ee7d72af path="/var/lib/kubelet/pods/f0de23db-b771-4c49-9086-dc08ee7d72af/volumes"
Apr 20 00:20:24 kind-worker2 kubelet[297]: I0420 00:20:24.068235     297 topology_manager.go:200] "Topology Admit Handler"
Apr 20 00:20:24 kind-worker2 kubelet[297]: I0420 00:20:24.135339     297 reconciler.go:342] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-f5bw5\" (UniqueName: \"kubernetes.io/projected/ee41d767-65fa-477f-92cb-5dc0cf824a19-kube-api-access-f5bw5\") pod \"load-generator\" (UID: \"ee41d767-65fa-477f-92cb-5dc0cf824a19\") " pod="default/load-generator"
Apr 20 00:20:42 kind-worker2 kubelet[297]: I0420 00:20:42.167866     297 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"kube-api-access-f5bw5\" (UniqueName: \"kubernetes.io/projected/ee41d767-65fa-477f-92cb-5dc0cf824a19-kube-api-access-f5bw5\") pod \"ee41d767-65fa-477f-92cb-5dc0cf824a19\" (UID: \"ee41d767-65fa-477f-92cb-5dc0cf824a19\") "
Apr 20 00:20:42 kind-worker2 kubelet[297]: I0420 00:20:42.204032     297 operation_generator.go:863] UnmountVolume.TearDown succeeded for volume "kubernetes.io/projected/ee41d767-65fa-477f-92cb-5dc0cf824a19-kube-api-access-f5bw5" (OuterVolumeSpecName: "kube-api-access-f5bw5") pod "ee41d767-65fa-477f-92cb-5dc0cf824a19" (UID: "ee41d767-65fa-477f-92cb-5dc0cf824a19"). InnerVolumeSpecName "kube-api-access-f5bw5". PluginName "kubernetes.io/projected", VolumeGidValue ""
Apr 20 00:20:42 kind-worker2 kubelet[297]: I0420 00:20:42.268561     297 reconciler.go:384] "Volume detached for volume \"kube-api-access-f5bw5\" (UniqueName: \"kubernetes.io/projected/ee41d767-65fa-477f-92cb-5dc0cf824a19-kube-api-access-f5bw5\") on node \"kind-worker2\" DevicePath \"\""
Apr 20 00:20:42 kind-worker2 kubelet[297]: I0420 00:20:42.682796     297 pod_container_deletor.go:79] "Container not found in pod's containers" containerID="7bd7497fc1eb5908ccf5ae677cbf308508097eac4073e11cda174d15536cca71"
Apr 20 00:22:14 kind-worker2 kubelet[297]: I0420 00:22:14.811469     297 kubelet_volumes.go:160] "Cleaned up orphaned pod volumes dir" podUID=ee41d767-65fa-477f-92cb-5dc0cf824a19 path="/var/lib/kubelet/pods/ee41d767-65fa-477f-92cb-5dc0cf824a19/volumes"
Apr 20 00:22:34 kind-worker2 kubelet[297]: I0420 00:22:34.102493     297 topology_manager.go:200] "Topology Admit Handler"
Apr 20 00:22:34 kind-worker2 kubelet[297]: E0420 00:22:34.102904     297 cpu_manager.go:394] "RemoveStaleState: removing container" podUID="ee41d767-65fa-477f-92cb-5dc0cf824a19" containerName="load-generator"
Apr 20 00:22:34 kind-worker2 kubelet[297]: I0420 00:22:34.103184     297 memory_manager.go:345] "RemoveStaleState removing state" podUID="ee41d767-65fa-477f-92cb-5dc0cf824a19" containerName="load-generator"
Apr 20 00:22:34 kind-worker2 kubelet[297]: I0420 00:22:34.221255     297 reconciler.go:342] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-jjm9k\" (UniqueName: \"kubernetes.io/projected/09afb1d9-c1ef-4470-ac42-c5d8405644d7-kube-api-access-jjm9k\") pod \"load-generator\" (UID: \"09afb1d9-c1ef-4470-ac42-c5d8405644d7\") " pod="default/load-generator"
Apr 20 00:23:12 kind-worker2 kubelet[297]: I0420 00:23:12.922957     297 scope.go:110] "RemoveContainer" containerID="8959cc74f9b7684f6e2f324e39f4cbe82af5826683ce18e6bbe6d6cd4861d046"
Apr 20 00:45:54 kind-worker2 kubelet[297]: I0420 00:45:54.973443     297 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"kube-api-access-jjm9k\" (UniqueName: \"kubernetes.io/projected/09afb1d9-c1ef-4470-ac42-c5d8405644d7-kube-api-access-jjm9k\") pod \"09afb1d9-c1ef-4470-ac42-c5d8405644d7\" (UID: \"09afb1d9-c1ef-4470-ac42-c5d8405644d7\") "
Apr 20 00:45:54 kind-worker2 kubelet[297]: I0420 00:45:54.996791     297 operation_generator.go:863] UnmountVolume.TearDown succeeded for volume "kubernetes.io/projected/09afb1d9-c1ef-4470-ac42-c5d8405644d7-kube-api-access-jjm9k" (OuterVolumeSpecName: "kube-api-access-jjm9k") pod "09afb1d9-c1ef-4470-ac42-c5d8405644d7" (UID: "09afb1d9-c1ef-4470-ac42-c5d8405644d7"). InnerVolumeSpecName "kube-api-access-jjm9k". PluginName "kubernetes.io/projected", VolumeGidValue ""
Apr 20 00:45:55 kind-worker2 kubelet[297]: I0420 00:45:55.074209     297 reconciler.go:384] "Volume detached for volume \"kube-api-access-jjm9k\" (UniqueName: \"kubernetes.io/projected/09afb1d9-c1ef-4470-ac42-c5d8405644d7-kube-api-access-jjm9k\") on node \"kind-worker2\" DevicePath \"\""
Apr 20 00:45:55 kind-worker2 kubelet[297]: I0420 00:45:55.574504     297 pod_container_deletor.go:79] "Container not found in pod's containers" containerID="7a404b81cce45e13836915c7672d461027a2c1767675893ab8ee50429ad4c51b"
Apr 20 00:46:00 kind-worker2 kubelet[297]: I0420 00:46:00.818513     297 kubelet_volumes.go:160] "Cleaned up orphaned pod volumes dir" podUID=09afb1d9-c1ef-4470-ac42-c5d8405644d7 path="/var/lib/kubelet/pods/09afb1d9-c1ef-4470-ac42-c5d8405644d7/volumes"
Apr 20 00:46:13 kind-worker2 kubelet[297]: I0420 00:46:13.197455     297 scope.go:110] "RemoveContainer" containerID="b60867ebfd7d2ab423c982e50a145a0550698e7f7ad17677889794c95f1fecb8"
Apr 20 00:46:27 kind-worker2 kubelet[297]: I0420 00:46:27.148594     297 topology_manager.go:200] "Topology Admit Handler"
Apr 20 00:46:27 kind-worker2 kubelet[297]: E0420 00:46:27.148706     297 cpu_manager.go:394] "RemoveStaleState: removing container" podUID="09afb1d9-c1ef-4470-ac42-c5d8405644d7" containerName="load-generator"
Apr 20 00:46:27 kind-worker2 kubelet[297]: I0420 00:46:27.148772     297 memory_manager.go:345] "RemoveStaleState removing state" podUID="09afb1d9-c1ef-4470-ac42-c5d8405644d7" containerName="load-generator"
Apr 20 00:46:27 kind-worker2 kubelet[297]: I0420 00:46:27.208538     297 reconciler.go:342] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-8mdrs\" (UniqueName: \"kubernetes.io/projected/d5eb8942-67ae-4ea8-b434-f1132cf6cca1-kube-api-access-8mdrs\") pod \"load-generator\" (UID: \"d5eb8942-67ae-4ea8-b434-f1132cf6cca1\") " pod="default/load-generator"
Apr 20 01:07:45 kind-worker2 kubelet[297]: I0420 01:07:45.246338     297 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"kube-api-access-8mdrs\" (UniqueName: \"kubernetes.io/projected/d5eb8942-67ae-4ea8-b434-f1132cf6cca1-kube-api-access-8mdrs\") pod \"d5eb8942-67ae-4ea8-b434-f1132cf6cca1\" (UID: \"d5eb8942-67ae-4ea8-b434-f1132cf6cca1\") "
Apr 20 01:07:45 kind-worker2 kubelet[297]: I0420 01:07:45.271861     297 operation_generator.go:863] UnmountVolume.TearDown succeeded for volume "kubernetes.io/projected/d5eb8942-67ae-4ea8-b434-f1132cf6cca1-kube-api-access-8mdrs" (OuterVolumeSpecName: "kube-api-access-8mdrs") pod "d5eb8942-67ae-4ea8-b434-f1132cf6cca1" (UID: "d5eb8942-67ae-4ea8-b434-f1132cf6cca1"). InnerVolumeSpecName "kube-api-access-8mdrs". PluginName "kubernetes.io/projected", VolumeGidValue ""
Apr 20 01:07:45 kind-worker2 kubelet[297]: I0420 01:07:45.347418     297 reconciler.go:384] "Volume detached for volume \"kube-api-access-8mdrs\" (UniqueName: \"kubernetes.io/projected/d5eb8942-67ae-4ea8-b434-f1132cf6cca1-kube-api-access-8mdrs\") on node \"kind-worker2\" DevicePath \"\""
Apr 20 01:07:45 kind-worker2 kubelet[297]: I0420 01:07:45.850977     297 pod_container_deletor.go:79] "Container not found in pod's containers" containerID="b0c0451d7a96fee90f9b6d6385eca54a72b6b2bf6c52fe78fc6cabe2843b5470"
Apr 20 01:07:50 kind-worker2 kubelet[297]: I0420 01:07:50.810108     297 kubelet_volumes.go:160] "Cleaned up orphaned pod volumes dir" podUID=d5eb8942-67ae-4ea8-b434-f1132cf6cca1 path="/var/lib/kubelet/pods/d5eb8942-67ae-4ea8-b434-f1132cf6cca1/volumes"
Apr 20 01:08:13 kind-worker2 kubelet[297]: I0420 01:08:13.469145     297 scope.go:110] "RemoveContainer" containerID="34d2e1110afeb8e6b0e144ce1ddbd8272656715f4e6af833961ef26b41872388"
Apr 20 05:33:30 kind-worker2 kubelet[297]: I0420 05:33:30.081091     297 topology_manager.go:200] "Topology Admit Handler"
Apr 20 05:33:30 kind-worker2 kubelet[297]: E0420 05:33:30.081456     297 cpu_manager.go:394] "RemoveStaleState: removing container" podUID="d5eb8942-67ae-4ea8-b434-f1132cf6cca1" containerName="load-generator"
Apr 20 05:33:30 kind-worker2 kubelet[297]: I0420 05:33:30.081641     297 memory_manager.go:345] "RemoveStaleState removing state" podUID="d5eb8942-67ae-4ea8-b434-f1132cf6cca1" containerName="load-generator"
Apr 20 05:33:30 kind-worker2 kubelet[297]: I0420 05:33:30.230694     297 reconciler.go:342] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-9bmgd\" (UniqueName: \"kubernetes.io/projected/04b9e2cb-c710-4f1e-af28-3fa47a382068-kube-api-access-9bmgd\") pod \"php-apache-698db99f59-b4964\" (UID: \"04b9e2cb-c710-4f1e-af28-3fa47a382068\") " pod="default/php-apache-698db99f59-b4964"
Apr 20 05:39:31 kind-worker2 kubelet[297]: I0420 05:39:31.806011     297 pod_container_deletor.go:79] "Container not found in pod's containers" containerID="9beac3969687ad69f65f6032e766d0eb39a10c05c1fe830dae148e5db656a25f"
Apr 20 05:39:32 kind-worker2 kubelet[297]: I0420 05:39:32.000783     297 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"kube-api-access-9bmgd\" (UniqueName: \"kubernetes.io/projected/04b9e2cb-c710-4f1e-af28-3fa47a382068-kube-api-access-9bmgd\") pod \"04b9e2cb-c710-4f1e-af28-3fa47a382068\" (UID: \"04b9e2cb-c710-4f1e-af28-3fa47a382068\") "
Apr 20 05:39:32 kind-worker2 kubelet[297]: I0420 05:39:32.040584     297 operation_generator.go:863] UnmountVolume.TearDown succeeded for volume "kubernetes.io/projected/04b9e2cb-c710-4f1e-af28-3fa47a382068-kube-api-access-9bmgd" (OuterVolumeSpecName: "kube-api-access-9bmgd") pod "04b9e2cb-c710-4f1e-af28-3fa47a382068" (UID: "04b9e2cb-c710-4f1e-af28-3fa47a382068"). InnerVolumeSpecName "kube-api-access-9bmgd". PluginName "kubernetes.io/projected", VolumeGidValue ""
Apr 20 05:39:32 kind-worker2 kubelet[297]: I0420 05:39:32.101408     297 reconciler.go:384] "Volume detached for volume \"kube-api-access-9bmgd\" (UniqueName: \"kubernetes.io/projected/04b9e2cb-c710-4f1e-af28-3fa47a382068-kube-api-access-9bmgd\") on node \"kind-worker2\" DevicePath \"\""
Apr 20 05:39:34 kind-worker2 kubelet[297]: I0420 05:39:34.812756     297 kubelet_volumes.go:160] "Cleaned up orphaned pod volumes dir" podUID=04b9e2cb-c710-4f1e-af28-3fa47a382068 path="/var/lib/kubelet/pods/04b9e2cb-c710-4f1e-af28-3fa47a382068/volumes"
Apr 20 05:40:15 kind-worker2 kubelet[297]: I0420 05:40:15.005005     297 scope.go:110] "RemoveContainer" containerID="a34790d1fb058ee76340c9b38eee3806af967de6496ac617f151a5300afe93ca"
Apr 20 18:36:50 kind-worker2 kubelet[297]: I0420 18:36:50.476604     297 topology_manager.go:200] "Topology Admit Handler"
Apr 20 18:36:50 kind-worker2 kubelet[297]: E0420 18:36:50.476915     297 cpu_manager.go:394] "RemoveStaleState: removing container" podUID="04b9e2cb-c710-4f1e-af28-3fa47a382068" containerName="php-apache"
Apr 20 18:36:50 kind-worker2 kubelet[297]: I0420 18:36:50.477056     297 memory_manager.go:345] "RemoveStaleState removing state" podUID="04b9e2cb-c710-4f1e-af28-3fa47a382068" containerName="php-apache"
Apr 20 18:36:50 kind-worker2 kubelet[297]: I0420 18:36:50.490637     297 reconciler.go:342] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-nj2k2\" (UniqueName: \"kubernetes.io/projected/e0699935-2020-4c95-a95a-e5ab7ce3e73a-kube-api-access-nj2k2\") pod \"php-apache-698db99f59-kq5mw\" (UID: \"e0699935-2020-4c95-a95a-e5ab7ce3e73a\") " pod="default/php-apache-698db99f59-kq5mw"
Apr 20 18:42:06 kind-worker2 kubelet[297]: I0420 18:42:06.882376     297 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"kube-api-access-nj2k2\" (UniqueName: \"kubernetes.io/projected/e0699935-2020-4c95-a95a-e5ab7ce3e73a-kube-api-access-nj2k2\") pod \"e0699935-2020-4c95-a95a-e5ab7ce3e73a\" (UID: \"e0699935-2020-4c95-a95a-e5ab7ce3e73a\") "
Apr 20 18:42:06 kind-worker2 kubelet[297]: I0420 18:42:06.908505     297 operation_generator.go:863] UnmountVolume.TearDown succeeded for volume "kubernetes.io/projected/e0699935-2020-4c95-a95a-e5ab7ce3e73a-kube-api-access-nj2k2" (OuterVolumeSpecName: "kube-api-access-nj2k2") pod "e0699935-2020-4c95-a95a-e5ab7ce3e73a" (UID: "e0699935-2020-4c95-a95a-e5ab7ce3e73a"). InnerVolumeSpecName "kube-api-access-nj2k2". PluginName "kubernetes.io/projected", VolumeGidValue ""
Apr 20 18:42:06 kind-worker2 kubelet[297]: I0420 18:42:06.983702     297 reconciler.go:384] "Volume detached for volume \"kube-api-access-nj2k2\" (UniqueName: \"kubernetes.io/projected/e0699935-2020-4c95-a95a-e5ab7ce3e73a-kube-api-access-nj2k2\") on node \"kind-worker2\" DevicePath \"\""
Apr 20 18:42:07 kind-worker2 kubelet[297]: I0420 18:42:07.275730     297 scope.go:110] "RemoveContainer" containerID="c9eaa12504d8e0f1e82e706452587c37eca171586238132f58bc570aadab9936"
Apr 20 18:42:07 kind-worker2 kubelet[297]: I0420 18:42:07.417528     297 scope.go:110] "RemoveContainer" containerID="c9eaa12504d8e0f1e82e706452587c37eca171586238132f58bc570aadab9936"
Apr 20 18:42:07 kind-worker2 kubelet[297]: E0420 18:42:07.418522     297 remote_runtime.go:604] "ContainerStatus from runtime service failed" err="rpc error: code = NotFound desc = an error occurred when try to find container \"c9eaa12504d8e0f1e82e706452587c37eca171586238132f58bc570aadab9936\": not found" containerID="c9eaa12504d8e0f1e82e706452587c37eca171586238132f58bc570aadab9936"
Apr 20 18:42:07 kind-worker2 kubelet[297]: I0420 18:42:07.418634     297 pod_container_deletor.go:52] "DeleteContainer returned error" containerID={Type:containerd ID:c9eaa12504d8e0f1e82e706452587c37eca171586238132f58bc570aadab9936} err="failed to get container status \"c9eaa12504d8e0f1e82e706452587c37eca171586238132f58bc570aadab9936\": rpc error: code = NotFound desc = an error occurred when try to find container \"c9eaa12504d8e0f1e82e706452587c37eca171586238132f58bc570aadab9936\": not found"
Apr 20 18:42:08 kind-worker2 kubelet[297]: I0420 18:42:08.819674     297 kubelet_volumes.go:160] "Cleaned up orphaned pod volumes dir" podUID=e0699935-2020-4c95-a95a-e5ab7ce3e73a path="/var/lib/kubelet/pods/e0699935-2020-4c95-a95a-e5ab7ce3e73a/volumes"
Apr 20 18:44:36 kind-worker2 kubelet[297]: I0420 18:44:36.575745     297 topology_manager.go:200] "Topology Admit Handler"
Apr 20 18:44:36 kind-worker2 kubelet[297]: E0420 18:44:36.576129     297 cpu_manager.go:394] "RemoveStaleState: removing container" podUID="e0699935-2020-4c95-a95a-e5ab7ce3e73a" containerName="php-apache"
Apr 20 18:44:36 kind-worker2 kubelet[297]: I0420 18:44:36.576394     297 memory_manager.go:345] "RemoveStaleState removing state" podUID="e0699935-2020-4c95-a95a-e5ab7ce3e73a" containerName="php-apache"
Apr 20 18:44:36 kind-worker2 kubelet[297]: I0420 18:44:36.696987     297 reconciler.go:342] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-c8wwb\" (UniqueName: \"kubernetes.io/projected/44c02c0a-a7c0-4807-8286-d12ac4cf11e2-kube-api-access-c8wwb\") pod \"php-apache-698db99f59-kl97r\" (UID: \"44c02c0a-a7c0-4807-8286-d12ac4cf11e2\") " pod="default/php-apache-698db99f59-kl97r"
Apr 20 18:53:12 kind-worker2 kubelet[297]: I0420 18:53:12.835170     297 topology_manager.go:200] "Topology Admit Handler"
Apr 20 18:53:12 kind-worker2 kubelet[297]: I0420 18:53:12.891815     297 reconciler.go:342] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-dtrjd\" (UniqueName: \"kubernetes.io/projected/f51d3beb-c6a1-46a3-83d7-068bee71d166-kube-api-access-dtrjd\") pod \"php-apache-698db99f59-hchzd\" (UID: \"f51d3beb-c6a1-46a3-83d7-068bee71d166\") " pod="default/php-apache-698db99f59-hchzd"
Apr 20 18:53:12 kind-worker2 kubelet[297]: I0420 18:53:12.900601     297 topology_manager.go:200] "Topology Admit Handler"
Apr 20 18:53:13 kind-worker2 kubelet[297]: I0420 18:53:13.093932     297 reconciler.go:342] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-4xhtp\" (UniqueName: \"kubernetes.io/projected/34f231f4-8937-4bff-a1f8-c06353a20f03-kube-api-access-4xhtp\") pod \"php-apache-698db99f59-7bzwk\" (UID: \"34f231f4-8937-4bff-a1f8-c06353a20f03\") " pod="default/php-apache-698db99f59-7bzwk"
Apr 20 18:54:24 kind-worker2 kubelet[297]: I0420 18:54:24.654388     297 pod_container_deletor.go:79] "Container not found in pod's containers" containerID="395823eaa54e4f19f35f53dfa6bba74a02aeb9185cf7528b185ac9362687c596"
Apr 20 18:54:24 kind-worker2 kubelet[297]: I0420 18:54:24.660150     297 pod_container_deletor.go:79] "Container not found in pod's containers" containerID="f0108c6fef2751983758b77ec323648935234aaca6578971f75ec451501e7b57"
Apr 20 18:54:24 kind-worker2 kubelet[297]: I0420 18:54:24.805580     297 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"kube-api-access-c8wwb\" (UniqueName: \"kubernetes.io/projected/44c02c0a-a7c0-4807-8286-d12ac4cf11e2-kube-api-access-c8wwb\") pod \"44c02c0a-a7c0-4807-8286-d12ac4cf11e2\" (UID: \"44c02c0a-a7c0-4807-8286-d12ac4cf11e2\") "
Apr 20 18:54:24 kind-worker2 kubelet[297]: I0420 18:54:24.827808     297 operation_generator.go:863] UnmountVolume.TearDown succeeded for volume "kubernetes.io/projected/44c02c0a-a7c0-4807-8286-d12ac4cf11e2-kube-api-access-c8wwb" (OuterVolumeSpecName: "kube-api-access-c8wwb") pod "44c02c0a-a7c0-4807-8286-d12ac4cf11e2" (UID: "44c02c0a-a7c0-4807-8286-d12ac4cf11e2"). InnerVolumeSpecName "kube-api-access-c8wwb". PluginName "kubernetes.io/projected", VolumeGidValue ""
Apr 20 18:54:24 kind-worker2 kubelet[297]: I0420 18:54:24.906185     297 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"kube-api-access-dtrjd\" (UniqueName: \"kubernetes.io/projected/f51d3beb-c6a1-46a3-83d7-068bee71d166-kube-api-access-dtrjd\") pod \"f51d3beb-c6a1-46a3-83d7-068bee71d166\" (UID: \"f51d3beb-c6a1-46a3-83d7-068bee71d166\") "
Apr 20 18:54:24 kind-worker2 kubelet[297]: I0420 18:54:24.906290     297 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"kube-api-access-4xhtp\" (UniqueName: \"kubernetes.io/projected/34f231f4-8937-4bff-a1f8-c06353a20f03-kube-api-access-4xhtp\") pod \"34f231f4-8937-4bff-a1f8-c06353a20f03\" (UID: \"34f231f4-8937-4bff-a1f8-c06353a20f03\") "
Apr 20 18:54:24 kind-worker2 kubelet[297]: I0420 18:54:24.906380     297 reconciler.go:384] "Volume detached for volume \"kube-api-access-c8wwb\" (UniqueName: \"kubernetes.io/projected/44c02c0a-a7c0-4807-8286-d12ac4cf11e2-kube-api-access-c8wwb\") on node \"kind-worker2\" DevicePath \"\""
Apr 20 18:54:24 kind-worker2 kubelet[297]: I0420 18:54:24.939998     297 operation_generator.go:863] UnmountVolume.TearDown succeeded for volume "kubernetes.io/projected/f51d3beb-c6a1-46a3-83d7-068bee71d166-kube-api-access-dtrjd" (OuterVolumeSpecName: "kube-api-access-dtrjd") pod "f51d3beb-c6a1-46a3-83d7-068bee71d166" (UID: "f51d3beb-c6a1-46a3-83d7-068bee71d166"). InnerVolumeSpecName "kube-api-access-dtrjd". PluginName "kubernetes.io/projected", VolumeGidValue ""
Apr 20 18:54:24 kind-worker2 kubelet[297]: I0420 18:54:24.940039     297 operation_generator.go:863] UnmountVolume.TearDown succeeded for volume "kubernetes.io/projected/34f231f4-8937-4bff-a1f8-c06353a20f03-kube-api-access-4xhtp" (OuterVolumeSpecName: "kube-api-access-4xhtp") pod "34f231f4-8937-4bff-a1f8-c06353a20f03" (UID: "34f231f4-8937-4bff-a1f8-c06353a20f03"). InnerVolumeSpecName "kube-api-access-4xhtp". PluginName "kubernetes.io/projected", VolumeGidValue ""
Apr 20 18:54:25 kind-worker2 kubelet[297]: I0420 18:54:25.006849     297 reconciler.go:384] "Volume detached for volume \"kube-api-access-4xhtp\" (UniqueName: \"kubernetes.io/projected/34f231f4-8937-4bff-a1f8-c06353a20f03-kube-api-access-4xhtp\") on node \"kind-worker2\" DevicePath \"\""
Apr 20 18:54:25 kind-worker2 kubelet[297]: I0420 18:54:25.006960     297 reconciler.go:384] "Volume detached for volume \"kube-api-access-dtrjd\" (UniqueName: \"kubernetes.io/projected/f51d3beb-c6a1-46a3-83d7-068bee71d166-kube-api-access-dtrjd\") on node \"kind-worker2\" DevicePath \"\""
Apr 20 18:54:25 kind-worker2 kubelet[297]: I0420 18:54:25.669710     297 scope.go:110] "RemoveContainer" containerID="1d6277cdfd3615bf9d9ceb447d02fcb269423419f626c31b5823c054dadb3c37"
Apr 20 18:54:26 kind-worker2 kubelet[297]: I0420 18:54:26.814353     297 kubelet_volumes.go:160] "Cleaned up orphaned pod volumes dir" podUID=34f231f4-8937-4bff-a1f8-c06353a20f03 path="/var/lib/kubelet/pods/34f231f4-8937-4bff-a1f8-c06353a20f03/volumes"
Apr 20 18:54:26 kind-worker2 kubelet[297]: I0420 18:54:26.816018     297 kubelet_volumes.go:160] "Cleaned up orphaned pod volumes dir" podUID=44c02c0a-a7c0-4807-8286-d12ac4cf11e2 path="/var/lib/kubelet/pods/44c02c0a-a7c0-4807-8286-d12ac4cf11e2/volumes"
Apr 20 18:54:26 kind-worker2 kubelet[297]: I0420 18:54:26.817630     297 kubelet_volumes.go:160] "Cleaned up orphaned pod volumes dir" podUID=f51d3beb-c6a1-46a3-83d7-068bee71d166 path="/var/lib/kubelet/pods/f51d3beb-c6a1-46a3-83d7-068bee71d166/volumes"
Apr 20 18:54:38 kind-worker2 kubelet[297]: I0420 18:54:38.316290     297 topology_manager.go:200] "Topology Admit Handler"
Apr 20 18:54:38 kind-worker2 kubelet[297]: E0420 18:54:38.316467     297 cpu_manager.go:394] "RemoveStaleState: removing container" podUID="44c02c0a-a7c0-4807-8286-d12ac4cf11e2" containerName="php-apache"
Apr 20 18:54:38 kind-worker2 kubelet[297]: E0420 18:54:38.316545     297 cpu_manager.go:394] "RemoveStaleState: removing container" podUID="f51d3beb-c6a1-46a3-83d7-068bee71d166" containerName="php-apache"
Apr 20 18:54:38 kind-worker2 kubelet[297]: E0420 18:54:38.316604     297 cpu_manager.go:394] "RemoveStaleState: removing container" podUID="34f231f4-8937-4bff-a1f8-c06353a20f03" containerName="php-apache"
Apr 20 18:54:38 kind-worker2 kubelet[297]: I0420 18:54:38.316689     297 memory_manager.go:345] "RemoveStaleState removing state" podUID="f51d3beb-c6a1-46a3-83d7-068bee71d166" containerName="php-apache"
Apr 20 18:54:38 kind-worker2 kubelet[297]: I0420 18:54:38.316715     297 memory_manager.go:345] "RemoveStaleState removing state" podUID="34f231f4-8937-4bff-a1f8-c06353a20f03" containerName="php-apache"
Apr 20 18:54:38 kind-worker2 kubelet[297]: I0420 18:54:38.316734     297 memory_manager.go:345] "RemoveStaleState removing state" podUID="44c02c0a-a7c0-4807-8286-d12ac4cf11e2" containerName="php-apache"
Apr 20 18:54:38 kind-worker2 kubelet[297]: I0420 18:54:38.349226     297 topology_manager.go:200] "Topology Admit Handler"
Apr 20 18:54:38 kind-worker2 kubelet[297]: I0420 18:54:38.400031     297 reconciler.go:342] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-z88n2\" (UniqueName: \"kubernetes.io/projected/c4e13960-4869-404e-848d-bad0efd6a8fb-kube-api-access-z88n2\") pod \"php-apache-698db99f59-kqwz7\" (UID: \"c4e13960-4869-404e-848d-bad0efd6a8fb\") " pod="default/php-apache-698db99f59-kqwz7"
Apr 20 18:54:38 kind-worker2 kubelet[297]: I0420 18:54:38.501083     297 reconciler.go:342] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-kh2rd\" (UniqueName: \"kubernetes.io/projected/5a367cad-fb6d-4dd6-920e-c080593f97f3-kube-api-access-kh2rd\") pod \"php-apache-698db99f59-f5tfj\" (UID: \"5a367cad-fb6d-4dd6-920e-c080593f97f3\") " pod="default/php-apache-698db99f59-f5tfj"
Apr 20 18:55:18 kind-worker2 kubelet[297]: I0420 18:55:18.826178     297 scope.go:110] "RemoveContainer" containerID="d7bb49ab1ed4936e8adab2e7fc259b098ca3577f004ee29182ace81b516d7d94"
Apr 20 18:55:18 kind-worker2 kubelet[297]: I0420 18:55:18.945277     297 scope.go:110] "RemoveContainer" containerID="c18169cfae9b147496e1cf93b94e0532e5060fda01c5fb75ffded77ed5b28d80"
Apr 20 19:00:10 kind-worker2 kubelet[297]: I0420 19:00:10.350334     297 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"kube-api-access-kh2rd\" (UniqueName: \"kubernetes.io/projected/5a367cad-fb6d-4dd6-920e-c080593f97f3-kube-api-access-kh2rd\") pod \"5a367cad-fb6d-4dd6-920e-c080593f97f3\" (UID: \"5a367cad-fb6d-4dd6-920e-c080593f97f3\") "
Apr 20 19:00:10 kind-worker2 kubelet[297]: I0420 19:00:10.376180     297 operation_generator.go:863] UnmountVolume.TearDown succeeded for volume "kubernetes.io/projected/5a367cad-fb6d-4dd6-920e-c080593f97f3-kube-api-access-kh2rd" (OuterVolumeSpecName: "kube-api-access-kh2rd") pod "5a367cad-fb6d-4dd6-920e-c080593f97f3" (UID: "5a367cad-fb6d-4dd6-920e-c080593f97f3"). InnerVolumeSpecName "kube-api-access-kh2rd". PluginName "kubernetes.io/projected", VolumeGidValue ""
Apr 20 19:00:10 kind-worker2 kubelet[297]: I0420 19:00:10.451431     297 reconciler.go:384] "Volume detached for volume \"kube-api-access-kh2rd\" (UniqueName: \"kubernetes.io/projected/5a367cad-fb6d-4dd6-920e-c080593f97f3-kube-api-access-kh2rd\") on node \"kind-worker2\" DevicePath \"\""
Apr 20 19:00:10 kind-worker2 kubelet[297]: I0420 19:00:10.866585     297 scope.go:110] "RemoveContainer" containerID="71b2bc2ddcc573d5f3423dd2a7f1d637f54b2deb7b9984a525c509a2f9c3b64f"
Apr 20 19:00:12 kind-worker2 kubelet[297]: I0420 19:00:12.815685     297 kubelet_volumes.go:160] "Cleaned up orphaned pod volumes dir" podUID=5a367cad-fb6d-4dd6-920e-c080593f97f3 path="/var/lib/kubelet/pods/5a367cad-fb6d-4dd6-920e-c080593f97f3/volumes"
Apr 20 19:17:59 kind-worker2 kubelet[297]: I0420 19:17:59.119894     297 topology_manager.go:200] "Topology Admit Handler"
Apr 20 19:17:59 kind-worker2 kubelet[297]: E0420 19:17:59.120057     297 cpu_manager.go:394] "RemoveStaleState: removing container" podUID="5a367cad-fb6d-4dd6-920e-c080593f97f3" containerName="php-apache"
Apr 20 19:17:59 kind-worker2 kubelet[297]: I0420 19:17:59.120139     297 memory_manager.go:345] "RemoveStaleState removing state" podUID="5a367cad-fb6d-4dd6-920e-c080593f97f3" containerName="php-apache"
Apr 20 19:17:59 kind-worker2 kubelet[297]: I0420 19:17:59.187209     297 reconciler.go:342] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-7l5gq\" (UniqueName: \"kubernetes.io/projected/850a7266-3ccc-4f00-9eb3-25b719bbf00f-kube-api-access-7l5gq\") pod \"php-apache-698db99f59-pnd86\" (UID: \"850a7266-3ccc-4f00-9eb3-25b719bbf00f\") " pod="default/php-apache-698db99f59-pnd86"
Apr 20 19:20:11 kind-worker2 kubelet[297]: I0420 19:20:11.602921     297 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"kube-api-access-7l5gq\" (UniqueName: \"kubernetes.io/projected/850a7266-3ccc-4f00-9eb3-25b719bbf00f-kube-api-access-7l5gq\") pod \"850a7266-3ccc-4f00-9eb3-25b719bbf00f\" (UID: \"850a7266-3ccc-4f00-9eb3-25b719bbf00f\") "
Apr 20 19:20:11 kind-worker2 kubelet[297]: I0420 19:20:11.640498     297 operation_generator.go:863] UnmountVolume.TearDown succeeded for volume "kubernetes.io/projected/850a7266-3ccc-4f00-9eb3-25b719bbf00f-kube-api-access-7l5gq" (OuterVolumeSpecName: "kube-api-access-7l5gq") pod "850a7266-3ccc-4f00-9eb3-25b719bbf00f" (UID: "850a7266-3ccc-4f00-9eb3-25b719bbf00f"). InnerVolumeSpecName "kube-api-access-7l5gq". PluginName "kubernetes.io/projected", VolumeGidValue ""
Apr 20 19:20:11 kind-worker2 kubelet[297]: I0420 19:20:11.660279     297 scope.go:110] "RemoveContainer" containerID="5f8ada466fbe7423587de9910e2ceeab563f50e0194903f245cd7bb449b439ad"
Apr 20 19:20:11 kind-worker2 kubelet[297]: I0420 19:20:11.703663     297 reconciler.go:384] "Volume detached for volume \"kube-api-access-7l5gq\" (UniqueName: \"kubernetes.io/projected/850a7266-3ccc-4f00-9eb3-25b719bbf00f-kube-api-access-7l5gq\") on node \"kind-worker2\" DevicePath \"\""
Apr 20 19:20:11 kind-worker2 kubelet[297]: I0420 19:20:11.784213     297 scope.go:110] "RemoveContainer" containerID="5f8ada466fbe7423587de9910e2ceeab563f50e0194903f245cd7bb449b439ad"
Apr 20 19:20:11 kind-worker2 kubelet[297]: E0420 19:20:11.785231     297 remote_runtime.go:604] "ContainerStatus from runtime service failed" err="rpc error: code = NotFound desc = an error occurred when try to find container \"5f8ada466fbe7423587de9910e2ceeab563f50e0194903f245cd7bb449b439ad\": not found" containerID="5f8ada466fbe7423587de9910e2ceeab563f50e0194903f245cd7bb449b439ad"
Apr 20 19:20:11 kind-worker2 kubelet[297]: I0420 19:20:11.785349     297 pod_container_deletor.go:52] "DeleteContainer returned error" containerID={Type:containerd ID:5f8ada466fbe7423587de9910e2ceeab563f50e0194903f245cd7bb449b439ad} err="failed to get container status \"5f8ada466fbe7423587de9910e2ceeab563f50e0194903f245cd7bb449b439ad\": rpc error: code = NotFound desc = an error occurred when try to find container \"5f8ada466fbe7423587de9910e2ceeab563f50e0194903f245cd7bb449b439ad\": not found"
Apr 20 19:20:12 kind-worker2 kubelet[297]: I0420 19:20:12.332499     297 topology_manager.go:200] "Topology Admit Handler"
Apr 20 19:20:12 kind-worker2 kubelet[297]: E0420 19:20:12.332615     297 cpu_manager.go:394] "RemoveStaleState: removing container" podUID="850a7266-3ccc-4f00-9eb3-25b719bbf00f" containerName="php-apache"
Apr 20 19:20:12 kind-worker2 kubelet[297]: I0420 19:20:12.332678     297 memory_manager.go:345] "RemoveStaleState removing state" podUID="850a7266-3ccc-4f00-9eb3-25b719bbf00f" containerName="php-apache"
Apr 20 19:20:12 kind-worker2 kubelet[297]: I0420 19:20:12.510054     297 reconciler.go:342] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-lmpcg\" (UniqueName: \"kubernetes.io/projected/3de230f6-f448-4ca9-b38a-29c3192d2fc2-kube-api-access-lmpcg\") pod \"php-apache-698db99f59-f5sz9\" (UID: \"3de230f6-f448-4ca9-b38a-29c3192d2fc2\") " pod="default/php-apache-698db99f59-f5sz9"
Apr 20 19:20:12 kind-worker2 kubelet[297]: I0420 19:20:12.816484     297 kubelet_volumes.go:160] "Cleaned up orphaned pod volumes dir" podUID=850a7266-3ccc-4f00-9eb3-25b719bbf00f path="/var/lib/kubelet/pods/850a7266-3ccc-4f00-9eb3-25b719bbf00f/volumes"
Apr 20 19:20:40 kind-worker2 kubelet[297]: I0420 19:20:40.503269     297 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"kube-api-access-lmpcg\" (UniqueName: \"kubernetes.io/projected/3de230f6-f448-4ca9-b38a-29c3192d2fc2-kube-api-access-lmpcg\") pod \"3de230f6-f448-4ca9-b38a-29c3192d2fc2\" (UID: \"3de230f6-f448-4ca9-b38a-29c3192d2fc2\") "
Apr 20 19:20:40 kind-worker2 kubelet[297]: I0420 19:20:40.540306     297 operation_generator.go:863] UnmountVolume.TearDown succeeded for volume "kubernetes.io/projected/3de230f6-f448-4ca9-b38a-29c3192d2fc2-kube-api-access-lmpcg" (OuterVolumeSpecName: "kube-api-access-lmpcg") pod "3de230f6-f448-4ca9-b38a-29c3192d2fc2" (UID: "3de230f6-f448-4ca9-b38a-29c3192d2fc2"). InnerVolumeSpecName "kube-api-access-lmpcg". PluginName "kubernetes.io/projected", VolumeGidValue ""
Apr 20 19:20:40 kind-worker2 kubelet[297]: I0420 19:20:40.603609     297 reconciler.go:384] "Volume detached for volume \"kube-api-access-lmpcg\" (UniqueName: \"kubernetes.io/projected/3de230f6-f448-4ca9-b38a-29c3192d2fc2-kube-api-access-lmpcg\") on node \"kind-worker2\" DevicePath \"\""
Apr 20 19:20:40 kind-worker2 kubelet[297]: I0420 19:20:40.781040     297 scope.go:110] "RemoveContainer" containerID="bce86b7ab6ab7bd7a692d02ba6178e949fb643f9ada083a2888bc2eccf517428"
Apr 20 19:20:40 kind-worker2 kubelet[297]: I0420 19:20:40.997730     297 scope.go:110] "RemoveContainer" containerID="bce86b7ab6ab7bd7a692d02ba6178e949fb643f9ada083a2888bc2eccf517428"
Apr 20 19:20:41 kind-worker2 kubelet[297]: E0420 19:20:41.003627     297 remote_runtime.go:604] "ContainerStatus from runtime service failed" err="rpc error: code = NotFound desc = an error occurred when try to find container \"bce86b7ab6ab7bd7a692d02ba6178e949fb643f9ada083a2888bc2eccf517428\": not found" containerID="bce86b7ab6ab7bd7a692d02ba6178e949fb643f9ada083a2888bc2eccf517428"
Apr 20 19:20:41 kind-worker2 kubelet[297]: I0420 19:20:41.003735     297 pod_container_deletor.go:52] "DeleteContainer returned error" containerID={Type:containerd ID:bce86b7ab6ab7bd7a692d02ba6178e949fb643f9ada083a2888bc2eccf517428} err="failed to get container status \"bce86b7ab6ab7bd7a692d02ba6178e949fb643f9ada083a2888bc2eccf517428\": rpc error: code = NotFound desc = an error occurred when try to find container \"bce86b7ab6ab7bd7a692d02ba6178e949fb643f9ada083a2888bc2eccf517428\": not found"
Apr 20 19:20:42 kind-worker2 kubelet[297]: I0420 19:20:42.562438     297 topology_manager.go:200] "Topology Admit Handler"
Apr 20 19:20:42 kind-worker2 kubelet[297]: E0420 19:20:42.562536     297 cpu_manager.go:394] "RemoveStaleState: removing container" podUID="3de230f6-f448-4ca9-b38a-29c3192d2fc2" containerName="php-apache"
Apr 20 19:20:42 kind-worker2 kubelet[297]: I0420 19:20:42.562588     297 memory_manager.go:345] "RemoveStaleState removing state" podUID="3de230f6-f448-4ca9-b38a-29c3192d2fc2" containerName="php-apache"
Apr 20 19:20:42 kind-worker2 kubelet[297]: I0420 19:20:42.619075     297 reconciler.go:342] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-7zn7z\" (UniqueName: \"kubernetes.io/projected/4b47d318-f8ef-4507-97b5-edc4da51e509-kube-api-access-7zn7z\") pod \"php-apache-698db99f59-9qbgl\" (UID: \"4b47d318-f8ef-4507-97b5-edc4da51e509\") " pod="default/php-apache-698db99f59-9qbgl"
Apr 20 19:20:42 kind-worker2 kubelet[297]: I0420 19:20:42.822381     297 kubelet_volumes.go:160] "Cleaned up orphaned pod volumes dir" podUID=3de230f6-f448-4ca9-b38a-29c3192d2fc2 path="/var/lib/kubelet/pods/3de230f6-f448-4ca9-b38a-29c3192d2fc2/volumes"
Apr 20 19:22:04 kind-worker2 kubelet[297]: I0420 19:22:04.392754     297 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"kube-api-access-7zn7z\" (UniqueName: \"kubernetes.io/projected/4b47d318-f8ef-4507-97b5-edc4da51e509-kube-api-access-7zn7z\") pod \"4b47d318-f8ef-4507-97b5-edc4da51e509\" (UID: \"4b47d318-f8ef-4507-97b5-edc4da51e509\") "
Apr 20 19:22:04 kind-worker2 kubelet[297]: I0420 19:22:04.428360     297 operation_generator.go:863] UnmountVolume.TearDown succeeded for volume "kubernetes.io/projected/4b47d318-f8ef-4507-97b5-edc4da51e509-kube-api-access-7zn7z" (OuterVolumeSpecName: "kube-api-access-7zn7z") pod "4b47d318-f8ef-4507-97b5-edc4da51e509" (UID: "4b47d318-f8ef-4507-97b5-edc4da51e509"). InnerVolumeSpecName "kube-api-access-7zn7z". PluginName "kubernetes.io/projected", VolumeGidValue ""
Apr 20 19:22:04 kind-worker2 kubelet[297]: I0420 19:22:04.494084     297 reconciler.go:384] "Volume detached for volume \"kube-api-access-7zn7z\" (UniqueName: \"kubernetes.io/projected/4b47d318-f8ef-4507-97b5-edc4da51e509-kube-api-access-7zn7z\") on node \"kind-worker2\" DevicePath \"\""
Apr 20 19:22:05 kind-worker2 kubelet[297]: I0420 19:22:05.067892     297 scope.go:110] "RemoveContainer" containerID="b00c357da34642ccc8ff3c865ecab86e2d7ed57fb951d70cd96a3ce5aec0dfae"
Apr 20 19:22:06 kind-worker2 kubelet[297]: I0420 19:22:06.815495     297 kubelet_volumes.go:160] "Cleaned up orphaned pod volumes dir" podUID=4b47d318-f8ef-4507-97b5-edc4da51e509 path="/var/lib/kubelet/pods/4b47d318-f8ef-4507-97b5-edc4da51e509/volumes"
Apr 20 19:22:12 kind-worker2 kubelet[297]: I0420 19:22:12.907780     297 topology_manager.go:200] "Topology Admit Handler"
Apr 20 19:22:12 kind-worker2 kubelet[297]: E0420 19:22:12.907916     297 cpu_manager.go:394] "RemoveStaleState: removing container" podUID="4b47d318-f8ef-4507-97b5-edc4da51e509" containerName="php-apache"
Apr 20 19:22:12 kind-worker2 kubelet[297]: I0420 19:22:12.907997     297 memory_manager.go:345] "RemoveStaleState removing state" podUID="4b47d318-f8ef-4507-97b5-edc4da51e509" containerName="php-apache"
Apr 20 19:22:13 kind-worker2 kubelet[297]: I0420 19:22:13.058185     297 reconciler.go:342] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-2v5v4\" (UniqueName: \"kubernetes.io/projected/fa141922-3592-4154-87f2-2a76d3df38ae-kube-api-access-2v5v4\") pod \"php-apache-698db99f59-7zqq7\" (UID: \"fa141922-3592-4154-87f2-2a76d3df38ae\") " pod="default/php-apache-698db99f59-7zqq7"
Apr 20 19:23:39 kind-worker2 kubelet[297]: I0420 19:23:39.316996     297 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"kube-api-access-2v5v4\" (UniqueName: \"kubernetes.io/projected/fa141922-3592-4154-87f2-2a76d3df38ae-kube-api-access-2v5v4\") pod \"fa141922-3592-4154-87f2-2a76d3df38ae\" (UID: \"fa141922-3592-4154-87f2-2a76d3df38ae\") "
Apr 20 19:23:39 kind-worker2 kubelet[297]: I0420 19:23:39.317180     297 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"kube-api-access-z88n2\" (UniqueName: \"kubernetes.io/projected/c4e13960-4869-404e-848d-bad0efd6a8fb-kube-api-access-z88n2\") pod \"c4e13960-4869-404e-848d-bad0efd6a8fb\" (UID: \"c4e13960-4869-404e-848d-bad0efd6a8fb\") "
Apr 20 19:23:39 kind-worker2 kubelet[297]: I0420 19:23:39.340214     297 operation_generator.go:863] UnmountVolume.TearDown succeeded for volume "kubernetes.io/projected/fa141922-3592-4154-87f2-2a76d3df38ae-kube-api-access-2v5v4" (OuterVolumeSpecName: "kube-api-access-2v5v4") pod "fa141922-3592-4154-87f2-2a76d3df38ae" (UID: "fa141922-3592-4154-87f2-2a76d3df38ae"). InnerVolumeSpecName "kube-api-access-2v5v4". PluginName "kubernetes.io/projected", VolumeGidValue ""
Apr 20 19:23:39 kind-worker2 kubelet[297]: I0420 19:23:39.352061     297 operation_generator.go:863] UnmountVolume.TearDown succeeded for volume "kubernetes.io/projected/c4e13960-4869-404e-848d-bad0efd6a8fb-kube-api-access-z88n2" (OuterVolumeSpecName: "kube-api-access-z88n2") pod "c4e13960-4869-404e-848d-bad0efd6a8fb" (UID: "c4e13960-4869-404e-848d-bad0efd6a8fb"). InnerVolumeSpecName "kube-api-access-z88n2". PluginName "kubernetes.io/projected", VolumeGidValue ""
Apr 20 19:23:39 kind-worker2 kubelet[297]: I0420 19:23:39.412716     297 scope.go:110] "RemoveContainer" containerID="7bdb865ece1c2b67444a3f09676ca0e54ff6597bf4027c49e4d1229cf9f165ae"
Apr 20 19:23:39 kind-worker2 kubelet[297]: I0420 19:23:39.418139     297 reconciler.go:384] "Volume detached for volume \"kube-api-access-z88n2\" (UniqueName: \"kubernetes.io/projected/c4e13960-4869-404e-848d-bad0efd6a8fb-kube-api-access-z88n2\") on node \"kind-worker2\" DevicePath \"\""
Apr 20 19:23:39 kind-worker2 kubelet[297]: I0420 19:23:39.418196     297 reconciler.go:384] "Volume detached for volume \"kube-api-access-2v5v4\" (UniqueName: \"kubernetes.io/projected/fa141922-3592-4154-87f2-2a76d3df38ae-kube-api-access-2v5v4\") on node \"kind-worker2\" DevicePath \"\""
Apr 20 19:23:39 kind-worker2 kubelet[297]: I0420 19:23:39.540746     297 scope.go:110] "RemoveContainer" containerID="7bdb865ece1c2b67444a3f09676ca0e54ff6597bf4027c49e4d1229cf9f165ae"
Apr 20 19:23:39 kind-worker2 kubelet[297]: E0420 19:23:39.543728     297 remote_runtime.go:604] "ContainerStatus from runtime service failed" err="rpc error: code = NotFound desc = an error occurred when try to find container \"7bdb865ece1c2b67444a3f09676ca0e54ff6597bf4027c49e4d1229cf9f165ae\": not found" containerID="7bdb865ece1c2b67444a3f09676ca0e54ff6597bf4027c49e4d1229cf9f165ae"
Apr 20 19:23:39 kind-worker2 kubelet[297]: I0420 19:23:39.543801     297 pod_container_deletor.go:52] "DeleteContainer returned error" containerID={Type:containerd ID:7bdb865ece1c2b67444a3f09676ca0e54ff6597bf4027c49e4d1229cf9f165ae} err="failed to get container status \"7bdb865ece1c2b67444a3f09676ca0e54ff6597bf4027c49e4d1229cf9f165ae\": rpc error: code = NotFound desc = an error occurred when try to find container \"7bdb865ece1c2b67444a3f09676ca0e54ff6597bf4027c49e4d1229cf9f165ae\": not found"
Apr 20 19:23:39 kind-worker2 kubelet[297]: I0420 19:23:39.543849     297 scope.go:110] "RemoveContainer" containerID="28b7d76efcae8b0be856c59504a4fc6fdf8445700b910f857a58fe509579657c"
Apr 20 19:23:39 kind-worker2 kubelet[297]: I0420 19:23:39.665925     297 scope.go:110] "RemoveContainer" containerID="28b7d76efcae8b0be856c59504a4fc6fdf8445700b910f857a58fe509579657c"
Apr 20 19:23:39 kind-worker2 kubelet[297]: E0420 19:23:39.666778     297 remote_runtime.go:604] "ContainerStatus from runtime service failed" err="rpc error: code = NotFound desc = an error occurred when try to find container \"28b7d76efcae8b0be856c59504a4fc6fdf8445700b910f857a58fe509579657c\": not found" containerID="28b7d76efcae8b0be856c59504a4fc6fdf8445700b910f857a58fe509579657c"
Apr 20 19:23:39 kind-worker2 kubelet[297]: I0420 19:23:39.667019     297 pod_container_deletor.go:52] "DeleteContainer returned error" containerID={Type:containerd ID:28b7d76efcae8b0be856c59504a4fc6fdf8445700b910f857a58fe509579657c} err="failed to get container status \"28b7d76efcae8b0be856c59504a4fc6fdf8445700b910f857a58fe509579657c\": rpc error: code = NotFound desc = an error occurred when try to find container \"28b7d76efcae8b0be856c59504a4fc6fdf8445700b910f857a58fe509579657c\": not found"
Apr 20 19:23:40 kind-worker2 kubelet[297]: I0420 19:23:40.810674     297 kubelet_volumes.go:160] "Cleaned up orphaned pod volumes dir" podUID=c4e13960-4869-404e-848d-bad0efd6a8fb path="/var/lib/kubelet/pods/c4e13960-4869-404e-848d-bad0efd6a8fb/volumes"
Apr 20 19:23:40 kind-worker2 kubelet[297]: I0420 19:23:40.812594     297 kubelet_volumes.go:160] "Cleaned up orphaned pod volumes dir" podUID=fa141922-3592-4154-87f2-2a76d3df38ae path="/var/lib/kubelet/pods/fa141922-3592-4154-87f2-2a76d3df38ae/volumes"
Apr 20 19:24:58 kind-worker2 kubelet[297]: I0420 19:24:58.457358     297 topology_manager.go:200] "Topology Admit Handler"
Apr 20 19:24:58 kind-worker2 kubelet[297]: E0420 19:24:58.457588     297 cpu_manager.go:394] "RemoveStaleState: removing container" podUID="c4e13960-4869-404e-848d-bad0efd6a8fb" containerName="php-apache"
Apr 20 19:24:58 kind-worker2 kubelet[297]: E0420 19:24:58.457622     297 cpu_manager.go:394] "RemoveStaleState: removing container" podUID="fa141922-3592-4154-87f2-2a76d3df38ae" containerName="php-apache"
Apr 20 19:24:58 kind-worker2 kubelet[297]: I0420 19:24:58.457804     297 memory_manager.go:345] "RemoveStaleState removing state" podUID="fa141922-3592-4154-87f2-2a76d3df38ae" containerName="php-apache"
Apr 20 19:24:58 kind-worker2 kubelet[297]: I0420 19:24:58.457833     297 memory_manager.go:345] "RemoveStaleState removing state" podUID="c4e13960-4869-404e-848d-bad0efd6a8fb" containerName="php-apache"
Apr 20 19:24:58 kind-worker2 kubelet[297]: I0420 19:24:58.528320     297 topology_manager.go:200] "Topology Admit Handler"
Apr 20 19:24:58 kind-worker2 kubelet[297]: I0420 19:24:58.612157     297 reconciler.go:342] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-qqxf6\" (UniqueName: \"kubernetes.io/projected/7e03310c-5f98-40b7-afa4-6d90b090b931-kube-api-access-qqxf6\") pod \"php-apache-698db99f59-9w4dd\" (UID: \"7e03310c-5f98-40b7-afa4-6d90b090b931\") " pod="default/php-apache-698db99f59-9w4dd"
Apr 20 19:24:58 kind-worker2 kubelet[297]: I0420 19:24:58.612398     297 reconciler.go:342] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-vgtph\" (UniqueName: \"kubernetes.io/projected/c313c7c0-1f15-4544-9b19-72190cfea5cf-kube-api-access-vgtph\") pod \"php-apache-698db99f59-xkslw\" (UID: \"c313c7c0-1f15-4544-9b19-72190cfea5cf\") " pod="default/php-apache-698db99f59-xkslw"
Apr 20 19:29:39 kind-worker2 kubelet[297]: I0420 19:29:39.000665     297 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"kube-api-access-vgtph\" (UniqueName: \"kubernetes.io/projected/c313c7c0-1f15-4544-9b19-72190cfea5cf-kube-api-access-vgtph\") pod \"c313c7c0-1f15-4544-9b19-72190cfea5cf\" (UID: \"c313c7c0-1f15-4544-9b19-72190cfea5cf\") "
Apr 20 19:29:39 kind-worker2 kubelet[297]: I0420 19:29:39.024221     297 operation_generator.go:863] UnmountVolume.TearDown succeeded for volume "kubernetes.io/projected/c313c7c0-1f15-4544-9b19-72190cfea5cf-kube-api-access-vgtph" (OuterVolumeSpecName: "kube-api-access-vgtph") pod "c313c7c0-1f15-4544-9b19-72190cfea5cf" (UID: "c313c7c0-1f15-4544-9b19-72190cfea5cf"). InnerVolumeSpecName "kube-api-access-vgtph". PluginName "kubernetes.io/projected", VolumeGidValue ""
Apr 20 19:29:39 kind-worker2 kubelet[297]: I0420 19:29:39.101528     297 reconciler.go:384] "Volume detached for volume \"kube-api-access-vgtph\" (UniqueName: \"kubernetes.io/projected/c313c7c0-1f15-4544-9b19-72190cfea5cf-kube-api-access-vgtph\") on node \"kind-worker2\" DevicePath \"\""
Apr 20 19:29:39 kind-worker2 kubelet[297]: I0420 19:29:39.622263     297 scope.go:110] "RemoveContainer" containerID="e5e98499d8ac849546decc0a6df1980ff7b53e7f56e803cb53576da28f549090"
Apr 20 19:29:40 kind-worker2 kubelet[297]: I0420 19:29:40.818980     297 kubelet_volumes.go:160] "Cleaned up orphaned pod volumes dir" podUID=c313c7c0-1f15-4544-9b19-72190cfea5cf path="/var/lib/kubelet/pods/c313c7c0-1f15-4544-9b19-72190cfea5cf/volumes"
Apr 20 19:33:28 kind-worker2 kubelet[297]: I0420 19:33:28.008361     297 topology_manager.go:200] "Topology Admit Handler"
Apr 20 19:33:28 kind-worker2 kubelet[297]: E0420 19:33:28.008485     297 cpu_manager.go:394] "RemoveStaleState: removing container" podUID="c313c7c0-1f15-4544-9b19-72190cfea5cf" containerName="php-apache"
Apr 20 19:33:28 kind-worker2 kubelet[297]: I0420 19:33:28.008532     297 memory_manager.go:345] "RemoveStaleState removing state" podUID="c313c7c0-1f15-4544-9b19-72190cfea5cf" containerName="php-apache"
Apr 20 19:33:28 kind-worker2 kubelet[297]: I0420 19:33:28.089687     297 topology_manager.go:200] "Topology Admit Handler"
Apr 20 19:33:28 kind-worker2 kubelet[297]: I0420 19:33:28.106639     297 reconciler.go:342] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-dp4fw\" (UniqueName: \"kubernetes.io/projected/b5c229ee-bce6-4f07-af63-12e138186bea-kube-api-access-dp4fw\") pod \"php-apache-698db99f59-rtj82\" (UID: \"b5c229ee-bce6-4f07-af63-12e138186bea\") " pod="default/php-apache-698db99f59-rtj82"
Apr 20 19:33:28 kind-worker2 kubelet[297]: I0420 19:33:28.208409     297 reconciler.go:342] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-k8v6k\" (UniqueName: \"kubernetes.io/projected/b5ba7922-e5eb-48c2-a132-5e0b2c6509b5-kube-api-access-k8v6k\") pod \"php-apache-698db99f59-n5jbz\" (UID: \"b5ba7922-e5eb-48c2-a132-5e0b2c6509b5\") " pod="default/php-apache-698db99f59-n5jbz"
Apr 20 19:34:04 kind-worker2 kubelet[297]: I0420 19:34:04.792875     297 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"kube-api-access-dp4fw\" (UniqueName: \"kubernetes.io/projected/b5c229ee-bce6-4f07-af63-12e138186bea-kube-api-access-dp4fw\") pod \"b5c229ee-bce6-4f07-af63-12e138186bea\" (UID: \"b5c229ee-bce6-4f07-af63-12e138186bea\") "
Apr 20 19:34:04 kind-worker2 kubelet[297]: I0420 19:34:04.815791     297 operation_generator.go:863] UnmountVolume.TearDown succeeded for volume "kubernetes.io/projected/b5c229ee-bce6-4f07-af63-12e138186bea-kube-api-access-dp4fw" (OuterVolumeSpecName: "kube-api-access-dp4fw") pod "b5c229ee-bce6-4f07-af63-12e138186bea" (UID: "b5c229ee-bce6-4f07-af63-12e138186bea"). InnerVolumeSpecName "kube-api-access-dp4fw". PluginName "kubernetes.io/projected", VolumeGidValue ""
Apr 20 19:34:04 kind-worker2 kubelet[297]: I0420 19:34:04.893626     297 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"kube-api-access-k8v6k\" (UniqueName: \"kubernetes.io/projected/b5ba7922-e5eb-48c2-a132-5e0b2c6509b5-kube-api-access-k8v6k\") pod \"b5ba7922-e5eb-48c2-a132-5e0b2c6509b5\" (UID: \"b5ba7922-e5eb-48c2-a132-5e0b2c6509b5\") "
Apr 20 19:34:04 kind-worker2 kubelet[297]: I0420 19:34:04.893817     297 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"kube-api-access-qqxf6\" (UniqueName: \"kubernetes.io/projected/7e03310c-5f98-40b7-afa4-6d90b090b931-kube-api-access-qqxf6\") pod \"7e03310c-5f98-40b7-afa4-6d90b090b931\" (UID: \"7e03310c-5f98-40b7-afa4-6d90b090b931\") "
Apr 20 19:34:04 kind-worker2 kubelet[297]: I0420 19:34:04.894012     297 reconciler.go:384] "Volume detached for volume \"kube-api-access-dp4fw\" (UniqueName: \"kubernetes.io/projected/b5c229ee-bce6-4f07-af63-12e138186bea-kube-api-access-dp4fw\") on node \"kind-worker2\" DevicePath \"\""
Apr 20 19:34:04 kind-worker2 kubelet[297]: I0420 19:34:04.936572     297 operation_generator.go:863] UnmountVolume.TearDown succeeded for volume "kubernetes.io/projected/b5ba7922-e5eb-48c2-a132-5e0b2c6509b5-kube-api-access-k8v6k" (OuterVolumeSpecName: "kube-api-access-k8v6k") pod "b5ba7922-e5eb-48c2-a132-5e0b2c6509b5" (UID: "b5ba7922-e5eb-48c2-a132-5e0b2c6509b5"). InnerVolumeSpecName "kube-api-access-k8v6k". PluginName "kubernetes.io/projected", VolumeGidValue ""
Apr 20 19:34:04 kind-worker2 kubelet[297]: I0420 19:34:04.937316     297 operation_generator.go:863] UnmountVolume.TearDown succeeded for volume "kubernetes.io/projected/7e03310c-5f98-40b7-afa4-6d90b090b931-kube-api-access-qqxf6" (OuterVolumeSpecName: "kube-api-access-qqxf6") pod "7e03310c-5f98-40b7-afa4-6d90b090b931" (UID: "7e03310c-5f98-40b7-afa4-6d90b090b931"). InnerVolumeSpecName "kube-api-access-qqxf6". PluginName "kubernetes.io/projected", VolumeGidValue ""
Apr 20 19:34:04 kind-worker2 kubelet[297]: I0420 19:34:04.994937     297 reconciler.go:384] "Volume detached for volume \"kube-api-access-k8v6k\" (UniqueName: \"kubernetes.io/projected/b5ba7922-e5eb-48c2-a132-5e0b2c6509b5-kube-api-access-k8v6k\") on node \"kind-worker2\" DevicePath \"\""
Apr 20 19:34:04 kind-worker2 kubelet[297]: I0420 19:34:04.995069     297 reconciler.go:384] "Volume detached for volume \"kube-api-access-qqxf6\" (UniqueName: \"kubernetes.io/projected/7e03310c-5f98-40b7-afa4-6d90b090b931-kube-api-access-qqxf6\") on node \"kind-worker2\" DevicePath \"\""
Apr 20 19:34:05 kind-worker2 kubelet[297]: I0420 19:34:05.521513     297 scope.go:110] "RemoveContainer" containerID="33e2c5b20466021daf336f2a2d3820288bd02d69160590bd6449d7fb4380c039"
Apr 20 19:34:05 kind-worker2 kubelet[297]: I0420 19:34:05.668726     297 scope.go:110] "RemoveContainer" containerID="539e8a62f5b9cd5c7be8af2e7179381691995174d001c3b5ebe32f03263c5d65"
Apr 20 19:34:05 kind-worker2 kubelet[297]: I0420 19:34:05.809449     297 scope.go:110] "RemoveContainer" containerID="e17404ded6aee72d36a22022295ab49b3d41a26ca29bbc359c4003071e72ce14"
Apr 20 19:34:06 kind-worker2 kubelet[297]: I0420 19:34:06.814089     297 kubelet_volumes.go:160] "Cleaned up orphaned pod volumes dir" podUID=7e03310c-5f98-40b7-afa4-6d90b090b931 path="/var/lib/kubelet/pods/7e03310c-5f98-40b7-afa4-6d90b090b931/volumes"
Apr 20 19:34:06 kind-worker2 kubelet[297]: I0420 19:34:06.815199     297 kubelet_volumes.go:160] "Cleaned up orphaned pod volumes dir" podUID=b5ba7922-e5eb-48c2-a132-5e0b2c6509b5 path="/var/lib/kubelet/pods/b5ba7922-e5eb-48c2-a132-5e0b2c6509b5/volumes"
Apr 20 19:34:06 kind-worker2 kubelet[297]: I0420 19:34:06.816240     297 kubelet_volumes.go:160] "Cleaned up orphaned pod volumes dir" podUID=b5c229ee-bce6-4f07-af63-12e138186bea path="/var/lib/kubelet/pods/b5c229ee-bce6-4f07-af63-12e138186bea/volumes"
Apr 21 05:40:31 kind-worker2 kubelet[297]: I0421 05:40:31.825422     297 topology_manager.go:200] "Topology Admit Handler"
Apr 21 05:40:31 kind-worker2 kubelet[297]: E0421 05:40:31.827751     297 cpu_manager.go:394] "RemoveStaleState: removing container" podUID="7e03310c-5f98-40b7-afa4-6d90b090b931" containerName="php-apache"
Apr 21 05:40:31 kind-worker2 kubelet[297]: E0421 05:40:31.827992     297 cpu_manager.go:394] "RemoveStaleState: removing container" podUID="b5c229ee-bce6-4f07-af63-12e138186bea" containerName="php-apache"
Apr 21 05:40:31 kind-worker2 kubelet[297]: E0421 05:40:31.828169     297 cpu_manager.go:394] "RemoveStaleState: removing container" podUID="b5ba7922-e5eb-48c2-a132-5e0b2c6509b5" containerName="php-apache"
Apr 21 05:40:31 kind-worker2 kubelet[297]: I0421 05:40:31.828469     297 memory_manager.go:345] "RemoveStaleState removing state" podUID="7e03310c-5f98-40b7-afa4-6d90b090b931" containerName="php-apache"
Apr 21 05:40:31 kind-worker2 kubelet[297]: I0421 05:40:31.828648     297 memory_manager.go:345] "RemoveStaleState removing state" podUID="b5c229ee-bce6-4f07-af63-12e138186bea" containerName="php-apache"
Apr 21 05:40:31 kind-worker2 kubelet[297]: I0421 05:40:31.828817     297 memory_manager.go:345] "RemoveStaleState removing state" podUID="b5ba7922-e5eb-48c2-a132-5e0b2c6509b5" containerName="php-apache"
Apr 21 05:40:31 kind-worker2 kubelet[297]: I0421 05:40:31.963572     297 reconciler.go:342] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-g4vs4\" (UniqueName: \"kubernetes.io/projected/7d23e8c7-dd9f-4ead-80d1-2e43818a9d5e-kube-api-access-g4vs4\") pod \"php-apache-698db99f59-4mqtv\" (UID: \"7d23e8c7-dd9f-4ead-80d1-2e43818a9d5e\") " pod="default/php-apache-698db99f59-4mqtv"
Apr 21 05:42:37 kind-worker2 kubelet[297]: I0421 05:42:37.576079     297 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"kube-api-access-g4vs4\" (UniqueName: \"kubernetes.io/projected/7d23e8c7-dd9f-4ead-80d1-2e43818a9d5e-kube-api-access-g4vs4\") pod \"7d23e8c7-dd9f-4ead-80d1-2e43818a9d5e\" (UID: \"7d23e8c7-dd9f-4ead-80d1-2e43818a9d5e\") "
Apr 21 05:42:37 kind-worker2 kubelet[297]: I0421 05:42:37.604125     297 operation_generator.go:863] UnmountVolume.TearDown succeeded for volume "kubernetes.io/projected/7d23e8c7-dd9f-4ead-80d1-2e43818a9d5e-kube-api-access-g4vs4" (OuterVolumeSpecName: "kube-api-access-g4vs4") pod "7d23e8c7-dd9f-4ead-80d1-2e43818a9d5e" (UID: "7d23e8c7-dd9f-4ead-80d1-2e43818a9d5e"). InnerVolumeSpecName "kube-api-access-g4vs4". PluginName "kubernetes.io/projected", VolumeGidValue ""
Apr 21 05:42:37 kind-worker2 kubelet[297]: I0421 05:42:37.677344     297 reconciler.go:384] "Volume detached for volume \"kube-api-access-g4vs4\" (UniqueName: \"kubernetes.io/projected/7d23e8c7-dd9f-4ead-80d1-2e43818a9d5e-kube-api-access-g4vs4\") on node \"kind-worker2\" DevicePath \"\""
Apr 21 05:42:38 kind-worker2 kubelet[297]: I0421 05:42:38.151253     297 scope.go:110] "RemoveContainer" containerID="095716fccfb8b8ff9b26ba9d344e3157bbabe01f41262f7ae08bd73ed6755b14"
Apr 21 05:42:38 kind-worker2 kubelet[297]: E0421 05:42:38.811716     297 remote_runtime.go:484] "StopContainer from runtime service failed" err="rpc error: code = NotFound desc = an error occurred when try to find container \"095716fccfb8b8ff9b26ba9d344e3157bbabe01f41262f7ae08bd73ed6755b14\": not found" containerID="095716fccfb8b8ff9b26ba9d344e3157bbabe01f41262f7ae08bd73ed6755b14"
Apr 21 05:42:38 kind-worker2 kubelet[297]: I0421 05:42:38.811871     297 kubelet_volumes.go:160] "Cleaned up orphaned pod volumes dir" podUID=7d23e8c7-dd9f-4ead-80d1-2e43818a9d5e path="/var/lib/kubelet/pods/7d23e8c7-dd9f-4ead-80d1-2e43818a9d5e/volumes"
Apr 21 18:09:04 kind-worker2 kubelet[297]: I0421 18:09:04.870613     297 topology_manager.go:200] "Topology Admit Handler"
Apr 21 18:09:04 kind-worker2 kubelet[297]: E0421 18:09:04.870776     297 cpu_manager.go:394] "RemoveStaleState: removing container" podUID="7d23e8c7-dd9f-4ead-80d1-2e43818a9d5e" containerName="php-apache"
Apr 21 18:09:04 kind-worker2 kubelet[297]: I0421 18:09:04.870855     297 memory_manager.go:345] "RemoveStaleState removing state" podUID="7d23e8c7-dd9f-4ead-80d1-2e43818a9d5e" containerName="php-apache"
Apr 21 18:09:04 kind-worker2 kubelet[297]: I0421 18:09:04.956056     297 reconciler.go:342] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-jklq7\" (UniqueName: \"kubernetes.io/projected/47147844-841d-4550-a5cf-7c2faae525af-kube-api-access-jklq7\") pod \"php-apache-7654df5976-pdjv4\" (UID: \"47147844-841d-4550-a5cf-7c2faae525af\") " pod="default/php-apache-7654df5976-pdjv4"
Apr 21 18:10:36 kind-worker2 kubelet[297]: I0421 18:10:36.087955     297 topology_manager.go:200] "Topology Admit Handler"
Apr 21 18:10:36 kind-worker2 kubelet[297]: I0421 18:10:36.109815     297 reconciler.go:342] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-ctxn5\" (UniqueName: \"kubernetes.io/projected/87222c2f-702f-4a4d-a68c-3ac55730da4e-kube-api-access-ctxn5\") pod \"php-apache-7654df5976-z5p6c\" (UID: \"87222c2f-702f-4a4d-a68c-3ac55730da4e\") " pod="default/php-apache-7654df5976-z5p6c"
Apr 21 18:13:16 kind-worker2 kubelet[297]: I0421 18:13:16.362662     297 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"kube-api-access-ctxn5\" (UniqueName: \"kubernetes.io/projected/87222c2f-702f-4a4d-a68c-3ac55730da4e-kube-api-access-ctxn5\") pod \"87222c2f-702f-4a4d-a68c-3ac55730da4e\" (UID: \"87222c2f-702f-4a4d-a68c-3ac55730da4e\") "
Apr 21 18:13:16 kind-worker2 kubelet[297]: I0421 18:13:16.388651     297 operation_generator.go:863] UnmountVolume.TearDown succeeded for volume "kubernetes.io/projected/87222c2f-702f-4a4d-a68c-3ac55730da4e-kube-api-access-ctxn5" (OuterVolumeSpecName: "kube-api-access-ctxn5") pod "87222c2f-702f-4a4d-a68c-3ac55730da4e" (UID: "87222c2f-702f-4a4d-a68c-3ac55730da4e"). InnerVolumeSpecName "kube-api-access-ctxn5". PluginName "kubernetes.io/projected", VolumeGidValue ""
Apr 21 18:13:16 kind-worker2 kubelet[297]: I0421 18:13:16.463984     297 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"kube-api-access-jklq7\" (UniqueName: \"kubernetes.io/projected/47147844-841d-4550-a5cf-7c2faae525af-kube-api-access-jklq7\") pod \"47147844-841d-4550-a5cf-7c2faae525af\" (UID: \"47147844-841d-4550-a5cf-7c2faae525af\") "
Apr 21 18:13:16 kind-worker2 kubelet[297]: I0421 18:13:16.464400     297 reconciler.go:384] "Volume detached for volume \"kube-api-access-ctxn5\" (UniqueName: \"kubernetes.io/projected/87222c2f-702f-4a4d-a68c-3ac55730da4e-kube-api-access-ctxn5\") on node \"kind-worker2\" DevicePath \"\""
Apr 21 18:13:16 kind-worker2 kubelet[297]: I0421 18:13:16.500560     297 operation_generator.go:863] UnmountVolume.TearDown succeeded for volume "kubernetes.io/projected/47147844-841d-4550-a5cf-7c2faae525af-kube-api-access-jklq7" (OuterVolumeSpecName: "kube-api-access-jklq7") pod "47147844-841d-4550-a5cf-7c2faae525af" (UID: "47147844-841d-4550-a5cf-7c2faae525af"). InnerVolumeSpecName "kube-api-access-jklq7". PluginName "kubernetes.io/projected", VolumeGidValue ""
Apr 21 18:13:16 kind-worker2 kubelet[297]: I0421 18:13:16.565894     297 reconciler.go:384] "Volume detached for volume \"kube-api-access-jklq7\" (UniqueName: \"kubernetes.io/projected/47147844-841d-4550-a5cf-7c2faae525af-kube-api-access-jklq7\") on node \"kind-worker2\" DevicePath \"\""
Apr 21 18:13:16 kind-worker2 kubelet[297]: I0421 18:13:16.627382     297 scope.go:110] "RemoveContainer" containerID="c0d91d463cc28edce25dbb52eda0713b1aecddf5e293bf06e8dee26baccbad61"
Apr 21 18:13:16 kind-worker2 kubelet[297]: I0421 18:13:16.746182     297 scope.go:110] "RemoveContainer" containerID="c0d91d463cc28edce25dbb52eda0713b1aecddf5e293bf06e8dee26baccbad61"
Apr 21 18:13:16 kind-worker2 kubelet[297]: E0421 18:13:16.747288     297 remote_runtime.go:604] "ContainerStatus from runtime service failed" err="rpc error: code = NotFound desc = an error occurred when try to find container \"c0d91d463cc28edce25dbb52eda0713b1aecddf5e293bf06e8dee26baccbad61\": not found" containerID="c0d91d463cc28edce25dbb52eda0713b1aecddf5e293bf06e8dee26baccbad61"
Apr 21 18:13:16 kind-worker2 kubelet[297]: I0421 18:13:16.747372     297 pod_container_deletor.go:52] "DeleteContainer returned error" containerID={Type:containerd ID:c0d91d463cc28edce25dbb52eda0713b1aecddf5e293bf06e8dee26baccbad61} err="failed to get container status \"c0d91d463cc28edce25dbb52eda0713b1aecddf5e293bf06e8dee26baccbad61\": rpc error: code = NotFound desc = an error occurred when try to find container \"c0d91d463cc28edce25dbb52eda0713b1aecddf5e293bf06e8dee26baccbad61\": not found"
Apr 21 18:13:16 kind-worker2 kubelet[297]: I0421 18:13:16.747405     297 scope.go:110] "RemoveContainer" containerID="aa0ec62e53cf9ed370dcf33679c4feb4e522f28f3d34ed43283d2e8372287004"
Apr 21 18:13:16 kind-worker2 kubelet[297]: I0421 18:13:16.904893     297 scope.go:110] "RemoveContainer" containerID="aa0ec62e53cf9ed370dcf33679c4feb4e522f28f3d34ed43283d2e8372287004"
Apr 21 18:13:16 kind-worker2 kubelet[297]: E0421 18:13:16.908733     297 remote_runtime.go:604] "ContainerStatus from runtime service failed" err="rpc error: code = NotFound desc = an error occurred when try to find container \"aa0ec62e53cf9ed370dcf33679c4feb4e522f28f3d34ed43283d2e8372287004\": not found" containerID="aa0ec62e53cf9ed370dcf33679c4feb4e522f28f3d34ed43283d2e8372287004"
Apr 21 18:13:16 kind-worker2 kubelet[297]: I0421 18:13:16.908853     297 pod_container_deletor.go:52] "DeleteContainer returned error" containerID={Type:containerd ID:aa0ec62e53cf9ed370dcf33679c4feb4e522f28f3d34ed43283d2e8372287004} err="failed to get container status \"aa0ec62e53cf9ed370dcf33679c4feb4e522f28f3d34ed43283d2e8372287004\": rpc error: code = NotFound desc = an error occurred when try to find container \"aa0ec62e53cf9ed370dcf33679c4feb4e522f28f3d34ed43283d2e8372287004\": not found"
Apr 21 18:13:18 kind-worker2 kubelet[297]: I0421 18:13:18.818175     297 kubelet_volumes.go:160] "Cleaned up orphaned pod volumes dir" podUID=47147844-841d-4550-a5cf-7c2faae525af path="/var/lib/kubelet/pods/47147844-841d-4550-a5cf-7c2faae525af/volumes"
Apr 21 18:13:18 kind-worker2 kubelet[297]: I0421 18:13:18.820168     297 kubelet_volumes.go:160] "Cleaned up orphaned pod volumes dir" podUID=87222c2f-702f-4a4d-a68c-3ac55730da4e path="/var/lib/kubelet/pods/87222c2f-702f-4a4d-a68c-3ac55730da4e/volumes"
Apr 21 19:55:48 kind-worker2 kubelet[297]: I0421 19:55:48.742032     297 topology_manager.go:200] "Topology Admit Handler"
Apr 21 19:55:48 kind-worker2 kubelet[297]: E0421 19:55:48.742459     297 cpu_manager.go:394] "RemoveStaleState: removing container" podUID="47147844-841d-4550-a5cf-7c2faae525af" containerName="php-apache"
Apr 21 19:55:48 kind-worker2 kubelet[297]: E0421 19:55:48.742525     297 cpu_manager.go:394] "RemoveStaleState: removing container" podUID="87222c2f-702f-4a4d-a68c-3ac55730da4e" containerName="php-apache"
Apr 21 19:55:48 kind-worker2 kubelet[297]: I0421 19:55:48.742632     297 memory_manager.go:345] "RemoveStaleState removing state" podUID="47147844-841d-4550-a5cf-7c2faae525af" containerName="php-apache"
Apr 21 19:55:48 kind-worker2 kubelet[297]: I0421 19:55:48.742660     297 memory_manager.go:345] "RemoveStaleState removing state" podUID="87222c2f-702f-4a4d-a68c-3ac55730da4e" containerName="php-apache"
Apr 21 19:55:48 kind-worker2 kubelet[297]: I0421 19:55:48.826727     297 reconciler.go:342] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-jr6tb\" (UniqueName: \"kubernetes.io/projected/96ea60ec-f29c-4421-855e-a958b476b836-kube-api-access-jr6tb\") pod \"php-apache-698db99f59-x7zxn\" (UID: \"96ea60ec-f29c-4421-855e-a958b476b836\") " pod="default/php-apache-698db99f59-x7zxn"
Apr 21 20:34:15 kind-worker2 kubelet[297]: I0421 20:34:15.601795     297 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"kube-api-access-jr6tb\" (UniqueName: \"kubernetes.io/projected/96ea60ec-f29c-4421-855e-a958b476b836-kube-api-access-jr6tb\") pod \"96ea60ec-f29c-4421-855e-a958b476b836\" (UID: \"96ea60ec-f29c-4421-855e-a958b476b836\") "
Apr 21 20:34:15 kind-worker2 kubelet[297]: I0421 20:34:15.636408     297 operation_generator.go:863] UnmountVolume.TearDown succeeded for volume "kubernetes.io/projected/96ea60ec-f29c-4421-855e-a958b476b836-kube-api-access-jr6tb" (OuterVolumeSpecName: "kube-api-access-jr6tb") pod "96ea60ec-f29c-4421-855e-a958b476b836" (UID: "96ea60ec-f29c-4421-855e-a958b476b836"). InnerVolumeSpecName "kube-api-access-jr6tb". PluginName "kubernetes.io/projected", VolumeGidValue ""
Apr 21 20:34:15 kind-worker2 kubelet[297]: I0421 20:34:15.702752     297 reconciler.go:384] "Volume detached for volume \"kube-api-access-jr6tb\" (UniqueName: \"kubernetes.io/projected/96ea60ec-f29c-4421-855e-a958b476b836-kube-api-access-jr6tb\") on node \"kind-worker2\" DevicePath \"\""
Apr 21 20:34:15 kind-worker2 kubelet[297]: I0421 20:34:15.870948     297 scope.go:110] "RemoveContainer" containerID="5626ef49997dd4c53f9bde7cc1fa36959450f45f292a0eefa14d378f0c6047b1"
Apr 21 20:34:15 kind-worker2 kubelet[297]: I0421 20:34:15.982084     297 scope.go:110] "RemoveContainer" containerID="5626ef49997dd4c53f9bde7cc1fa36959450f45f292a0eefa14d378f0c6047b1"
Apr 21 20:34:15 kind-worker2 kubelet[297]: E0421 20:34:15.983271     297 remote_runtime.go:604] "ContainerStatus from runtime service failed" err="rpc error: code = NotFound desc = an error occurred when try to find container \"5626ef49997dd4c53f9bde7cc1fa36959450f45f292a0eefa14d378f0c6047b1\": not found" containerID="5626ef49997dd4c53f9bde7cc1fa36959450f45f292a0eefa14d378f0c6047b1"
Apr 21 20:34:15 kind-worker2 kubelet[297]: I0421 20:34:15.983431     297 pod_container_deletor.go:52] "DeleteContainer returned error" containerID={Type:containerd ID:5626ef49997dd4c53f9bde7cc1fa36959450f45f292a0eefa14d378f0c6047b1} err="failed to get container status \"5626ef49997dd4c53f9bde7cc1fa36959450f45f292a0eefa14d378f0c6047b1\": rpc error: code = NotFound desc = an error occurred when try to find container \"5626ef49997dd4c53f9bde7cc1fa36959450f45f292a0eefa14d378f0c6047b1\": not found"
Apr 21 20:34:16 kind-worker2 kubelet[297]: I0421 20:34:16.817982     297 kubelet_volumes.go:160] "Cleaned up orphaned pod volumes dir" podUID=96ea60ec-f29c-4421-855e-a958b476b836 path="/var/lib/kubelet/pods/96ea60ec-f29c-4421-855e-a958b476b836/volumes"
Apr 21 20:43:00 kind-worker2 kubelet[297]: I0421 20:43:00.822585     297 topology_manager.go:200] "Topology Admit Handler"
Apr 21 20:43:00 kind-worker2 kubelet[297]: E0421 20:43:00.822836     297 cpu_manager.go:394] "RemoveStaleState: removing container" podUID="96ea60ec-f29c-4421-855e-a958b476b836" containerName="php-apache"
Apr 21 20:43:00 kind-worker2 kubelet[297]: I0421 20:43:00.822944     297 memory_manager.go:345] "RemoveStaleState removing state" podUID="96ea60ec-f29c-4421-855e-a958b476b836" containerName="php-apache"
Apr 21 20:43:00 kind-worker2 kubelet[297]: I0421 20:43:00.875297     297 reconciler.go:342] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-8vswq\" (UniqueName: \"kubernetes.io/projected/0c6ae8eb-e1cb-40a7-9efd-a5045f345ed2-kube-api-access-8vswq\") pod \"php-apache-7654df5976-lctzd\" (UID: \"0c6ae8eb-e1cb-40a7-9efd-a5045f345ed2\") " pod="default/php-apache-7654df5976-lctzd"
Apr 21 20:44:28 kind-worker2 kubelet[297]: I0421 20:44:28.383343     297 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"kube-api-access-8vswq\" (UniqueName: \"kubernetes.io/projected/0c6ae8eb-e1cb-40a7-9efd-a5045f345ed2-kube-api-access-8vswq\") pod \"0c6ae8eb-e1cb-40a7-9efd-a5045f345ed2\" (UID: \"0c6ae8eb-e1cb-40a7-9efd-a5045f345ed2\") "
Apr 21 20:44:28 kind-worker2 kubelet[297]: I0421 20:44:28.414284     297 operation_generator.go:863] UnmountVolume.TearDown succeeded for volume "kubernetes.io/projected/0c6ae8eb-e1cb-40a7-9efd-a5045f345ed2-kube-api-access-8vswq" (OuterVolumeSpecName: "kube-api-access-8vswq") pod "0c6ae8eb-e1cb-40a7-9efd-a5045f345ed2" (UID: "0c6ae8eb-e1cb-40a7-9efd-a5045f345ed2"). InnerVolumeSpecName "kube-api-access-8vswq". PluginName "kubernetes.io/projected", VolumeGidValue ""
Apr 21 20:44:28 kind-worker2 kubelet[297]: I0421 20:44:28.483988     297 reconciler.go:384] "Volume detached for volume \"kube-api-access-8vswq\" (UniqueName: \"kubernetes.io/projected/0c6ae8eb-e1cb-40a7-9efd-a5045f345ed2-kube-api-access-8vswq\") on node \"kind-worker2\" DevicePath \"\""
Apr 21 20:44:28 kind-worker2 kubelet[297]: I0421 20:44:28.895993     297 scope.go:110] "RemoveContainer" containerID="ac2be79f8fab995ac0a3ee14df695ea2485016cde43959894a67ed1c2937cd4d"
Apr 21 20:44:29 kind-worker2 kubelet[297]: I0421 20:44:29.389936     297 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"kube-api-access-bzlmc\" (UniqueName: \"kubernetes.io/projected/21f18b4d-6bae-4640-81f4-6ef08f7a00b0-kube-api-access-bzlmc\") pod \"21f18b4d-6bae-4640-81f4-6ef08f7a00b0\" (UID: \"21f18b4d-6bae-4640-81f4-6ef08f7a00b0\") "
Apr 21 20:44:29 kind-worker2 kubelet[297]: I0421 20:44:29.390074     297 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"tmp-dir\" (UniqueName: \"kubernetes.io/empty-dir/21f18b4d-6bae-4640-81f4-6ef08f7a00b0-tmp-dir\") pod \"21f18b4d-6bae-4640-81f4-6ef08f7a00b0\" (UID: \"21f18b4d-6bae-4640-81f4-6ef08f7a00b0\") "
Apr 21 20:44:29 kind-worker2 kubelet[297]: W0421 20:44:29.390643     297 empty_dir.go:519] Warning: Failed to clear quota on /var/lib/kubelet/pods/21f18b4d-6bae-4640-81f4-6ef08f7a00b0/volumes/kubernetes.io~empty-dir/tmp-dir: clearQuota called, but quotas disabled
Apr 21 20:44:29 kind-worker2 kubelet[297]: I0421 20:44:29.390939     297 operation_generator.go:863] UnmountVolume.TearDown succeeded for volume "kubernetes.io/empty-dir/21f18b4d-6bae-4640-81f4-6ef08f7a00b0-tmp-dir" (OuterVolumeSpecName: "tmp-dir") pod "21f18b4d-6bae-4640-81f4-6ef08f7a00b0" (UID: "21f18b4d-6bae-4640-81f4-6ef08f7a00b0"). InnerVolumeSpecName "tmp-dir". PluginName "kubernetes.io/empty-dir", VolumeGidValue ""
Apr 21 20:44:29 kind-worker2 kubelet[297]: I0421 20:44:29.408754     297 operation_generator.go:863] UnmountVolume.TearDown succeeded for volume "kubernetes.io/projected/21f18b4d-6bae-4640-81f4-6ef08f7a00b0-kube-api-access-bzlmc" (OuterVolumeSpecName: "kube-api-access-bzlmc") pod "21f18b4d-6bae-4640-81f4-6ef08f7a00b0" (UID: "21f18b4d-6bae-4640-81f4-6ef08f7a00b0"). InnerVolumeSpecName "kube-api-access-bzlmc". PluginName "kubernetes.io/projected", VolumeGidValue ""
Apr 21 20:44:29 kind-worker2 kubelet[297]: I0421 20:44:29.490673     297 reconciler.go:384] "Volume detached for volume \"kube-api-access-bzlmc\" (UniqueName: \"kubernetes.io/projected/21f18b4d-6bae-4640-81f4-6ef08f7a00b0-kube-api-access-bzlmc\") on node \"kind-worker2\" DevicePath \"\""
Apr 21 20:44:29 kind-worker2 kubelet[297]: I0421 20:44:29.490755     297 reconciler.go:384] "Volume detached for volume \"tmp-dir\" (UniqueName: \"kubernetes.io/empty-dir/21f18b4d-6bae-4640-81f4-6ef08f7a00b0-tmp-dir\") on node \"kind-worker2\" DevicePath \"\""
Apr 21 20:44:29 kind-worker2 kubelet[297]: I0421 20:44:29.909792     297 scope.go:110] "RemoveContainer" containerID="d882ed90843406b30b2377a3c2ec2134f1531d648b811c579b416f397a63ec7a"
Apr 21 20:44:30 kind-worker2 kubelet[297]: I0421 20:44:30.816606     297 kubelet_volumes.go:160] "Cleaned up orphaned pod volumes dir" podUID=0c6ae8eb-e1cb-40a7-9efd-a5045f345ed2 path="/var/lib/kubelet/pods/0c6ae8eb-e1cb-40a7-9efd-a5045f345ed2/volumes"
Apr 21 20:44:30 kind-worker2 kubelet[297]: I0421 20:44:30.818407     297 kubelet_volumes.go:160] "Cleaned up orphaned pod volumes dir" podUID=21f18b4d-6bae-4640-81f4-6ef08f7a00b0 path="/var/lib/kubelet/pods/21f18b4d-6bae-4640-81f4-6ef08f7a00b0/volumes"
Apr 21 20:44:59 kind-worker2 kubelet[297]: I0421 20:44:59.949692     297 topology_manager.go:200] "Topology Admit Handler"
Apr 21 20:44:59 kind-worker2 kubelet[297]: E0421 20:44:59.949793     297 cpu_manager.go:394] "RemoveStaleState: removing container" podUID="0c6ae8eb-e1cb-40a7-9efd-a5045f345ed2" containerName="php-apache"
Apr 21 20:44:59 kind-worker2 kubelet[297]: E0421 20:44:59.949823     297 cpu_manager.go:394] "RemoveStaleState: removing container" podUID="21f18b4d-6bae-4640-81f4-6ef08f7a00b0" containerName="metrics-server"
Apr 21 20:44:59 kind-worker2 kubelet[297]: I0421 20:44:59.949860     297 memory_manager.go:345] "RemoveStaleState removing state" podUID="0c6ae8eb-e1cb-40a7-9efd-a5045f345ed2" containerName="php-apache"
Apr 21 20:44:59 kind-worker2 kubelet[297]: I0421 20:44:59.949891     297 memory_manager.go:345] "RemoveStaleState removing state" podUID="21f18b4d-6bae-4640-81f4-6ef08f7a00b0" containerName="metrics-server"
Apr 21 20:45:00 kind-worker2 kubelet[297]: I0421 20:45:00.095223     297 reconciler.go:342] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-fzgf7\" (UniqueName: \"kubernetes.io/projected/47af790c-acdb-44d7-b277-591a91cc490b-kube-api-access-fzgf7\") pod \"php-apache-7654df5976-l7qrh\" (UID: \"47af790c-acdb-44d7-b277-591a91cc490b\") " pod="default/php-apache-7654df5976-l7qrh"
Apr 21 20:45:00 kind-worker2 kubelet[297]: I0421 20:45:00.852728     297 topology_manager.go:200] "Topology Admit Handler"
Apr 21 20:45:01 kind-worker2 kubelet[297]: I0421 20:45:01.001690     297 reconciler.go:342] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-lb8k9\" (UniqueName: \"kubernetes.io/projected/3f48224f-c7b6-4a38-9b09-8bb0e96fed00-kube-api-access-lb8k9\") pod \"php-apache-7654df5976-4q2xm\" (UID: \"3f48224f-c7b6-4a38-9b09-8bb0e96fed00\") " pod="default/php-apache-7654df5976-4q2xm"
Apr 21 22:28:40 kind-worker2 kubelet[297]: I0421 22:28:40.605667     297 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"kube-api-access-fzgf7\" (UniqueName: \"kubernetes.io/projected/47af790c-acdb-44d7-b277-591a91cc490b-kube-api-access-fzgf7\") pod \"47af790c-acdb-44d7-b277-591a91cc490b\" (UID: \"47af790c-acdb-44d7-b277-591a91cc490b\") "
Apr 21 22:28:40 kind-worker2 kubelet[297]: I0421 22:28:40.606855     297 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"kube-api-access-lb8k9\" (UniqueName: \"kubernetes.io/projected/3f48224f-c7b6-4a38-9b09-8bb0e96fed00-kube-api-access-lb8k9\") pod \"3f48224f-c7b6-4a38-9b09-8bb0e96fed00\" (UID: \"3f48224f-c7b6-4a38-9b09-8bb0e96fed00\") "
Apr 21 22:28:40 kind-worker2 kubelet[297]: I0421 22:28:40.628125     297 operation_generator.go:863] UnmountVolume.TearDown succeeded for volume "kubernetes.io/projected/47af790c-acdb-44d7-b277-591a91cc490b-kube-api-access-fzgf7" (OuterVolumeSpecName: "kube-api-access-fzgf7") pod "47af790c-acdb-44d7-b277-591a91cc490b" (UID: "47af790c-acdb-44d7-b277-591a91cc490b"). InnerVolumeSpecName "kube-api-access-fzgf7". PluginName "kubernetes.io/projected", VolumeGidValue ""
Apr 21 22:28:40 kind-worker2 kubelet[297]: I0421 22:28:40.629030     297 operation_generator.go:863] UnmountVolume.TearDown succeeded for volume "kubernetes.io/projected/3f48224f-c7b6-4a38-9b09-8bb0e96fed00-kube-api-access-lb8k9" (OuterVolumeSpecName: "kube-api-access-lb8k9") pod "3f48224f-c7b6-4a38-9b09-8bb0e96fed00" (UID: "3f48224f-c7b6-4a38-9b09-8bb0e96fed00"). InnerVolumeSpecName "kube-api-access-lb8k9". PluginName "kubernetes.io/projected", VolumeGidValue ""
Apr 21 22:28:40 kind-worker2 kubelet[297]: I0421 22:28:40.707447     297 reconciler.go:384] "Volume detached for volume \"kube-api-access-fzgf7\" (UniqueName: \"kubernetes.io/projected/47af790c-acdb-44d7-b277-591a91cc490b-kube-api-access-fzgf7\") on node \"kind-worker2\" DevicePath \"\""
Apr 21 22:28:40 kind-worker2 kubelet[297]: I0421 22:28:40.707570     297 reconciler.go:384] "Volume detached for volume \"kube-api-access-lb8k9\" (UniqueName: \"kubernetes.io/projected/3f48224f-c7b6-4a38-9b09-8bb0e96fed00-kube-api-access-lb8k9\") on node \"kind-worker2\" DevicePath \"\""
Apr 21 22:28:41 kind-worker2 kubelet[297]: I0421 22:28:41.114160     297 scope.go:110] "RemoveContainer" containerID="be897865dd2d1bba772adf92e1af4d1bec4d8d5c5863f91de6fd2c3f80092e15"
Apr 21 22:28:41 kind-worker2 kubelet[297]: I0421 22:28:41.493159     297 scope.go:110] "RemoveContainer" containerID="16a782603d5a1723fae17cc2b68388cbd98612c3980efe064a736a6bbd9c2aa5"
Apr 21 22:28:42 kind-worker2 kubelet[297]: I0421 22:28:42.816126     297 kubelet_volumes.go:160] "Cleaned up orphaned pod volumes dir" podUID=3f48224f-c7b6-4a38-9b09-8bb0e96fed00 path="/var/lib/kubelet/pods/3f48224f-c7b6-4a38-9b09-8bb0e96fed00/volumes"
Apr 21 22:28:42 kind-worker2 kubelet[297]: I0421 22:28:42.817277     297 kubelet_volumes.go:160] "Cleaned up orphaned pod volumes dir" podUID=47af790c-acdb-44d7-b277-591a91cc490b path="/var/lib/kubelet/pods/47af790c-acdb-44d7-b277-591a91cc490b/volumes"
Apr 22 04:26:17 kind-worker2 kubelet[297]: I0422 04:26:17.974807     297 topology_manager.go:200] "Topology Admit Handler"
Apr 22 04:26:17 kind-worker2 kubelet[297]: E0422 04:26:17.977566     297 cpu_manager.go:394] "RemoveStaleState: removing container" podUID="3f48224f-c7b6-4a38-9b09-8bb0e96fed00" containerName="php-apache"
Apr 22 04:26:17 kind-worker2 kubelet[297]: E0422 04:26:17.977707     297 cpu_manager.go:394] "RemoveStaleState: removing container" podUID="47af790c-acdb-44d7-b277-591a91cc490b" containerName="php-apache"
Apr 22 04:26:17 kind-worker2 kubelet[297]: I0422 04:26:17.977981     297 memory_manager.go:345] "RemoveStaleState removing state" podUID="47af790c-acdb-44d7-b277-591a91cc490b" containerName="php-apache"
Apr 22 04:26:17 kind-worker2 kubelet[297]: I0422 04:26:17.978029     297 memory_manager.go:345] "RemoveStaleState removing state" podUID="3f48224f-c7b6-4a38-9b09-8bb0e96fed00" containerName="php-apache"
Apr 22 04:26:18 kind-worker2 kubelet[297]: I0422 04:26:18.143550     297 reconciler.go:342] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-6gtkb\" (UniqueName: \"kubernetes.io/projected/6c414594-23c3-4c97-a8af-4911e0366722-kube-api-access-6gtkb\") pod \"php-apache-7654df5976-45nnq\" (UID: \"6c414594-23c3-4c97-a8af-4911e0366722\") " pod="default/php-apache-7654df5976-45nnq"
Apr 22 20:17:45 kind-worker2 kubelet[297]: I0422 20:17:45.140908     297 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"kube-api-access-6gtkb\" (UniqueName: \"kubernetes.io/projected/6c414594-23c3-4c97-a8af-4911e0366722-kube-api-access-6gtkb\") pod \"6c414594-23c3-4c97-a8af-4911e0366722\" (UID: \"6c414594-23c3-4c97-a8af-4911e0366722\") "
Apr 22 20:17:45 kind-worker2 kubelet[297]: I0422 20:17:45.164114     297 operation_generator.go:863] UnmountVolume.TearDown succeeded for volume "kubernetes.io/projected/6c414594-23c3-4c97-a8af-4911e0366722-kube-api-access-6gtkb" (OuterVolumeSpecName: "kube-api-access-6gtkb") pod "6c414594-23c3-4c97-a8af-4911e0366722" (UID: "6c414594-23c3-4c97-a8af-4911e0366722"). InnerVolumeSpecName "kube-api-access-6gtkb". PluginName "kubernetes.io/projected", VolumeGidValue ""
Apr 22 20:17:45 kind-worker2 kubelet[297]: I0422 20:17:45.241636     297 reconciler.go:384] "Volume detached for volume \"kube-api-access-6gtkb\" (UniqueName: \"kubernetes.io/projected/6c414594-23c3-4c97-a8af-4911e0366722-kube-api-access-6gtkb\") on node \"kind-worker2\" DevicePath \"\""
Apr 22 20:17:45 kind-worker2 kubelet[297]: I0422 20:17:45.959595     297 scope.go:110] "RemoveContainer" containerID="95af128e73187e0556867e871a652cb11de3e22ecb17a0f5b3dc4ec82188b3b4"
Apr 22 20:17:46 kind-worker2 kubelet[297]: I0422 20:17:46.817250     297 kubelet_volumes.go:160] "Cleaned up orphaned pod volumes dir" podUID=6c414594-23c3-4c97-a8af-4911e0366722 path="/var/lib/kubelet/pods/6c414594-23c3-4c97-a8af-4911e0366722/volumes"
Apr 22 20:31:49 kind-worker2 kubelet[297]: I0422 20:31:49.683961     297 topology_manager.go:200] "Topology Admit Handler"
Apr 22 20:31:49 kind-worker2 kubelet[297]: E0422 20:31:49.684323     297 cpu_manager.go:394] "RemoveStaleState: removing container" podUID="6c414594-23c3-4c97-a8af-4911e0366722" containerName="php-apache"
Apr 22 20:31:49 kind-worker2 kubelet[297]: I0422 20:31:49.684503     297 memory_manager.go:345] "RemoveStaleState removing state" podUID="6c414594-23c3-4c97-a8af-4911e0366722" containerName="php-apache"
Apr 22 20:31:49 kind-worker2 kubelet[297]: I0422 20:31:49.723032     297 reconciler.go:342] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-nqm4h\" (UniqueName: \"kubernetes.io/projected/7c645c21-53ac-4805-8f5b-c35b8376f457-kube-api-access-nqm4h\") pod \"php-apache-698db99f59-5vxqp\" (UID: \"7c645c21-53ac-4805-8f5b-c35b8376f457\") " pod="default/php-apache-698db99f59-5vxqp"
